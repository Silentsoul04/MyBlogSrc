<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>泽民博客</title>
    <description>夏泽民的个人主页，学习笔记。</description>
    <link>https://xiazemin.github.io/MyBlog/</link>
    <atom:link href="https://xiazemin.github.io/MyBlog/feed.xml" rel="self" type="application/rss+xml"/>
    <pubDate>Sat, 18 Nov 2017 18:02:32 +0800</pubDate>
    <lastBuildDate>Sat, 18 Nov 2017 18:02:32 +0800</lastBuildDate>
    <generator>Jekyll v3.6.0.pre.beta1</generator>
    
      <item>
        <title>redis协议</title>
        <description>&lt;!-- more --&gt;
&lt;p&gt;redis命令发送格式：
*&lt;参数数量&gt; CRLF 
$&amp;lt;参数 1 的字节数量&amp;gt; CRLF
&amp;lt;参数 1 的数据&amp;gt; CRLF 
... 
$&lt;参数 N=&quot;&quot; 的字节数量=&quot;&quot;&gt; CRLF&lt;/参数&gt;&lt;/参数数量&gt;&lt;/p&gt;
&lt;参数 N=&quot;&quot; 的数据=&quot;&quot;&gt; CRLF 
其中CRLF表示 rn

举个例子：set name wuzhc

格式化输出：

*3 
$3 
set 
$4 
name 
$5 
wuzhc

说明：

*开头，表示有多少个参数，例如*3表示有3个参数（set, name, wuzhc）
$开头，表示参数的字节长度，例如$3表示set有3个字节，$4表示name有4个字节
每行rn结尾
通信协议为：

*3\r\n$3\r\nset\r\n$4\r\nname\r\n$5\r\nwuzhc\r\n
Redis 回复
状态回复（status reply）的第一个字节是 &quot;+&quot;，例如+OK\r\n
错误回复（error reply）的第一个字节是 &quot;-&quot;，例如-No such key\r\n
整数回复（integer reply）的第一个字节是 &quot;:&quot;，例如:1\r\n
批量回复（bulk reply）的第一个字节是 &quot;$&quot;，例如 $5\r\nwuzhc\r\n
多条批量回复（multi bulk reply）的第一个字节是 &quot;*&quot;，例如*2\r\n$5\r\nwuzhc\r\n$3r\nage\r\n
PHP 实现Redis客户端

&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-php&quot; data-lang=&quot;php&quot;&gt;&lt;span&gt;&lt;/span&gt;&lt;span class=&quot;lineno&quot;&gt;  1 &lt;/span&gt;&lt;span class=&quot;cp&quot;&gt;&amp;lt;?php&lt;/span&gt;
&lt;span class=&quot;lineno&quot;&gt;  2 &lt;/span&gt;&lt;span class=&quot;sd&quot;&gt;/**&lt;/span&gt;
&lt;span class=&quot;lineno&quot;&gt;  3 &lt;/span&gt;&lt;span class=&quot;sd&quot;&gt; * Created by PhpStorm.&lt;/span&gt;
&lt;span class=&quot;lineno&quot;&gt;  4 &lt;/span&gt;&lt;span class=&quot;sd&quot;&gt; * User: wuzhc2016@163.com&lt;/span&gt;
&lt;span class=&quot;lineno&quot;&gt;  5 &lt;/span&gt;&lt;span class=&quot;sd&quot;&gt; * Date: 2017年09月12日&lt;/span&gt;
&lt;span class=&quot;lineno&quot;&gt;  6 &lt;/span&gt;&lt;span class=&quot;sd&quot;&gt; * Time: 9:08&lt;/span&gt;
&lt;span class=&quot;lineno&quot;&gt;  7 &lt;/span&gt;&lt;span class=&quot;sd&quot;&gt; */&lt;/span&gt;
&lt;span class=&quot;lineno&quot;&gt;  8 &lt;/span&gt;&lt;span class=&quot;k&quot;&gt;class&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;Client&lt;/span&gt;
&lt;span class=&quot;lineno&quot;&gt;  9 &lt;/span&gt;&lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;
&lt;span class=&quot;lineno&quot;&gt; 10 &lt;/span&gt;    &lt;span class=&quot;k&quot;&gt;private&lt;/span&gt; &lt;span class=&quot;nv&quot;&gt;$_socket&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;null&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
&lt;span class=&quot;lineno&quot;&gt; 11 &lt;/span&gt;    &lt;span class=&quot;k&quot;&gt;public&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;function&lt;/span&gt; &lt;span class=&quot;fm&quot;&gt;__construct&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nv&quot;&gt;$ip&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;nv&quot;&gt;$port&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; 
&lt;span class=&quot;lineno&quot;&gt; 12 &lt;/span&gt;    &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;
&lt;span class=&quot;lineno&quot;&gt; 13 &lt;/span&gt;        &lt;span class=&quot;nv&quot;&gt;$this&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&amp;gt;&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;_socket&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;stream_socket_client&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;
&lt;span class=&quot;lineno&quot;&gt; 14 &lt;/span&gt;            &lt;span class=&quot;s2&quot;&gt;&amp;quot;tcp://&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;nv&quot;&gt;$ip&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;nv&quot;&gt;$port&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&amp;quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
&lt;span class=&quot;lineno&quot;&gt; 15 &lt;/span&gt;            &lt;span class=&quot;nv&quot;&gt;$errno&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
&lt;span class=&quot;lineno&quot;&gt; 16 &lt;/span&gt;            &lt;span class=&quot;nv&quot;&gt;$errstr&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
&lt;span class=&quot;lineno&quot;&gt; 17 &lt;/span&gt;            &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
&lt;span class=&quot;lineno&quot;&gt; 18 &lt;/span&gt;            &lt;span class=&quot;nx&quot;&gt;STREAM_CLIENT_CONNECT&lt;/span&gt;
&lt;span class=&quot;lineno&quot;&gt; 19 &lt;/span&gt;        &lt;span class=&quot;p&quot;&gt;);&lt;/span&gt;
&lt;span class=&quot;lineno&quot;&gt; 20 &lt;/span&gt;        &lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;!&lt;/span&gt;&lt;span class=&quot;nv&quot;&gt;$this&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&amp;gt;&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;_socket&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;
&lt;span class=&quot;lineno&quot;&gt; 21 &lt;/span&gt;            &lt;span class=&quot;k&quot;&gt;exit&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nv&quot;&gt;$errstr&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;);&lt;/span&gt;
&lt;span class=&quot;lineno&quot;&gt; 22 &lt;/span&gt;        &lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;
&lt;span class=&quot;lineno&quot;&gt; 23 &lt;/span&gt;    &lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;
&lt;span class=&quot;lineno&quot;&gt; 24 &lt;/span&gt;    &lt;span class=&quot;sd&quot;&gt;/**&lt;/span&gt;
&lt;span class=&quot;lineno&quot;&gt; 25 &lt;/span&gt;&lt;span class=&quot;sd&quot;&gt;     * 执行redis命令&lt;/span&gt;
&lt;span class=&quot;lineno&quot;&gt; 26 &lt;/span&gt;&lt;span class=&quot;sd&quot;&gt;     * @param $command&lt;/span&gt;
&lt;span class=&quot;lineno&quot;&gt; 27 &lt;/span&gt;&lt;span class=&quot;sd&quot;&gt;     * @return array|bool|string&lt;/span&gt;
&lt;span class=&quot;lineno&quot;&gt; 28 &lt;/span&gt;&lt;span class=&quot;sd&quot;&gt;     */&lt;/span&gt;
&lt;span class=&quot;lineno&quot;&gt; 29 &lt;/span&gt;    &lt;span class=&quot;k&quot;&gt;public&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;function&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;exec&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nv&quot;&gt;$command&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;lineno&quot;&gt; 30 &lt;/span&gt;    &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;      
&lt;span class=&quot;lineno&quot;&gt; 31 &lt;/span&gt;        &lt;span class=&quot;c1&quot;&gt;// 拼装发送命令格式&lt;/span&gt;
&lt;span class=&quot;lineno&quot;&gt; 32 &lt;/span&gt;        &lt;span class=&quot;nv&quot;&gt;$command&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;nv&quot;&gt;$this&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&amp;gt;&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;_execCommand&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nv&quot;&gt;$command&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;);&lt;/span&gt;
&lt;span class=&quot;lineno&quot;&gt; 33 &lt;/span&gt;
&lt;span class=&quot;lineno&quot;&gt; 34 &lt;/span&gt;        &lt;span class=&quot;c1&quot;&gt;// 发送命令到redis&lt;/span&gt;
&lt;span class=&quot;lineno&quot;&gt; 35 &lt;/span&gt;        &lt;span class=&quot;nb&quot;&gt;fwrite&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nv&quot;&gt;$this&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&amp;gt;&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;_socket&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;nv&quot;&gt;$command&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;);&lt;/span&gt;
&lt;span class=&quot;lineno&quot;&gt; 36 &lt;/span&gt;
&lt;span class=&quot;lineno&quot;&gt; 37 &lt;/span&gt;        &lt;span class=&quot;c1&quot;&gt;// 解析redis响应内容&lt;/span&gt;
&lt;span class=&quot;lineno&quot;&gt; 38 &lt;/span&gt;        &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;nv&quot;&gt;$this&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&amp;gt;&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;_parseResponse&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;();&lt;/span&gt;
&lt;span class=&quot;lineno&quot;&gt; 39 &lt;/span&gt;    &lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;
&lt;span class=&quot;lineno&quot;&gt; 40 &lt;/span&gt;    &lt;span class=&quot;sd&quot;&gt;/**&lt;/span&gt;
&lt;span class=&quot;lineno&quot;&gt; 41 &lt;/span&gt;&lt;span class=&quot;sd&quot;&gt;     * 将字符改为redis通讯协议格式&lt;/span&gt;
&lt;span class=&quot;lineno&quot;&gt; 42 &lt;/span&gt;&lt;span class=&quot;sd&quot;&gt;     * 例如mget name age 格式化为 *3\r\n$4\r\nmget\r\n$4\r\nname\r\n$3\r\nage\r\n&lt;/span&gt;
&lt;span class=&quot;lineno&quot;&gt; 43 &lt;/span&gt;&lt;span class=&quot;sd&quot;&gt;     * @param $command&lt;/span&gt;
&lt;span class=&quot;lineno&quot;&gt; 44 &lt;/span&gt;&lt;span class=&quot;sd&quot;&gt;     * @return bool|string&lt;/span&gt;
&lt;span class=&quot;lineno&quot;&gt; 45 &lt;/span&gt;&lt;span class=&quot;sd&quot;&gt;     */&lt;/span&gt;
&lt;span class=&quot;lineno&quot;&gt; 46 &lt;/span&gt;    &lt;span class=&quot;k&quot;&gt;private&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;function&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;_execCommand&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nv&quot;&gt;$command&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;lineno&quot;&gt; 47 &lt;/span&gt;    &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;
&lt;span class=&quot;lineno&quot;&gt; 48 &lt;/span&gt;        &lt;span class=&quot;nv&quot;&gt;$line&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;&amp;#39;&amp;#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
&lt;span class=&quot;lineno&quot;&gt; 49 &lt;/span&gt;        &lt;span class=&quot;nv&quot;&gt;$crlf&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;&amp;quot;&lt;/span&gt;&lt;span class=&quot;se&quot;&gt;\r\n&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&amp;quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
&lt;span class=&quot;lineno&quot;&gt; 50 &lt;/span&gt;        &lt;span class=&quot;nv&quot;&gt;$params&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;explode&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;&amp;#39; &amp;#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;nv&quot;&gt;$command&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;);&lt;/span&gt;
&lt;span class=&quot;lineno&quot;&gt; 51 &lt;/span&gt;        &lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;empty&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nv&quot;&gt;$params&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;
&lt;span class=&quot;lineno&quot;&gt; 52 &lt;/span&gt;            &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;nv&quot;&gt;$line&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
&lt;span class=&quot;lineno&quot;&gt; 53 &lt;/span&gt;        &lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;
&lt;span class=&quot;lineno&quot;&gt; 54 &lt;/span&gt;
&lt;span class=&quot;lineno&quot;&gt; 55 &lt;/span&gt;        &lt;span class=&quot;c1&quot;&gt;// 参数个数&lt;/span&gt;
&lt;span class=&quot;lineno&quot;&gt; 56 &lt;/span&gt;        &lt;span class=&quot;nv&quot;&gt;$line&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;.=&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;&amp;#39;*&amp;#39;&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;.&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;count&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nv&quot;&gt;$params&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;.&lt;/span&gt; &lt;span class=&quot;nv&quot;&gt;$crlf&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
&lt;span class=&quot;lineno&quot;&gt; 57 &lt;/span&gt;
&lt;span class=&quot;lineno&quot;&gt; 58 &lt;/span&gt;        &lt;span class=&quot;c1&quot;&gt;// 各个参数拼装&lt;/span&gt;
&lt;span class=&quot;lineno&quot;&gt; 59 &lt;/span&gt;        &lt;span class=&quot;k&quot;&gt;foreach&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;((&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;array&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;nv&quot;&gt;$params&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;as&lt;/span&gt; &lt;span class=&quot;nv&quot;&gt;$param&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;
&lt;span class=&quot;lineno&quot;&gt; 60 &lt;/span&gt;            &lt;span class=&quot;nv&quot;&gt;$line&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;.=&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;&amp;#39;$&amp;#39;&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;.&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;mb_strlen&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nv&quot;&gt;$param&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;&amp;#39;8bit&amp;#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;.&lt;/span&gt; &lt;span class=&quot;nv&quot;&gt;$crlf&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
&lt;span class=&quot;lineno&quot;&gt; 61 &lt;/span&gt;            &lt;span class=&quot;nv&quot;&gt;$line&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;.=&lt;/span&gt; &lt;span class=&quot;nv&quot;&gt;$param&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;.&lt;/span&gt; &lt;span class=&quot;nv&quot;&gt;$crlf&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
&lt;span class=&quot;lineno&quot;&gt; 62 &lt;/span&gt;        &lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;
&lt;span class=&quot;lineno&quot;&gt; 63 &lt;/span&gt;
&lt;span class=&quot;lineno&quot;&gt; 64 &lt;/span&gt;        &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;nv&quot;&gt;$line&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
&lt;span class=&quot;lineno&quot;&gt; 65 &lt;/span&gt;    &lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;
&lt;span class=&quot;lineno&quot;&gt; 66 &lt;/span&gt;    &lt;span class=&quot;sd&quot;&gt;/**&lt;/span&gt;
&lt;span class=&quot;lineno&quot;&gt; 67 &lt;/span&gt;&lt;span class=&quot;sd&quot;&gt;     * 解析redis回复&lt;/span&gt;
&lt;span class=&quot;lineno&quot;&gt; 68 &lt;/span&gt;&lt;span class=&quot;sd&quot;&gt;     * @return array|bool|string&lt;/span&gt;
&lt;span class=&quot;lineno&quot;&gt; 69 &lt;/span&gt;&lt;span class=&quot;sd&quot;&gt;     */&lt;/span&gt;
&lt;span class=&quot;lineno&quot;&gt; 70 &lt;/span&gt;    &lt;span class=&quot;k&quot;&gt;private&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;function&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;_parseResponse&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
&lt;span class=&quot;lineno&quot;&gt; 71 &lt;/span&gt;    &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;
&lt;span class=&quot;lineno&quot;&gt; 72 &lt;/span&gt;        &lt;span class=&quot;nv&quot;&gt;$line&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;fgets&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nv&quot;&gt;$this&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&amp;gt;&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;_socket&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;);&lt;/span&gt; 
&lt;span class=&quot;lineno&quot;&gt; 73 &lt;/span&gt;        &lt;span class=&quot;nv&quot;&gt;$type&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;nv&quot;&gt;$line&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;];&lt;/span&gt; 
&lt;span class=&quot;lineno&quot;&gt; 74 &lt;/span&gt;        &lt;span class=&quot;nv&quot;&gt;$msg&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;mb_substr&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nv&quot;&gt;$line&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;&amp;#39;8bit&amp;#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;);&lt;/span&gt; 
&lt;span class=&quot;lineno&quot;&gt; 75 &lt;/span&gt;
&lt;span class=&quot;lineno&quot;&gt; 76 &lt;/span&gt;        &lt;span class=&quot;k&quot;&gt;switch&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nv&quot;&gt;$type&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;
&lt;span class=&quot;lineno&quot;&gt; 77 &lt;/span&gt;            &lt;span class=&quot;c1&quot;&gt;// 状态回复&lt;/span&gt;
&lt;span class=&quot;lineno&quot;&gt; 78 &lt;/span&gt;            &lt;span class=&quot;k&quot;&gt;case&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;&amp;#39;+&amp;#39;&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;:&lt;/span&gt;
&lt;span class=&quot;lineno&quot;&gt; 79 &lt;/span&gt;                &lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nv&quot;&gt;$msg&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;==&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;&amp;#39;OK&amp;#39;&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;||&lt;/span&gt; &lt;span class=&quot;nv&quot;&gt;$msg&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;==&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;&amp;#39;PONG&amp;#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;
&lt;span class=&quot;lineno&quot;&gt; 80 &lt;/span&gt;                    &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;true&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
&lt;span class=&quot;lineno&quot;&gt; 81 &lt;/span&gt;                &lt;span class=&quot;p&quot;&gt;}&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;else&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;
&lt;span class=&quot;lineno&quot;&gt; 82 &lt;/span&gt;                    &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;nv&quot;&gt;$msg&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
&lt;span class=&quot;lineno&quot;&gt; 83 &lt;/span&gt;                &lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;
&lt;span class=&quot;lineno&quot;&gt; 84 &lt;/span&gt;            &lt;span class=&quot;c1&quot;&gt;// 错误回复&lt;/span&gt;
&lt;span class=&quot;lineno&quot;&gt; 85 &lt;/span&gt;            &lt;span class=&quot;k&quot;&gt;case&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;&amp;#39;-&amp;#39;&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;:&lt;/span&gt;
&lt;span class=&quot;lineno&quot;&gt; 86 &lt;/span&gt;                &lt;span class=&quot;k&quot;&gt;exit&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nv&quot;&gt;$msg&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;);&lt;/span&gt;
&lt;span class=&quot;lineno&quot;&gt; 87 &lt;/span&gt;            &lt;span class=&quot;c1&quot;&gt;// 整数回复&lt;/span&gt;
&lt;span class=&quot;lineno&quot;&gt; 88 &lt;/span&gt;            &lt;span class=&quot;k&quot;&gt;case&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;&amp;#39;:&amp;#39;&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;:&lt;/span&gt;
&lt;span class=&quot;lineno&quot;&gt; 89 &lt;/span&gt;                &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;nv&quot;&gt;$msg&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
&lt;span class=&quot;lineno&quot;&gt; 90 &lt;/span&gt;            &lt;span class=&quot;c1&quot;&gt;// 批量回复&lt;/span&gt;
&lt;span class=&quot;lineno&quot;&gt; 91 &lt;/span&gt;            &lt;span class=&quot;k&quot;&gt;case&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;&amp;#39;$&amp;#39;&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;c1&quot;&gt;// $后面跟数据字节数(长度)&lt;/span&gt;
&lt;span class=&quot;lineno&quot;&gt; 92 &lt;/span&gt;                &lt;span class=&quot;nv&quot;&gt;$line&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;fread&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nv&quot;&gt;$this&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&amp;gt;&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;_socket&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nx&quot;&gt;int&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;nv&quot;&gt;$msg&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;);&lt;/span&gt; &lt;span class=&quot;c1&quot;&gt;// 数据字节数 + (\r\n)两个字节&lt;/span&gt;
&lt;span class=&quot;lineno&quot;&gt; 93 &lt;/span&gt;                &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;mb_substr&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nv&quot;&gt;$line&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;&amp;#39;8bit&amp;#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;);&lt;/span&gt; &lt;span class=&quot;c1&quot;&gt;// 去除最后两个字节&lt;/span&gt;
&lt;span class=&quot;lineno&quot;&gt; 94 &lt;/span&gt;            &lt;span class=&quot;c1&quot;&gt;// 多条批量回复&lt;/span&gt;
&lt;span class=&quot;lineno&quot;&gt; 95 &lt;/span&gt;            &lt;span class=&quot;k&quot;&gt;case&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;&amp;#39;*&amp;#39;&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;c1&quot;&gt;// *表示后面有多少个参数&lt;/span&gt;
&lt;span class=&quot;lineno&quot;&gt; 96 &lt;/span&gt;                &lt;span class=&quot;nv&quot;&gt;$data&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[];&lt;/span&gt;
&lt;span class=&quot;lineno&quot;&gt; 97 &lt;/span&gt;                &lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nv&quot;&gt;$i&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt; &lt;span class=&quot;nv&quot;&gt;$i&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;lt;&lt;/span&gt; &lt;span class=&quot;nv&quot;&gt;$msg&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt; &lt;span class=&quot;nv&quot;&gt;$i&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;++&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;
&lt;span class=&quot;lineno&quot;&gt; 98 &lt;/span&gt;                    &lt;span class=&quot;nv&quot;&gt;$data&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[]&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;nv&quot;&gt;$this&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&amp;gt;&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;_parseResponse&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;();&lt;/span&gt;
&lt;span class=&quot;lineno&quot;&gt; 99 &lt;/span&gt;                &lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;
&lt;span class=&quot;lineno&quot;&gt;100 &lt;/span&gt;                &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;nv&quot;&gt;$data&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
&lt;span class=&quot;lineno&quot;&gt;101 &lt;/span&gt;        &lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;
&lt;span class=&quot;lineno&quot;&gt;102 &lt;/span&gt;    &lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;
&lt;span class=&quot;lineno&quot;&gt;103 &lt;/span&gt;&lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;
&lt;span class=&quot;lineno&quot;&gt;104 &lt;/span&gt;&lt;span class=&quot;c1&quot;&gt;// demo&lt;/span&gt;
&lt;span class=&quot;lineno&quot;&gt;105 &lt;/span&gt;&lt;span class=&quot;nv&quot;&gt;$client&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;new&lt;/span&gt; &lt;span class=&quot;nx&quot;&gt;Client&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;&amp;#39;127.0.0.1&amp;#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;6379&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;);&lt;/span&gt;
&lt;span class=&quot;lineno&quot;&gt;106 &lt;/span&gt;&lt;span class=&quot;nv&quot;&gt;$client&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&amp;gt;&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;exec&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;&amp;#39;set name wuzhc&amp;#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;);&lt;/span&gt;
&lt;span class=&quot;lineno&quot;&gt;107 &lt;/span&gt;&lt;span class=&quot;nv&quot;&gt;$res&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;nv&quot;&gt;$client&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&amp;gt;&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;exec&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;&amp;#39;get name&amp;#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;);&lt;/span&gt;
&lt;span class=&quot;lineno&quot;&gt;108 &lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;var_dump&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nv&quot;&gt;$res&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;);&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;

SET
C:
SET HENRY  HENRYFAN
以上命令是设置HENRY 的值为HENRYFAN.在Redis的通讯协议上会以空格把命令拆分成三行;得到最终的命令如下：
*3\r\n
$3\r\n
SET\r\n
$5\r\n
HENRY\r\n
$8\r\n
HENRYFAN\r\n
S:
服务端操作成功
+OK\r\n
如果出现错误服务端会返回
-错误信息\r\n
GET
C:
GET HENRY
产生的通讯指令是：
*2\r\n
$3\r\n
GET\r\n
$5\r\n
HENRY\r\n
S:
 如果存在这个Key则返回
$8\r\n
HENRYFAN\r\n
不存在返回
$-1\r\n
HKEYS
C:
HKEYS HENRY
以上命令是获取对应HENRY有多少个field成员
*2\r\n
$5\r\n
HKEYS\r\n
$5\r\n
HENRY\r\n
S:
如果不存在任何字段信息
*0\r\n
如果存在QQ字段信息
*1\r\n
$2\r\n
QQ\r\n
HMGET
C:
HMGET HENRY QQ
以上命令是获取HENRY的QQ信息。
*3\r\n
$5\r\n
HMGET\r\n
$5\r\n
HENRY\r\n
$2\r\n
QQ\r\n
S:
如果不存在字段值

*1\r\n
$-1\r\n
存在字段值

*1\r\n
$8\r\n
28304340\r\n
&lt;/参数&gt;
</description>
        <pubDate>Sat, 18 Nov 2017 00:00:00 +0800</pubDate>
        <link>https://xiazemin.github.io/MyBlog/web/2017/11/18/redis_protocal.html</link>
        <guid isPermaLink="true">https://xiazemin.github.io/MyBlog/web/2017/11/18/redis_protocal.html</guid>
        
        
        <category>web</category>
        
      </item>
    
      <item>
        <title>jupyter 数学公式</title>
        <description>&lt;!-- more --&gt;
&lt;div class=&quot;container&quot;&gt;

&lt;div class=&quot;row&quot;&gt;
1、数学公式的前后要加上 $ 或 \( 和 \)，比如：$f(x) = 3x + 7$ 和 f(x)=3x+7 效果是一样的；如果用 \[ 和 \]，或者使用 $$ 和 $$，则该公式独占一行；如果用 \begin{equation} 和 \end{equation}，则公式除了独占一行还会自动被添加序号， 如何公式不想编号则使用 \begin{equation*} 和\end{equation*}.
2、字符
除了# $ % &amp;amp; ~ _ ^ \ { }普通字符在数学公式中含义一样，若要在数学环境中表示这些符号# $ % &amp;amp; _ { }，需要分别表示为\# \$ \% \&amp;amp; \_ \{ \}，即在个字符前加上\。

3、上标和下标
用 ^ 来表示上标，用 _ 来表示下标，看一简单例子：
LaTeX可以通过这符号 $^$ 和 $_$ 来设置上标和下标。使用可以参见：技巧十。
用 ^ 来表示上标，用 _ 来表示下标，如果上标的内容多于一个字符，注意用 { } 把上标括起来，上下标是可以嵌套的，下面是一些简单例子：
$\sum_{i=1}^n a_i=0$
$f(x)=x^{x^x}$
4、希腊字母
5、数学函数
例如sin x， 输入应该为\sin x
6、在公式中插入文本可以通过 \mbox{text} 在公式中添加text，比如：
   \documentclass{article}
	\usepackage{CJK}
	\begin{CJK*}{GBK}{song} 
	\begin{document} 
	$$\mbox{对任意的$x&amp;gt;0$}, \mbox{有 }f(x)&amp;gt;0. $$ 
	\end{CJK*}
	\end{document}
7、分数及开方
\frac{numerator}{denominator} \sqrt{expression_r_r_r}表示开平方，
\sqrt[n]{expression_r_r_r} 表示开 n 次方.
8、省略号（3个点）
\ldots 表示跟文本底线对齐的省略号；\cdots 表示跟文本中线对齐的省略号，
9、括号和分隔符
() 和 [ ] 和 ｜ 对应于自己；
{} 对应于 \{ \}；
|| 对应于 \|。
当要显示大号的括号或分隔符时，要对应用 \left 和 \right
10、多行的数学公式
其中&amp;amp;是对其点，表示在此对齐。
*使latex不自动显示序号，如果想让latex自动标上序号，则把*去掉
11、矩阵
12、导数、极限、求和、积分(Derivatives, Limits, Sums and Integrals)
$\frac{du}{dt}   $
$  \frac{d^2 u}{dx^2}$
$\lim_{x \to +\infty}, \inf_{x &amp;gt; s}$
$\frac{1}{\lim_{u \rightarrow \infty}}, \frac{1}{\lim\limits_{u \rightarrow \infty}} or
\frac{1}{ \displaystyle \lim_{u \rightarrow \infty}}$
&lt;/div&gt;
&lt;/div&gt;
</description>
        <pubDate>Sat, 18 Nov 2017 00:00:00 +0800</pubDate>
        <link>https://xiazemin.github.io/MyBlog/spark/2017/11/18/jupyter_math.html</link>
        <guid isPermaLink="true">https://xiazemin.github.io/MyBlog/spark/2017/11/18/jupyter_math.html</guid>
        
        
        <category>spark</category>
        
      </item>
    
      <item>
        <title>jupyter 数学公式</title>
        <description>&lt;div class=&quot;container&quot;&gt;
&lt;div class=&quot;row&quot;&gt;
	Notebook 文档是由一系列单元（Cell）构成，如何使用Cell？

类型

Code
可执行的代码，Jupyter命令、Unix命令、各种脚本语言代码
Markdown
可书写markdown
Raw NBconvert
应该是默认格式（不确定）
Heading
标题级别，相当于html里面的h1、h2……

主要有两种形式的单元：

代码单元：这里是你编写代码的地方，通过按 Shift + Enter 运行代码，其结果显示在本单元下方。代码单元左边有 In [1]: 这样的序列标记，方便人们查看代码的执行次序。
Markdown 单元：在这里对文本进行编辑，采用 markdown 的语法规范，可以设置文本格式、插入链接、图片甚至数学公式。同样使用 Shift + Enter 运行 markdown 单元来显示格式化的文本。

类似于 Linux 的 Vim 编辑器，在 notebook 中也有两种模式：

编辑模式：编辑文本和代码。选中单元并按 Enter 键进入编辑模式，此时单元左侧显示绿色竖线。
命令模式：用于执行键盘输入的快捷命令。通过 Esc 键进入命令模式，此时单元左侧显示蓝色竖线。
如果要使用快捷键，首先按 Esc 键进入命令模式，然后按相应的键实现对文档的操作。比如切换成代码单元（Y）或 markdown 单元（M），或者在本单元的下方增加一单元（B）。查看所有快捷命令可以按H。
&lt;/div&gt;
&lt;div class=&quot;row&quot;&gt;
数学公式编辑
&lt;/div&gt;
&lt;div class=&quot;row&quot;&gt;
如果你曾做过严肃的学术研究，一定对 LaTeX 并不陌生，这简直是写科研论文的必备工具，不但能实现严格的文档排版，而且能编辑复杂的数学公式。在 Jupyter Notebook 的 markdown 单元中我们也可以使用 LaTeX 的语法来插入数学公式。

在文本行中插入数学公式，使用一对 $符号，比如质能方程 $E = mc^2$。如果要插入一个数学区块，则使用一对美元$符号。比如下面公式表示 z=x/y：
&lt;!-- more --&gt;
&lt;/div&gt;
&lt;div class=&quot;row&quot;&gt;
幻灯片制作
&lt;/div&gt;
&lt;div class=&quot;row&quot;&gt;
既然Jupyter Notebook 擅长展示数据分析的过程，除了通过网页形式分享外，当然也可以将其制作成幻灯片的形式。这里有一个幻灯片示例供参考，其制作风格简洁明晰。

那么如何用 Jupyter Notebook 制作幻灯片呢？首先在 notebook 的菜单栏选择 View &amp;gt; Cell Toolbar &amp;gt; Slideshow，这时在文档的每个单元右上角显示了 Slide Type 的选项。通过设置不同的类型，来控制幻灯片的格式。有如下5中类型：

Slide：主页面，通过按左右方向键进行切换。
Sub-Slide：副页面，通过按上下方向键进行切换。
Fragment：一开始是隐藏的，按空格键或方向键后显示，实现动态效果。
Skip：在幻灯片中不显示的单元。
Notes：作为演讲者的备忘笔记，也不在幻灯片中显示。

当编写好了幻灯片形式的 notebook，如何来演示呢？这时需要使用 nbconvert：

&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-bash&quot; data-lang=&quot;bash&quot;&gt;&lt;span&gt;&lt;/span&gt;jupyter nbconvert notebook.ipynb --to slides --post serve&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;

&lt;/div&gt;

&lt;div class=&quot;row&quot;&gt;
魔术关键字

魔术关键字（magic keywords），正如其名，是用于控制 notebook 的特殊的命令。它们运行在代码单元中，以 % 或者 %% 开头，前者控制一行，后者控制整个单元。

比如，要得到代码运行的时间，则可以使用 %timeit；如果要在文档中显示 matplotlib 包生成的图形，则使用 % matplotlib inline；如果要做代码调试，则使用 %pdb。但注意这些命令大多是在Python kernel 中适用的，其他 kernel 大多不适用。有许许多多的魔术关键字可以使用，更详细的清单请参考 Built-in magic commands 。
&lt;/div&gt;
&lt;/div&gt;
</description>
        <pubDate>Sat, 18 Nov 2017 00:00:00 +0800</pubDate>
        <link>https://xiazemin.github.io/MyBlog/saprk/2017/11/18/jupyter_latex.html</link>
        <guid isPermaLink="true">https://xiazemin.github.io/MyBlog/saprk/2017/11/18/jupyter_latex.html</guid>
        
        
        <category>saprk</category>
        
      </item>
    
      <item>
        <title>Jupyter Notebook 添加目录</title>
        <description>&lt;!-- more --&gt;
&lt;div class=&quot;container&quot;&gt;	
&lt;/div&gt;
&lt;div class=&quot;row&quot;&gt;
1.  安装 jupyter_contrib_nbextensions

pip install jupyter_contrib_nbextensions

2. 配置 nbextension
jupyter contrib nbextension install --user

3. 启动jupyter notebook
选择 Nbextensions
勾选 Table of Contents
勾选 Add a Table of Contents cell at the top of the notebook
4. 在markdown cell 中输入 
＃ 空格 一级标题
＃＃ 空格 二级标题
5. 运行显示标题
&lt;/div&gt;
&lt;p&gt;&amp;lt;/div&amp;gt;&lt;/p&gt;
</description>
        <pubDate>Sat, 18 Nov 2017 00:00:00 +0800</pubDate>
        <link>https://xiazemin.github.io/MyBlog/spark/2017/11/18/jupyter_index.html</link>
        <guid isPermaLink="true">https://xiazemin.github.io/MyBlog/spark/2017/11/18/jupyter_index.html</guid>
        
        
        <category>spark</category>
        
      </item>
    
      <item>
        <title>文字特征提取算法</title>
        <description>&lt;!-- more --&gt;
&lt;div class=&quot;container&quot;&gt;
		&lt;div class=&quot;row&quot;&gt;
	  TFIDF的主要思想是：如果某个词或短语在一篇文章中出现的频率TF高，并且在其他文章中很少出现，则认为此词或者短语具有很好的类别区分能力，适合用来分类。
	&lt;/div&gt;
	&lt;div class=&quot;row&quot;&gt;
	&lt;img src=&quot;https://xiazemin.github.io/MyBlog/img/TF.png&quot; /&gt;
	&lt;/div&gt;
	&lt;div class=&quot;row&quot;&gt;
	&lt;img src=&quot;https://xiazemin.github.io/MyBlog/img/IDF.png&quot; /&gt;
	&lt;/div&gt;
		&lt;img src=&quot;https://xiazemin.github.io/MyBlog/img/TF_IDF.png&quot; /&gt;
	&lt;/div&gt;

&lt;div class=&quot;row&quot;&gt;
LDA（Latent Dirichlet Allocation）是一种文档主题生成模型，也称为一个三层贝叶斯概率模型，包含词、主题和文档三层结构。所谓生成模型，就是说，我们认为一篇文章的每个词都是通过“以一定概率选择了某个主题，并从这个主题中以一定概率选择某个词语”这样一个过程得到。文档到主题服从多项式分布，主题到词服从多项式分布
1.对每一篇文档，从主题分布中抽取一个主题；
2.从上述被抽到的主题所对应的单词分布中抽取一个单词；
3.重复上述过程直至遍历文档中的每一个单词。
先定义一些字母的含义：文档集合D，主题（topic)集合T
D中每个文档d看作一个单词序列&amp;lt;w1,w2,...,wn&amp;gt;，wi表示第i个单词，设d有n个单词。（LDA里面称之为wordbag，实际上每个单词的出现位置对LDA算法无影响）
·D中涉及的所有不同单词组成一个大集合VOCABULARY（简称VOC），LDA以文档集合D作为输入，希望训练出的两个结果向量（设聚成k个topic，VOC中共包含m个词）：
·对每个D中的文档d，对应到不同Topic的概率θd&amp;lt;pt1,...,ptk&amp;gt;，其中，pti表示d对应T中第i个topic的概率。计算方法是直观的，pti=nti/n，其中nti表示d中对应第i个topic的词的数目，n是d中所有词的总数。
·对每个T中的topict，生成不同单词的概率φt&amp;lt;pw1,...,pwm&amp;gt;，其中，pwi表示t生成VOC中第i个单词的概率。计算方法同样很直观，pwi=Nwi/N，其中Nwi表示对应到topict的VOC中第i个单词的数目，N表示所有对应到topict的单词总数。
LDA的核心公式如下：
p(w|d)=p(w|t)*p(t|d)
直观的看这个公式，就是以Topic作为中间层，可以通过当前的θd和φt给出了文档d中出现单词w的概率。其中p(t|d)利用θd计算得到，p(w|t)利用φt计算得到。
实际上，利用当前的θd和φt，我们可以为一个文档中的一个单词计算它对应任意一个Topic时的p(w|d)，然后根据这些结果来更新这个词应该对应的topic。然后，如果这个更新改变了这个单词所对应的Topic，就会反过来影响θd和φt。
&lt;/div&gt;

&lt;div class=&quot;row&quot;&gt;
Word2Vec是从大量文本语料中以无监督的方式学习语义知识的一种模型，它被大量地用在自然语言处理（NLP）中。Word2Vec模型中，主要有Skip-Gram和CBOW两种模型，从直观上理解，Skip-Gram是给定input word来预测上下文。而CBOW是给定上下文，来预测input word。
&lt;/div&gt;
&lt;div class=&quot;row&quot;&gt;
&lt;img src=&quot;https://xiazemin.github.io/MyBlog/img/CBOW.jpeg&quot; /&gt;
&lt;/div&gt;
&lt;p&gt;Skip-Gram模型的基础形式非常简单，为了更清楚地解释模型，我们先从最一般的基础模型来看Word2Vec（下文中所有的Word2Vec都是指Skip-Gram模型）。&lt;/p&gt;

&lt;p&gt;Word2Vec模型实际上分为了两个部分，第一部分为建立模型，第二部分是通过模型获取嵌入词向量。Word2Vec的整个建模过程实际上与自编码器（auto-encoder）的思想很相似，即先基于训练数据构建一个神经网络，当这个模型训练好以后，我们并不会用这个训练好的模型处理新的任务，我们真正需要的是这个模型通过训练数据所学得的参数，例如隐层的权重矩阵——后面我们将会看到这些权重在Word2Vec中实际上就是我们试图去学习的“word vectors”。基于训练数据建模的过程，我们给它一个名字叫“Fake Task”，意味着建模并不是我们最终的目的。&lt;/p&gt;

&lt;p&gt;上面提到的这种方法实际上会在无监督特征学习（unsupervised feature learning）中见到，最常见的就是自编码器（auto-encoder）：通过在隐层将输入进行编码压缩，继而在输出层将数据解码恢复初始状态，训练完成后，我们会将输出层“砍掉”，仅保留隐层。
The Fake Task&lt;/p&gt;

&lt;p&gt;我们在上面提到，训练模型的真正目的是获得模型基于训练数据学得的隐层权重。为了得到这些权重，我们首先要构建一个完整的神经网络作为我们的“Fake Task”，后面再返回来看通过“Fake Task”我们如何间接地得到这些词向量。&lt;/p&gt;

&lt;p&gt;接下来我们来看看如何训练我们的神经网络。假如我们有一个句子“The dog barked at the mailman”。&lt;/p&gt;

&lt;p&gt;首先我们选句子中间的一个词作为我们的输入词，例如我们选取“dog”作为input word；&lt;/p&gt;

&lt;p&gt;有了input word以后，我们再定义一个叫做skip_window的参数，它代表着我们从当前input word的一侧（左边或右边）选取词的数量。如果我们设置skip_window=2，那么我们最终获得窗口中的词（包括input word在内）就是[‘The’, ‘dog’，’barked’, ‘at’]。skip_window=2代表着选取左input word左侧2个词和右侧2个词进入我们的窗口，所以整个窗口大小span=2x2=4。另一个参数叫num_skips，它代表着我们从整个窗口中选取多少个不同的词作为我们的output word，当skip_window=2，num_skips=2时，我们将会得到两组 (input word, output word) 形式的训练数据，即 (‘dog’, ‘barked’)，(‘dog’, ‘the’)。&lt;/p&gt;

&lt;p&gt;神经网络基于这些训练数据将会输出一个概率分布，这个概率代表着我们的词典中的每个词是output word的可能性。这句话有点绕，我们来看个栗子。第二步中我们在设置skip_window和num_skips=2的情况下获得了两组训练数据。假如我们先拿一组数据 (‘dog’, ‘barked’) 来训练神经网络，那么模型通过学习这个训练样本，会告诉我们词汇表中每个单词是“barked”的概率大小。&lt;/p&gt;

&lt;p&gt;模型的输出概率代表着到我们词典中每个词有多大可能性跟input word同时出现。举个栗子，如果我们向神经网络模型中输入一个单词“Soviet“，那么最终模型的输出概率中，像“Union”， ”Russia“这种相关词的概率将远高于像”watermelon“，”kangaroo“非相关词的概率。因为”Union“，”Russia“在文本中更大可能在”Soviet“的窗口中出现。我们将通过给神经网络输入文本中成对的单词来训练它完成上面所说的概率计算。下面的图中给出了一些我们的训练样本的例子。我们选定句子“The quick brown fox jumps over lazy dog”，设定我们的窗口大小为2（window_size=2），也就是说我们仅选输入词前后各两个词和输入词进行组合。下图中，蓝色代表input word，方框内代表位于窗口内的单词。&lt;/p&gt;

&lt;p&gt;一文详解 Word2vec 之 Skip-Gram 模型（结构篇）&lt;/p&gt;

&lt;p&gt;我们的模型将会从每对单词出现的次数中习得统计结果。例如，我们的神经网络可能会得到更多类似（“Soviet“，”Union“）这样的训练样本对，而对于（”Soviet“，”Sasquatch“）这样的组合却看到的很少。因此，当我们的模型完成训练后，给定一个单词”Soviet“作为输入，输出的结果中”Union“或者”Russia“要比”Sasquatch“被赋予更高的概率。
&amp;lt;/div&amp;gt;&lt;/p&gt;
</description>
        <pubDate>Fri, 17 Nov 2017 00:00:00 +0800</pubDate>
        <link>https://xiazemin.github.io/MyBlog/spark/2017/11/17/word_feature.html</link>
        <guid isPermaLink="true">https://xiazemin.github.io/MyBlog/spark/2017/11/17/word_feature.html</guid>
        
        
        <category>spark</category>
        
      </item>
    
      <item>
        <title>sparl_ml_pipline</title>
        <description>&lt;div class=&quot;container&quot;&gt;
&lt;div class=&quot;row&quot;&gt;
inspired by the scikit-learn project.
&lt;/div&gt;
&lt;div class=&quot;row&quot;&gt;
DataFrame: This ML API uses DataFrame from Spark SQL as an ML dataset, which can hold a variety of data types. E.g., a DataFrame could have different columns storing text, feature vectors, true labels, and predictions.
&lt;/div&gt;
&lt;div class=&quot;row&quot;&gt;
Transformer: A Transformer is an algorithm which can transform one DataFrame into another DataFrame. E.g., an ML model is a Transformer which transforms a DataFrame with features into a DataFrame with predictions.
&lt;/div&gt;
&lt;div class=&quot;row&quot;&gt;
Estimator: An Estimator is an algorithm which can be fit on a DataFrame to produce a Transformer. E.g., a learning algorithm is an Estimator which trains on a DataFrame and produces a model.Technically, an Estimator implements a method fit(), which accepts a DataFrame and produces a Model, which is a Transformer. 
&lt;/div&gt;
&lt;div class=&quot;row&quot;&gt;
Pipeline: A Pipeline chains multiple Transformers and Estimators together to specify an ML workflow.
&lt;/div&gt;
&lt;div class=&quot;row&quot;&gt;
Parameter: All Transformers and Estimators now share a common API for specifying parameters.
&lt;!-- more --&gt;
参考：http://spark.apache.org/docs/latest/ml-pipeline.html
&lt;/div&gt;
&lt;div class=&quot;row&quot;&gt;
一句话概括：管道（Pipeline）是运用数据（DataFrame）训练算法模型（Estimator）调整参数（Parameter）得到一个最优的算法模型（Transformer）,转换数据（DataFrame）的流程。
 For Transformer stages, the transform() method is called on the DataFrame. For Estimator stages, the fit() method is called to produce a Transformer (which becomes part of the PipelineModel, or fitted Pipeline), and that Transformer’s transform() method is called on the DataFrame.
&lt;/div&gt;
&lt;/div&gt;
</description>
        <pubDate>Thu, 16 Nov 2017 00:00:00 +0800</pubDate>
        <link>https://xiazemin.github.io/MyBlog/spark/2017/11/16/sparl_ml_pipline.html</link>
        <guid isPermaLink="true">https://xiazemin.github.io/MyBlog/spark/2017/11/16/sparl_ml_pipline.html</guid>
        
        
        <category>spark</category>
        
      </item>
    
      <item>
        <title>mysql 的排序</title>
        <description>&lt;div class=&quot;container&quot;&gt;
用户通过Order by语句即能达到将指定的结果集排序的目的，其实不仅仅是Order by语句，Group by语句，Distinct语句都会隐含使用排序

1.排序优化与索引使用
      为了优化SQL语句的排序性能，最好的情况是避免排序，合理利用索引是一个不错的方法。因为索引本身也是有序的，如果在需要排序的字段上面建立了合适的索引，那么就可以跳过排序的过程，提高SQL的查询速度。

不能利用索引避免排序的SQL
//排序字段在多个索引中，无法使用索引排序
SELECT * FROM t1 ORDER BY key_part1,key_part2, key2;
 
//排序键顺序与索引中列顺序不一致，无法使用索引排序
SELECT * FROM t1 ORDER BY key_part2, key_part1;
 
//升降序不一致，无法使用索引排序
SELECT * FROM t1 ORDER BY key_part1 DESC, key_part2 ASC;
 
//key_part1是范围查询，key_part2无法使用索引排序
SELECT * FROM t1 WHERE key_part1&amp;gt; constant ORDER BY key_part2;

2.排序实现的算法
      对于不能利用索引避免排序的SQL，数据库不得不自己实现排序功能以满足用户需求，此时SQL的执行计划中会出现“Using filesort”，这里需要注意的是filesort并不意味着就是文件排序，其实也有可能是内存排序，这个主要由sort_buffer_size参数与结果集大小确定。MySQL内部实现排序主要有3种方式，常规排序，优化排序和优先队列排序，主要涉及3种排序算法：快速排序、归并排序和堆排序。
      
a.常规排序
(1).从表t1中获取满足WHERE条件的记录
(2).对于每条记录，将记录的主键+排序键(id,col2)取出放入sort buffer
(3).如果sort buffer可以存放所有满足条件的(id,col2)对，则进行排序；否则sort buffer满后，进行排序并固化到临时文件中。(排序算法采用的是快速排序算法)
(4).若排序中产生了临时文件，需要利用归并排序算法，保证临时文件中记录是有序的
(5).循环执行上述过程，直到所有满足条件的记录全部参与排序
(6).扫描排好序的(id,col2)对，并利用id去捞取SELECT需要返回的列(col1,col2,col3)
(7).将获取的结果集返回给用户。
      从上述流程来看，是否使用文件排序主要看sort buffer是否能容下需要排序的(id,col2)对，这个buffer的大小由sort_buffer_size参数控制。此外一次排序需要两次IO，一次是捞(id,col2),第二次是捞(col1,col2,col3)，由于返回的结果集是按col2排序，因此id是乱序的，通过乱序的id去捞(col1,col2,col3)时会产生大量的随机IO。对于第二次MySQL本身一个优化，即在捞之前首先将id排序，并放入缓冲区，这个缓存区大小由参数read_rnd_buffer_size控制，然后有序去捞记录，将随机IO转为顺序IO。
b.优化排序
     常规排序方式除了排序本身，还需要额外两次IO。优化的排序方式相对于常规排序，减少了第二次IO。主要区别在于，放入sort buffer不是(id,col2),而是(col1,col2,col3)。由于sort buffer中包含了查询需要的所有字段，因此排序完成后可以直接返回，无需二次捞数据。这种方式的代价在于，同样大小的sort buffer，能存放的(col1,col2,col3)数目要小于(id,col2)，如果sort buffer不够大，可能导致需要写临时文件，造成额外的IO。当然MySQL提供了参数max_length_for_sort_data，只有当排序元组小于max_length_for_sort_data时，才能利用优化排序方式，否则只能用常规排序方式。
c.优先队列排序
     为了得到最终的排序结果，无论怎样，我们都需要将所有满足条件的记录进行排序才能返回。那么相对于优化排序方式，是否还有优化空间呢？5.6版本针对Order by limit M，N语句，在空间层面做了优化，加入了一种新的排序方式--优先队列，这种方式采用堆排序实现。堆排序算法特征正好可以解limit M，N 这类排序的问题，虽然仍然需要所有元素参与排序，但是只需要M+N个元组的sort buffer空间即可，对于M，N很小的场景，基本不会因为sort buffer不够而导致需要临时文件进行归并排序的问题。对于升序，采用大顶堆，最终堆中的元素组成了最小的N个元素，对于降序，采用小顶堆，最终堆中的元素组成了最大的N的元素。      

合并排序的强大之处
    你可以更改算法，以便于节省内存空间，方法是不创建新的序列而是直接修改输入序列。
注：这种算法叫『原地算法』(in-place algorithm)

你可以更改算法，以便于同时使用磁盘空间和少量内存而避免巨量磁盘 I/O。方法是只向内存中加载当前处理的部分。在仅仅100MB的内存缓冲区内排序一个几个GB的表时，这是个很重要的技巧。
注：这种算法叫『外部排序』(external sorting)。

你可以更改算法，以便于在 多处理器/多线程/多服务器 上运行。
比如，分布式合并排序是Hadoop（那个著名的大数据框架）的关键组件之一。

B+树索引

查找一个特定值这个树挺好用，但是当你需要查找两个值之间的多个元素时，就会有大麻烦了。你的成本将是 O(N)，因为你必须查找树的每一个节点，以判断它是否处于那 2 个值之间（例如，对树使用中序遍历）。而且这个操作不是磁盘I/O有利的，因为你必须读取整个树。我们需要找到高效的范围查询方法。为了解决这个问题，现代数据库使用了一种修订版的树，叫做B+树。在一个B+树里：

只有最底层的节点（叶子节点）才保存信息（相关表的行位置）
其它节点只是在搜索中用来指引到正确节点的。
&lt;!-- more --&gt;
&lt;div class=&quot;row&quot;&gt;
&lt;img src=&quot;https://xiazemin.github.io/MyBlog/img/BPlusTree.png&quot; /&gt;
&lt;/div&gt;
你可以看到，节点更多了（多了两倍）。确实，你有了额外的节点，它们就是帮助你找到正确节点的『决策节点』（正确节点保存着相关表中行的位置）。但是搜索复杂度还是在 O(log(N))（只多了一层）。一个重要的不同点是，最底层的节点是跟后续节点相连接的。

用这个 B+树，假设你要找40到100间的值：

你只需要找 40（若40不存在则找40之后最贴近的值），就像你在上一个树中所做的那样。
然后用那些连接来收集40的后续节点，直到找到100。
比方说你找到了 M 个后续节点，树总共有 N 个节点。对指定节点的搜索成本是 log(N)，跟上一个树相同。但是当你找到这个节点，你得通过后续节点的连接得到 M 个后续节点，这需要 M 次运算。那么这次搜索只消耗了 M+log(N) 次运算，区别于上一个树所用的 N 次运算。此外，你不需要读取整个树（仅需要读 M+log(N) 个节点）,这意味着更少的磁盘访问。如果 M 很小（比如 200 行）并且 N 很大（1,000,000），那结果就是天壤之别了。

然而还有新的问题（又来了！）。如果你在数据库中增加或删除一行（从而在相关的 B+树索引里）：

你必须在B+树中的节点之间保持顺序，否则节点会变得一团糟，你无法从中找到想要的节点。
你必须尽可能降低B+树的层数，否则 O(log(N)) 复杂度会变成 O(N)。
换句话说，B+树需要自我整理和自我平衡。谢天谢地，我们有智能删除和插入。但是这样也带来了成本：在B+树中，插入和删除操作是 O(log(N)) 复杂度。所以有些人听到过使用太多索引不是个好主意这类说法。没错，你减慢了快速插入/更新/删除表中的一个行的操作，因为数据库需要以代价高昂的每索引 O(log(N)) 运算来更新表的索引。再者，增加索引意味着给事务管理器带来更多的工作负荷（在本文结尾我们会探讨这个管理器）。

https://blog.jcole.us/2013/01/07/the-physical-structure-of-innodb-index-pages/

https://blog.jcole.us/2013/01/10/btree-index-structures-in-innodb/
哈希表

我们最后一个重要的数据结构是哈希表。当你想快速查找值时，哈希表是非常有用的。而且，理解哈希表会帮助我们接下来理解一个数据库常见的联接操作，叫做『哈希联接』。这个数据结构也被数据库用来保存一些内部的东西（比如锁表或者缓冲池，我们在下文会研究这两个概念）。

哈希表这种数据结构可以用关键字来快速找到一个元素。为了构建一个哈希表，你需要定义：

元素的关键字
关键字的哈希函数。关键字计算出来的哈希值给出了元素的位置（叫做哈希桶）。
关键字比较函数。一旦你找到正确的哈希桶，你必须用比较函数在桶内找到你要的元素。

阵列 vs 哈希表

为什么不用阵列呢?
一个哈希表可以只装载一半到内存，剩下的哈希桶可以留在硬盘上。
用阵列的话，你需要一个连续内存空间。如果你加载一个大表，很难分配足够的连续内存空间。
用哈希表的话，你可以选择你要的关键字（比如，一个人的国家和姓氏）。

数据库是由多种互相交互的组件构成的。

核心组件：

进程管理器（process manager）：很多数据库具备一个需要妥善管理的进程/线程池。再者，为了实现纳秒级操作，一些现代数据库使用自己的线程而不是操作系统线程。
网络管理器（network manager）：网路I/O是个大问题，尤其是对于分布式数据库。所以一些数据库具备自己的网络管理器。
文件系统管理器（File system manager）：磁盘I/O是数据库的首要瓶颈。具备一个文件系统管理器来完美地处理OS文件系统甚至取代OS文件系统，是非常重要的。
内存管理器（memory manager）：为了避免磁盘I/O带来的性能损失，需要大量的内存。但是如果你要处理大容量内存你需要高效的内存管理器，尤其是你有很多查询同时使用内存的时候。
安全管理器（Security Manager）：用于对用户的验证和授权。
客户端管理器（Client manager）：用于管理客户端连接。
……
工具：

备份管理器（Backup manager）：用于保存和恢复数据。
复原管理器（Recovery manager）：用于崩溃后重启数据库到一个一致状态。
监控管理器（Monitor manager）：用于记录数据库活动信息和提供监控数据库的工具。
Administration管理器（Administration manager）：用于保存元数据（比如表的名称和结构），提供管理数据库、模式、表空间的工具。【译者注：好吧，我真的不知道Administration manager该翻译成什么，有知道的麻烦告知，不胜感激……】
……
查询管理器：

查询解析器（Query parser）：用于检查查询是否合法
查询重写器（Query rewriter）：用于预优化查询
查询优化器（Query optimizer）：用于优化查询
查询执行器（Query executor）：用于编译和执行查询
数据管理器：

事务管理器（Transaction manager）：用于处理事务
缓存管理器（Cache manager）：数据被使用之前置于内存，或者数据写入磁盘之前置于内存
数据访问管理器（Data access manager）：访问磁盘中的数据
&lt;/div&gt;
</description>
        <pubDate>Thu, 16 Nov 2017 00:00:00 +0800</pubDate>
        <link>https://xiazemin.github.io/MyBlog/web/2017/11/16/mysql_sort.html</link>
        <guid isPermaLink="true">https://xiazemin.github.io/MyBlog/web/2017/11/16/mysql_sort.html</guid>
        
        
        <category>web</category>
        
      </item>
    
      <item>
        <title>mysql_maneager</title>
        <description>&lt;div class=&quot;container&quot;&gt;
客户端管理器
&lt;div class=&quot;row&quot;&gt;
&lt;img src=&quot;https://xiazemin.github.io/MyBlog/img/mysqlManager.jpg&quot; /&gt;
&lt;/div&gt;
&lt;div class=&quot;row&quot;&gt;
客户端管理器是处理客户端通信的。客户端可以是一个（网站）服务器或者一个最终用户或最终应用。客户端管理器通过一系列知名的API（JDBC, ODBC, OLE-DB …）提供不同的方式来访问数据库。

客户端管理器也提供专有的数据库访问API。
当你连接到数据库时：
   管理器首先检查你的验证信息（用户名和密码），然后检查你是否有访问数据库的授权。这些权限由DBA分配。
然后，管理器检查是否有空闲进程（或线程）来处理你对查询。
管理器还会检查数据库是否负载很重。
管理器可能会等待一会儿来获取需要的资源。如果等待时间达到超时时间，它会关闭连接并给出一个可读的错误信息。
然后管理器会把你的查询送给查询管理器来处理。
因为查询处理进程不是『不全则无』的，一旦它从查询管理器得到数据，它会把部分结果保存到一个缓冲区并且开始给你发送。
如果遇到问题，管理器关闭连接，向你发送可读的解释信息，然后释放资源。
查询管理器
这部分是数据库的威力所在，在这部分里，一个写得糟糕的查询可以转换成一个快速执行的代码，代码执行的结果被送到客户端管理器。这个多步骤操作过程如下：

查询首先被解析并判断是否合法
然后被重写，去除了无用的操作并且加入预优化部分
接着被优化以便提升性能，并被转换为可执行代码和数据访问计划。
然后计划被编译
最后，被执行
&lt;!-- more --&gt;
&lt;/div&gt;
&lt;div class=&quot;row&quot;&gt;
查询解析器

每一条SQL语句都要送到解析器来检查语法，如果你的查询有错，解析器将拒绝该查询。比如，如果你写成”SLECT …” 而不是 “SELECT …”，那就没有下文了。

但这还不算完，解析器还会检查关键字是否使用正确的顺序，比如 WHERE 写在 SELECT 之前会被拒绝。

然后，解析器要分析查询中的表和字段，使用数据库元数据来检查：

表是否存在
表的字段是否存在
对某类型字段的 运算 是否 可能（比如，你不能将整数和字符串进行比较，你不能对一个整数使用 substring() 函数）
接着，解析器检查在查询中你是否有权限来读取（或写入）表。再强调一次：这些权限由DBA分配。

在解析过程中，SQL 查询被转换为内部表示（通常是一个树）。

如果一切正常，内部表示被送到查询重写器。
&lt;/div&gt;
&lt;div class=&quot;row&quot;&gt;
查询重写器

在这一步，我们已经有了查询的内部表示，重写器的目标是：

预优化查询
避免不必要的运算
帮助优化器找到合理的最佳解决方案
重写器按照一系列已知的规则对查询执行检测。如果查询匹配一种模式的规则，查询就会按照这条规则来重写。下面是（可选）规则的非详尽的列表：

视图合并：如果你在查询中使用视图，视图就会转换为它的 SQL 代码。
子查询扁平化：子查询是很难优化的，因此重写器会尝试移除子查询

去除不必要的运算符：比如，如果你用了 DISTINCT，而其实你有 UNIQUE 约束（这本身就防止了数据出现重复），那么 DISTINCT 关键字就被去掉了。
排除冗余的联接：如果相同的 JOIN 条件出现两次，比如隐藏在视图中的 JOIN 条件，或者由于传递性产生的无用 JOIN，都会被消除。
常数计算赋值：如果你的查询需要计算，那么在重写过程中计算会执行一次。比如 WHERE AGE &amp;gt; 10+2 会转换为 WHERE AGE &amp;gt; 12 ， TODATE(“日期字符串”) 会转换为 datetime 格式的日期值。
（高级）分区裁剪（Partition Pruning）：如果你用了分区表，重写器能够找到需要使用的分区。
（高级）物化视图重写（Materialized view rewrite）：如果你有个物化视图匹配查询谓词的一个子集，重写器将检查视图是否最新并修改查询，令查询使用物化视图而不是原始表。
（高级）自定义规则：如果你有自定义规则来修改查询（就像 Oracle policy），重写器就会执行这些规则。
（高级）OLAP转换：分析/加窗 函数，星形联接，ROLLUP 函数……都会发生转换（但我不确定这是由重写器还是优化器来完成，因为两个进程联系很紧，必须看是什么数据库）。

当你要求数据库收集统计信息，数据库会计算下列值：

表中行和页的数量
表中每个列中的：
唯一值
数据长度（最小，最大，平均）
数据范围（最小，最大，平均）
表的索引信息
这些统计信息会帮助优化器估计查询所需的磁盘 I/O、CPU、和内存使用

对每个列的统计非常重要。
比如，如果一个表 PERSON 需要联接 2 个列： LAST_NAME, FIRST_NAME。
根据统计信息，数据库知道FIRST_NAME只有 1,000 个不同的值，LAST_NAME 有 1,000,000 个不同的值。
因此，数据库就会按照 LAST_NAME, FIRST_NAME 联接。
因为 LAST_NAME 不大可能重复，多数情况下比较 LAST_NAME 的头 2 、 3 个字符就够了，这将大大减少比较的次数。

所有的现代数据库都在用基于成本的优化（即CBO）来优化查询。道理是针对每个运算设置一个成本，通过应用成本最低廉的一系列运算，来找到最佳的降低查询成本的方法。

为了理解成本优化器的原理，我觉得最好用个例子来『感受』一下这个任务背后的复杂性。这里我将给出联接 2 个表的 3 个方法，我们很快就能看到即便一个简单的联接查询对于优化器来说都是个噩梦。之后，我们会了解真正的优化器是怎么做的。

对于这些联接操作，我会专注于它们的时间复杂度，但是，数据库优化器计算的是它们的 CPU 成本、磁盘 I/O 成本、和内存需求。时间复杂度和 CPU 成本的区别是，时间成本是个近似值（给我这样的懒家伙准备的）。而 CPU 成本，我这里包括了所有的运算，比如：加法、条件判断、乘法、迭代……还有呢：

每一个高级代码运算都要特定数量的低级 CPU 运算。
对于 Intel Core i7、Intel Pentium 4、AMD Opteron…等，（就 CPU 周期而言）CPU 的运算成本是不同的，也就是说它取决于 CPU 的架构。
使用时间复杂度就容易多了（至少对我来说），用它我也能了解到 CBO 的概念。由于磁盘 I/O 是个重要的概念，我偶尔也会提到它。请牢记，大多数时候瓶颈在于磁盘 I/O 而不是 CPU 使用。
&lt;/div&gt;
&lt;div class=&quot;row&quot;&gt;
索引

在研究 B+树的时候我们谈到了索引，要记住一点，索引都是已经排了序的。

仅供参考：还有其他类型的索引，比如位图索引，在 CPU、磁盘I/O、和内存方面与B+树索引的成本并不相同。

另外，很多现代数据库为了改善执行计划的成本，可以仅为当前查询动态地生成临时索引。

存取路径

在应用联接运算符（join operators）之前，你首先需要获得数据。以下就是获得数据的方法。
全扫描

如果你读过执行计划，一定看到过『全扫描』（或只是『扫描』）一词。简单的说全扫描就是数据库完整的读一个表或索引。就磁盘 I/O 而言，很明显全表扫描的成本比索引全扫描要高昂。

范围扫描

其他类型的扫描有索引范围扫描，比如当你使用谓词 ” WHERE AGE &amp;gt; 20 AND AGE &amp;lt; 40 ” 的时候它就会发生。

当然，你需要在 AGE 字段上有索引才能用到索引范围扫描。

在第一部分我们已经知道，范围查询的时间成本大约是 log(N)+M，这里 N 是索引的数据量，M 是范围内估测的行数。多亏有了统计我们才能知道 N 和 M 的值（注： M 是谓词 “ AGE &amp;gt; 20 AND AGE &amp;lt; 40 ” 的选择率）。另外范围扫描时，你不需要读取整个索引，因此在磁盘 I/O 方面没有全扫描那么昂贵。

唯一扫描

如果你只需要从索引中取一个值你可以用唯一扫描。

根据 ROW ID 存取

多数情况下，如果数据库使用索引，它就必须查找与索引相关的行，这样就会用到根据 ROW ID 存取的方式。


其它路径

我没有列举所有的存取路径，如果你感兴趣可以读一读 Oracle文档。其它数据库里也许叫法不同但背后的概念是一样的。

联接运算符

那么，我们知道如何获取数据了，那现在就把它们联接起来！

我要展现的是3个个常用联接运算符：合并联接（Merge join），哈希联接（Hash Join）和嵌套循环联接（Nested Loop Join）。但是在此之前，我需要引入新词汇了：内关系和外关系（ inner relation and outer relation） 【译者注： “内关系和外关系” 这个说法来源不明，跟查询的“内联接（INNER JOIN）  、外联接（OUTER JOIN）  ” 不是一个概念 。只查到百度百科词条：关系数据库 里提到“每个表格（有时被称为一个关系）……” 。 其他参考链接 “Merge Join”   “Hash Join”   “Nested Loop Join” 】  。 一个关系可以是：

一个表
一个索引
上一个运算的中间结果（比如上一个联接运算的结果）
当你联接两个关系时，联接算法对两个关系的处理是不同的。在本文剩余部分，我将假定：

外关系是左侧数据集
内关系是右侧数据集
比如， A JOIN B 是 A 和 B 的联接，这里 A 是外关系，B 是内关系。

多数情况下， A JOIN B 的成本跟 B JOIN A 的成本是不同的。

在这一部分，我还将假定外关系有 N 个元素，内关系有 M 个元素。要记住，真实的优化器通过统计知道 N 和 M 的值。

注：N 和 M 是关系的基数。【译者注： 基数 】

嵌套循环联接

嵌套循环联接是最简单的

哈希联接

哈希联接更复杂，不过在很多场合比嵌套循环联接成本低

哈希联接的道理是：

1) 读取内关系的所有元素
2) 在内存里建一个哈希表
3) 逐条读取外关系的所有元素
4) （用哈希表的哈希函数）计算每个元素的哈希值，来查找内关系里相关的哈希桶内
5) 是否与外关系的元素匹配。
在时间复杂度方面我需要做些假设来简化问题：

内关系被划分成 X 个哈希桶
哈希函数几乎均匀地分布每个关系内数据的哈希值，就是说哈希桶大小一致。
外关系的元素与哈希桶内的所有元素的匹配，成本是哈希桶内元素的数量。
时间复杂度是 (M/X) * N + 创建哈希表的成本(M) + 哈希函数的成本 * N 。
如果哈希函数创建了足够小规模的哈希桶，那么复杂度就是 O(M+N)。

还有个哈希联接的版本，对内存有利但是对磁盘 I/O 不够有利。 这回是这样的：

1) 计算内关系和外关系双方的哈希表
2) 保存哈希表到磁盘
3) 然后逐个哈希桶比较（其中一个读入内存，另一个逐行读取）。
合并联接

合并联接是唯一产生排序的联接算法。

注：这个简化的合并联接不区分内表或外表；两个表扮演同样的角色。但是真实的实现方式是不同的，比如当处理重复值时。

1.（可选）排序联接运算：两个输入源都按照联接关键字排序。

2.合并联接运算：排序后的输入源合并到一起。
&lt;/div&gt;
&lt;div class=&quot;row&quot;&gt;
排序

我们已经谈到过合并排序，在这里合并排序是个很好的算法（但是并非最好的，如果内存足够用的话，还是哈希联接更好）。

然而有时数据集已经排序了，比如：

如果表内部就是有序的，比如联接条件里一个索引组织表 【译者注： index-organized table 】
如果关系是联接条件里的一个索引
如果联接应用在一个查询中已经排序的中间结果
空闲内存：没有足够的内存的话就跟强大的哈希联接拜拜吧（至少是完全内存中哈希联接）。
两个数据集的大小。比如，如果一个大表联接一个很小的表，那么嵌套循环联接就比哈希联接快，因为后者有创建哈希的高昂成本；如果两个表都非常大，那么嵌套循环联接CPU成本就很高昂。
是否有索引：有两个 B+树索引的话，聪明的选择似乎是合并联接。
结果是否需要排序：即使你用到的是未排序的数据集，你也可能想用成本较高的合并联接（带排序的），因为最终得到排序的结果后，你可以把它和另一个合并联接串起来（或者也许因为查询用 ORDER BY/GROUP BY/DISTINCT 等操作符隐式或显式地要求一个排序结果）。
关系是否已经排序：这时候合并联接是最好的候选项。
联接的类型：是等值联接（比如 tableA.col1 = tableB.col2 ）？ 还是内联接？外联接？笛卡尔乘积？或者自联接？有些联接在特定环境下是无法工作的。
数据的分布：如果联接条件的数据是倾斜的（比如根据姓氏来联接人，但是很多人同姓），用哈希联接将是个灾难，原因是哈希函数将产生分布极不均匀的哈希桶。
如果你希望联接操作使用多线程或多进程。
动态规划，贪婪算法和启发式算法

关系型数据库会尝试我刚刚提到的多种方法，优化器真正的工作是在有限时间里找到一个好的解决方案。

多数时候，优化器找到的不是最佳的方案，而是一个『不错』的

对于小规模的查询，采取粗暴的方式是有可能的。但是为了让中等规模的查询也能采取粗暴的方式，我们有办法避免不必要的计算，这就是动态规划。

动态规划

这几个字背后的理念是，很多执行计划是非常相似的。


贪婪算法

但是，优化器面对一个非常大的查询，或者为了尽快找到答案（然而查询速度就快不起来了），会应用另一种算法，叫贪婪算法。

原理是按照一个规则（或启发）以渐进的方式制定查询计划。在这个规则下，贪婪算法逐步寻找最佳算法，先处理一条JOIN，接着每一步按照同样规则加一条新的JOIN。

我们来看个简单的例子。比如一个针对5张表（A,B,C,D,E）4次JOIN 的查询，为了简化我们把嵌套JOIN作为可能的联接方式，按照『使用最低成本的联接』规则。

直接从 5 个表里选一个开始（比如 A）
计算每一个与 A 的联接（A 作为内关系或外关系）
发现 “A JOIN B” 成本最低
计算每一个与 “A JOIN B” 的结果联接的成本（“A JOIN B” 作为内关系或外关系）
发现 “(A JOIN B) JOIN C” 成本最低
计算每一个与 “(A JOIN B) JOIN C” 的结果联接的成本 ……
最后确定执行计划 “( ( (A JOIN B) JOIN C) JOIN D ) JOIN E )”
因为我们是武断地从表 A 开始，我们可以把同样的算法用在 B，然后 C，然后 D, 然后 E。最后保留成本最低的执行计划。

顺便说一句，这个算法有个名字，叫『最近邻居算法』。

抛开细节不谈，只需一个良好的模型和一个 N*log(N) 复杂度的排序，问题就轻松解决了。这个算法的复杂度是 O(N*log(N)) ，对比一下完全动态规划的 O(3^N)。如果你有个20个联接的大型查询，这意味着 26 vs 3,486,784,401 ，天壤之别！

这个算法的问题是，我们做的假设是：找到 2 个表的最佳联接方法，保留这个联接结果，再联接下一个表，就能得到最低的成本。但是：

即使在 A, B, C 之间，A JOIN B 可得最低成本
(A JOIN C) JOIN B 也许比 (A JOIN B) JOIN C 更好。
为了改善这一状况，你可以多次使用基于不同规则的贪婪算法，并保留最佳的执行计划。

其他算法

[ 如果你已经受够了算法话题，就直接跳到下一部分。这部分对文章余下的内容不重要。] 【译者注：我也很想把这段跳过去 -_- 】

很多计算机科学研究者热衷于寻找最佳的执行计划，他们经常为特定问题或模式探寻更好的解决方案，比如：

如果查询是星型联接（一种多联接查询），某些数据库使用一种特定的算法。
如果查询是并行的，某些数据库使用一种特定的算法。 ……
其他算法也在研究之中，就是为了替换在大型查询中的动态规划算法。贪婪算法属于一个叫做启发式算法的大家族，它根据一条规则（或启发），保存上一步找到的方法，『附加』到当前步骤来进一步搜寻解决方法。有些算法根据特定规则，一步步的应用规则但不总是保留上一步找到的最佳方法。它们统称启发式算法。

比如，基因算法就是一种：

一个方法代表一种可能的完整查询计划
每一步保留了 P 个方法（即计划），而不是一个。
0) P 个计划随机创建
1) 成本最低的计划才会保留
2) 这些最佳计划混合在一起产生 P 个新的计划
3) 一些新的计划被随机改写
4) 1，2，3步重复 T 次
5) 然后在最后一次循环，从 P 个计划里得到最佳计划。
循环次数越多，计划就越好。

我们来看看 SQLite 优化器 是怎么工作的。这是个轻量化数据库，它使用一种简单优化器，基于带有附加规则的贪婪算法，来限制可能性的数量。

SQLite 在有 CROSS JOIN 操作符时从不给表重新排序
使用嵌套联接
外联接始终按顺序评估
……
3.8.0之前的版本使用『最近邻居』贪婪算法来搜寻最佳查询计划
等等……我们见过这个算法！真是巧哈！
从3.8.0版本（发布于2015年）开始，SQLite使用『N最近邻居』贪婪算法来搜寻最佳查询计划
我们再看看另一个优化器是怎么工作的。IBM DB2 跟所有企业级数据库都类似，我讨论它是因为在切换到大数据之前，它是我最后真正使用的数据库。

看过官方文档后，我们了解到 DB2 优化器可以让你使用 7 种级别的优化：

对联接使用贪婪算法
    0 – 最小优化，使用索引扫描和嵌套循环联接，避免一些查询重写
    1 – 低级优化
    2 – 完全优化
对联接使用动态规划算法
    3 – 中等优化和粗略的近似法
    5 – 完全优化，使用带有启发式的所有技术
    7 – 完全优化，类似级别5，但不用启发式
    9 – 最大优化，完全不顾开销，考虑所有可能的联接顺序，包括笛卡尔乘积
可以看到 DB2 使用贪婪算法和动态规划算法。当然，他们不会把自己的启发算法分享出来的，因为查询优化器是数据库的看家本领。

DB2 的默认级别是 5，优化器使用下列特性： 【译者注：以下出现的一些概念我没有做考证，因为[ 这段不重要，可以跳过 ]】

使用所有可用的统计，包括线段树（frequent-value）和分位数统计（quantile statistics）。
使用所有查询重写规则（含物化查询表路由，materialized query table routing），除了在极少情况下适用的计算密集型规则。
使用动态规划模拟联接
    有限使用组合内关系（composite inner relation）
    对于涉及查找表的星型模式，有限使用笛卡尔乘积
考虑宽泛的访问方式，含列表预取（list prefetch，注：我们将讨论什么是列表预取），index ANDing（注：一种对索引的特殊操作），和物化查询表路由。
默认的，DB2 对联接排列使用受启发式限制的动态规划算法。

其它情况 (GROUP BY, DISTINCT…) 由简单规则处理。
&lt;/div&gt;
&lt;div class=&quot;row&quot;&gt;
查询计划缓存

由于创建查询计划是耗时的，大多数据库把计划保存在查询计划缓存，来避免重复计算。这个话题比较大，因为数据库需要知道什么时候更新过时的计划。办法是设置一个上限，如果一个表的统计变化超过了上限，关于该表的查询计划就从缓存中清除。

查询执行器

在这个阶段，我们有了一个优化的执行计划，再编译为可执行代码。然后，如果有足够资源（内存，CPU），查询执行器就会执行它。计划中的操作符 (JOIN, SORT BY …) 可以顺序或并行执行，这取决于执行器。为了获得和写入数据，查询执行器与数据管理器交互，本文下一部分来讨论数据管理器

在这一步，查询管理器执行了查询，需要从表和索引获取数据，于是向数据管理器提出请求。但是有 2 个问题：

关系型数据库使用事务模型，所以，当其他人在同一时刻使用或修改数据时，你无法得到这部分数据。
数据提取是数据库中速度最慢的操作，所以数据管理器需要足够聪明地获得数据并保存在内存缓冲区内。
在这一部分，我没看看关系型数据库是如何处理这两个问题的。我不会讲数据管理器是怎么获得数据的，因为这不是最重要的（而且本文已经够长的了！）。
&lt;/div&gt;
&lt;div class=&quot;row&quot;&gt;
缓存管理器

我已经说过，数据库的主要瓶颈是磁盘 I/O。为了提高性能，现代数据库使用缓存管理器。



查询执行器不会直接从文件系统拿数据，而是向缓存管理器要。缓存管理器有一个内存缓存区，叫做缓冲池，从内存读取数据显著地提升数据库性能。对此很难给出一个数量级，因为这取决于你需要的是哪种操作：

顺序访问（比如：全扫描） vs 随机访问（比如：按照row id访问）
读还是写
以及数据库使用的磁盘类型：

7.2k/10k/15k rpm的硬盘
SSD
RAID 1/5/…
要我说，内存比磁盘要快100到10万倍。

然而，这导致了另一个问题（数据库总是这样…)，缓存管理器需要在查询执行器使用数据之前得到数据，否则查询管理器不得不等待数据从缓慢的磁盘中读出来。

预读

这个问题叫预读。查询执行器知道它将需要什么数据，因为它了解整个查询流，而且通过统计也了解磁盘上的数据。道理是这样的：

当查询执行器处理它的第一批数据时
会告诉缓存管理器预先装载第二批数据
当开始处理第二批数据时
告诉缓存管理器预先装载第三批数据，并且告诉缓存管理器第一批可以从缓存里清掉了。
……
缓存管理器在缓冲池里保存所有的这些数据。为了确定一条数据是否有用，缓存管理器给缓存的数据添加了额外的信息（叫闩锁）。

有时查询执行器不知道它需要什么数据，有的数据库也不提供这个功能。相反，它们使用一种推测预读法（比如：如果查询执行器想要数据1、3、5，它不久后很可能会要 7、9、11），或者顺序预读法（这时候缓存管理器只是读取一批数据后简单地从磁盘加载下一批连续数据）。

为了监控预读的工作状况，现代数据库引入了一个度量叫缓冲/缓存命中率，用来显示请求的数据在缓存中找到而不是从磁盘读取的频率。

注：糟糕的缓存命中率不总是意味着缓存工作状态不佳。更多信息请阅读Oracle文档。

缓冲只是容量有限的内存空间，因此，为了加载新的数据，它需要移除一些数据。加载和清除缓存需要一些磁盘和网络I/O的成本。如果你有个经常执行的查询，那么每次都把查询结果加载然后清除，效率就太低了。现代数据库用缓冲区置换策略来解决这个问题。
&lt;/div&gt;
&lt;div class=&quot;row&quot;&gt;
缓冲区置换策略

多数现代数据库(至少 SQL Server, MySQL, Oracle 和 DB2)使用 LRU 算法。

LRU

LRU代表最近最少使用（Least Recently Used）算法，背后的原理是：在缓存里保留的数据是最近使用的，所以更有可能再次使用。

图解：



为了更好的理解，我假设缓冲区里的数据没有被闩锁锁住（就是说是可以被移除的）。在这个简单的例子里，缓冲区可以保存 3 个元素：

1：缓存管理器（简称CM）使用数据1，把它放入空的缓冲区
2：CM使用数据4，把它放入半载的缓冲区
3：CM使用数据3，把它放入半载的缓冲区
4：CM使用数据9，缓冲区满了，所以数据1被清除，因为它是最后一个最近使用的，数据9加入到缓冲区
5：CM使用数据4，数据4已经在缓冲区了，所以它再次成为第一个最近使用的。
6：CM使用数据1，缓冲区满了，所以数据9被清除，因为它是最后一个最近使用的，数据1加入到缓冲区
……
这个算法效果很好，但是有些限制。如果对一个大表执行全表扫描怎么办？换句话说，当表/索引的大小超出缓冲区会发生什么？使用这个算法会清除之前缓存内所有的数据，而且全扫描的数据很可能只使用一次。

改进

为了防止这个现象，有些数据库增加了特殊的规则，比如Oracle文档中的描述：

『对非常大的表来说，数据库通常使用直接路径来读取，即直接加载区块[……]，来避免填满缓冲区。对于中等大小的表，数据库可以使用直接读取或缓存读取。如果选择缓存读取，数据库把区块置于LRU的尾部，防止清空当前缓冲区。』
还有一些可能，比如使用高级版本的LRU，叫做 LRU-K。例如，SQL Server 使用 LRU-2。

这个算法的原理是把更多的历史记录考虑进来。简单LRU（也就是 LRU-1），只考虑最后一次使用的数据。LRU-K呢：

考虑数据最后第K次使用的情况
数据使用的次数加进了权重
一批新数据加载进入缓存，旧的但是经常使用的数据不会被清除（因为权重更高）
但是这个算法不会保留缓存中不再使用的数据
所以数据如果不再使用，权重值随着时间推移而降低
计算权重是需要成本的，所以SQL Server只是使用 K=2，这个值性能不错而且额外开销可以接受。

其他算法

当然还有其他管理缓存的算法，比如：

2Q（类LRU-K算法）
CLOCK（类LRU-K算法）
MRU（最新使用的算法，用LRU同样的逻辑但不同的规则）
LRFU（Least Recently and Frequently Used，最近最少使用最近最不常用）
……
写缓冲区

我只探讨了读缓存 —— 在使用之前预先加载数据。用来保存数据、成批刷入磁盘，而不是逐条写入数据从而造成很多单次磁盘访问。

要记住，缓冲区保存的是页（最小的数据单位）而不是行（逻辑上/人类习惯的观察数据的方式）。缓冲池内的页如果被修改了但还没有写入磁盘，就是脏页。有很多算法来决定写入脏页的最佳时机，但这个问题与事务的概念高度关联，下面我们就谈谈事务。
&lt;/div&gt;
&lt;div class=&quot;row&quot;&gt;
事务管理器

最后但同样重要的，是事务管理器，我们将看到这个进程是如何保证每个查询在自己的事务内执行的。但开始之前，我们需要理解ACID事务的概念。

现代数据库不会使用纯粹的隔离作为默认模式，因为它会带来巨大的性能消耗。SQL一般定义4个隔离级别：

串行化(Serializable，SQLite默认模式）：最高级别的隔离。两个同时发生的事务100%隔离，每个事务有自己的『世界』。
可重复读（Repeatable read，MySQL默认模式）：每个事务有自己的『世界』，除了一种情况。如果一个事务成功执行并且添加了新数据，这些数据对其他正在执行的事务是可见的。但是如果事务成功修改了一条数据，修改结果对正在运行的事务不可见。所以，事务之间只是在新数据方面突破了隔离，对已存在的数据仍旧隔离。
举个例子，如果事务A运行”SELECT count(1) from TABLE_X” ，然后事务B在 TABLE_X 加入一条新数据并提交，当事务A再运行一次 count(1)结果不会是一样的。
这叫幻读（phantom read）。
读取已提交（Read committed，Oracle、PostgreSQL、SQL Server默认模式）：可重复读+新的隔离突破。如果事务A读取了数据D，然后数据D被事务B修改（或删除）并提交，事务A再次读取数据D时数据的变化（或删除）是可见的。
这叫不可重复读（non-repeatable read）。
读取未提交（Read uncommitted）：最低级别的隔离，是读取已提交+新的隔离突破。如果事务A读取了数据D，然后数据D被事务B修改（但并未提交，事务B仍在运行中），事务A再次读取数据D时，数据修改是可见的。如果事务B回滚，那么事务A第二次读取的数据D是无意义的，因为那是事务B所做的从未发生的修改（已经回滚了嘛）。
这叫脏读（dirty read）。
多数数据库添加了自定义的隔离级别（比如 PostgreSQL、Oracle、SQL Server的快照隔离），而且并没有实现SQL规范里的所有级别（尤其是读取未提交级别）。

默认的隔离级别可以由用户/开发者在建立连接时覆盖（只需要增加很简单的一行代码）。
&lt;/div&gt;
&lt;div class=&quot;row&quot;&gt;
并发控制

确保隔离性、一致性和原子性的真正问题是对相同数据的写操作（增、更、删）：

如果所有事务只是读取数据，它们可以同时工作，不会更改另一个事务的行为。
如果（至少）有一个事务在修改其他事务读取的数据，数据库需要找个办法对其它事务隐藏这种修改。而且，它还需要确保这个修改操作不会被另一个看不到这些数据修改的事务擦除。
这个问题叫并发控制。

最简单的解决办法是依次执行每个事务（即顺序执行），但这样就完全没有伸缩性了，在一个多处理器/多核服务器上只有一个核心在工作，效率很低。

理想的办法是，每次一个事务创建或取消时：

监控所有事务的所有操作
检查是否2个（或更多）事务的部分操作因为读取/修改相同的数据而存在冲突
重新编排冲突事务中的操作来减少冲突的部分
按照一定的顺序执行冲突的部分（同时非冲突事务仍然在并发运行）
考虑事务有可能被取消
用更正规的说法，这是对冲突的调度问题。更具体点儿说，这是个非常困难而且CPU开销很大的优化问题。企业级数据库无法承担等待几个小时，来寻找每个新事务活动最好的调度，因此就使用不那么理想的方式以避免更多的时间浪费在解决冲突上。
&lt;/div&gt;
&lt;div class=&quot;row&quot;&gt;
锁管理器

为了解决这个问题，多数数据库使用锁和/或数据版本控制。这是个很大的话题，我会集中探讨锁，和一点点数据版本控制。

悲观锁

原理是：

如果一个事务需要一条数据
它就把数据锁住
如果另一个事务也需要这条数据
它就必须要等第一个事务释放这条数据
这个锁叫排他锁。
但是对一个仅仅读取数据的事务使用排他锁非常昂贵，因为这会迫使其它只需要读取相同数据的事务等待。因此就有了另一种锁，共享锁。

共享锁是这样的：

如果一个事务只需要读取数据A
它会给数据A加上『共享锁』并读取
如果第二个事务也需要仅仅读取数据A
它会给数据A加上『共享锁』并读取
如果第三个事务需要修改数据A
它会给数据A加上『排他锁』，但是必须等待另外两个事务释放它们的共享锁。
同样的，如果一块数据被加上排他锁，一个只需要读取该数据的事务必须等待排他锁释放才能给该数据加上共享锁。



锁管理器是添加和释放锁的进程，在内部用一个哈希表保存锁信息（关键字是被锁的数据），并且了解每一块数据是：

被哪个事务加的锁
哪个事务在等待数据解锁
死锁

但是使用锁会导致一种情况，2个事务永远在等待一块数据：

&lt;/div&gt;
&lt;div class=&quot;row&quot;&gt;

在本图中：

事务A 给 数据1 加上排他锁并且等待获取数据2
事务B 给 数据2 加上排他锁并且等待获取数据1
这叫死锁。

在死锁发生时，锁管理器要选择取消（回滚）一个事务，以便消除死锁。这可是个艰难的决定：

杀死数据修改量最少的事务（这样能减少回滚的成本）？
杀死持续时间最短的事务，因为其它事务的用户等的时间更长？
杀死能用更少时间结束的事务（避免可能的资源饥荒）？
一旦发生回滚，有多少事务会受到回滚的影响？
在作出选择之前，锁管理器需要检查是否有死锁存在。

哈希表可以看作是个图表（见上文图），图中出现循环就说明有死锁。由于检查循环是昂贵的（所有锁组成的图表是很庞大的），经常会通过简单的途径解决：使用超时设定。如果一个锁在超时时间内没有加上，那事务就进入死锁状态。

锁管理器也可以在加锁之前检查该锁会不会变成死锁，但是想要完美的做到这一点还是很昂贵的。因此这些预检经常设置一些基本规则。

两段锁

实现纯粹的隔离最简单的方法是：事务开始时获取锁，结束时释放锁。就是说，事务开始前必须等待确保自己能加上所有的锁，当事务结束时释放自己持有的锁。这是行得通的，但是为了等待所有的锁，大量的时间被浪费了。

更快的方法是两段锁协议（Two-Phase Locking Protocol，由 DB2 和 SQL Server使用），在这里，事务分为两个阶段：

成长阶段：事务可以获得锁，但不能释放锁。
收缩阶段：事务可以释放锁（对于已经处理完而且不会再次处理的数据），但不能获得新锁。


这两条简单规则背后的原理是：

释放不再使用的锁，来降低其它事务的等待时间
防止发生这类情况：事务最初获得的数据，在事务开始后被修改，当事务重新读取该数据时发生不一致。
这个规则可以很好地工作，但有个例外：如果修改了一条数据、释放了关联的锁后，事务被取消（回滚），而另一个事务读到了修改后的值，但最后这个值却被回滚。为了避免这个问题，所有独占锁必须在事务结束时释放。

多说几句

当然了，真实的数据库使用更复杂的系统，涉及到更多类型的锁（比如意向锁，intention locks）和更多的粒度（行级锁、页级锁、分区锁、表锁、表空间锁），但是道理是相同的。

我只探讨纯粹基于锁的方法，数据版本控制是解决这个问题的另一个方法。

版本控制是这样的：

每个事务可以在相同时刻修改相同的数据
每个事务有自己的数据拷贝（或者叫版本）
如果2个事务修改相同的数据，只接受一个修改，另一个将被拒绝，相关的事务回滚（或重新运行）
这将提高性能，因为：

读事务不会阻塞写事务
写事务不会阻塞读
没有『臃肿缓慢』的锁管理器带来的额外开销
除了两个事务写相同数据的时候，数据版本控制各个方面都比锁表现得更好。只不过，你很快就会发现磁盘空间消耗巨大。

数据版本控制和锁机制是两种不同的见解：乐观锁和悲观锁。两者各有利弊，完全取决于使用场景（读多还是写多）。关于数据版本控制，我推荐这篇非常优秀的文章，讲的是PostgreSQL如何实现多版本并发控制的。

一些数据库，比如DB2（直到版本 9.7）和 SQL Server（不含快照隔离）仅使用锁机制。其他的像PostgreSQL, MySQL 和 Oracle 使用锁和鼠标版本控制混合机制。我不知道是否有仅用版本控制的数据库（如果你知道请告诉我）。

[2015-08-20更新]一名读者告诉我：

Firebird 和 Interbase 用不带锁的版本控制。

版本控制对索引的影响挺有趣的：有时唯一索引会出现重复，索引的条目会多于表行数，等等。
如果你读过不同级别的隔离那部分内容，你会知道，提高隔离级别就会增加锁的数量和事务等待加锁的时间。这就是为什么多数数据库默认不会使用最高级别的隔离（即串行化）。

当然，你总是可以自己去主流数据库（像MySQL, PostgreSQL 或 Oracle）的文档里查一下。
&lt;/div&gt;
&lt;div class=&quot;row&quot;&gt;
日志管理器

我们已经知道，为了提升性能，数据库把数据保存在内存缓冲区内。但如果当事务提交时服务器崩溃，崩溃时还在内存里的数据会丢失，这破坏了事务的持久性。

你可以把所有数据都写在磁盘上，但是如果服务器崩溃，最终数据可能只有部分写入磁盘，这破坏了事务的原子性。

事务作出的任何修改必须是或者撤销，或者完成。

有 2 个办法解决这个问题：

影子副本/页（Shadow copies/pages）：每个事务创建自己的数据库副本（或部分数据库的副本），并基于这个副本来工作。一旦出错，这个副本就被移除；一旦成功，数据库立即使用文件系统的一个把戏，把副本替换到数据中，然后删掉『旧』数据。
事务日志（Transaction log）：事务日志是一个存储空间，在每次写盘之前，数据库在事务日志中写入一些信息，这样当事务崩溃或回滚，数据库知道如何移除或完成尚未完成的事务。
WAL（预写式日志）

影子副本/页在运行较多事务的大型数据库时制造了大量磁盘开销，所以现代数据库使用事务日志。事务日志必须保存在稳定的存储上，我不会深挖存储技术，但至少RAID磁盘是必须的，以防磁盘故障。

多数数据库（至少是Oracle, SQL Server, DB2, PostgreSQL, MySQL 和 SQLite) 使用预写日志协议（Write-Ahead Logging protocol ，WAL）来处理事务日志。WAL协议有 3 个规则：

1) 每个对数据库的修改都产生一条日志记录，在数据写入磁盘之前日志记录必须写入事务日志。
2) 日志记录必须按顺序写入；记录 A 发生在记录 B 之前，则 A 必须写在 B 之前。
3) 当一个事务提交时，在事务成功之前，提交顺序必须写入到事务日志。


这个工作由日志管理器完成。简单的理解就是，日志管理器处于缓存管理器（cache manager）和数据访问管理器（data access manager，负责把数据写入磁盘）之间，每个 update / delete / create / commit / rollback 操作在写入磁盘之前先写入事务日志。简单，对吧？

回答错误！ 我们研究了这么多内容，现在你应该知道与数据库相关的每一件事都带着『数据库效应』的诅咒。好吧，我们说正经的，问题在于，如何找到写日志的同时保持良好的性能的方法。如果事务日志写得太慢，整体都会慢下来。
&lt;/div&gt;
&lt;div class=&quot;row&quot;&gt;
ARIES

1992年，IBM 研究人员『发明』了WAL的增强版，叫 ARIES。ARIES 或多或少地在现代数据库中使用，逻辑未必相同，但AIRES背后的概念无处不在。我给发明加了引号是因为，按照MIT这门课的说法，IBM 的研究人员『仅仅是写了事务恢复的最佳实践方法』。AIRES 论文发表的时候我才 5 岁，我不关心那些酸溜溜的科研人员老掉牙的闲言碎语。事实上，我提及这个典故，是在开始探讨最后一个技术点前让你轻松一下。我阅读过这篇 ARIES 论文 的大量篇幅，发现它很有趣。在这一部分我只是简要的谈一下 ARIES，不过我强烈建议，如果你想了解真正的知识，就去读那篇论文。

ARIES 代表『数据库恢复原型算法』（Algorithms for Recovery and Isolation Exploiting Semantics）。

这个技术要达到一个双重目标：

1) 写日志的同时保持良好性能
2) 快速和可靠的数据恢复
有多个原因让数据库不得不回滚事务：

因为用户取消
因为服务器或网络故障
因为事务破坏了数据库完整性（比如一个列有唯一性约束而事务添加了重复值）
因为死锁
有时候（比如网络出现故障），数据库可以恢复事务。

这怎么可能呢？为了回答这个问题，我们需要了解日志里保存的信息。
&lt;/div&gt;
&lt;div class=&quot;row&quot;&gt;
日志

事务的每一个操作（增/删/改）产生一条日志，由如下内容组成：

LSN：一个唯一的日志序列号（Log Sequence Number）。LSN是按时间顺序分配的 * ，这意味着如果操作 A 先于操作 B，log A 的 LSN 要比 log B 的 LSN 小。
TransID：产生操作的事务ID。
PageID：被修改的数据在磁盘上的位置。磁盘数据的最小单位是页，所以数据的位置就是它所处页的位置。
PrevLSN：同一个事务产生的上一条日志记录的链接。
UNDO：取消本次操作的方法。
比如，如果操作是一次更新，UNDO将或者保存元素更新前的值/状态（物理UNDO），或者回到原来状态的反向操作（逻辑UNDO） **。
REDO：重复本次操作的方法。 同样的，有 2 种方法：或者保存操作后的元素值/状态，或者保存操作本身以便重复。
…：（供您参考，一个 ARIES 日志还有 2 个字段：UndoNxtLSN 和 Type）。
进一步说，磁盘上每个页（保存数据的，不是保存日志的）都记录着最后一个修改该数据操作的LSN。

*LSN的分配其实更复杂，因为它关系到日志存储的方式。但道理是相同的。

** ARIES 只使用逻辑UNDO，因为处理物理UNDO太过混乱了。

注：据我所知，只有 PostgreSQL 没有使用UNDO，而是用一个垃圾回收服务来删除旧版本的数据。这个跟 PostgreSQL 对数据版本控制的实现有关。

为了更好的说明这一点，这有一个简单的日志记录演示图，是由查询 “UPDATE FROM PERSON SET AGE = 18;” 产生的，我们假设这个查询是事务18执行的。【译者注： SQL 语句原文如此，应该是作者笔误 】



每条日志都有一个唯一的LSN，链接在一起的日志属于同一个事务。日志按照时间顺序链接（链接列表的最后一条日志是最后一个操作产生的）。

日志缓冲区

为了防止写日志成为主要的瓶颈，数据库使用了日志缓冲区。

&lt;/div&gt;
&lt;div class=&quot;row&quot;&gt;

当查询执行器要求做一次修改：

1) 缓存管理器将修改存入自己的缓冲区；
2) 日志管理器将相关的日志存入自己的缓冲区；
3) 到了这一步，查询执行器认为操作完成了（因此可以请求做另一次修改）；
4) 接着（不久以后）日志管理器把日志写入事务日志，什么时候写日志由某算法来决定。
5) 接着（不久以后）缓存管理器把修改写入磁盘，什么时候写盘由某算法来决定。
当事务提交，意味着事务每一个操作的 1 2 3 4 5 步骤都完成了。写事务日志是很快的，因为它只是『在事务日志某处增加一条日志』；而数据写盘就更复杂了，因为要用『能够快速读取的方式写入数据』。

STEAL 和 FORCE 策略

出于性能方面的原因，第 5 步有可能在提交之后完成，因为一旦发生崩溃，还有可能用REDO日志恢复事务。这叫做 NO-FORCE策略。

数据库可以选择FORCE策略（比如第 5 步在提交之前必须完成）来降低恢复时的负载。

另一个问题是，要选择数据是一步步的写入（STEAL策略），还是缓冲管理器需要等待提交命令来一次性全部写入（NO-STEAL策略）。选择STEAL还是NO-STEAL取决于你想要什么：快速写入但是从 UNDO 日志恢复缓慢，还是快速恢复。

总结一下这些策略对恢复的影响：

STEAL/NO-FORCE 需要 UNDO 和 REDO: 性能高，但是日志和恢复过程更复杂 (比如 ARIES)。多数数据库选择这个策略。 注：这是我从多个学术论文和教程里看到的，但并没有看到官方文档里显式说明这一点。
STEAL/ FORCE 只需要 UNDO.
NO-STEAL/NO-FORCE 只需要 REDO.
NO-STEAL/FORCE 什么也不需要: 性能最差，而且需要巨大的内存。
关于恢复

Ok，有了不错的日志，我们来用用它们！

假设新来的实习生让数据库崩溃了（首要规矩：永远是实习生的错。），你重启了数据库，恢复过程开始了。

ARIES从崩溃中恢复有三个阶段：

1) 分析阶段：恢复进程读取全部事务日志，来重建崩溃过程中所发生事情的时间线，决定哪个事务要回滚（所有未提交的事务都要回滚）、崩溃时哪些数据需要写盘。
2) Redo阶段：这一关从分析中选中的一条日志记录开始，使用 REDO 来将数据库恢复到崩溃之前的状态。
在REDO阶段，REDO日志按照时间顺序处理（使用LSN）。

对每一条日志，恢复进程需要读取包含数据的磁盘页LSN。

如果LSN（磁盘页）&amp;gt;= LSN（日志记录），说明数据已经在崩溃前写到磁盘（但是值已经被日志之后、崩溃之前的某个操作覆盖），所以不需要做什么。

如果LSN（磁盘页）&amp;lt; LSN（日志记录），那么磁盘上的页将被更新。

即使将被回滚的事务，REDO也是要做的，因为这样简化了恢复过程（但是我相信现代数据库不会这么做的）。

3) Undo阶段：这一阶段回滚所有崩溃时未完成的事务。回滚从每个事务的最后一条日志开始，并且按照时间倒序处理UNDO日志（使用日志记录的PrevLSN）。
 

恢复过程中，事务日志必须留意恢复过程的操作，以便写入磁盘的数据与事务日志相一致。一个解决办法是移除被取消的事务产生的日志记录，但是这个太困难了。相反，ARIES在事务日志中记录补偿日志，来逻辑上删除被取消的事务的日志记录。

当事务被『手工』取消，或者被锁管理器取消（为了消除死锁），或仅仅因为网络故障而取消，那么分析阶段就不需要了。对于哪些需要 REDO 哪些需要 UNDO 的信息在 2 个内存表中：

事务表（保存当前所有事务的状态）
脏页表（保存哪些数据需要写入磁盘）
当新的事务产生时，这两个表由缓存管理器和事务管理器更新。因为是在内存中，当数据库崩溃时它们也被破坏掉了。

分析阶段的任务就是在崩溃之后，用事务日志中的信息重建上述的两个表。为了加快分析阶段，ARIES提出了一个概念：检查点（check point），就是不时地把事务表和脏页表的内容，还有此时最后一条LSN写入磁盘。那么在分析阶段当中，只需要分析这个LSN之后的日志即可。
&lt;/div&gt;
&lt;/div&gt;
</description>
        <pubDate>Thu, 16 Nov 2017 00:00:00 +0800</pubDate>
        <link>https://xiazemin.github.io/MyBlog/web/2017/11/16/mysql_maneager.html</link>
        <guid isPermaLink="true">https://xiazemin.github.io/MyBlog/web/2017/11/16/mysql_maneager.html</guid>
        
        
        <category>web</category>
        
      </item>
    
      <item>
        <title>mysql_index</title>
        <description>&lt;p&gt;MySQL官方对索引的定义为：索引（Index）是帮助MySQL高效获取数据的数据结构。提取句子主干，就可以得到索引的本质：索引是数据结构。&lt;/p&gt;

&lt;p&gt;我们知道，数据库查询是数据库的最主要功能之一。我们都希望查询数据的速度能尽可能的快，因此数据库系统的设计者会从查询算法的角度进行优化。最基本的查询算法当然是顺序查找（linear search），这种复杂度为O(n)的算法在数据量很大时显然是糟糕的，好在计算机科学的发展提供了很多更优秀的查找算法，例如二分查找（binary search）、二叉树查找（binary tree search）等。如果稍微分析一下会发现，每种查找算法都只能应用于特定的数据结构之上，例如二分查找要求被检索数据有序，而二叉树查找只能应用于二叉查找树上，但是数据本身的组织结构不可能完全满足各种数据结构（例如，理论上不可能同时将两列都按顺序进行组织），所以，在数据之外，数据库系统还维护着满足特定查找算法的数据结构，这些数据结构以某种方式引用（指向）数据，这样就可以在这些数据结构上实现高级查找算法。这种数据结构，就是索引。
实际的数据库系统几乎没有使用二叉查找树或其进化品种红黑树（red-black tree）实现的，原因会在下文介绍。&lt;/p&gt;

&lt;p&gt;B-Tree和B+Tree&lt;/p&gt;

&lt;p&gt;目前大部分数据库系统及文件系统都采用B-Tree或其变种B+Tree作为索引结构，在本文的下一节会结合存储器原理及计算机存取原理讨论为什么B-Tree和B+Tree在被如此广泛用于索引，这一节先单纯从数据结构角度描述它们。&lt;/p&gt;

&lt;p&gt;B-Tree&lt;/p&gt;

&lt;p&gt;为了描述B-Tree，首先定义一条数据记录为一个二元组[key, data]，key为记录的键值，对于不同数据记录，key是互不相同的；data为数据记录除key外的数据。那么B-Tree是满足下列条件的数据结构：&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;
    &lt;p&gt;d为大于1的一个正整数，称为B-Tree的度。&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;h为一个正整数，称为B-Tree的高度。&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;每个非叶子节点由n-1个key和n个指针组成，其中d&amp;lt;=n&amp;lt;=2d。&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;每个叶子节点最少包含一个key和两个指针，最多包含2d-1个key和2d个指针，叶节点的指针均为null 。&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;所有叶节点具有相同的深度，等于树高h。&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;key和指针互相间隔，节点两端是指针。&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;一个节点中的key从左到右非递减排列。&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;所有节点组成树结构。&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;每个指针要么为null，要么指向另外一个节点。&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;如果某个指针在节点node最左边且不为null，则其指向节点的所有key小于v(key1)，其中v(key1)为node的第一个key的值。&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;如果某个指针在节点node最右边且不为null，则其指向节点的所有key大于v(keym)，其中v(keym)为node的最后一个key的值。&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;如果某个指针在节点node的左右相邻key分别是keyi和keyi+1且不为null，则其指向节点的所有key小于v(keyi+1)且大于v(keyi)。&lt;/p&gt;
  &lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;图2是一个d=2的B-Tree示意图。&lt;/p&gt;

&lt;p&gt;MySQL索引背后的数据结构及算法原理
由于B-Tree的特性，在B-Tree中按key检索数据的算法非常直观：首先从根节点进行二分查找，如果找到则返回对应节点的data，否则对相应区间的指针指向的节点递归进行查找，直到找到节点或找到null指针，前者查找成功，后者查找失败。B-Tree上查找算法的伪代码如下：&lt;/p&gt;

&lt;p&gt;C&lt;/p&gt;

&lt;p&gt;BTree_Search(node, key)
{
    if(node == null) return null;&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;foreach(node.key)
{
    if(node.key[i] == key) return node.data[i];
    if(node.key[i] &amp;gt; key) return BTree_Search(point[i]-&amp;gt;node);
}

return BTree_Search(point[i+1]-&amp;gt;node); }
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;data = BTree_Search(root, my_key);&lt;/p&gt;

&lt;p&gt;BTree_Search(node, key)
{
    if(node == null) return null;&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;foreach(node.key)
{
    if(node.key[i] == key) return node.data[i];
    if(node.key[i] &amp;gt; key) return BTree_Search(point[i]-&amp;gt;node);
}
 
return BTree_Search(point[i+1]-&amp;gt;node); }
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;data = BTree_Search(root, my_key);
关于B-Tree有一系列有趣的性质，例如一个度为d的B-Tree，设其索引N个key，则其树高h的上限为logd((N+1)/2)，检索一个key，其查找节点个数的渐进复杂度为O(logdN)。从这点可以看出，B-Tree是一个非常有效率的索引数据结构。&lt;/p&gt;

&lt;p&gt;另外，由于插入删除新的数据记录会破坏B-Tree的性质，因此在插入删除时，需要对树进行一个分裂、合并、转移等操作以保持B-Tree性质，本文不打算完整讨论B-Tree这些内容，因为已经有许多资料详细说明了B-Tree的数学性质及插入删除算法，有兴趣的朋友可以在本文末的参考文献一栏找到相应的资料进行阅读。&lt;/p&gt;

&lt;p&gt;B+Tree&lt;/p&gt;

&lt;p&gt;B-Tree有许多变种，其中最常见的是B+Tree，例如MySQL就普遍使用B+Tree实现其索引结构。&lt;/p&gt;

&lt;p&gt;与B-Tree相比，B+Tree有以下不同点：&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;
    &lt;p&gt;每个节点的指针上限为2d而不是2d+1。&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;内节点不存储data，只存储key；叶子节点不存储指针。&lt;/p&gt;
  &lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;图3是一个简单的B+Tree示意。&lt;/p&gt;

&lt;p&gt;MySQL索引背后的数据结构及算法原理
由于并不是所有节点都具有相同的域，因此B+Tree中叶节点和内节点一般大小不同。这点与B-Tree不同，虽然B-Tree中不同节点存放的key和指针可能数量不一致，但是每个节点的域和上限是一致的，所以在实现中B-Tree往往对每个节点申请同等大小的空间。&lt;/p&gt;

&lt;p&gt;一般来说，B+Tree比B-Tree更适合实现外存储索引结构，具体原因与外存储器原理及计算机存取原理有关，将在下面讨论。&lt;/p&gt;

&lt;p&gt;带有顺序访问指针的B+Tree&lt;/p&gt;

&lt;p&gt;一般在数据库系统或文件系统中使用的B+Tree结构都在经典B+Tree的基础上进行了优化，增加了顺序访问指针。&lt;/p&gt;

&lt;p&gt;MySQL索引背后的数据结构及算法原理&lt;/p&gt;

&lt;p&gt;如图4所示，在B+Tree的每个叶子节点增加一个指向相邻叶子节点的指针，就形成了带有顺序访问指针的B+Tree。做这个优化的目的是为了提高区间访问的性能，例如图4中如果要查询key为从18到49的所有数据记录，当找到18后，只需顺着节点和指针顺序遍历就可以一次性访问到所有数据节点，极大提到了区间查询效率。&lt;/p&gt;

&lt;p&gt;这一节对B-Tree和B+Tree进行了一个简单的介绍，下一节结合存储器存取原理介绍为什么目前B+Tree是数据库系统实现索引的首选数据结构。&lt;/p&gt;

&lt;p&gt;为什么使用B-Tree（B+Tree）&lt;/p&gt;

&lt;p&gt;上文说过，红黑树等数据结构也可以用来实现索引，但是文件系统及数据库系统普遍采用B-/+Tree作为索引结构，这一节将结合计算机组成原理相关知识讨论B-/+Tree作为索引的理论基础。&lt;/p&gt;

&lt;p&gt;一般来说，索引本身也很大，不可能全部存储在内存中，因此索引往往以索引文件的形式存储的磁盘上。这样的话，索引查找过程中就要产生磁盘I/O消耗，相对于内存存取，I/O存取的消耗要高几个数量级，所以评价一个数据结构作为索引的优劣最重要的指标就是在查找过程中磁盘I/O操作次数的渐进复杂度。换句话说，索引的结构组织要尽量减少查找过程中磁盘I/O的存取次数。下面先介绍内存和磁盘存取原理，然后再结合这些原理分析B-/+Tree作为索引的效率。&lt;/p&gt;

&lt;p&gt;主存存取原理&lt;/p&gt;

&lt;p&gt;目前计算机使用的主存基本都是随机读写存储器（RAM），现代RAM的结构和存取原理比较复杂，这里本文抛却具体差别，抽象出一个十分简单的存取模型来说明RAM的工作原理。&lt;/p&gt;

&lt;p&gt;MySQL索引背后的数据结构及算法原理&lt;/p&gt;

&lt;p&gt;从抽象角度看，主存是一系列的存储单元组成的矩阵，每个存储单元存储固定大小的数据。每个存储单元有唯一的地址，现代主存的编址规则比较复杂，这里将其简化成一个二维地址：通过一个行地址和一个列地址可以唯一定位到一个存储单元。图5展示了一个4 x 4的主存模型。&lt;/p&gt;

&lt;p&gt;主存的存取过程如下：&lt;/p&gt;

&lt;p&gt;当系统需要读取主存时，则将地址信号放到地址总线上传给主存，主存读到地址信号后，解析信号并定位到指定存储单元，然后将此存储单元数据放到数据总线上，供其它部件读取。&lt;/p&gt;

&lt;p&gt;写主存的过程类似，系统将要写入单元地址和数据分别放在地址总线和数据总线上，主存读取两个总线的内容，做相应的写操作。&lt;/p&gt;

&lt;p&gt;这里可以看出，主存存取的时间仅与存取次数呈线性关系，因为不存在机械操作，两次存取的数据的“距离”不会对时间有任何影响，例如，先取A0再取A1和先取A0再取D3的时间消耗是一样的。&lt;/p&gt;

&lt;p&gt;磁盘存取原理&lt;/p&gt;

&lt;p&gt;上文说过，索引一般以文件形式存储在磁盘上，索引检索需要磁盘I/O操作。与主存不同，磁盘I/O存在机械运动耗费，因此磁盘I/O的时间消耗是巨大的。&lt;/p&gt;

&lt;p&gt;图6是磁盘的整体结构示意图。&lt;/p&gt;

&lt;p&gt;MySQL索引背后的数据结构及算法原理&lt;/p&gt;

&lt;p&gt;一个磁盘由大小相同且同轴的圆形盘片组成，磁盘可以转动（各个磁盘必须同步转动）。在磁盘的一侧有磁头支架，磁头支架固定了一组磁头，每个磁头负责存取一个磁盘的内容。磁头不能转动，但是可以沿磁盘半径方向运动（实际是斜切向运动），每个磁头同一时刻也必须是同轴的，即从正上方向下看，所有磁头任何时候都是重叠的（不过目前已经有多磁头独立技术，可不受此限制）。&lt;/p&gt;

&lt;p&gt;图7是磁盘结构的示意图。&lt;/p&gt;

&lt;p&gt;MySQL索引背后的数据结构及算法原理
盘片被划分成一系列同心环，圆心是盘片中心，每个同心环叫做一个磁道，所有半径相同的磁道组成一个柱面。磁道被沿半径线划分成一个个小的段，每个段叫做一个扇区，每个扇区是磁盘的最小存储单元。为了简单起见，我们下面假设磁盘只有一个盘片和一个磁头。&lt;/p&gt;

&lt;p&gt;当需要从磁盘读取数据时，系统会将数据逻辑地址传给磁盘，磁盘的控制电路按照寻址逻辑将逻辑地址翻译成物理地址，即确定要读的数据在哪个磁道，哪个扇区。为了读取这个扇区的数据，需要将磁头放到这个扇区上方，为了实现这一点，磁头需要移动对准相应磁道，这个过程叫做寻道，所耗费时间叫做寻道时间，然后磁盘旋转将目标扇区旋转到磁头下，这个过程耗费的时间叫做旋转时间。&lt;/p&gt;

&lt;p&gt;局部性原理与磁盘预读&lt;/p&gt;

&lt;p&gt;由于存储介质的特性，磁盘本身存取就比主存慢很多，再加上机械运动耗费，磁盘的存取速度往往是主存的几百分分之一，因此为了提高效率，要尽量减少磁盘I/O。为了达到这个目的，磁盘往往不是严格按需读取，而是每次都会预读，即使只需要一个字节，磁盘也会从这个位置开始，顺序向后读取一定长度的数据放入内存。这样做的理论依据是计算机科学中著名的局部性原理：&lt;/p&gt;

&lt;p&gt;当一个数据被用到时，其附近的数据也通常会马上被使用。&lt;/p&gt;

&lt;p&gt;程序运行期间所需要的数据通常比较集中。&lt;/p&gt;

&lt;p&gt;由于磁盘顺序读取的效率很高（不需要寻道时间，只需很少的旋转时间），因此对于具有局部性的程序来说，预读可以提高I/O效率。&lt;/p&gt;

&lt;p&gt;预读的长度一般为页（page）的整倍数。页是计算机管理存储器的逻辑块，硬件及操作系统往往将主存和磁盘存储区分割为连续的大小相等的块，每个存储块称为一页（在许多操作系统中，页得大小通常为4k），主存和磁盘以页为单位交换数据。当程序要读取的数据不在主存中时，会触发一个缺页异常，此时系统会向磁盘发出读盘信号，磁盘会找到数据的起始位置并向后连续读取一页或几页载入内存中，然后异常返回，程序继续运行。&lt;/p&gt;

&lt;p&gt;B-/+Tree索引的性能分析&lt;/p&gt;

&lt;p&gt;到这里终于可以分析B-/+Tree索引的性能了。&lt;/p&gt;

&lt;p&gt;上文说过一般使用磁盘I/O次数评价索引结构的优劣。先从B-Tree分析，根据B-Tree的定义，可知检索一次最多需要访问h个节点。数据库系统的设计者巧妙利用了磁盘预读原理，将一个节点的大小设为等于一个页，这样每个节点只需要一次I/O就可以完全载入。为了达到这个目的，在实际实现B-Tree还需要使用如下技巧：&lt;/p&gt;

&lt;p&gt;每次新建节点时，直接申请一个页的空间，这样就保证一个节点物理上也存储在一个页里，加之计算机存储分配都是按页对齐的，就实现了一个node只需一次I/O。&lt;/p&gt;

&lt;p&gt;B-Tree中一次检索最多需要h-1次I/O（根节点常驻内存），渐进复杂度为O(h)=O(logdN)。一般实际应用中，出度d是非常大的数字，通常超过100，因此h非常小（通常不超过3）。&lt;/p&gt;

&lt;p&gt;综上所述，用B-Tree作为索引结构效率是非常高的。&lt;/p&gt;

&lt;p&gt;而红黑树这种结构，h明显要深的多。由于逻辑上很近的节点（父子）物理上可能很远，无法利用局部性，所以红黑树的I/O渐进复杂度也为O(h)，效率明显比B-Tree差很多。&lt;/p&gt;

&lt;p&gt;上文还说过，B+Tree更适合外存索引，原因和内节点出度d有关。从上面分析可以看到，d越大索引的性能越好，而出度的上限取决于节点内key和data的大小：&lt;/p&gt;

&lt;p&gt;dmax = floor(pagesize / (keysize + datasize + pointsize))   (pagesize – dmax &amp;gt;= pointsize)&lt;/p&gt;

&lt;p&gt;或&lt;/p&gt;

&lt;p&gt;dmax = floor(pagesize / (keysize + datasize + pointsize)) – 1   (pagesize – dmax &amp;lt; pointsize)&lt;/p&gt;

&lt;p&gt;floor表示向下取整。由于B+Tree内节点去掉了data域，因此可以拥有更大的出度，拥有更好的性能。&lt;/p&gt;

&lt;p&gt;这一章从理论角度讨论了与索引相关的数据结构与算法问题，下一章将讨论B+Tree是如何具体实现为MySQL中索引，同时将结合MyISAM和InnDB存储引擎介绍非聚集索引和聚集索引两种不同的索引实现形式。&lt;/p&gt;

&lt;p&gt;MySQL索引实现&lt;/p&gt;

&lt;p&gt;在MySQL中，索引属于存储引擎级别的概念，不同存储引擎对索引的实现方式是不同的，本文主要讨论MyISAM和InnoDB两个存储引擎的索引实现方式。&lt;/p&gt;

&lt;p&gt;MyISAM索引实现&lt;/p&gt;

&lt;p&gt;MyISAM引擎使用B+Tree作为索引结构，叶节点的data域存放的是数据记录的地址。下图是MyISAM索引的原理图：&lt;/p&gt;

&lt;p&gt;MySQL索引背后的数据结构及算法原理
这里设表一共有三列，假设我们以Col1为主键，则图8是一个MyISAM表的主索引（Primary key）示意。可以看出MyISAM的索引文件仅仅保存数据记录的地址。在MyISAM中，主索引和辅助索引（Secondary key）在结构上没有任何区别，只是主索引要求key是唯一的，而辅助索引的key可以重复。如果我们在Col2上建立一个辅助索引，则此索引的结构如下图所示：&lt;/p&gt;

&lt;p&gt;MySQL索引背后的数据结构及算法原理
同样也是一颗B+Tree，data域保存数据记录的地址。因此，MyISAM中索引检索的算法为首先按照B+Tree搜索算法搜索索引，如果指定的Key存在，则取出其data域的值，然后以data域的值为地址，读取相应数据记录。&lt;/p&gt;

&lt;p&gt;MyISAM的索引方式也叫做“非聚集”的，之所以这么称呼是为了与InnoDB的聚集索引区分。&lt;/p&gt;

&lt;p&gt;InnoDB索引实现&lt;/p&gt;

&lt;p&gt;虽然InnoDB也使用B+Tree作为索引结构，但具体实现方式却与MyISAM截然不同。&lt;/p&gt;

&lt;p&gt;第一个重大区别是InnoDB的数据文件本身就是索引文件。从上文知道，MyISAM索引文件和数据文件是分离的，索引文件仅保存数据记录的地址。而在InnoDB中，表数据文件本身就是按B+Tree组织的一个索引结构，这棵树的叶节点data域保存了完整的数据记录。这个索引的key是数据表的主键，因此InnoDB表数据文件本身就是主索引。&lt;/p&gt;

&lt;p&gt;MySQL索引背后的数据结构及算法原理&lt;/p&gt;

&lt;p&gt;是InnoDB主索引（同时也是数据文件）的示意图，可以看到叶节点包含了完整的数据记录。这种索引叫做聚集索引。因为InnoDB的数据文件本身要按主键聚集，所以InnoDB要求表必须有主键（MyISAM可以没有），如果没有显式指定，则MySQL系统会自动选择一个可以唯一标识数据记录的列作为主键，如果不存在这种列，则MySQL自动为InnoDB表生成一个隐含字段作为主键，这个字段长度为6个字节，类型为长整形。&lt;/p&gt;

&lt;p&gt;第二个与MyISAM索引的不同是InnoDB的辅助索引data域存储相应记录主键的值而不是地址。换句话说，InnoDB的所有辅助索引都引用主键作为data域。例如，图11为定义在Col3上的一个辅助索引：&lt;/p&gt;

&lt;p&gt;MySQL索引背后的数据结构及算法原理
这里以英文字符的ASCII码作为比较准则。聚集索引这种实现方式使得按主键的搜索十分高效，但是辅助索引搜索需要检索两遍索引：首先检索辅助索引获得主键，然后用主键到主索引中检索获得记录。&lt;/p&gt;

&lt;p&gt;了解不同存储引擎的索引实现方式对于正确使用和优化索引都非常有帮助，例如知道了InnoDB的索引实现后，就很容易明白为什么不建议使用过长的字段作为主键，因为所有辅助索引都引用主索引，过长的主索引会令辅助索引变得过大。再例如，用非单调的字段作为主键在InnoDB中不是个好主意，因为InnoDB数据文件本身是一颗B+Tree，非单调的主键会造成在插入新记录时数据文件为了维持B+Tree的特性而频繁的分裂调整，十分低效，而使用自增字段作为主键则是一个很好的选择。&lt;/p&gt;
</description>
        <pubDate>Thu, 16 Nov 2017 00:00:00 +0800</pubDate>
        <link>https://xiazemin.github.io/MyBlog/web/2017/11/16/mysql_index.html</link>
        <guid isPermaLink="true">https://xiazemin.github.io/MyBlog/web/2017/11/16/mysql_index.html</guid>
        
        
        <category>web</category>
        
      </item>
    
      <item>
        <title>MySQL的表类型的（存储引擎）</title>
        <description>&lt;p&gt;查看数据库支持的存储引擎： \G或者分号表示命令结束
MySQL&amp;gt;show engines \G
or show variables like ‘have%’;
mysql -h localhost -u root -p123
show databases;
use database;
show tables;&lt;/p&gt;

&lt;p&gt;创建指定存储引擎的表：
create table tableA(
i bigint(20) not null auto_increment,
primary key(i)
)engine=MyISAM default charset=gbk;&lt;/p&gt;

&lt;p&gt;改变表的存储引擎：
alter
table tableA engine=innodb;&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;show engines \G
ERROR 2006 (HY000): MySQL server has gone away
No connection. Trying to reconnect…
Connection id:    1
Current database: carpool&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;&lt;strong&gt;**&lt;/strong&gt;&lt;strong&gt;**&lt;/strong&gt;&lt;strong&gt;**&lt;/strong&gt;&lt;strong&gt;**&lt;/strong&gt;&lt;strong&gt;* 1. row **&lt;/strong&gt;&lt;strong&gt;**&lt;/strong&gt;&lt;strong&gt;**&lt;/strong&gt;&lt;strong&gt;**&lt;/strong&gt;&lt;strong&gt;***
      Engine: InnoDB
     Support: DEFAULT
     Comment: Supports transactions, row-level locking, and foreign keys
Transactions: YES
          XA: YES
  Savepoints: YES
**&lt;/strong&gt;&lt;strong&gt;**&lt;/strong&gt;&lt;strong&gt;**&lt;/strong&gt;&lt;strong&gt;**&lt;/strong&gt;&lt;strong&gt;*** 2. row **&lt;/strong&gt;&lt;strong&gt;**&lt;/strong&gt;&lt;strong&gt;**&lt;/strong&gt;&lt;strong&gt;**&lt;/strong&gt;&lt;strong&gt;***
      Engine: MRG_MYISAM
     Support: YES
     Comment: Collection of identical MyISAM tables
Transactions: NO
          XA: NO
  Savepoints: NO
**&lt;/strong&gt;&lt;strong&gt;**&lt;/strong&gt;&lt;strong&gt;**&lt;/strong&gt;&lt;strong&gt;**&lt;/strong&gt;&lt;strong&gt;*** 3. row **&lt;/strong&gt;&lt;strong&gt;**&lt;/strong&gt;&lt;strong&gt;**&lt;/strong&gt;&lt;strong&gt;**&lt;/strong&gt;&lt;strong&gt;***
      Engine: MEMORY
     Support: YES
     Comment: Hash based, stored in memory, useful for temporary tables
Transactions: NO
          XA: NO
  Savepoints: NO
**&lt;/strong&gt;&lt;strong&gt;**&lt;/strong&gt;&lt;strong&gt;**&lt;/strong&gt;&lt;strong&gt;**&lt;/strong&gt;&lt;strong&gt;*** 4. row **&lt;/strong&gt;&lt;strong&gt;**&lt;/strong&gt;&lt;strong&gt;**&lt;/strong&gt;&lt;strong&gt;**&lt;/strong&gt;&lt;strong&gt;***
      Engine: BLACKHOLE
     Support: YES
     Comment: /dev/null storage engine (anything you write to it disappears)
Transactions: NO
          XA: NO
  Savepoints: NO
**&lt;/strong&gt;&lt;strong&gt;**&lt;/strong&gt;&lt;strong&gt;**&lt;/strong&gt;&lt;strong&gt;**&lt;/strong&gt;&lt;strong&gt;*** 5. row **&lt;/strong&gt;&lt;strong&gt;**&lt;/strong&gt;&lt;strong&gt;**&lt;/strong&gt;&lt;strong&gt;**&lt;/strong&gt;&lt;strong&gt;***
      Engine: MyISAM
     Support: YES
     Comment: MyISAM storage engine
Transactions: NO
          XA: NO
  Savepoints: NO
**&lt;/strong&gt;&lt;strong&gt;**&lt;/strong&gt;&lt;strong&gt;**&lt;/strong&gt;&lt;strong&gt;**&lt;/strong&gt;&lt;strong&gt;*** 6. row **&lt;/strong&gt;&lt;strong&gt;**&lt;/strong&gt;&lt;strong&gt;**&lt;/strong&gt;&lt;strong&gt;**&lt;/strong&gt;&lt;strong&gt;***
      Engine: CSV
     Support: YES
     Comment: CSV storage engine
Transactions: NO
          XA: NO
  Savepoints: NO
**&lt;/strong&gt;&lt;strong&gt;**&lt;/strong&gt;&lt;strong&gt;**&lt;/strong&gt;&lt;strong&gt;**&lt;/strong&gt;&lt;strong&gt;*** 7. row **&lt;/strong&gt;&lt;strong&gt;**&lt;/strong&gt;&lt;strong&gt;**&lt;/strong&gt;&lt;strong&gt;**&lt;/strong&gt;&lt;strong&gt;***
      Engine: ARCHIVE
     Support: YES
     Comment: Archive storage engine
Transactions: NO
          XA: NO
  Savepoints: NO
**&lt;/strong&gt;&lt;strong&gt;**&lt;/strong&gt;&lt;strong&gt;**&lt;/strong&gt;&lt;strong&gt;**&lt;/strong&gt;&lt;strong&gt;*** 8. row **&lt;/strong&gt;&lt;strong&gt;**&lt;/strong&gt;&lt;strong&gt;**&lt;/strong&gt;&lt;strong&gt;**&lt;/strong&gt;&lt;strong&gt;***
      Engine: PERFORMANCE_SCHEMA
     Support: YES
     Comment: Performance Schema
Transactions: NO
          XA: NO
  Savepoints: NO
**&lt;/strong&gt;&lt;strong&gt;**&lt;/strong&gt;&lt;strong&gt;**&lt;/strong&gt;&lt;strong&gt;**&lt;/strong&gt;&lt;strong&gt;*** 9. row **&lt;/strong&gt;&lt;strong&gt;**&lt;/strong&gt;&lt;strong&gt;**&lt;/strong&gt;&lt;strong&gt;**&lt;/strong&gt;*****
      Engine: FEDERATED
     Support: NO
     Comment: Federated MySQL storage engine
Transactions: NULL
          XA: NULL
  Savepoints: NULL&lt;/p&gt;

&lt;p&gt;各种存储引擎的特性：&lt;/p&gt;
&lt;h3 id=&quot;一&quot;&gt;一&lt;/h3&gt;
&lt;p&gt;MyISAM：不支持事务和外键；
访问速度快，对事务完整性没有要求的或者以select insert为主的应用适合；
每个MyISAM 在磁盘上存储三个文件，文件名都和表名相同，但扩展名分别是：
.frm 存储表定义
myd 存储数据
myi 存储索引&lt;/p&gt;

&lt;p&gt;数据文件和存储文件可以放在不同目录，平均分布io,获得更快的速度；
表容易被损坏，check table, repair table;
MyISAM的表还支持三种不同的存储格式：
静态表（固定长度）：存储迅速，容易缓存，出现故障容易恢复；占用空间比动态表多；空格补充，返回时去掉空格；
create databases test_mysql;
create table Myisam_char (name char(10))engine=myisam;
insert into Myisam_char 
values(‘abcde’),(‘abcde ‘),(‘ abcde’),(‘ abcde ‘); //5 5 7 7&lt;/p&gt;

&lt;p&gt;select name,length(name) 
from Myisam_char;
插入进去前面的空格保留，后面的空格都被去掉了。&lt;/p&gt;

&lt;p&gt;动态表包含变长字段，记录不是固定长度的，这样存储：占用的空间少，频繁地删除记录会产生碎片，定期执行优化改善性能（optimize table 或者 myisamchk-r ），出故障恢复困难；&lt;/p&gt;

&lt;p&gt;压缩表：由myisampack工具创建，占据非常小的磁盘空间，每条记录被单独压缩，只有非常小访问开支；&lt;/p&gt;

&lt;p&gt;InnoDB:
具有提交，回滚，崩溃恢复能力的事务安全。相遇于MyISAM引擎，写处理速度略差，占用更多存储空间保留数据和索引。&lt;/p&gt;

&lt;p&gt;2.1自动增长列：插入的是0或者null，则实际插入的是增长后的值；
create table autoincre_demo ( i smallint not null auto_increment, name varchar(10), primary key(i) ) engine=innodb;&lt;/p&gt;

&lt;p&gt;insert into autoincre_demo values(1,’1’),(0,’2’),(3,’3’);
select * from autoincre_demo;&lt;/p&gt;

&lt;p&gt;select last_insert_id(); //查询当前线程最后插入记录使用的值；如果是多条，返回第一条；
改变初始值，初始值默认为1，存在内存中，重启数据库需要重新设定；
alert table tableA auto_increment=n;&lt;/p&gt;

&lt;p&gt;InnoDB表：自动增长列必须是索引，如果是组合索引，必须是组合索引的第一列；&lt;/p&gt;

&lt;p&gt;MyISAM表：自动增长列可以是组合索引的其他列；
create table autoincre_demo ( d1 samllint not null auto_increment,
d2 smalliint not null, 
name varchar(10), index(d2,d1) )engine=MyISAM；
insert into autoincre_demo(d2,name) values(2,’2’),(3,’3’),(4,’4’),(2,’2’),(3,’3’),(4,’4’);
select * from autoincre_demo;
2.2 外键约束：
mysql支持外键的存储引擎只有InnoDB；&lt;/p&gt;

&lt;p&gt;key
 是数据库的物理结构，它包含两层意义，一是约束（偏重于约束和规范数据库的结构完整性），二是索引（辅助查询用的）
index是数据库的物理结构，它只是辅助查询的，它创建时会在另外的表空间（mysql中的innodb表空间）以一个类似目录的结构存储。索引要分类的话，分为前缀索引、全文本索引等；因此，索引只是索引，它不会去约束索引的字段的行为。&lt;/p&gt;

&lt;p&gt;各种引擎对比：
MyISAM：读和插入为主，很少更新和删除；并对事务的完整性，并发性要求不高 ；
InnoDB：事务处理提交和回滚，支持外键。插入查询，更新删除。类似的计费系统财务系统；
MEMORY：快速定位记录；
MERGE：突破对单个MyISAM表大小的限制，使用VLＤＢ；&lt;/p&gt;

&lt;p&gt;MyISAM
特性
不支持事务：MyISAM存储引擎不支持事务，所以对事务有要求的业务场景不能使用
表级锁定：其锁定机制是表级索引，这虽然可以让锁定的实现成本很小但是也同时大大降低了其并发性能
读写互相阻塞：不仅会在写入的时候阻塞读取，MyISAM还会在读取的时候阻塞写入，但读本身并不会阻塞另外的读
只会缓存索引：MyISAM可以通过key_buffer缓存以大大提高访问性能减少磁盘IO，但是这个缓存区只会缓存索引，而不会缓存数据
适用场景
不需要事务支持（不支持）
并发相对较低（锁定机制问题）
数据修改相对较少（阻塞问题）
以读为主
数据一致性要求不是非常高
最佳实践
尽量索引（缓存机制）
调整读写优先级，根据实际需求确保重要操作更优先
启用延迟插入改善大批量写入性能
尽量顺序操作让insert数据都写入到尾部，减少阻塞
分解大的操作，降低单个操作的阻塞时间
降低并发数，某些高并发场景通过应用来进行排队机制
对于相对静态的数据，充分利用Query Cache可以极大的提高访问效率
MyISAM的Count只有在全表扫描的时候特别高效，带有其他条件的count都需要进行实际的数据访问
InnoDB
特性
具有较好的事务支持：支持4个事务隔离级别，支持多版本读
行级锁定：通过索引实现，全表扫描仍然会是表锁，注意间隙锁的影响
读写阻塞与事务隔离级别相关
具有非常高效的缓存特性：能缓存索引，也能缓存数据
整个表和主键以Cluster方式存储，组成一颗平衡树
所有Secondary Index都会保存主键信息
适用场景
需要事务支持（具有较好的事务特性）
行级锁定对高并发有很好的适应能力，但需要确保查询是通过索引完成
数据更新较为频繁的场景
数据一致性要求较高
硬件设备内存较大，可以利用InnoDB较好的缓存能力来提高内存利用率，尽可能减少磁盘 IO
最佳实践
主键尽可能小，避免给Secondary index带来过大的空间负担
避免全表扫描，因为会使用表锁
尽可能缓存所有的索引和数据，提高响应速度
在大批量小插入的时候，尽量自己控制事务而不要使用autocommit自动提交
合理设置innodb_flush_log_at_trx_commit参数值，不要过度追求安全性
避免主键更新，因为这会带来大量的数据移动
NDBCluster
特性
分布式：分布式存储引擎，可以由多个NDBCluster存储引擎组成集群分别存放整体数据的一部分
支持事务：和Innodb一样，支持事务
可与mysqld不在一台主机：可以和mysqld分开存在于独立的主机上，然后通过网络和mysqld通信交互
内存需求量巨大：新版本索引以及被索引的数据必须存放在内存中，老版本所有数据和索引必须存在与内存中
适用场景
具有非常高的并发需求
对单个请求的响应并不是非常的critical
查询简单，过滤条件较为固定，每次请求数据量较少，又不希望自己进行水平Sharding
最佳实践
尽可能让查询简单，避免数据的跨节点传输
尽可能满足SQL节点的计算性能，大一点的集群SQL节点会明显多余Data节点
在各节点之间尽可能使用万兆网络环境互联，以减少数据在网络层传输过程中的延时
注：以上三个存储引擎是目前相对主流的存储引擎，还有其他类似如：Memory，Merge，CSV，Archive等存储引擎的使用场景都相对较少&lt;/p&gt;

&lt;!-- more --&gt;
&lt;p&gt;&lt;img src=&quot;https://xiazemin.github.io/MyBlog/img/jupyterSlider.png&quot; /&gt;&lt;/p&gt;
</description>
        <pubDate>Thu, 16 Nov 2017 00:00:00 +0800</pubDate>
        <link>https://xiazemin.github.io/MyBlog/web/2017/11/16/mysql_engine.html</link>
        <guid isPermaLink="true">https://xiazemin.github.io/MyBlog/web/2017/11/16/mysql_engine.html</guid>
        
        
        <category>web</category>
        
      </item>
    
  </channel>
</rss>
