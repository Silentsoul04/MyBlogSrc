<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>泽民博客</title>
    <description>夏泽民的个人主页，学习笔记。</description>
    <link>https://xiazemin.github.io/MyBlog/</link>
    <atom:link href="https://xiazemin.github.io/MyBlog/feed.xml" rel="self" type="application/rss+xml"/>
    <pubDate>Fri, 12 Jan 2018 21:21:48 +0800</pubDate>
    <lastBuildDate>Fri, 12 Jan 2018 21:21:48 +0800</lastBuildDate>
    <generator>Jekyll v3.6.0.pre.beta1</generator>
    
      <item>
        <title>scala maven 版本冲突问题解决</title>
        <description>&lt;p&gt;scalatest_2.10-1.9.1.jar of core build path is cross-compiled with an incompatible version of Scala (2.10.0)&lt;/p&gt;

&lt;p&gt;Eclipse - Preferences - Scala - Compiler - Build manager
uncheck withVersionClasspathVariable&lt;/p&gt;

&lt;p&gt;More than one scala library found in the build path (/home/hadoop/eclipse/plugins/org.scala-lang.scala-library_2.11.7.v20150622-112736-1fbce4612c.jar, /usr/local/spark/spark-1.5.1-bin-hadoop2.6/lib/spark-assembly-1.5.1-hadoop2.6.0.jar).At least one has an incompatible version. Please update the project build path so it contains only one compatible scala library. hello-test Unknown Scala Classpath Problem&lt;/p&gt;

&lt;p&gt;修改工程中的scala编译版本
右击 –&amp;gt; Scala –&amp;gt; set the Scala Installation&lt;/p&gt;

&lt;p&gt;也可以&lt;/p&gt;

&lt;p&gt;右击工程–&amp;gt; Properties –&amp;gt; Scala Compiler –&amp;gt; Use project Setting 中选择spark对应的scala版本，此处选择Lastest2.10 bundle&lt;/p&gt;

&lt;p&gt;上述方法仍然没有解决
原因maven pom.xml 中的版本与eclipse里面设置的版本冲出
解决办法修改pom.xml&lt;/p&gt;
&lt;properties&gt;
    &lt;scala.compat.version&gt;2.11&lt;/scala.compat.version&gt;
    &lt;scala.version&gt;2.12.3&lt;/scala.version&gt;
    
 问题解决
 
 Unsupported major.minor version 52.0
 You get this error because a Java 7 VM tries to load a class compiled for Java 8

Java 8 has the class file version 52.0 but a Java 7 VM can only load class files up to version 51.0

In your case the Java 7 VM is your gradle build and the class is com.android.build.gradle.AppPlugin
简单来说，就是java的编译环境版本太低，java 8 class file的版本是52，Java 7虚拟机只能支持到51。所以需要升级到java 8 vm才行


mvn -V
Apache Maven 3.5.2 (138edd61fd100ec658bfa2d307c43b76940a5d7d; 2017-10-18T15:58:13+08:00)
Maven home: /Users/didi/maven
Java version: 1.8.0_144, vendor: Oracle Corporation

Missing artifact org.scalatest:scalatest_2.12:jar:  2.2.4

http://mvnrepository.com/artifact/org.scalatest/scalatest_2.12/3.0.3


  &lt;dependency&gt;
      &lt;groupId&gt;org.specs2&lt;/groupId&gt;
      &lt;artifactId&gt;specs2-core_${scala.compat.version}&lt;/artifactId&gt;
      &lt;version&gt;${scala.compat.version}&lt;/version&gt;
      &lt;scope&gt;test&lt;/scope&gt;
    &lt;/dependency&gt;
    &lt;dependency&gt;
      &lt;groupId&gt;org.scalatest&lt;/groupId&gt;
      &lt;artifactId&gt;scalatest_${scala.compat.version}&lt;/artifactId&gt;
      &lt;version&gt;3.0.3&lt;/version&gt;
      &lt;scope&gt;test&lt;/scope&gt;
    &lt;/dependency&gt;
    
vi /Users/didi/maven/conf/settings.xml

 在maven的默认配置中，对于jdk的配置是1.4版本，那么创建/导入maven工程过程中，工程中未指定jdk版本。

对工程进行maven的update，就会出现工程依赖的JRE System Library会自动变成JavaSE-1.4。



解决方案1：修改maven的默认jdk配置

           maven的conf\setting.xml文件中找到jdk配置的地方，修改如下：


[html] view plaincopy在CODE上查看代码片派生到我的代码片

&lt;profile&gt;   
    &lt;id&gt;jdk1.6&lt;/id&gt;    
    &lt;activation&gt;   
        &lt;activeByDefault&gt;true&lt;/activeByDefault&gt;    
        &lt;jdk&gt;1.6&lt;/jdk&gt;   
    &lt;/activation&gt;    
    &lt;properties&gt;   
        &lt;maven.compiler.source&gt;1.6&lt;/maven.compiler.source&gt;    
        &lt;maven.compiler.target&gt;1.6&lt;/maven.compiler.target&gt;    
        &lt;maven.compiler.compilerVersion&gt;1.6&lt;/maven.compiler.compilerVersion&gt;   
    &lt;/properties&gt;   
&lt;/profile&gt;  

解决方案2：修改项目中pom.xml文件，这样避免在导入项目时的jdk版本指定

 打开项目中pom.xml文件，修改如下：
&lt;build&gt;  
    &lt;plugins&gt;  
        &lt;plugin&gt;  
            &lt;groupId&gt;org.apache.maven.plugins&lt;/groupId&gt;  
            &lt;artifactId&gt;maven-compiler-plugin&lt;/artifactId&gt;  
            &lt;configuration&gt;  
                &lt;source /&gt;1.6&amp;lt;/source&amp;gt;  
                &lt;target&gt;1.6&lt;/target&gt;  
            &lt;/configuration&gt;  
        &lt;/plugin&gt;  
    &lt;/plugins&gt;  
&lt;/build&gt;  

右键－》propertity  
   remove jre1.6  
      add jre1.8
      
      
&lt;!-- more --&gt;
运行成功

Could not resolve dependencies for project maven.scala:mavenScala:jar:0.0.1-SNAPSHOT: Failure to find org.specs2:specs2-core_2.12:jar:2.12 in https://repo.maven.apache.org/maven2 was cached in the local repository, resolution will not be reattempted until the update interval of central has elapsed or updates are forced

http://maven.outofmemory.cn/org.specs2/specs2-core_2.12.0-M4/3.8.4/


&lt;dependency&gt;
    &lt;groupId&gt;org.specs2&lt;/groupId&gt;
    &lt;artifactId&gt;specs2-core_2.12.0-M4&lt;/artifactId&gt;
    &lt;version&gt;3.8.4&lt;/version&gt;
&lt;/dependency&gt;


删除
&lt;dependency&gt;
    &lt;groupId&gt;org.specs2&lt;/groupId&gt;
    &lt;artifactId&gt;specs2-core_2.12.0-M4&lt;/artifactId&gt;
    &lt;version&gt;3.8.4&lt;/version&gt;
&lt;/dependency&gt;


scalac error: bad option: '-make:transitive'
解决方法：

（1）打开pom.xml，删除

       &lt;parameter value=&quot;-make:transitive&quot; /&gt;
（2）添加dependance

        &lt;dependency&gt;
            &lt;groupId&gt;org.specs2&lt;/groupId&gt;
            &lt;artifactId&gt;specs2_2.11&lt;/artifactId&gt;
            &lt;version&gt;2.4.6&lt;/version&gt;
            &lt;scope&gt;test&lt;/scope&gt;
        &lt;/dependency&gt;


测试报错  删除

mvn package

[INFO] Building jar: /Users/didi/PhpstormProjects/ProjGit/Spark/ScalaMaven/MavenScala/target/MavenScala-0.0.1-SNAPSHOT.jar
[INFO] ------------------------------------------------------------------------
[INFO] BUILD SUCCESS
[INFO] ----------------


Description Resource  Path  Location  Type
Project configuration is not up-to-date with pom.xml. Select: Maven-&amp;gt;Update Project... from the project context menu or use Quick Fix.  MavenScala    line 1  Maven Configuration Problem

右键  Maven-&amp;gt;Update Project

至此没有错误了




&lt;/properties&gt;
</description>
        <pubDate>Fri, 12 Jan 2018 00:00:00 +0800</pubDate>
        <link>https://xiazemin.github.io/MyBlog/spark/2018/01/12/scala_version.html</link>
        <guid isPermaLink="true">https://xiazemin.github.io/MyBlog/spark/2018/01/12/scala_version.html</guid>
        
        
        <category>spark</category>
        
      </item>
    
      <item>
        <title>Eclipse中操作Hive、HDFS、spark时的jar包列表</title>
        <description>&lt;!-- more --&gt;
&lt;pre&gt;&lt;code&gt;&amp;lt;img src=&quot;https://xiazemin.github.io/MyBlog/img/hivejar.pnghdfsjar&quot;/&amp;gt;

	&amp;lt;img src=&quot;https://xiazemin.github.io/MyBlog/img/hdfsjar.png&quot;/&amp;gt; 右击“SaprkScala”工程，选择“Properties”，在弹出的框中，按照下图所示，依次选择“Java Build Path” –&amp;gt;“Libraties” –&amp;gt;“Add External JARs…”，导入文章“Apache Spark：将Spark部署到Hadoop 2.2.0上”中给出的 assembly/target/scala-2.9.3/目录下的spark-assembly-0.8.1-incubating- hadoop2.2.0.jar
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;高版本的在jars 里面&lt;/p&gt;

&lt;p&gt;只需要加载所有jars即可&lt;/p&gt;

&lt;p&gt;Description	Resource	Path	Location	Type
More than one scala library found in the build path (/Users/didi/.p2/pool/plugins/org.scala-lang.scala-library_2.12.3.v20170725-052526-VFINAL-6ac6da8.jar, /Users/didi/spark/spark/jars/scala-library-2.11.8.jar).At least one has an incompatible version. Please update the project build path so it contains only one compatible scala library.	online		Unknown	Scala Classpath Problem&lt;/p&gt;

&lt;p&gt;移除
jars/scala-library-2.11.8.jar
即可&lt;/p&gt;

</description>
        <pubDate>Fri, 12 Jan 2018 00:00:00 +0800</pubDate>
        <link>https://xiazemin.github.io/MyBlog/spark/2018/01/12/hive.html</link>
        <guid isPermaLink="true">https://xiazemin.github.io/MyBlog/spark/2018/01/12/hive.html</guid>
        
        
        <category>spark</category>
        
      </item>
    
      <item>
        <title>Eclipse+maven+scala+spark环境搭建</title>
        <description>&lt;p&gt;1.安装Scala-IDE
在Eclipse中开发Scala程序需要有scala插件，我们现在安装scala插件 
2.安装m2e-scala插件
m2e-scala用来支持scala开发中对maven的一些定制功能。通过eclipse的Install New Software安装。 
安装过程 
   1.Help-&amp;gt;Install New Software 
   2.输入m2e-scala下载的url 
具体URL为http://alchim31.free.fr/m2e-scala/update-site/
	&lt;img src=&quot;https://xiazemin.github.io/MyBlog/img/m2e_scala.png&quot; /&gt;
    3.安装完成后，可在Help-&amp;gt;Installation Details中查看 
    4.添加远程的原型或模板目录
    	&lt;img src=&quot;https://xiazemin.github.io/MyBlog/img/archetypes.png&quot; /&gt;
    	Catalog file:http://repo1.maven.org/maven2/archetype-catalog.xml
Description:Remote Catalog Scala
    5、出现过mvn连不上公共库的问题;
     解决方法：vi eclipse.ini
      add : -vmargs -Djava.net.preferIPv4Stack=true&lt;/p&gt;

&lt;p&gt;3.新建Eclipse+scala+maven工程
新建maven工程
此时的maven的Archetype需要设置为 org.scala-tools.archetypes 
如果没有安装Scala-IDE的话，会找不到org.scala-tools.archetypes这个类别&lt;/p&gt;

&lt;p&gt;新建Archetype，因为maven默认没有Group Id: net.alchim31.maven Artifact Id: scala-archetype-simple Version:1.6&lt;/p&gt;

&lt;p&gt;　　Select New -&amp;gt; Project -&amp;gt; Other and then select Maven Project. On the next window, search forscala-archetype. Make sure you select the one in group net.alchim31.maven, and click Next。
　　&lt;img src=&quot;https://xiazemin.github.io/MyBlog/img/configureScala.png&quot; /&gt;configure
　　
&lt;!-- more --&gt;&lt;/p&gt;
&lt;plugin&gt;
  &lt;groupId&gt;net.alchim31.maven&lt;/groupId&gt;
  &lt;artifactId&gt;scala-maven-plugin&lt;/artifactId&gt;
  &lt;version&gt;3.1.3&lt;/version&gt;
  &lt;executions&gt;
    &lt;execution&gt;
      &lt;goals&gt;
        &lt;goal&gt;compile&lt;/goal&gt;
        &lt;goal&gt;testCompile&lt;/goal&gt;
      &lt;/goals&gt;
    &lt;/execution&gt;
  &lt;/executions&gt;
  
  
  scala的新版本对老版本的兼容似乎并不好。这里可以自己修正pom.xml文件，不过估计代码可能也要修改。从git上下载了一个现成的基于scala2.11.5的maven工程。
git网址：https://github.com/scala/scala-module-dependency-sample
使用git clone下来之后，在eclipse中导入maven工程（maven-sample

或者直接编译scala-maven-plugin
https://github.com/davidB/scala-maven-plugin

 运行Maven是报错：No goals have been specified for this build
 pom.xml文件&lt;build&gt;标签后面加上&lt;defaultGoal&gt;compile&lt;/defaultGoal&gt;即可  
 
 一个错误示例，子项目引用了父项目，子项目parent标签处报错如下：
Multiple annotations found at this line:
- maven-enforcer-plugin (goal &quot;enforce&quot;) is ignored by m2e.
- Plugin execution not covered by lifecycle configuration: org.codehaus.mojo:aspectj-maven-plugin:1.3.1:compile (execution: 
 default, phase: compile)
 
解决办法
官网给出解释及解决办法：http://wiki.eclipse.org/M2E_plugin_execution_not_covered

这里有人说下面这样也可以解决， 即 &lt;plugins&gt; 标签外再套一个 &lt;pluginManagement&gt; 标签，我试验是成功的：
http://stackoverflow.com/questions/6352208/how-to-solve-plugin-execution-not-covered-by-lifecycle-configuration-for-sprin
&lt;build&gt;
    &lt;pluginManagement&gt;
        &lt;plugins&gt;
            &lt;plugin&gt; ... &lt;/plugin&gt;
            &lt;plugin&gt; ... &lt;/plugin&gt;
                  ....
        &lt;/plugins&gt;
    &lt;/pluginManagement&gt;
&lt;/build&gt;

 
 
 scala配置
很多时候我们希望可以使用java+scala混合开发模式，此时只需要在maven进行如下配置即可：

&lt;dependencies&gt;
    &lt;dependency&gt;
      &lt;groupId&gt;org.scala-lang&lt;/groupId&gt;
      &lt;artifactId&gt;scala-library&lt;/artifactId&gt;
      &lt;version&gt;${scala.version}&lt;/version&gt;
      &lt;scope&gt;compile&lt;/scope&gt;
    &lt;/dependency&gt;
&lt;/dependencies&gt;

&lt;build&gt;
    &lt;plugins&gt;
      &lt;plugin&gt;
        &lt;groupId&gt;org.scala-tools&lt;/groupId&gt;
        &lt;artifactId&gt;maven-scala-plugin&lt;/artifactId&gt;
        &lt;version&gt;2.15.2&lt;/version&gt;
        &lt;executions&gt;
          &lt;execution&gt;
            &lt;id&gt;scala-compile-first&lt;/id&gt;
            &lt;goals&gt;
              &lt;goal&gt;compile&lt;/goal&gt;
            &lt;/goals&gt;
            &lt;configuration&gt;
              &lt;includes&gt;
                &lt;include&gt;**/*.scala&lt;/include&gt;
              &lt;/includes&gt;
            &lt;/configuration&gt;
          &lt;/execution&gt;
          &lt;execution&gt;
            &lt;id&gt;scala-test-compile&lt;/id&gt;
            &lt;goals&gt;
              &lt;goal&gt;testCompile&lt;/goal&gt;
            &lt;/goals&gt;
          &lt;/execution&gt;
        &lt;/executions&gt;
      &lt;/plugin&gt;
    &lt;/plugins&gt;   
&lt;/build&gt; 

可运行jar打包
&lt;plugin&gt;
                &lt;groupId&gt;org.apache.maven.plugins&lt;/groupId&gt;
                &lt;artifactId&gt;maven-shade-plugin&lt;/artifactId&gt;
                &lt;executions&gt;
                    &lt;execution&gt;
                        &lt;phase&gt;package&lt;/phase&gt;
                        &lt;goals&gt;
                            &lt;goal&gt;shade&lt;/goal&gt;
                        &lt;/goals&gt;
                        &lt;configuration&gt;
                            &lt;transformers&gt;
                                &lt;transformer implementation=&quot;org.apache.maven.plugins.shade.resource.ManifestResourceTransformer&quot;&gt;
                                    &lt;mainClass&gt;{此处填写main主类}&lt;/mainClass&gt;
                                &lt;/transformer&gt;
                            &lt;/transformers&gt;
                            &lt;filters&gt; 
                                &lt;filter&gt;
                                    &lt;artifact&gt;*:*&lt;/artifact&gt;
                                    &lt;excludes&gt;
                                        &lt;exclude&gt;META-INF/*.SF&lt;/exclude&gt;
                                        &lt;exclude&gt;META-INF/*.DSA&lt;/exclude&gt;
                                        &lt;exclude&gt;META-INF/*.RSA&lt;/exclude&gt;
                                    &lt;/excludes&gt;
                                &lt;/filter&gt;
                            &lt;/filters&gt;
                        &lt;/configuration&gt;
                    &lt;/execution&gt;
                &lt;/executions&gt;
            &lt;/plugin&gt;
            
            
     
&lt;/pluginManagement&gt;&lt;/plugins&gt;&lt;/build&gt;&lt;/plugin&gt;
</description>
        <pubDate>Thu, 11 Jan 2018 00:00:00 +0800</pubDate>
        <link>https://xiazemin.github.io/MyBlog/spark/2018/01/11/maven_scala_eclipse.html</link>
        <guid isPermaLink="true">https://xiazemin.github.io/MyBlog/spark/2018/01/11/maven_scala_eclipse.html</guid>
        
        
        <category>spark</category>
        
      </item>
    
      <item>
        <title>maven</title>
        <description>&lt;p&gt;1.1 常用的mvn命令
mvn archetype:create 创建 Maven 项目
mvn compile 编译主程序源代码，不会编译test目录的源代码。第一次运行时，会下载相关的依赖包，可能会比较费时
mvn test-compile 编译测试代码，compile之后会生成target文件夹，主程序编译在classes下面，测试程序放在test-classes下
mvn test 运行应用程序中的单元测试 
mvn site 生成项目相关信息的网站
mvn clean 清除目标目录中的生成结果
mvn package 依据项目生成 jar 文件，打包之前会进行编译，测试
mvn install在本地 Repository 中安装 jar。
mvn eclipse:eclipse 生成 Eclipse 项目文件及包引用定义
mvn deploy 在整合或者发布环境下执行，将最终版本的包拷贝到远程 的repository，使得其他的开发者或者工程可以共享。
一些高级功能命令
跳过测试类 ： -Dmaven.test.skip=true
下载jar包源码： -DdownloadSource=true
下载javadocs： -DdownloadJavadocs=true
2.1 编写POM
就像Make的Makefile、Ant的build.xml一样，Maven项目的核心是pom.xml。POM(Project Object Model)，项目对象模型定义了项目的基本信息，用于描述项目如何构建，声明项目依赖，等等。现在先为HelloWorld项目编写一个最简单的pom. xml，
XML头&lt;/p&gt;

&lt;p&gt;代码的第一行是XML头，指定了该xml文档的版本和编码方式。&lt;/p&gt;

&lt;p&gt;project元素&lt;/p&gt;

&lt;p&gt;XML头之后紧接着就是project元素，project是所有pom.xml的根元素，它还声明了一些POM相关的命名空间及xsd元素，虽然这些属性不是必须的，但使用这些属性能够让第三方工具（如IDE中的XMl编辑器）帮助我们快速编辑POM 。&lt;/p&gt;

&lt;p&gt;modelVersion元素&lt;/p&gt;

&lt;p&gt;根元素下的第一个子元素modelVersion，它指定了当前POM模型的版本，对于Maven 3以及Maven 3来说，它只能是4.0.0。&lt;/p&gt;

&lt;p&gt;坐标&lt;/p&gt;

&lt;p&gt;这段代码中最重要的是：包含groupId、artifactId和version的三行。这三个元素定义了一个项目基本的坐标，在Maven的世界，任何的jar、pom或者war都是以基于这些基本的坐标进行区分的。&lt;/p&gt;

&lt;p&gt;groupId元素&lt;/p&gt;

&lt;p&gt;groupId定义了项目属于哪个组，这个组往往和项目所在的组织或公司存在关联。譬如在googlecode上建立了一个名为myapp的项目，那么groupId就应该是com.googlecod.myapp，如果你的公司是mycom，有一个项目为myapp。耶么groupId就应该是com.mycom.myapp。&lt;/p&gt;

&lt;p&gt;artifactId元素&lt;/p&gt;

&lt;p&gt;artifactId定义了当前Maven项目在组中唯一的ID，我们为这个HelloWord项目定义artifactId为hello-world。在前面的groupld为&lt;/p&gt;

&lt;p&gt;com.googlecode.myapp的例子中，你可能会为不同的子项目（模块）分配artifactId，如myapp-util、myapp-domain、myapp-web等。&lt;/p&gt;

&lt;p&gt;version元素&lt;/p&gt;

&lt;p&gt;顾名思义，version指定了Hello World项目当前的版本0.0.1。SNAPSHOT意为快照，说明该项目还处于开发中，是不稳定的版本。随着项目的展，version会不断更新，如升级为0.0.2、0.0.3、1.0.0等。&lt;/p&gt;

&lt;p&gt;name元素&lt;/p&gt;

&lt;p&gt;最后一个name元素，声明了一个对于用户更为友好的项目名称，虽然这不是必须的，但还是推荐为每个POM声明name。以方便信息交流。&lt;/p&gt;

&lt;p&gt;没有任何实际的Java代码，我们就能够定义一个Maven项目的POM，这体现了Maven的一大优点，它能让项目对象模型最大程度地与实际代码相独立，我们可以称之为解耦，或者正交性。这在很大程度上避免了Java代码和POM代码的相互影响：比如当项目需要升级版本时，只需要修改POM。而不需要更改Java代码；而在POM稳定之后，日常的Java代码开发工作基本不涉及POM的修改。&lt;/p&gt;

&lt;p&gt;2.2 编写主代码
项目主代码和测试代码不同，项目的主代码会被打包到最终的构件中如：jar。而测试代码只在运行测试时用到，不会被打包。默认情况下，Maven假设项目主代码位于src/main/java目录，我们遵循Maven的约定，创建该目录，然后在该目录下创建文件org/hebut/test/helloworld/HelloWorld. java&lt;/p&gt;

&lt;p&gt;有两点需要注意：首先，在绝大多数情况下，应该把项目主代码放到src/main/java/目录下，而无须额外的配置，Maven会自动搜寻该目录找到项目主代码。其次，该Java类的包名是org.hebut.test.helloworld，这与之前在POM中定义的groupId和artifactld相吻合。一般来说，项目中Java类的包都应该基于项目的groupld和anifactId。这样更加清晰，更加符合逻辑，也方便搜索构件或者Java类。&lt;/p&gt;

&lt;p&gt;使用的clean命令告诉Maven清理输出目录target/，compile告诉Maven编译项目主代码，从输出中看到Maven首先执行了clean：clean任务，删除target/目录。默认情况下，Maven构建的所有输出都在target/目录中；接着执行resources：resources任务，未定义项目资源，暂且略过；&lt;/p&gt;

&lt;p&gt;最后执行compiler：compile任务，将项目主代码编译至target/classes目录，编译好的类为：&lt;/p&gt;

&lt;p&gt;org/hebut/test/helloworld/HelloWorld.Class&lt;/p&gt;

&lt;p&gt;上文提到的clean:clean、resources:resources和compiler:compile对应了一些Maven插件及插件目标，比如clean:clean是clean插件的clean目标，compiler:compile是compiler插件的compile目。&lt;/p&gt;

&lt;p&gt;至此，Maven在没有任何额外的配置的情况下就执行了项目的清理和编译任务。接下来，编写一些单元测试代码并让Maven执行自动化测试。&lt;/p&gt;

&lt;p&gt;2.3 编写测试代码
为了使项目结构保持清晰，主代码与测试代码应陔分别位于独立的目录中。正如上面所述，Maven项目中默认的主代码目录是src/main/java。对应地，Maven项目中默认的测试代码目录是src/test/java&lt;/p&gt;

&lt;p&gt;dependencies元素&lt;/p&gt;

&lt;p&gt;代码中添加了dependencies元素，该元素下可以包含多个dependency元素以声明项目的依赖。&lt;/p&gt;

&lt;p&gt;dependency元素&lt;/p&gt;

&lt;p&gt;dependency元素用以声明项目的依赖，这里添加了一个依赖groupId是junit，artifactld是junit，version是4.7。前面提到groupId、artifactId和versIon是任何一个Maven项目最基本的坐标。JUnit也不例外，有了这段声明Maven就能够自动下载junit-4.7.jar。&lt;/p&gt;

&lt;p&gt;scope元素&lt;/p&gt;

&lt;p&gt;上述POM代码中还有一个值为test的元素scope，scope为依赖范围，若依赖范围为test则表示该依赖只对测试有效。换句话说，测试代码中的import JUnit代码是没有问题的，但是如果在主代码中用import Junit代码，就会造成编译错误。如果不声明依赖范围，那么默认值就是compile，表示该依赖对主代码和测试代码都有效。&lt;/p&gt;

&lt;p&gt;默认Maven生成的JAR包只包含了编译生成的.class文件和项目资源文件，而要得到一个可以直接在命令行通过java命令运行的JAR文件，还要满足两个条件&lt;/p&gt;

&lt;p&gt;■ JAR包中的/META-INF/MANIFEST.MF元数据文件必须包含Main-Class信息。&lt;/p&gt;

&lt;p&gt;■ 项目所有的依赖都必须在Classpath中。&lt;/p&gt;

&lt;p&gt;三、使用Archetype生成项目骨架
3.1 Maven 项目约定
HelloWorld项目中有一些Maven的约定：在项目的根目录中放置pom.xml，在src/main/java目录中放置项目的主代码，在src/test/java中放置项目的测试代码。我们称这些基本的目录结构和pom. xml文件内容称为项目的骨架&lt;/p&gt;

&lt;p&gt;3.2 Maven Archetype
当第一次创建项目骨架的时候，你还会饶有兴趣地去体会这些默认约定背后的思想，第二次，第三次，你也许还会满意自己的熟练程度，但第四、第五次做同样的事情，你可能就会恼火了。为此Maven提供了Archetype以帮助我们快速勾勒出项目骨架。还是以Hello World为例，我们使用maven archetype来创建该项目的骨架，离开当前的Maven项目目录。&lt;/p&gt;

&lt;p&gt;如果是Maven 3简单地运行：&lt;/p&gt;

&lt;p&gt;mvn archetype:generate&lt;/p&gt;

&lt;p&gt;如果是Maven 2最好运行如下命令：&lt;/p&gt;

&lt;p&gt;mvn org.apache.maven.plugins:maven-archetype-plugin:2.0-alpha-5:generate&lt;/p&gt;

&lt;p&gt;m2eclipse是Eclipse中的一款Maven插件&lt;/p&gt;

&lt;!-- more --&gt;
&lt;p&gt;spark-submit 错误： ava.lang.ClassNotFoundException: WordCount&lt;/p&gt;

&lt;p&gt;跟package name有关&lt;/p&gt;

&lt;p&gt;# ./spark-submit –class spark.wordcount.WordCount  /opt/spark-wordcount-in-scala.jar&lt;/p&gt;

&lt;p&gt;–class后接的格式应该是packageName.objectName。&lt;/p&gt;

</description>
        <pubDate>Thu, 11 Jan 2018 00:00:00 +0800</pubDate>
        <link>https://xiazemin.github.io/MyBlog/spark/2018/01/11/maven.html</link>
        <guid isPermaLink="true">https://xiazemin.github.io/MyBlog/spark/2018/01/11/maven.html</guid>
        
        
        <category>spark</category>
        
      </item>
    
      <item>
        <title>随机森林</title>
        <description>&lt;!-- more --&gt;
&lt;p&gt;1 什么是随机森林？
　　作为新兴起的、高度灵活的一种机器学习算法，随机森林（Random Forest，简称RF）拥有广泛的应用前景，从市场营销到医疗保健保险，既可以用来做市场营销模拟的建模，统计客户来源，保留和流失，也可用来预测疾病的风险和病患者的易感性。最初，我是在参加校外竞赛时接触到随机森林算法的。最近几年的国内外大赛，包括2013年百度校园电影推荐系统大赛、2014年阿里巴巴天池大数据竞赛以及Kaggle数据科学竞赛，参赛者对随机森林的使用占有相当高的比例。此外，据我的个人了解来看，一大部分成功进入答辩的队伍也都选择了Random Forest 或者 GBDT 算法。所以可以看出，Random Forest在准确率方面还是相当有优势的。&lt;/p&gt;

&lt;p&gt;　　那说了这么多，那随机森林到底是怎样的一种算法呢？&lt;/p&gt;

&lt;p&gt;　　如果读者接触过决策树（Decision Tree）的话，那么会很容易理解什么是随机森林。随机森林就是通过集成学习的思想将多棵树集成的一种算法，它的基本单元是决策树，而它的本质属于机器学习的一大分支——集成学习（Ensemble Learning）方法。随机森林的名称中有两个关键词，一个是“随机”，一个就是“森林”。“森林”我们很好理解，一棵叫做树，那么成百上千棵就可以叫做森林了，这样的比喻还是很贴切的，其实这也是随机森林的主要思想–集成思想的体现。“随机”的含义我们会在下边部分讲到。&lt;/p&gt;

&lt;p&gt;　　其实从直观角度来解释，每棵决策树都是一个分类器（假设现在针对的是分类问题），那么对于一个输入样本，N棵树会有N个分类结果。而随机森林集成了所有的分类投票结果，将投票次数最多的类别指定为最终的输出，这就是一种最简单的 Bagging 思想。&lt;/p&gt;

&lt;p&gt;回到顶部
2 随机森林的特点
　　我们前边提到，随机森林是一种很灵活实用的方法，它有如下几个特点：&lt;/p&gt;

&lt;p&gt;在当前所有算法中，具有极好的准确率/It is unexcelled in accuracy among current algorithms；
能够有效地运行在大数据集上/It runs efficiently on large data bases；
能够处理具有高维特征的输入样本，而且不需要降维/It can handle thousands of input variables without variable deletion；
能够评估各个特征在分类问题上的重要性/It gives estimates of what variables are important in the classification；
在生成过程中，能够获取到内部生成误差的一种无偏估计/It generates an internal unbiased estimate of the generalization error as the forest building progresses；
对于缺省值问题也能够获得很好得结果/It has an effective method for estimating missing data and maintains accuracy when a large proportion of the data are missing
… …
　　实际上，随机森林的特点不只有这六点，它就相当于机器学习领域的Leatherman（多面手），你几乎可以把任何东西扔进去，它基本上都是可供使用的。在估计推断映射方面特别好用，以致都不需要像SVM那样做很多参数的调试。具体的随机森林介绍可以参见随机森林主页：Random Forest。&lt;/p&gt;

&lt;p&gt;回到顶部
3 随机森林的相关基础知识
　　随机森林看起来是很好理解，但是要完全搞明白它的工作原理，需要很多机器学习方面相关的基础知识。在本文中，我们简单谈一下，而不逐一进行赘述，如果有同学不太了解相关的知识，可以参阅其他博友的一些相关博文或者文献。&lt;/p&gt;

&lt;p&gt;　　1）信息、熵以及信息增益的概念&lt;/p&gt;

&lt;p&gt;　　这三个基本概念是决策树的根本，是决策树利用特征来分类时，确定特征选取顺序的依据。理解了它们，决策树你也就了解了大概。&lt;/p&gt;

&lt;p&gt;　　引用香农的话来说，信息是用来消除随机不确定性的东西。当然这句话虽然经典，但是还是很难去搞明白这种东西到底是个什么样，可能在不同的地方来说，指的东西又不一样。对于机器学习中的决策树而言，如果带分类的事物集合可以划分为多个类别当中，则某个类（xi）的信息可以定义如下:&lt;/p&gt;

&lt;p&gt;　　I(x)用来表示随机变量的信息，p(xi)指是当xi发生时的概率。&lt;/p&gt;

&lt;p&gt;　　熵是用来度量不确定性的，当熵越大，X=xi的不确定性越大，反之越小。对于机器学习中的分类问题而言，熵越大即这个类别的不确定性更大，反之越小。&lt;/p&gt;

&lt;p&gt;　　信息增益在决策树算法中是用来选择特征的指标，信息增益越大，则这个特征的选择性越好。&lt;/p&gt;

&lt;p&gt;　　这方面的内容不再细述，感兴趣的同学可以看 信息&amp;amp;熵&amp;amp;信息增益 这篇博文。&lt;/p&gt;

&lt;p&gt;　　2）决策树&lt;/p&gt;

&lt;p&gt;　　决策树是一种树形结构，其中每个内部节点表示一个属性上的测试，每个分支代表一个测试输出，每个叶节点代表一种类别。常见的决策树算法有C4.5、ID3和CART。&lt;/p&gt;

&lt;p&gt;　　3）集成学习　&lt;/p&gt;

&lt;p&gt;　　集成学习通过建立几个模型组合的来解决单一预测问题。它的工作原理是生成多个分类器/模型，各自独立地学习和作出预测。这些预测最后结合成单预测，因此优于任何一个单分类的做出预测。&lt;/p&gt;

&lt;p&gt;　　随机森林是集成学习的一个子类，它依靠于决策树的投票选择来决定最后的分类结果。你可以在这找到用python实现集成学习的文档：Scikit 学习文档。&lt;/p&gt;

&lt;p&gt;回到顶部
4 随机森林的生成
　　前面提到，随机森林中有许多的分类树。我们要将一个输入样本进行分类，我们需要将输入样本输入到每棵树中进行分类。打个形象的比喻：森林中召开会议，讨论某个动物到底是老鼠还是松鼠，每棵树都要独立地发表自己对这个问题的看法，也就是每棵树都要投票。该动物到底是老鼠还是松鼠，要依据投票情况来确定，获得票数最多的类别就是森林的分类结果。森林中的每棵树都是独立的，99.9%不相关的树做出的预测结果涵盖所有的情况，这些预测结果将会彼此抵消。少数优秀的树的预测结果将会超脱于芸芸“噪音”，做出一个好的预测。将若干个弱分类器的分类结果进行投票选择，从而组成一个强分类器，这就是随机森林bagging的思想（关于bagging的一个有必要提及的问题：bagging的代价是不用单棵决策树来做预测，具体哪个变量起到重要作用变得未知，所以bagging改进了预测准确率但损失了解释性。）。下图可以形象地描述这个情况：&lt;/p&gt;

&lt;p&gt;　&lt;/p&gt;

&lt;p&gt;　　有了树我们就可以分类了，但是森林中的每棵树是怎么生成的呢？&lt;/p&gt;

&lt;p&gt;　　每棵树的按照如下规则生成：&lt;/p&gt;

&lt;p&gt;　　1）如果训练集大小为N，对于每棵树而言，随机且有放回地从训练集中的抽取N个训练样本（这种采样方式称为bootstrap sample方法），作为该树的训练集；&lt;/p&gt;

&lt;p&gt;　　从这里我们可以知道：每棵树的训练集都是不同的，而且里面包含重复的训练样本（理解这点很重要）。&lt;/p&gt;

&lt;p&gt;　　为什么要随机抽样训练集？（add @2016.05.28）&lt;/p&gt;

&lt;p&gt;　　如果不进行随机抽样，每棵树的训练集都一样，那么最终训练出的树分类结果也是完全一样的，这样的话完全没有bagging的必要；&lt;/p&gt;

&lt;p&gt;　　为什么要有放回地抽样？（add @2016.05.28）&lt;/p&gt;

&lt;p&gt;　　我理解的是这样的：如果不是有放回的抽样，那么每棵树的训练样本都是不同的，都是没有交集的，这样每棵树都是”有偏的”，都是绝对”片面的”（当然这样说可能不对），也就是说每棵树训练出来都是有很大的差异的；而随机森林最后分类取决于多棵树（弱分类器）的投票表决，这种表决应该是”求同”，因此使用完全不同的训练集来训练每棵树这样对最终分类结果是没有帮助的，这样无异于是”盲人摸象”。&lt;/p&gt;

&lt;p&gt;　　2）如果每个样本的特征维度为M，指定一个常数m«M，随机地从M个特征中选取m个特征子集，每次树进行分裂时，从这m个特征中选择最优的；&lt;/p&gt;

&lt;p&gt;　　3）每棵树都尽最大程度的生长，并且没有剪枝过程。&lt;/p&gt;

&lt;p&gt;　　一开始我们提到的随机森林中的“随机”就是指的这里的两个随机性。两个随机性的引入对随机森林的分类性能至关重要。由于它们的引入，使得随机森林不容易陷入过拟合，并且具有很好得抗噪能力（比如：对缺省值不敏感）。&lt;/p&gt;

&lt;p&gt;　　随机森林分类效果（错误率）与两个因素有关：&lt;/p&gt;

&lt;p&gt;森林中任意两棵树的相关性：相关性越大，错误率越大；
森林中每棵树的分类能力：每棵树的分类能力越强，整个森林的错误率越低。
　　减小特征选择个数m，树的相关性和分类能力也会相应的降低；增大m，两者也会随之增大。所以关键问题是如何选择最优的m（或者是范围），这也是随机森林唯一的一个参数。&lt;/p&gt;

&lt;p&gt;回到顶部
5 袋外错误率（oob error）
　　上面我们提到，构建随机森林的关键问题就是如何选择最优的m，要解决这个问题主要依据计算袋外错误率oob error（out-of-bag error）。&lt;/p&gt;

&lt;p&gt;　　随机森林有一个重要的优点就是，没有必要对它进行交叉验证或者用一个独立的测试集来获得误差的一个无偏估计。它可以在内部进行评估，也就是说在生成的过程中就可以对误差建立一个无偏估计。&lt;/p&gt;

&lt;p&gt;　　我们知道，在构建每棵树时，我们对训练集使用了不同的bootstrap sample（随机且有放回地抽取）。所以对于每棵树而言（假设对于第k棵树），大约有1/3的训练实例没有参与第k棵树的生成，它们称为第k棵树的oob样本。&lt;/p&gt;

&lt;p&gt;　　而这样的采样特点就允许我们进行oob估计，它的计算方式如下：&lt;/p&gt;

&lt;p&gt;　　（note：以样本为单位）&lt;/p&gt;

&lt;p&gt;　　1）对每个样本，计算它作为oob样本的树对它的分类情况（约1/3的树）；&lt;/p&gt;

&lt;p&gt;　　2）然后以简单多数投票作为该样本的分类结果；&lt;/p&gt;

&lt;p&gt;　　3）最后用误分个数占样本总数的比率作为随机森林的oob误分率。&lt;/p&gt;

&lt;p&gt;　　（文献原文：Put each case left out in the construction of the kth tree down the kth tree to get a classification. In this way, a test set classification is obtained for each case in about one-third of the trees. At the end of the run, take j to be the class that got most of the votes every time case n was oob. The proportion of times that j is not equal to the true class of n averaged over all cases is the oob error estimate. This has proven to be unbiased in many tests.）&lt;/p&gt;

&lt;p&gt;　　oob误分率是随机森林泛化误差的一个无偏估计，它的结果近似于需要大量计算的k折交叉验证。&lt;/p&gt;

&lt;p&gt;回到顶部
6 随机森林工作原理解释的一个简单例子
　　描述：根据已有的训练集已经生成了对应的随机森林，随机森林如何利用某一个人的年龄（Age）、性别（Gender）、教育情况（Highest Educational Qualification）、工作领域（Industry）以及住宅地（Residence）共5个字段来预测他的收入层次。&lt;/p&gt;

&lt;p&gt;　　收入层次 :&lt;/p&gt;

&lt;p&gt;　　　　Band 1 : Below $40,000&lt;/p&gt;

&lt;p&gt;　　　　Band 2: $40,000 – 150,000&lt;/p&gt;

&lt;p&gt;　　　　Band 3: More than $150,000&lt;/p&gt;

&lt;p&gt;　　随机森林中每一棵树都可以看做是一棵CART（分类回归树），这里假设森林中有5棵CART树，总特征个数N=5，我们取m=1（这里假设每个CART树对应一个不同的特征）。&lt;/p&gt;

&lt;p&gt;　　CART 1 : Variable Age&lt;/p&gt;

&lt;p&gt;　　rf1&lt;/p&gt;

&lt;p&gt;　　CART 2 : Variable Gender&lt;/p&gt;

&lt;p&gt;　　rf2&lt;/p&gt;

&lt;p&gt;　　CART 3 : Variable Education&lt;/p&gt;

&lt;p&gt;　　rf3&lt;/p&gt;

&lt;p&gt;　　CART 4 : Variable Residence&lt;/p&gt;

&lt;p&gt;　　rf4&lt;/p&gt;

&lt;p&gt;　　CART 5 : Variable Industry&lt;/p&gt;

&lt;p&gt;　　rf5&lt;/p&gt;

&lt;p&gt;　　我们要预测的某个人的信息如下：&lt;/p&gt;

&lt;p&gt;　　1. Age : 35 years ; 2. Gender : Male ; 3. Highest Educational Qualification : Diploma holder; 4. Industry : Manufacturing; 5. Residence : Metro.&lt;/p&gt;

&lt;p&gt;　　根据这五棵CART树的分类结果，我们可以针对这个人的信息建立收入层次的分布情况：&lt;/p&gt;

&lt;p&gt;　　DF&lt;/p&gt;

&lt;p&gt;　　最后，我们得出结论，这个人的收入层次70%是一等，大约24%为二等，6%为三等，所以最终认定该人属于一等收入层次（小于$40,000）。&lt;/p&gt;

&lt;p&gt;回到顶部
7 随机森林的Python实现
　　利用Python的两个模块，分别为pandas和scikit-learn来实现随机森林。
from sklearn.datasets import load_iris
from sklearn.ensemble import RandomForestClassifier
import pandas as pd
import numpy as np&lt;/p&gt;

&lt;p&gt;iris = load_iris()
df = pd.DataFrame(iris.data, columns=iris.feature_names)
df[‘is_train’] = np.random.uniform(0, 1, len(df)) &amp;lt;= .75
df[‘species’] = pd.Factor(iris.target, iris.target_names)
df.head()&lt;/p&gt;

&lt;p&gt;train, test = df[df[‘is_train’]==True], df[df[‘is_train’]==False]&lt;/p&gt;

&lt;p&gt;features = df.columns[:4]
clf = RandomForestClassifier(n_jobs=2)
y, _ = pd.factorize(train[‘species’])
clf.fit(train[features], y)&lt;/p&gt;

&lt;p&gt;preds = iris.target_names[clf.predict(test[features])]
pd.crosstab(test[‘species’], preds, rownames=[‘actual’], colnames=[‘preds’])&lt;/p&gt;

&lt;p&gt;import numpy as np
import matplotlib.pyplot as plt
from matplotlib.colors import ListedColormap
from sklearn.cross_validation import train_test_split
from sklearn.preprocessing import StandardScaler
from sklearn.datasets import make_moons, make_circles, make_classification
from sklearn.neighbors import KNeighborsClassifier
from sklearn.svm import SVC
from sklearn.tree import DecisionTreeClassifier
from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier
from sklearn.naive_bayes import GaussianNB
from sklearn.lda import LDA
from sklearn.qda import QDA&lt;/p&gt;

&lt;p&gt;h = .02  # step size in the mesh&lt;/p&gt;

&lt;p&gt;names = [“Nearest Neighbors”, “Linear SVM”, “RBF SVM”, “Decision Tree”,
         “Random Forest”, “AdaBoost”, “Naive Bayes”, “LDA”, “QDA”]
classifiers = [
    KNeighborsClassifier(3),
    SVC(kernel=”linear”, C=0.025),
    SVC(gamma=2, C=1),
    DecisionTreeClassifier(max_depth=5),
    RandomForestClassifier(max_depth=5, n_estimators=10, max_features=1),
    AdaBoostClassifier(),
    GaussianNB(),
    LDA(),
    QDA()]&lt;/p&gt;

&lt;p&gt;X, y = make_classification(n_features=2, n_redundant=0, n_informative=2,
                           random_state=1, n_clusters_per_class=1)
rng = np.random.RandomState(2)
X += 2 * rng.uniform(size=X.shape)
linearly_separable = (X, y)&lt;/p&gt;

&lt;p&gt;datasets = [make_moons(noise=0.3, random_state=0),
            make_circles(noise=0.2, factor=0.5, random_state=1),
            linearly_separable
            ]&lt;/p&gt;

&lt;p&gt;figure = plt.figure(figsize=(27, 9))
i = 1
 # iterate over datasets
for ds in datasets:
    # preprocess dataset, split into training and test part
    X, y = ds
    X = StandardScaler().fit_transform(X)
    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=.4)&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;x_min, x_max = X[:, 0].min() - .5, X[:, 0].max() + .5
y_min, y_max = X[:, 1].min() - .5, X[:, 1].max() + .5
xx, yy = np.meshgrid(np.arange(x_min, x_max, h),
                     np.arange(y_min, y_max, h))

# just plot the dataset first
cm = plt.cm.RdBu
cm_bright = ListedColormap(['#FF0000', '#0000FF'])
ax = plt.subplot(len(datasets), len(classifiers) + 1, i)
# Plot the training points
ax.scatter(X_train[:, 0], X_train[:, 1], c=y_train, cmap=cm_bright)
# and testing points
ax.scatter(X_test[:, 0], X_test[:, 1], c=y_test, cmap=cm_bright, alpha=0.6)
ax.set_xlim(xx.min(), xx.max())
ax.set_ylim(yy.min(), yy.max())
ax.set_xticks(())
ax.set_yticks(())
i += 1

# iterate over classifiers
for name, clf in zip(names, classifiers):
    ax = plt.subplot(len(datasets), len(classifiers) + 1, i)
    clf.fit(X_train, y_train)
    score = clf.score(X_test, y_test)

    # Plot the decision boundary. For that, we will assign a color to each
    # point in the mesh [x_min, m_max]x[y_min, y_max].
    if hasattr(clf, &quot;decision_function&quot;):
        Z = clf.decision_function(np.c_[xx.ravel(), yy.ravel()])
    else:
        Z = clf.predict_proba(np.c_[xx.ravel(), yy.ravel()])[:, 1]

    # Put the result into a color plot
    Z = Z.reshape(xx.shape)
    ax.contourf(xx, yy, Z, cmap=cm, alpha=.8)

    # Plot also the training points
    ax.scatter(X_train[:, 0], X_train[:, 1], c=y_train, cmap=cm_bright)
    # and testing points
    ax.scatter(X_test[:, 0], X_test[:, 1], c=y_test, cmap=cm_bright,
               alpha=0.6)

    ax.set_xlim(xx.min(), xx.max())
    ax.set_ylim(yy.min(), yy.max())
    ax.set_xticks(())
    ax.set_yticks(())
    ax.set_title(name)
    ax.text(xx.max() - .3, yy.min() + .3, ('%.2f' % score).lstrip('0'),
            size=15, horizontalalignment='right')
    i += 1
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;figure.subplots_adjust(left=.02, right=.98)
plt.show()
　　这里随机生成了三个样本集，分割面近似为月形、圆形和线形的。我们可以重点对比一下决策树和随机森林对样本空间的分割：&lt;/p&gt;

&lt;p&gt;　　1）从准确率上可以看出，随机森林在这三个测试集上都要优于单棵决策树，90%&amp;gt;85%，82%&amp;gt;80%，95%=95%；&lt;/p&gt;

&lt;p&gt;　　2）从特征空间上直观地可以看出，随机森林比决策树拥有更强的分割能力（非线性拟合能力）。&lt;/p&gt;
</description>
        <pubDate>Tue, 09 Jan 2018 00:00:00 +0800</pubDate>
        <link>https://xiazemin.github.io/MyBlog/spark/2018/01/09/random_foreast.html</link>
        <guid isPermaLink="true">https://xiazemin.github.io/MyBlog/spark/2018/01/09/random_foreast.html</guid>
        
        
        <category>spark</category>
        
      </item>
    
      <item>
        <title>svm</title>
        <description>&lt;p&gt;&lt;img src=&quot;https://xiazemin.github.io/MyBlog/img/svm.png&quot; /&gt;&lt;/p&gt;
</description>
        <pubDate>Mon, 08 Jan 2018 00:00:00 +0800</pubDate>
        <link>https://xiazemin.github.io/MyBlog/spark/2018/01/08/svm.html</link>
        <guid isPermaLink="true">https://xiazemin.github.io/MyBlog/spark/2018/01/08/svm.html</guid>
        
        
        <category>spark</category>
        
      </item>
    
      <item>
        <title>virtualenv</title>
        <description>&lt;p&gt;在开发Python应用程序的时候，系统安装的Python3只有一个版本：3.4。所有第三方的包都会被pip安装到Python3的site-packages目录下。&lt;/p&gt;

&lt;p&gt;如果我们要同时开发多个应用程序，那这些应用程序都会共用一个Python，就是安装在系统的Python 3。如果应用A需要jinja 2.7，而应用B需要jinja 2.6怎么办？&lt;/p&gt;

&lt;p&gt;这种情况下，每个应用可能需要各自拥有一套“独立”的Python运行环境。virtualenv就是用来为一个应用创建一套“隔离”的Python运行环境。&lt;/p&gt;

&lt;p&gt;首先，我们用pip安装virtualenv：&lt;/p&gt;

&lt;p&gt;$ pip3 install virtualenv
然后，假定我们要开发一个新的项目，需要一套独立的Python运行环境，可以这么做：&lt;/p&gt;

&lt;p&gt;第一步，创建目录：&lt;/p&gt;

&lt;p&gt;Mac:~ michael$ mkdir myproject
Mac:~ michael$ cd myproject/
Mac:myproject michael$
第二步，创建一个独立的Python运行环境，命名为venv：&lt;/p&gt;

&lt;p&gt;Mac:myproject michael$ virtualenv –no-site-packages venv
Using base prefix ‘/usr/local/…/Python.framework/Versions/3.4’
New python executable in venv/bin/python3.4
Also creating executable in venv/bin/python
Installing setuptools, pip, wheel…done.
命令virtualenv就可以创建一个独立的Python运行环境，我们还加上了参数–no-site-packages，这样，已经安装到系统Python环境中的所有第三方包都不会复制过来，这样，我们就得到了一个不带任何第三方包的“干净”的Python运行环境。&lt;/p&gt;

&lt;p&gt;新建的Python环境被放到当前目录下的venv目录。有了venv这个Python环境，可以用source进入该环境：&lt;/p&gt;

&lt;p&gt;Mac:myproject michael$ source venv/bin/activate
(venv)Mac:myproject michael$
注意到命令提示符变了，有个(venv)前缀，表示当前环境是一个名为venv的Python环境。&lt;/p&gt;

&lt;p&gt;下面正常安装各种第三方包，并运行python命令：&lt;/p&gt;

&lt;p&gt;(venv)Mac:myproject michael$ pip install jinja2
…
Successfully installed jinja2-2.7.3 markupsafe-0.23
(venv)Mac:myproject michael$ python myapp.py
…
在venv环境下，用pip安装的包都被安装到venv这个环境下，系统Python环境不受任何影响。也就是说，venv环境是专门针对myproject这个应用创建的。&lt;/p&gt;

&lt;p&gt;退出当前的venv环境，使用deactivate命令：&lt;/p&gt;

&lt;p&gt;(venv)Mac:myproject michael$ deactivate 
Mac:myproject michael$
此时就回到了正常的环境，现在pip或python均是在系统Python环境下执行。&lt;/p&gt;

&lt;p&gt;完全可以针对每个应用创建独立的Python运行环境，这样就可以对每个应用的Python环境进行隔离。&lt;/p&gt;

&lt;p&gt;virtualenv是如何创建“独立”的Python运行环境的呢？原理很简单，就是把系统Python复制一份到virtualenv的环境，用命令source venv/bin/activate进入一个virtualenv环境时，virtualenv会修改相关环境变量，让命令python和pip均指向当前的virtualenv环境。
&lt;!-- more --&gt;&lt;/p&gt;

&lt;p&gt;如果在命令行中运行virtualenv –system-site-packages ENV, 会继承/usr/lib/python2.7/site-packages下的所有库, 最新版本virtualenv把把访问全局site-packages作为默认行为
default behavior.&lt;/p&gt;

&lt;p&gt;2.1. 激活virtualenv&lt;/p&gt;

&lt;p&gt;#ENV目录下使用如下命令
➜  ENV git:(master) ✗ source ./bin/activate  #激活当前virtualenv
(ENV)➜  ENV git:(master) ✗ #注意终端发生了变化
#ENV目录下使用如下命令
➜  ENV git:(master) ✗ source ./bin/activate  #激活当前virtualenv
(ENV)➜  ENV git:(master) ✗ #注意终端发生了变化&lt;/p&gt;

&lt;p&gt;#使用pip查看当前库
(ENV)➜  ENV git:(master) ✗ pip list
pip (1.5.6)
setuptools (3.6)
wsgiref (0.1.2) #发现在只有这三个
pip freeze  #显示所有依赖
pip freeze &amp;gt; requirement.txt  #生成requirement.txt文件
pip install -r requirement.txt  #根据requirement.txt生成相同的环境
#使用pip查看当前库
(ENV)➜  ENV git:(master) ✗ pip list
pip (1.5.6)
setuptools (3.6)
wsgiref (0.1.2) #发现在只有这三个
pip freeze  #显示所有依赖
pip freeze &amp;gt; requirement.txt  #生成requirement.txt文件
pip install -r requirement.txt  #根据requirement.txt生成相同的环境
2.2. 关闭virtualenv
使用下面命令
$ deactivate
$ deactivate
2.3. 指定python版本
可以使用-p PYTHON_EXE选项在创建虚拟环境的时候指定python版本&lt;/p&gt;

&lt;p&gt;#创建python2.7虚拟环境
➜  Test git:(master) ✗ virtualenv -p /usr/bin/python2.7 ENV2.7
Running virtualenv with interpreter /usr/bin/python2.7
New python executable in ENV2.7/bin/python
Installing setuptools, pip…done.
#创建python2.7虚拟环境
➜  Test git:(master) ✗ virtualenv -p /usr/bin/python2.7 ENV2.7
Running virtualenv with interpreter /usr/bin/python2.7
New python executable in ENV2.7/bin/python
Installing setuptools, pip…done.&lt;/p&gt;

&lt;p&gt;#创建python3.4虚拟环境
➜  Test git:(master) ✗ virtualenv -p /usr/local/bin/python3.4 ENV3.4
Running virtualenv with interpreter /usr/local/bin/python3.4
Using base prefix ‘/Library/Frameworks/Python.framework/Versions/3.4’
New python executable in ENV3.4/bin/python3.4
Also creating executable in ENV3.4/bin/python
Installing setuptools, pip…done.
#创建python3.4虚拟环境
➜  Test git:(master) ✗ virtualenv -p /usr/local/bin/python3.4 ENV3.4
Running virtualenv with interpreter /usr/local/bin/python3.4
Using base prefix ‘/Library/Frameworks/Python.framework/Versions/3.4’
New python executable in ENV3.4/bin/python3.4
Also creating executable in ENV3.4/bin/python
Installing setuptools, pip…done.
到此已经可以解决python版本冲突问题和python库不同版本的问题&lt;/p&gt;
&lt;ol&gt;
  &lt;li&gt;其他
3.1. 生成可打包环境
某些特殊需求下,可能没有网络, 我们期望直接打包一个ENV, 可以解压后直接使用, 这时候可以使用virtualenv -relocatable指令将ENV修改为可更改位置的ENV&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;#对当前已经创建的虚拟环境更改为可迁移
➜  ENV3.4 git:(master) ✗ virtualenv –relocatable ./
Making script ./bin/easy_install relative
Making script ./bin/easy_install-3.4 relative
Making script ./bin/pip relative
Making script ./bin/pip3 relative
Making script ./bin/pip3.4 relative
#对当前已经创建的虚拟环境更改为可迁移
➜  ENV3.4 git:(master) ✗ virtualenv –relocatable ./
Making script ./bin/easy_install relative
Making script ./bin/easy_install-3.4 relative
Making script ./bin/pip relative
Making script ./bin/pip3 relative
Making script ./bin/pip3.4 relative
3.2. 获得帮助&lt;/p&gt;

&lt;p&gt;$ virtualenv -h
$ virtualenv -h
当前的ENV都被修改为相对路径, 可以打包当前目录, 上传到其他位置使用&lt;/p&gt;

&lt;p&gt;python模块以及导入出现ImportError: No module named ‘xxx’问题&lt;/p&gt;

&lt;p&gt;python中，每个py文件被称之为模块，每个具有__init__.py文件的目录被称为包。只要模
块或者包所在的目录在sys.path中，就可以使用import 模块或import 包来使用
如果你要使用的模块（py文件）和当前模块在同一目录，只要import相应的文件名就好，比
如在a.py中使用b.py： 
import b&lt;/p&gt;

&lt;p&gt;但是如果要import一个不同目录的文件(例如b.py)该怎么做呢？ 
首先需要使用sys.path.append方法将b.py所在目录加入到搜素目录中。然后进行import即
可，例如 
import sys 
sys.path.append(‘c:\xxxx\b.py’) # 这个例子针对 windows 用户来说的 
大多数情况，上面的代码工作的很好。但是如果你没有发现上面代码有什么问题的话，可要&lt;/p&gt;

&lt;p&gt;注意了，上面的代码有时会找不到模块或者包（ImportError: No module named 
xxxxxx），这是因为： 
sys模块是使用c语言编写的，因此字符串支持 ‘\n’, ‘\r’, ‘\t’等来表示特殊字符。所以&lt;/p&gt;

&lt;p&gt;上面代码最好写成： 
sys.path.append(‘c:\xxx\b.py’) 
或者sys.path.append(‘c:/xxxx/b.py’) 
这样可以避免因为错误的组成转义字符，而造成无效的搜索目录（sys.path）设置。&lt;/p&gt;

&lt;p&gt;sys.path是python的搜索模块的路径集，是一个list
可以在python 环境下使用sys.path.append(path)添加相关的路径，但在退出python环境后
自己添加的路径就会自动消失了！&lt;/p&gt;

&lt;p&gt;3、搜索路径和路径搜索&lt;/p&gt;

&lt;p&gt;模块的导入需要叫做“路径搜索”的过程。&lt;/p&gt;

&lt;p&gt;搜索路径：查找一组目录&lt;/p&gt;

&lt;p&gt;路径搜索：查找某个文件的操作&lt;/p&gt;

&lt;p&gt;ImportError: No module named myModule
这种错误就是说：模块不在搜索路径里，从而导致路径搜索失败！&lt;/p&gt;

&lt;p&gt;导入模块时，不带模块的后缀名，比如.py
Python搜索模块的路径：
1)、程序的主目录
2)、PTYHONPATH目录（如果已经进行了设置）
3)、标准连接库目录（一般在/usr/local/lib/python2.X/）
4)、任何的.pth文件的内容（如果存在的话）.新功能，允许用户把有效果的目录添加到模块搜索路径中去
.pth后缀的文本文件中一行一行的地列出目录。
这四个组建组合起来就变成了sys.path了，&lt;/p&gt;

&lt;blockquote&gt;
  &lt;blockquote&gt;
    &lt;blockquote&gt;
      &lt;p&gt;import sys
sys.path
导入时，Python会自动由左到右搜索这个列表中每个目录。&lt;/p&gt;
    &lt;/blockquote&gt;
  &lt;/blockquote&gt;
&lt;/blockquote&gt;

&lt;p&gt;关于 python ImportError: No module named ‘xxx’的问题?
解决方法如下：&lt;/p&gt;
&lt;ol&gt;
  &lt;li&gt;使用PYTHONPATH环境变量，在这个环境变量中输入相关的路径，不同的路径之间用逗号
（英文的！)分开，如果PYTHONPATH 变量还不存在，可以创建它！
这里的路径会自动加入到sys.path中，永久存在于sys.path中而且可以在不同的python版本
中共享，应该是一样较为方便的方法。
C:\Users\Administrator\Desktop\test\module1.py:
def func1():
 print(“func1”)&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;将C:\Users\Administrator\Desktop\test添加到PYTHONPATH即可直接import module1,然后
调用：module1.func1()即可。&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;
    &lt;p&gt;将自己做的py文件放到 site_packages 目录下&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;使用pth文件，在 site-packages 文件中创建 .pth文件，将模块的路径写进去，一行一
个路径，以下是一个示例，pth文件也可以使用注释：&lt;/p&gt;
  &lt;/li&gt;
&lt;/ol&gt;

&lt;h1 id=&quot;pth-file-for-the--my-project这行是注释命名为xxxpth文件&quot;&gt;.pth file for the  my project(这行是注释)，命名为xxx.pth文件&lt;/h1&gt;
&lt;p&gt;C:\Users\Administrator\Desktop\test
这个不失为一个好的方法，但存在管理上的问题，而且不能在不同的python版本中共享。&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;
    &lt;p&gt;在调用文件中添加sys.path.append(“模块文件目录”)；&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;直接把模块文件拷贝到$python_dir/Lib目录下。&lt;/p&gt;
  &lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;通过以上5个方法就可以直接使用import module_name了。&lt;/p&gt;

</description>
        <pubDate>Sun, 07 Jan 2018 00:00:00 +0800</pubDate>
        <link>https://xiazemin.github.io/MyBlog/web/2018/01/07/virtualenv.html</link>
        <guid isPermaLink="true">https://xiazemin.github.io/MyBlog/web/2018/01/07/virtualenv.html</guid>
        
        
        <category>web</category>
        
      </item>
    
      <item>
        <title>pip</title>
        <description>&lt;p&gt;1、pip下载安装
1.1 pip下载
 # wget “https://pypi.python.org/packages/source/p/pip/pip-1.5.4.tar.gz#md5=834b2904f92d46aaa333267fb1c922bb” –no-check-certificate
 # wget “https://pypi.python.org/packages/source/p/pip/pip-1.5.4.tar.gz#md5=834b2904f92d46aaa333267fb1c922bb” –no-check-certificate
1.2 pip安装
 # tar -xzvf pip-1.5.4.tar.gz
 # cd pip-1.5.4
 # python setup.py install
 # tar -xzvf pip-1.5.4.tar.gz
 # cd pip-1.5.4
 # python setup.py install&lt;/p&gt;
&lt;ol&gt;
  &lt;li&gt;pip使用详解
2.1 pip安装包
 # pip install SomePackage
  […]
  Successfully installed SomePackage
 # pip install SomePackage
  […]
  Successfully installed SomePackage
2.2 pip查看已安装的包
 # pip show –files SomePackage
  Name: SomePackage
  Version: 1.0
  Location: /my/env/lib/pythonx.x/site-packages
  Files:
../somepackage/&lt;strong&gt;init&lt;/strong&gt;.py
[…]
  # pip show –files SomePackage
  Name: SomePackage
  Version: 1.0
  Location: /my/env/lib/pythonx.x/site-packages
  Files:
../somepackage/&lt;strong&gt;init&lt;/strong&gt;.py
[…]
2.3 pip检查哪些包需要更新
 # pip list –outdated
  SomePackage (Current: 1.0 Latest: 2.0)
 # pip list –outdated
  SomePackage (Current: 1.0 Latest: 2.0)
2.4 pip升级包
 # pip install –upgrade SomePackage
  […]
  Found existing installation: SomePackage 1.0
  Uninstalling SomePackage:
 Successfully uninstalled SomePackage
  Running setup.py install for SomePackage
  Successfully installed SomePackage
2.5 pip卸载包
$ pip uninstall SomePackage
  Uninstalling SomePackage:
 /my/env/lib/pythonx.x/site-packages/somepackage
  Proceed (y/n)? y
  Successfully uninstalled SomePackage&lt;/li&gt;
  &lt;li&gt;pip参数解释
 # pip –help
Usage: &lt;br /&gt;
  pip &lt;command /&gt; [options]&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;Commands:
  install                     安装包.
  uninstall                   卸载包.
  freeze                      按着一定格式输出已安装包列表
  list                        列出已安装包.
  show                        显示包详细信息.
  search                      搜索包，类似yum里的search.
  wheel                       Build wheels from your requirements.
  zip                         不推荐. Zip individual packages.
  unzip                       不推荐. Unzip individual packages.
  bundle                      不推荐. Create pybundles.
  help                        当前帮助.&lt;/p&gt;

&lt;p&gt;General Options:
  -h, –help                  显示帮助.
  -v, –verbose               更多的输出，最多可以使用3次
  -V, –version               现实版本信息然后退出.
  -q, –quiet                 最少的输出.
  –log-file &lt;path&gt;           覆盖的方式记录verbose错误日志，默认文件：/root/.pip/pip.log
  --log &lt;path&gt;                不覆盖记录verbose输出的日志.
  --proxy &lt;proxy&gt;             Specify a proxy in the form [user:passwd@]proxy.server:port.
  --timeout &lt;sec&gt;             连接超时时间 (默认15秒).
  --exists-action &lt;action&gt;    Default action when a path already exists: (s)witch, (i)gnore, (w)ipe, (b)ackup.
  --cert &lt;path&gt;               证书.&lt;/path&gt;&lt;/action&gt;&lt;/sec&gt;&lt;/proxy&gt;&lt;/path&gt;&lt;/path&gt;&lt;/p&gt;

&lt;p&gt;#install pip3 for python 3.x
 pip3 install –upgrade pip
 2 Collecting pip
 3   Downloading pip-9.0.1-py2.py3-none-any.whl (1.3MB)
 4     100% |████████████████████████████████| 1.3MB 3.2kB/s 
 5 Installing collected packages: pip
 6   Found existing installation: pip 8.1.1
 7     Uninstalling pip-8.1.1:
 8       Successfully uninstalled pip-8.1.1
 9 Successfully installed pip-9.0.1&lt;/p&gt;

</description>
        <pubDate>Sun, 07 Jan 2018 00:00:00 +0800</pubDate>
        <link>https://xiazemin.github.io/MyBlog/web/2018/01/07/pip.html</link>
        <guid isPermaLink="true">https://xiazemin.github.io/MyBlog/web/2018/01/07/pip.html</guid>
        
        
        <category>web</category>
        
      </item>
    
      <item>
        <title>信息熵</title>
        <description>&lt;p&gt;熵定义如下：
变量的不确定性越大，熵也就越大，把它搞清楚所需要的信息量也就越大。香农不是用钱，而是用 “比特”（bit）这个概念来度量信息量。 信息量的比特数和所有可能情况的对数函数 log 有关。（二进制位数）常用的汉字（一级二级国标）大约有 7000 字。假如每个字等概率，那么我们大约需要 13 个比特（即 13 位二进制数）表示一个汉字。&lt;/p&gt;

&lt;p&gt;信息量可以表示为：
-log2(pi)
即信息占的bit数
信息熵其实是一个随机变量信息量的数学期望。
H(X)=−∑P(x)logP(x))&lt;/p&gt;

&lt;p&gt;信息熵（又叫香农熵 Shannon entropy）反映了一个系统的无序化（有序化）程度，一个系统越有序，信息熵就越低，反之就越高&lt;/p&gt;

&lt;p&gt;相对熵（relative entropy）
所谓相对，自然在两个随机变量之间。又称互熵，Kullback–Leibler divergence（K-L 散度）等。设 p(x)和 q(x) 是 X取值的两个概率分布，则 p 对 q的相对熵为： 
D(p||q)=∑i=1np(x)logp(x)q(x)&lt;/p&gt;

&lt;p&gt;在一定程度上，熵可以度量两个随机变量的距离。KL 散度是两个概率分布 P 和 Q 差别的非对称性的度量。KL 散度是用来度量使用基于 Q 的编码来编码来自 P 的样本平均所需的额外的位元数。
典型情况下，P 表示数据的真实分布，Q 表示数据的理论分布，模型分布，或 P 的近似分布。
相对熵的性质，相对熵（KL散度）有两个主要的性质。如下
（1）尽管 KL 散度从直观上是个度量或距离函数，但它并不是一个真正的度量或者距离，因为它不具有对称性，即
D(p||q)≠D(q||p)
（2）相对熵的值为非负值，即
D(p||q)≥0&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;交叉熵（cross entropy）
H(p,q)=−∑xp(x)logq(x)
在学习决策树时，最重要的步骤是构建决策树。&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;其中，最重要的步骤是根据属性划分数据集，其中先使用哪个属性，后使用哪个属性，是决定决策树构建的好坏的重要标准。&lt;/p&gt;

&lt;p&gt;其中，使用属性构建数据集，最重要的参考标准，就是使划分后的信息增益最大。&lt;/p&gt;

&lt;p&gt;熵：表示随机变量不确定性，即混乱程度的量化指标。&lt;/p&gt;

&lt;p&gt;熵越大，不确定性越大，越无序；越小，确定性越大，越有序。&lt;/p&gt;

&lt;p&gt;同理，一条信息的信息量大小，与不确定性直接相关。&lt;/p&gt;

&lt;p&gt;不确定性越大，信息量越大，熵越大；&lt;/p&gt;

&lt;p&gt;确定性越大，信息量越小，熵越小。&lt;/p&gt;

&lt;p&gt;熵的单位是bit。&lt;/p&gt;

&lt;p&gt;不计算信息量等，直接存储一个文件，需要的是正常的存储空间大小。&lt;/p&gt;

&lt;p&gt;通过压缩算法，仅保留有用信息的情况下，存储的是文件的信息量。&lt;/p&gt;

&lt;p&gt;两者数量上的差距，是冗余度。&lt;/p&gt;

&lt;p&gt;由此可见：冗余度越大，可压缩的空间越大。反之，亦然。&lt;/p&gt;

&lt;p&gt;另一种度量集合无序程度的方法是：Gini impurity，基尼不纯度。&lt;/p&gt;

&lt;p&gt;信息增益
信息增益 = 信息熵 - 条件熵
信息增益代表了在一个条件下，信息复杂度（不确定性）减少的程度&lt;/p&gt;

&lt;p&gt;条件熵&lt;/p&gt;

&lt;p&gt;条件熵是用来解释信息增益而引入的概念，概率定义：随机变量X在给定条件下随机变量Y的条件熵，对定义描述为：X给定条件下Y的条件干率分布的熵对X的数学期望，在机器学习中为选定某个特征后的熵，公式如下：
H(Y|X)=∑p(x)H(Y|X=x)&lt;/p&gt;

&lt;p&gt;3、信息增益
信息增益在决策树算法中是用来选择特征的指标，信息增益越大，则这个特征的选择性越好，在概率中定义为：待分类的集合的熵和选定某个特征的条件熵之差（这里只的是经验熵或经验条件熵，由于真正的熵并不知道，是根据样本计算出来的），公式如下：
IG=H(Y)-H(Y|X)&lt;/p&gt;

&lt;p&gt;随机变量X（嫁与不嫁）的信息熵为：
嫁的个数为6个，占1/2，那么信息熵为-1/2log1/2-1/2log1/2 = -log1/2=0.301
现在假如我知道了一个男生的身高信息。身高有三个可能的取值{矮，中，高}
矮包括{1,2,3,5,6,11,12}，嫁的个数为1个，不嫁的个数为6个
中包括{8,9} ，嫁的个数为2个，不嫁的个数为0个
高包括{4,7,10}，嫁的个数为3个，不嫁的个数为0个&lt;/p&gt;

&lt;p&gt;我们先求出公式对应的:
H(Y|X = 矮) = -1/7log1/7-6/7log6/7=0.178
H(Y|X=中) = -1log1-0 = 0
H(Y|X=高） = -1log1-0=0
p(X = 矮) = 7/12,p(X =中) = 2/12,p(X=高) = 3/12
则可以得出条件熵为：
7/12&lt;em&gt;0.178+2/12&lt;/em&gt;0+3/12*0 = 0.103
那么我们知道信息熵与条件熵相减就是我们的信息增益，为0.301-0.103=0.198&lt;/p&gt;

&lt;p&gt;信息增益是针对一个一个的特征而言的，就是看一个特征t，系统有它和没它的时候信息量各是多少，两者的差值就是这个特征给系统带来的信息量，即增益。系统含有特征t的时候信息量很好计算，就是刚才的式子，它表示的是包含所有特征时系统的信息量。&lt;/p&gt;

&lt;p&gt;用决策树来预测：&lt;/p&gt;

&lt;p&gt;决策树的形式类似于“如果天气怎么样，去玩；否则，怎么着怎么着”的树形分叉。那么问题是用哪个属性（即变量，如天气、温度、湿度和风力）最适合充当这颗树的根节点，在它上面没有其他节点，其他的属性都是它的后续节点。&lt;/p&gt;

&lt;p&gt;那么借用上面所述的能够衡量一个属性区分以上数据样本的能力的“信息增益”（Information Gain）理论。&lt;/p&gt;

&lt;p&gt;如果一个属性的信息增益量越大，这个属性作为一棵树的根节点就能使这棵树更简洁，比如说一棵树可以这么读成，如果风力弱，就去玩；风力强，再按天气、温度等分情况讨论，此时用风力作为这棵树的根节点就很有价值。如果说，风力弱，再又天气晴朗，就去玩；如果风力强，再又怎么怎么分情况讨论，这棵树相比就不够简洁了。&lt;/p&gt;

&lt;p&gt;ID3使用信息增益，c4.5使用信息增益比来选择特征&lt;/p&gt;

&lt;p&gt;作者：西门吹风
链接：https://www.zhihu.com/question/22928442/answer/117189907
来源：知乎
著作权归作者所有。商业转载请联系作者获得授权，非商业转载请注明出处。&lt;/p&gt;

&lt;p&gt;而信息增益（Info-Gain）就是指划分前后信息熵的变化：在ID3算法中，信息增益（Info-Gain）越大，划分越好，决策树算法本质上就是要找出每一列的最佳划分以及不同列划分的先后顺序及排布。后面回到题中的问题，C4.5中使用信息增益率（Gain-ratio），ID3算法使用信息增益（Info-Gain），二者有何区别？根据前文的例子，Info-Gain在面对类别较少的离散数据时效果较好，上例中的outlook、temperature等数据都是离散数据，而且每个类别都有一定数量的样本，这种情况下使用ID3与C4.5的区别并不大。但如果面对连续的数据（如体重、身高、年龄、距离等），或者每列数据没有明显的类别之分（最极端的例子的该列所有数据都独一无二），在这种情况下，我们分析信息增益（Info-Gain）的效果：根据公式，E(S)为初始label列的熵，并未发生变化，则IGain(S,A)的大小取决于E(A)的大小，E(A)越小，IGain(S,A)越大，而根据前文例子，，若某一列数据没有重复，ID3算法倾向于把每个数据自成一类，此时，这样E(A)为最小，IGain(S,A)最大，程序会倾向于选择这种划分，这样划分效果极差。为了解决这个问题，引入了信息增益率（Gain-ratio）的概念，计算方式如下：，这里Info为划分行为带来的信息，信息增益率如下计算：这样就减轻了划分行为本身的影响。评论中很多人对文中信息量和熵的部分有疑问，这确实是个很绕的问题，
目前对于信息的定义主要有以下几种：香农（C. E. Shannon）信息是不确定性的消除维纳信息定义 信息是独立于物质、能量的一种属性标示。逆香农信息定义 信息是确定性的增加。邓宇等人的定义 信息是事物现象及其属性标识的集合。上面几种定义各不相同，答主比较倾向于逆香农信息定义，但本质上还是香农那一套。&lt;/p&gt;

&lt;p&gt;基尼不纯度：将来自集合中的某种结果随机应用于集合中某一数据项的预期误差率。
公式：
&lt;img src=&quot;https://xiazemin.github.io/MyBlog/img/gini.png&quot; /&gt;&lt;/p&gt;

&lt;p&gt;基尼不纯度的大概意思是 一个随机事件变成它的对立事件的概率
      例如 一个随机事件X ，P(X=0) = 0.5 ,P(X=1)=0.5
      那么基尼不纯度就为   P(X=0)&lt;em&gt;(1 - P(X=0)) +   P(X=1)&lt;/em&gt;(1 - P(X=1))  = 0.5&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;   一个随机事件Y ，P(Y=0) = 0.1 ,P(Y=1)=0.9
  那么基尼不纯度就为P(Y=0)*(1 - P(Y=0)) +   P(Y=1)*(1 - P(Y=1))  = 0.18
 很明显 X比Y更混乱，因为两个都为0.5 很难判断哪个发生。而Y就确定得多，Y=0发生的概率很大。而基尼不纯度也就越小。
所以基尼不纯度也可以作为 衡量系统混乱程度的 标准
&lt;/code&gt;&lt;/pre&gt;

</description>
        <pubDate>Fri, 05 Jan 2018 00:00:00 +0800</pubDate>
        <link>https://xiazemin.github.io/MyBlog/spark/2018/01/05/shang.html</link>
        <guid isPermaLink="true">https://xiazemin.github.io/MyBlog/spark/2018/01/05/shang.html</guid>
        
        
        <category>spark</category>
        
      </item>
    
      <item>
        <title>Zookeeper与Paxos</title>
        <description>&lt;p&gt;　Zookeeper是一个开源的分布式协调服务，其设计目标是将那些复杂的且容易出错的分布式一致性服务封装起来，构成一个高效可靠的原语集，并以一些列简单的接口提供给用户使用。其是一个典型的分布式数据一致性的解决方案，分布式应用程序可以基于它实现诸如数据发布/发布、负载均衡、命名服务、分布式协调/通知、集群管理、Master选举、分布式锁和分布式队列等功能。其可以保证如下分布式一致性特性。&lt;/p&gt;

&lt;p&gt;　　① 顺序一致性，从同一个客户端发起的事务请求，最终将会严格地按照其发起顺序被应用到Zookeeper中去。&lt;/p&gt;

&lt;p&gt;　　② 原子性，所有事务请求的处理结果在整个集群中所有机器上的应用情况是一致的，即整个集群要么都成功应用了某个事务，要么都没有应用。&lt;/p&gt;

&lt;p&gt;　　③ 单一视图，无论客户端连接的是哪个Zookeeper服务器，其看到的服务端数据模型都是一致的。&lt;/p&gt;

&lt;p&gt;　　④ 可靠性，一旦服务端成功地应用了一个事务，并完成对客户端的响应，那么该事务所引起的服务端状态变更将会一直被保留，除非有另一个事务对其进行了变更。&lt;/p&gt;

&lt;p&gt;　　⑤ 实时性，Zookeeper保证在一定的时间段内，客户端最终一定能够从服务端上读取到最新的数据状态。&lt;/p&gt;

&lt;p&gt;　　2.1 设计目标&lt;/p&gt;

&lt;p&gt;　　Zookeeper致力于提供一个高性能、高可用、且具有严格的顺序访问控制能力（主要是写操作的严格顺序性）的分布式协调服务，其具有如下的设计目标。&lt;/p&gt;

&lt;p&gt;　　① 简单的数据模型，Zookeeper使得分布式程序能够通过一个共享的树形结构的名字空间来进行相互协调，即Zookeeper服务器内存中的数据模型由一系列被称为ZNode的数据节点组成，Zookeeper将全量的数据存储在内存中，以此来提高服务器吞吐、减少延迟的目的。&lt;/p&gt;

&lt;p&gt;　　② 可构建集群，一个Zookeeper集群通常由一组机器构成，组成Zookeeper集群的而每台机器都会在内存中维护当前服务器状态，并且每台机器之间都相互通信。&lt;/p&gt;

&lt;p&gt;　　③ 顺序访问，对于来自客户端的每个更新请求，Zookeeper都会分配一个全局唯一的递增编号，这个编号反映了所有事务操作的先后顺序。&lt;/p&gt;

&lt;p&gt;　　④ 高性能，Zookeeper将全量数据存储在内存中，并直接服务于客户端的所有非事务请求，因此它尤其适用于以读操作为主的应用场景。&lt;/p&gt;

&lt;p&gt;　　2.2 基本概念&lt;/p&gt;

&lt;p&gt;　　① 集群角色，最典型的集群就是Master/Slave模式（主备模式），此情况下把所有能够处理写操作的机器称为Master机器，把所有通过异步复制方式获取最新数据，并提供读服务的机器为Slave机器。Zookeeper引入了Leader、Follower、Observer三种角色，Zookeeper集群中的所有机器通过Leaser选举过程来选定一台被称为Leader的机器，Leader服务器为客户端提供写服务，Follower和Observer提供读服务，但是Observer不参与Leader选举过程，不参与写操作的过半写成功策略，Observer可以在不影响写性能的情况下提升集群的性能。&lt;/p&gt;

&lt;p&gt;　　② 会话，指客户端会话，一个客户端连接是指客户端和服务端之间的一个TCP长连接，Zookeeper对外的服务端口默认为2181，客户端启动的时候，首先会与服务器建立一个TCP连接，从第一次连接建立开始，客户端会话的生命周期也开始了，通过这个连接，客户端能够心跳检测与服务器保持有效的会话，也能够向Zookeeper服务器发送请求并接受响应，同时还能够通过该连接接受来自服务器的Watch事件通知。&lt;/p&gt;

&lt;p&gt;　　③ 数据节点，第一类指构成集群的机器，称为机器节点，第二类是指数据模型中的数据单元，称为数据节点-Znode，Zookeeper将所有数据存储在内存中，数据模型是一棵树，由斜杠/进行分割的路径，就是一个ZNode，如/foo/path1，每个ZNode都会保存自己的数据内存，同时还会保存一些列属性信息。ZNode分为持久节点和临时节点两类，持久节点是指一旦这个ZNode被创建了，除非主动进行ZNode的移除操作，否则这个ZNode将一直保存在Zookeeper上，而临时节点的生命周期和客户端会话绑定，一旦客户端会话失效，那么这个客户端创建的所有临时节点都会被移除。另外，Zookeeper还允许用户为每个节点添加一个特殊的属性：SEQUENTIAL。一旦节点被标记上这个属性，那么在这个节点被创建的时候，Zookeeper会自动在其节点后面追加一个整形数字，其是由父节点维护的自增数字。&lt;/p&gt;

&lt;p&gt;　　④ 版本，对于每个ZNode，Zookeeper都会为其维护一个叫作Stat的数据结构，Stat记录了这个ZNode的三个数据版本，分别是version（当前ZNode的版本）、cversion（当前ZNode子节点的版本）、aversion（当前ZNode的ACL版本）。&lt;/p&gt;

&lt;p&gt;　　⑤ Watcher，Zookeeper允许用户在指定节点上注册一些Watcher，并且在一些特定事件触发的时候，Zookeeper服务端会将事件通知到感兴趣的客户端。&lt;/p&gt;

&lt;p&gt;　　⑥ ACL，Zookeeper采用ACL（Access Control Lists）策略来进行权限控制，其定义了如下五种权限：&lt;/p&gt;

&lt;p&gt;　　　　· CREATE：创建子节点的权限。&lt;/p&gt;

&lt;p&gt;　　　　· READ：获取节点数据和子节点列表的权限。&lt;/p&gt;

&lt;p&gt;　　　　· WRITE：更新节点数据的权限。&lt;/p&gt;

&lt;p&gt;　　　　· DELETE：删除子节点的权限。&lt;/p&gt;

&lt;p&gt;　　　　· ADMIN：设置节点ACL的权限。&lt;/p&gt;

&lt;p&gt;　　2.3 ZAB协议&lt;/p&gt;

&lt;p&gt;　　Zookeeper使用了Zookeeper Atomic Broadcast（ZAB，Zookeeper原子消息广播协议）的协议作为其数据一致性的核心算法。ZAB协议是为Zookeeper专门设计的一种支持崩溃恢复的原子广播协议。&lt;/p&gt;

&lt;p&gt;　　Zookeeper依赖ZAB协议来实现分布式数据的一致性，基于该协议，Zookeeper实现了一种主备模式的系统架构来保持集群中各副本之间的数据的一致性，即其使用一个单一的诸进程来接收并处理客户端的所有事务请求，并采用ZAB的原子广播协议，将服务器数据的状态变更以事务Proposal的形式广播到所有的副本进程中，ZAB协议的主备模型架构保证了同一时刻集群中只能够有一个主进程来广播服务器的状态变更，因此能够很好地处理客户端大量的并发请求。&lt;/p&gt;

&lt;p&gt;　　ZAB协议的核心是定义了对于那些会改变Zookeeper服务器数据状态的事务请求的处理方式，即：所有事务请求必须由一个全局唯一的服务器来协调处理，这样的服务器被称为Leader服务器，余下的服务器则称为Follower服务器，Leader服务器负责将一个客户端事务请求转化成一个事务Proposal（提议），并将该Proposal分发给集群中所有的Follower服务器，之后Leader服务器需要等待所有Follower服务器的反馈，一旦超过半数的Follower服务器进行了正确的反馈后，那么Leader就会再次向所有的Follower服务器分发Commit消息，要求其将前一个Proposal进行提交。&lt;/p&gt;

&lt;p&gt;　　ZAB一些包括两种基本的模式：崩溃恢复和消息广播。&lt;/p&gt;

&lt;p&gt;　　当整个服务框架启动过程中或Leader服务器出现网络中断、崩溃退出与重启等异常情况时，ZAB协议就会进入恢复模式并选举产生新的Leader服务器。当选举产生了新的Leader服务器，同时集群中已经有过半的机器与该Leader服务器完成了状态同步之后，ZAB协议就会退出恢复模式，状态同步时指数据同步，用来保证集群在过半的机器能够和Leader服务器的数据状态保持一致。&lt;/p&gt;

&lt;p&gt;　　当集群中已经有过半的Follower服务器完成了和Leader服务器的状态同步，那么整个服务框架就可以进入消息广播模式，当一台同样遵守ZAB协议的服务器启动后加入到集群中，如果此时集群中已经存在一个Leader服务器在负责进行消息广播，那么加入的服务器就会自觉地进入数据恢复模式：找到Leader所在的服务器，并与其进行数据同步，然后一起参与到消息广播流程中去。Zookeeper只允许唯一的一个Leader服务器来进行事务请求的处理，Leader服务器在接收到客户端的事务请求后，会生成对应的事务提议并发起一轮广播协议，而如果集群中的其他机器收到客户端的事务请求后，那么这些非Leader服务器会首先将这个事务请求转发给Leader服务器。&lt;/p&gt;

&lt;p&gt;　　当Leader服务器出现崩溃或者机器重启、集群中已经不存在过半的服务器与Leader服务器保持正常通信时，那么在重新开始新的一轮的原子广播事务操作之前，所有进程首先会使用崩溃恢复协议来使彼此到达一致状态，于是整个ZAB流程就会从消息广播模式进入到崩溃恢复模式。一个机器要成为新的Leader，必须获得过半机器的支持，同时由于每个机器都有可能会崩溃，因此，ZAB协议运行过程中，前后会出现多个Leader，并且每台机器也有可能会多次成为Leader，进入崩溃恢复模式后，只要集群中存在过半的服务器能够彼此进行正常通信，那么就可以产生一个新的Leader并再次进入消息广播模式。如一个由三台机器组成的ZAB服务，通常由一个Leader、2个Follower服务器组成，某一个时刻，加入其中一个Follower挂了，整个ZAB集群是不会中断服务的。&lt;/p&gt;

&lt;p&gt;　　① 消息广播，ZAB协议的消息广播过程使用原子广播协议，类似于一个二阶段提交过程，针对客户端的事务请求，Leader服务器会为其生成对应的事务Proposal，并将其发送给集群中其余所有的机器，然后再分别收集各自的选票，最后进行事务提交。&lt;/p&gt;

&lt;p&gt;　　在ZAB的二阶段提交过程中，移除了中断逻辑，所有的Follower服务器要么正常反馈Leader提出的事务Proposal，要么就抛弃Leader服务器，同时，ZAB协议将二阶段提交中的中断逻辑移除意味着我们可以在过半的Follower服务器已经反馈Ack之后就开始提交事务Proposal，而不需要等待集群中所有的Follower服务器都反馈响应，但是，在这种简化的二阶段提交模型下，无法处理Leader服务器崩溃退出而带来的数据不一致问题，因此ZAB采用了崩溃恢复模式来解决此问题，另外，整个消息广播协议是基于具有FIFO特性的TCP协议来进行网络通信的，因此能够很容易保证消息广播过程中消息接受与发送的顺序性。再整个消息广播过程中，Leader服务器会为每个事务请求生成对应的Proposal来进行广播，并且在广播事务Proposal之前，Leader服务器会首先为这个事务Proposal分配一个全局单调递增的唯一ID，称之为事务ID（ZXID），由于ZAB协议需要保证每个消息严格的因果关系，因此必须将每个事务Proposal按照其ZXID的先后顺序来进行排序和处理。&lt;/p&gt;

&lt;p&gt;　　② 崩溃恢复，在Leader服务器出现崩溃，或者由于网络原因导致Leader服务器失去了与过半Follower的联系，那么就会进入崩溃恢复模式，在ZAB协议中，为了保证程序的正确运行，整个恢复过程结束后需要选举出一个新的Leader服务器，因此，ZAB协议需要一个高效且可靠的Leader选举算法，从而保证能够快速地选举出新的Leader，同时，Leader选举算法不仅仅需要让Leader自身知道已经被选举为Leader，同时还需要让集群中的所有其他机器也能够快速地感知到选举产生的新的Leader服务器。&lt;/p&gt;

&lt;p&gt;　　③ 基本特性，ZAB协议规定了如果一个事务Proposal在一台机器上被处理成功，那么应该在所有的机器上都被处理成功，哪怕机器出现故障崩溃。ZAB协议需要确保那些已经在Leader服务器上提交的事务最终被所有服务器都提交，假设一个事务在Leader服务器上被提交了，并且已经得到了过半Follower服务器的Ack反馈，但是在它Commit消息发送给所有Follower机器之前，Leader服务挂了。如下图所示&lt;/p&gt;

&lt;p&gt;　　在集群正常运行过程中的某一个时刻，Server1是Leader服务器，其先后广播了P1、P2、C1、P3、C2（C2是Commit Of Proposal2的缩写），其中，当Leader服务器发出C2后就立即崩溃退出了，针对这种情况，ZAB协议就需要确保事务Proposal2最终能够在所有的服务器上都被提交成功，否则将出现不一致。&lt;/p&gt;

&lt;p&gt;　　ZAB协议需要确保丢弃那些只在Leader服务器上被提出的事务。如果在崩溃恢复过程中出现一个需要被丢弃的提议，那么在崩溃恢复结束后需要跳过该事务Proposal，如下图所示&lt;/p&gt;

&lt;p&gt;　　假设初始的Leader服务器Server1在提出一个事务Proposal3之后就崩溃退出了，从而导致集群中的其他服务器都没有收到这个事务Proposal，于是，当Server1恢复过来再次加入到集群中的时候，ZAB协议需要确保丢弃Proposal3这个事务。&lt;/p&gt;

&lt;p&gt;　　在上述的崩溃恢复过程中需要处理的特殊情况，就决定了ZAB协议必须设计这样的Leader选举算法：能够确保提交已经被Leader提交的事务的Proposal，同时丢弃已经被跳过的事务Proposal。如果让Leader选举算法能够保证新选举出来的Leader服务器拥有集群中所有机器最高编号（ZXID最大）的事务Proposal，那么就可以保证这个新选举出来的Leader一定具有所有已经提交的提议，更为重要的是如果让具有最高编号事务的Proposal机器称为Leader，就可以省去Leader服务器查询Proposal的提交和丢弃工作这一步骤了。&lt;/p&gt;

&lt;p&gt;　　④ 数据同步，完成Leader选举后，在正式开始工作前，Leader服务器首先会确认日志中的所有Proposal是否都已经被集群中的过半机器提交了，即是否完成了数据同步。Leader服务器需要确所有的Follower服务器都能够接收到每一条事务Proposal，并且能够正确地将所有已经提交了的事务Proposal应用到内存数据库中。Leader服务器会为每个Follower服务器维护一个队列，并将那些没有被各Follower服务器同步的事务以Proposal消息的形式逐个发送给Follower服务器，并在每一个Proposal消息后面紧接着再发送一个Commit消息，以表示该事务已经被提交，等到Follower服务器将所有其尚未同步的事务Proposal都从Leader服务器上同步过来并成功应用到本地数据库后，Leader服务器就会将该Follower服务器加入到真正的可用Follower列表并开始之后的其他流程。&lt;/p&gt;

&lt;p&gt;　　下面分析ZAB协议如何处理需要丢弃的事务Proposal的，ZXID是一个64位的数字，其中32位可以看做是一个简单的单调递增的计数器，针对客户端的每一个事务请求，Leader服务器在产生一个新的事务Proposal时，都会对该计数器进行加1操作，而高32位则代表了Leader周期epoch的编号，每当选举产生一个新的Leader时，就会从这个Leader上取出其本地日志中最大事务Proposal的ZXID，并解析出epoch值，然后加1，之后以该编号作为新的epoch，低32位则置为0来开始生成新的ZXID，ZAB协议通过epoch号来区分Leader周期变化的策略，能够有效地避免不同的Leader服务器错误地使用不同的ZXID编号提出不一样的事务Proposal的异常情况。当一个包含了上一个Leader周期中尚未提交过的事务Proposal的服务器启动时，其肯定无法成为Leader，因为当前集群中一定包含了一个Quorum（过半）集合，该集合中的机器一定包含了更高epoch的事务的Proposal，因此这台机器的事务Proposal并非最高，也就无法成为Leader。&lt;/p&gt;

&lt;p&gt;　　2.4 ZAB协议原理&lt;/p&gt;

&lt;p&gt;　　ZAB主要包括消息广播和崩溃恢复两个过程，进一步可以分为三个阶段，分别是发现（Discovery）、同步（Synchronization）、广播（Broadcast）阶段。ZAB的每一个分布式进程会循环执行这三个阶段，称为主进程周期。&lt;/p&gt;

&lt;p&gt;　　· 发现，选举产生PL(prospective leader)，PL收集Follower epoch(cepoch)，根据Follower的反馈，PL产生newepoch(每次选举产生新Leader的同时产生新epoch)。&lt;/p&gt;

&lt;p&gt;　　· 同步，PL补齐相比Follower多数派缺失的状态、之后各Follower再补齐相比PL缺失的状态，PL和Follower完成状态同步后PL变为正式Leader(established leader)。&lt;/p&gt;

&lt;p&gt;　　· 广播，Leader处理客户端的写操作，并将状态变更广播至Follower，Follower多数派通过之后Leader发起将状态变更落地(deliver/commit)。&lt;/p&gt;

&lt;p&gt;　　在正常运行过程中，ZAB协议会一直运行于阶段三来反复进行消息广播流程，如果出现崩溃或其他原因导致Leader缺失，那么此时ZAB协议会再次进入发现阶段，选举新的Leader。&lt;/p&gt;

&lt;p&gt;　　2.4.1 运行分析&lt;/p&gt;

&lt;p&gt;　　每个进程都有可能处于如下三种状态之一&lt;/p&gt;

&lt;p&gt;　　· LOOKING：Leader选举阶段。&lt;/p&gt;

&lt;p&gt;　　· FOLLOWING：Follower服务器和Leader服务器保持同步状态。&lt;/p&gt;

&lt;p&gt;　　· LEADING：Leader服务器作为主进程领导状态。&lt;/p&gt;

&lt;p&gt;　　所有进程初始状态都是LOOKING状态，此时不存在Leader，此时，进程会试图选举出一个新的Leader，之后，如果进程发现已经选举出新的Leader了，那么它就会切换到FOLLOWING状态，并开始和Leader保持同步，处于FOLLOWING状态的进程称为Follower，LEADING状态的进程称为Leader，当Leader崩溃或放弃领导地位时，其余的Follower进程就会转换到LOOKING状态开始新一轮的Leader选举。&lt;/p&gt;

&lt;p&gt;　　一个Follower只能和一个Leader保持同步，Leader进程和所有与所有的Follower进程之间都通过心跳检测机制来感知彼此的情况。若Leader能够在超时时间内正常收到心跳检测，那么Follower就会一直与该Leader保持连接，而如果在指定时间内Leader无法从过半的Follower进程那里接收到心跳检测，或者TCP连接断开，那么Leader会放弃当前周期的领导，比你转换到LOOKING状态，其他的Follower也会选择放弃这个Leader，同时转换到LOOKING状态，之后会进行新一轮的Leader选举，并在选举产生新的Leader之后开始新的一轮主进程周期。&lt;/p&gt;

&lt;p&gt;　　2.5 ZAB与Paxos的联系和区别&lt;/p&gt;

&lt;p&gt;　　联系：&lt;/p&gt;

&lt;p&gt;　　① 都存在一个类似于Leader进程的角色，由其负责协调多个Follower进程的运行。&lt;/p&gt;

&lt;p&gt;　　② Leader进程都会等待超过半数的Follower做出正确的反馈后，才会将一个提议进行提交。&lt;/p&gt;

&lt;p&gt;　　③ 在ZAB协议中，每个Proposal中都包含了一个epoch值，用来代表当前的Leader周期，在Paxos算法中，同样存在这样的一个标识，名字为Ballot。&lt;/p&gt;

&lt;p&gt;　　区别：&lt;/p&gt;

&lt;p&gt;　　Paxos算法中，新选举产生的主进程会进行两个阶段的工作，第一阶段称为读阶段，新的主进程和其他进程通信来收集主进程提出的提议，并将它们提交。第二阶段称为写阶段，当前主进程开始提出自己的提议。&lt;/p&gt;

&lt;p&gt;　　ZAB协议在Paxos基础上添加了同步阶段，此时，新的Leader会确保存在过半的Follower已经提交了之前的Leader周期中的所有事务Proposal。&lt;/p&gt;

&lt;p&gt;　　ZAB协议主要用于构建一个高可用的分布式数据主备系统，而Paxos算法则用于构建一个分布式的一致性状态机系统。
&lt;!-- more --&gt;
Apache Zookeeper是由Apache Hadoop的子项目发展而来，于2010年11月正式成为Apache顶级项目。Zookeeper为分布式应用提供高效且可靠的分布式协调服务，提供了统一命名服务、配置管理、分布式锁等分布式的基础服务。Zookeeper并没有直接采用Paxos算法，而是采用了一种被称为ZAB(Zookeeper Atomic Broadcast)的一致性协议。&lt;/p&gt;

&lt;p&gt;初识Zookeeper
Zookeeper是一个开源的分布式协调服务，由Yahoo创建，是Google Chubby的开源实现。Zookeeper将那些复杂且容易出错的分布式一致性服务封装起来，构成一个高效可靠的原语集，并以一系列简单易用的接口提供给用户使用。&lt;/p&gt;

&lt;p&gt;分布式应用程序可以基于Zookeeper实现例如数据发布/订阅、负载均衡、命名服务、协调通知、集群管理、Master选举、分布式锁、分布式队列等功能。Zookeeper可以保证如下分布式一致性特性。&lt;/p&gt;

&lt;p&gt;1、顺序一致性：从同一个客户端发起的事务请求，最终将会严格地按照其发起顺序被应用到Zookeeper中；&lt;/p&gt;

&lt;p&gt;2、原子性：所有事务的请求结果在整个集群中所有机器上的应用情况是一致的，也就是说，要么在整个集群中所有机器上都成功应用了某一个事务，要么都没有应用，没有中间状态；&lt;/p&gt;

&lt;p&gt;3、单一视图：无论客户端连接的是哪个Zookeeper服务器，其看到的服务端数据模型都是一致的。&lt;/p&gt;

&lt;p&gt;4、实时性：Zookeeper仅仅保证在一定的时间内，客户端最终一定能够从服务端上读到最终的数据状态。&lt;/p&gt;

&lt;p&gt;Zookeeper的设计目标
目标一：简单的数据模型&lt;/p&gt;

&lt;p&gt;Zookeeper使得分布式程序能通过一个共享式的、树形结构的名字空间来进行相互协调。&lt;/p&gt;

&lt;p&gt;树形结构的名字空间是指Zookeeper服务器内存中的一个数据模型，由一系列被称为ZNode的数据节点组成，类似一个文件系统。&lt;/p&gt;

&lt;p&gt;目标二：可以构建集群&lt;/p&gt;

&lt;p&gt;组成Zookeeper集群的每台机器都会在内存中维护当前服务器状态，并且每台机器都保持通讯。只要集群中超过一半机器能够正常工作，整个集群就能对外正常服务。&lt;/p&gt;

&lt;p&gt;目标三：顺序访问&lt;/p&gt;

&lt;p&gt;对于来自客户端的每个更新请求，Zookeeper都会分配一个全局唯一递增编号，这个编号反映了所有事物操作的先后顺序，应用程序可以使用Zookeeper的这个特性来实现更加高层的同步原语。&lt;/p&gt;

&lt;p&gt;目标四：高性能&lt;/p&gt;

&lt;p&gt;Zookeeper将全量数据存储在内存中直接对外服务(除事务请求)，尤其适合于读操作为主的应用场景。&lt;/p&gt;

&lt;p&gt;Zookeeper基本概念&lt;/p&gt;

&lt;p&gt;集群角色
最典型的集群角色是Master/Slave模式，Master处理所有写操作，Slave提供读服务。&lt;/p&gt;

&lt;p&gt;在Zookeeper中，有Leader、Follower、Observer三种角色。集群中所有机器通过一个Leader选举来决定一台机器作为Leader，Leader为客户端提供读和写服务。Follower和Observer都提供读服务，区别在于Observer机器不参与选举，也不参与写操作的“过半写成功”策略，因此Observe可以在不影响写性能的情况下提升集群的读性能。&lt;/p&gt;

&lt;p&gt;会话
客户端与Zookeeper是TCP长连接，默认对外端口是2181，通过这个连接，客户端保持和服务器的心跳以维护连接，也能向Zookeeper发送请求并响应，同时还可以接收到注册通知。&lt;/p&gt;

&lt;p&gt;数据节点(ZNode)
Zookeeper所有数据都在内存中，模型类似一颗文件树，ZNode Tree，每个ZNode节点都会保存自己的数据内容和一系列属性。&lt;/p&gt;

&lt;p&gt;ZNode分为持久节点和临时节点，后者和客户端会话绑定。&lt;/p&gt;

&lt;p&gt;版本
每个ZNode，Zookeeper都会维护一个Stat数据结构记录这个ZNode的三个数据版本：当前ZNode版本version、当前ZNode子节点版本cversion、和当前Node的ACL版本aversion。&lt;/p&gt;

&lt;p&gt;Watcher
事件监听是Zookeeper的重要特性，他允许客户端在指定节点注册Watcher，并且在事件被触发后通知客户端。&lt;/p&gt;

&lt;p&gt;ACL
Access Control Lists，定义了5中权限：&lt;/p&gt;

&lt;p&gt;Create、Read、Write、Delete、Admin&lt;/p&gt;

&lt;p&gt;ZAB协议
在ZooKeeper中所有的事务请求都由一个主服务器也就是Leader来处理，其他服务器为Follower，Leader将客户端的事务请求转换为事务Proposal，并且将Proposal分发给集群中其他所有的Follower，然后Leader等待Follwer反馈，当有过半数（&amp;gt;=N/2+1）的Follower反馈信息后，Leader将再次向集群内Follower广播Commit信息，Commit为将之前的Proposal提交。&lt;/p&gt;

&lt;p&gt;ZAB协议中存在着三种状态，每个节点都属于以下三种中的一种：&lt;/p&gt;

&lt;p&gt;1.Looking：系统刚启动时或者Leader崩溃后正处于选举状态&lt;/p&gt;

&lt;p&gt;2.Following：Follower节点所处的状态，Follower与Leader处于数据同步阶段；&lt;/p&gt;

&lt;p&gt;3.Leading：Leader所处状态，当前集群中有一个Leader为主进程；&lt;/p&gt;

&lt;p&gt;ZooKeeper启动时所有节点初始状态为Looking，这时集群会尝试选举出一个Leader节点，选举出的Leader节点切换为Leading状态；当节点发现集群中已经选举出Leader则该节点会切换到Following状态，然后和Leader节点保持同步；当Follower节点与Leader失去联系时Follower节点则会切换到Looking状态，开始新一轮选举；在ZooKeeper的整个生命周期中每个节点都会在Looking、Following、Leading状态间不断转换；&lt;/p&gt;

&lt;p&gt;选举出Leader节点后ZAB进入原子广播阶段，这时Leader为和自己同步的每个节点Follower创建一个操作序列，一个时期一个Follower只能和一个Leader保持同步，Leader节点与Follower节点使用心跳检测来感知对方的存在；当Leader节点在超时时间内收到来自Follower的心跳检测那Follower节点会一直与该节点保持连接；若超时时间内Leader没有接收到来自过半Follower节点的心跳检测或TCP连接断开，那Leader会结束当前周期的领导，切换到Looking状态，所有Follower节点也会放弃该Leader节点切换到Looking状态，然后开始新一轮选举。&lt;/p&gt;

&lt;p&gt;ZAB协议定义了选举（election）、发现（discovery）、同步（sync）、广播(Broadcast)四个阶段；ZAB选举（election）时当Follower存在ZXID（事务ID）时判断所有Follower节点的事务日志，只有lastZXID的节点才有资格成为Leader，这种情况下选举出来的Leader总有最新的事务日志，基于这个原因所以ZooKeeper实现的时候把发现（discovery）与同步（sync）合并为恢复（recovery）阶段；&lt;/p&gt;

&lt;p&gt;1.Election：在Looking状态中选举出Leader节点，Leader的lastZXID总是最新的；&lt;/p&gt;

&lt;p&gt;2.Discovery：Follower节点向准Leader推送FOllOWERINFO，该信息中包含了上一周期的epoch，接受准Leader的NEWLEADER指令，检查newEpoch有效性，准Leader要确保Follower的epoch与ZXID小于或等于自身的；&lt;/p&gt;

&lt;p&gt;3.sync：将Follower与Leader的数据进行同步，由Leader发起同步指令，最总保持集群数据的一致性；&lt;/p&gt;

&lt;p&gt;4.Broadcast：Leader广播Proposal与Commit，Follower接受Proposal与Commit；&lt;/p&gt;

&lt;p&gt;5.Recovery：在Election阶段选举出Leader后本阶段主要工作就是进行数据的同步，使Leader具有highestZXID，集群保持数据的一致性；&lt;/p&gt;

&lt;p&gt;选举（Election）&lt;/p&gt;

&lt;p&gt;election阶段必须确保选出的Leader具有highestZXID，否则在Recovery阶段没法保证数据的一致性，Recovery阶段Leader要求Follower向自己同步数据没有Follower要求Leader保持数据同步，所有选举出来的Leader要具有最新的ZXID；&lt;/p&gt;

&lt;p&gt;在选举的过程中会对每个Follower节点的ZXID进行对比只有highestZXID的Follower才可能当选Leader；&lt;/p&gt;

&lt;p&gt;选举流程：&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;
    &lt;p&gt;每个Follower都向其他节点发送选自身为Leader的Vote投票请求，等待回复；&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Follower接受到的Vote如果比自身的大（ZXID更新）时则投票，并更新自身的Vote，否则拒绝投票；&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;每个Follower中维护着一个投票记录表，当某个节点收到过半的投票时，结束投票并把该Follower选为Leader，投票结束；&lt;/p&gt;
  &lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;ZAB协议中使用ZXID作为事务编号，ZXID为64位数字，低32位为一个递增的计数器，每一个客户端的一个事务请求时Leader产生新的事务后该计数器都会加1，高32位为Leader周期epoch编号，当新选举出一个Leader节点时Leader会取出本地日志中最大事务Proposal的ZXID解析出对应的epoch把该值加1作为新的epoch，将低32位从0开始生成新的ZXID；ZAB使用epoch来区分不同的Leader周期；&lt;/p&gt;

&lt;p&gt;恢复（Recovery）&lt;/p&gt;

&lt;p&gt;在election阶段选举出来的Leader已经具有最新的ZXID，所有本阶段的主要工作是根据Leader的事务日志对Follower节点数据进行更新；&lt;/p&gt;

&lt;p&gt;Leader：Leader生成新的ZXID与epoch，接收Follower发送过来的FOllOWERINFO（含有当前节点的LastZXID）然后往Follower发送NEWLEADER；Leader根据Follower发送过来的LastZXID根据数据更新策略向Follower发送更新指令；&lt;/p&gt;

&lt;p&gt;同步策略：&lt;/p&gt;

&lt;p&gt;1.SNAP：如果Follower数据太老，Leader将发送快照SNAP指令给Follower同步数据；&lt;/p&gt;

&lt;p&gt;2.DIFF：Leader发送从Follolwer.lastZXID到Leader.lastZXID议案的DIFF指令给Follower同步数据；&lt;/p&gt;

&lt;p&gt;3.TRUNC：当Follower.lastZXID比Leader.lastZXID大时，Leader发送从Leader.lastZXID到Follower.lastZXID的TRUNC指令让Follower丢弃该段数据；&lt;/p&gt;

&lt;p&gt;Follower：往Leader发送FOLLOERINFO指令，Leader拒绝就转到Election阶段；接收Leader的NEWLEADER指令，如果该指令中epoch比当前Follower的epoch小那么Follower转到Election阶段；Follower还有主要工作是接收SNAP/DIFF/TRUNC指令同步数据与ZXID，同步成功后回复ACKNETLEADER，然后进入下一阶段；Follower将所有事务都同步完成后Leader会把该节点添加到可用Follower列表中；&lt;/p&gt;

&lt;p&gt;SNAP与DIFF用于保证集群中Follower节点已经Committed的数据的一致性，TRUNC用于抛弃已经被处理但是没有Committed的数据；&lt;/p&gt;

&lt;p&gt;广播(Broadcast)&lt;/p&gt;

&lt;p&gt;客户端提交事务请求时Leader节点为每一个请求生成一个事务Proposal，将其发送给集群中所有的Follower节点，收到过半Follower的反馈后开始对事务进行提交，ZAB协议使用了原子广播协议；在ZAB协议中只需要得到过半的Follower节点反馈Ack就可以对事务进行提交，这也导致了Leader几点崩溃后可能会出现数据不一致的情况，ZAB使用了崩溃恢复来处理数字不一致问题；消息广播使用了TCP协议进行通讯所有保证了接受和发送事务的顺序性。广播消息时Leader节点为每个事务Proposal分配一个全局递增的ZXID（事务ID），每个事务Proposal都按照ZXID顺序来处理；&lt;/p&gt;

&lt;p&gt;Leader节点为每一个Follower节点分配一个队列按事务ZXID顺序放入到队列中，且根据队列的规则FIFO来进行事务的发送。Follower节点收到事务Proposal后会将该事务以事务日志方式写入到本地磁盘中，成功后反馈Ack消息给Leader节点，Leader在接收到过半Follower节点的Ack反馈后就会进行事务的提交，以此同时向所有的Follower节点广播Commit消息，Follower节点收到Commit后开始对事务进行提交。&lt;/p&gt;

&lt;p&gt;总的来说，ZAB主要是用来构建一个高可用的分布式数据主备系统，而Paxos则是构建一个分布式的一致性状态机系统。&lt;/p&gt;

&lt;p&gt;&amp;lt;Google的Chubby，Apache的Zookeeper都是基于它的理论来实现的，Paxos还被认为是到目前为止唯一的分布式一致性算法，其它的算法都是Paxos的改进或简化。有个问题要提一下，Paxos有一个前提：没有拜占庭将军问题。就是说Paxos只有在一个可信的计算环境中才能成立，这个环境是不会被入侵所破坏的。&lt;/p&gt;

&lt;p&gt;”&lt;/p&gt;

&lt;p&gt;Paxos 这个算法是Leslie Lamport在1990年提出的一种基于消息传递的一致性算法.Paxos 算法解决的问题是一个分布式系统如何就某个值（决议）达成一致。&lt;/p&gt;

&lt;p&gt;part-time parliament Paxos Made Simple里这样描述Paxos算法执行过程：&lt;/p&gt;

&lt;p&gt;prepare 阶段：
proposer 选择一个提案编号 n 并将 prepare 请求发送给 acceptors 中的一个多数派；
acceptor 收到 prepare 消息后，如果提案的编号大于它已经回复的所有 prepare 消息，则 acceptor 将自己上次接受的提案回复给 proposer，并承诺不再回复小于 n 的提案；
批准阶段：
当一个 proposer 收到了多数 acceptors 对 prepare 的回复后，就进入批准阶段。它要向回复 prepare 请求的 acceptors 发送 accept 请求，包括编号 n 和根据 P2c 决定的 value（如果根据 P2c 没有已经接受的 value，那么它可以自由决定 value）。
在不违背自己向其他 proposer 的承诺的前提下，acceptor 收到 accept 请求后即接受这个请求。
wiki上是两个阶段，论文里却是说三阶段，而且默认就有了个proposer相当于leader。查资料有大侠列出了第三个阶段(http://www.wuzesheng.com/?p=2724)：&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;Learn阶段:&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;当各个Acceptor达到一致之后，需要将达到一致的结果通知给所有的Learner.&lt;/p&gt;

&lt;p&gt;zookeeper采用org.apache.zookeeper.server.quorum.FastLeaderElection作为其缺省选举算法&lt;/p&gt;

&lt;p&gt;这篇文章http://csrd.aliapp.com/?p=162&amp;amp;replytocom=782 直接用paxos实现作为标题，提到  zookeeper在选举leader的时候采用了paxos算法(主要是fast paxos)&lt;/p&gt;

&lt;p&gt;偶然看到下边有人反驳：&lt;/p&gt;

&lt;p&gt;魏讲文：“&lt;/p&gt;

&lt;p&gt;FastLeaderElection根本不是Paxos，也不是Fast Paxos的实现。
FastLeaderElection源码与Paxos的论文相去甚远。&lt;/p&gt;

&lt;p&gt;Paxos与 FastPaxos算法中也有一个leader选举的问题。&lt;/p&gt;

&lt;p&gt;FastLeaderElection对于zookeeper来讲，只是相当于Paxos中的leader选举。&lt;/p&gt;

&lt;p&gt;”&lt;/p&gt;

&lt;p&gt;二、资料证实&lt;/p&gt;

&lt;p&gt;好的，查查资料，分析源码开始调研&lt;/p&gt;

&lt;p&gt;首先是魏讲文的反驳 ：&lt;/p&gt;

&lt;p&gt;There is a very common misunderstanding that the leader election algorithm in zookeeper is paxos or fast paxos. The leader election algorithm is not paxos or fast paxos, please consider the following facts:&lt;/p&gt;

&lt;p&gt;There is no the concept of proposal number in the leader election in zookeeper. the proposal number is a key concept to paxos. Some one think the epoch is the proposal number, but different followers may produce proposal with the same epoch which is not allowed in paxos.&lt;/p&gt;

&lt;p&gt;Fast paxos requires at least 3t + 1 acceptors, where t is the number of servers which are allowed to fail [3]. This is conflict with the fact that a zookeeper cluster with 3 servers works well even if one server failed.&lt;/p&gt;

&lt;p&gt;The leader election algorithm must make sure P1. However paxos does provide such guarantee.&lt;/p&gt;

&lt;p&gt;In paxos, a leader is also required to achieve progress. There are some similarities between the leader in paxos and the leader in zookeeper. Even if more than one servers believe they are the leader, the consistency is preserved both in zookeeper and in paxos. this is very clearly discussed in [1] and [2].&lt;/p&gt;

&lt;p&gt;然后是作者三次对比&lt;/p&gt;

&lt;p&gt;1）邮件列表&lt;/p&gt;

&lt;p&gt;Our protocol instead, has only two phases, just like a two-phase 
commit protocol. Of course, for Paxos, we can ignore the first phase in runs in 
which we have a single proposer as we can run phase 1 for multiple instances at 
a time, which is what Ben called previously Multi-Paxos, I believe. The trick 
with skipping phase 1 is to deal with leader switching. 
2）出书的访谈&lt;/p&gt;

&lt;p&gt;We made a few interesting observations about Paxos when contrasting it to Zab, like problems you could run into if you just implemented Paxos alone. Not that Paxos is broken or anything, just that in our setting, there were some properties it was not giving us. Some people still like to map Zab to Paxos, and they are not completely off, but the way we see it, Zab matches a service like ZooKeeper well.&lt;/p&gt;

&lt;p&gt;zk的分布式一致性算法有了个名称叫Zab&lt;/p&gt;

&lt;p&gt;3）论文&lt;/p&gt;

&lt;p&gt;We use an algorithm that shares some of the character- istics of Paxos, but that combines transaction logging needed for consensus with write-ahead logging needed for data tree recovery to enable an efficient implementa- tion.&lt;/p&gt;

&lt;p&gt;三、leader选举分析&lt;/p&gt;

&lt;p&gt;在我理解首先在选举时，并不能用到paxos算法，paxos里选总统也好，zk选leader也好，跟搞个提案让大部分人同意是有区别的。选主才能保证不会出现多proposer的并发提案冲突&lt;/p&gt;

&lt;p&gt;谁去作为proposer发提案？是paxos算法进行下去的前提。而提出提案让大部分follower同意则可用到类似paxos的算法实现一致性。zookeeper使用的是Zab算法实现一致性。&lt;/p&gt;

&lt;p&gt;zk的选主策略：&lt;/p&gt;

&lt;p&gt;there can be at most one leader (proposer) at any time, and we guarantee this by making sure 
that a quorum of replicas recognize the leader as a leader by committing to an 
epoch change. This change in epoch also allows us to get unique zxids since the 
epoch forms part of the zxid.&lt;/p&gt;

&lt;p&gt;每个server有一个id，收到提交的事务时则有一个zxid，随更新数据的变动，事务编号递增，server id各不同。首先选zxid最大的作为leader，如果zxid比较不出来，则选server id最大的为leader&lt;/p&gt;

&lt;p&gt;zxid包含一个epoch数字，epoch指示一个server作为leader的时期，随新的leader诞生而递增。&lt;/p&gt;

&lt;p&gt;再看代码：&lt;/p&gt;

&lt;p&gt;四、zookeeper数据更新原理分析&lt;/p&gt;

&lt;p&gt;了解完选主的做法后，来了解下同步数据的做法，同步数据则采用Zab协议：Zookeeper Atomic broadcast protocol，是个类似两阶段提交的协议：&lt;/p&gt;

&lt;p&gt;The leader sends a PROPOSAL message, p, to all followers.&lt;/p&gt;

&lt;p&gt;Upon receiving p, a follower responds to the leader with an ACK, informing the&lt;/p&gt;

&lt;p&gt;leader that it has accepted the proposal.&lt;/p&gt;

&lt;p&gt;Uponreceivingacknowledgmentsfromaquorum(thequorumincludestheleader&lt;/p&gt;

&lt;p&gt;itself), the leader sends a message informing the followers to COMMIT it.&lt;/p&gt;

&lt;p&gt;跟paxos的区别是leaer发送给所有follower，而不是大多数，所有follower都要确认并通知leader，而不是大多数。&lt;/p&gt;

&lt;p&gt;保证机制：按顺序广播的两个事务， T 和 Tʹ ，T在前则Tʹ 生效前必须提交T。如果有一个server 提交了T 和 Tʹ ，则所有其他server必须也在Tʹ前提交T。&lt;/p&gt;

&lt;p&gt;五、leader的探活&lt;/p&gt;

&lt;p&gt;为解决leader crash的问题，避免出现多个leader导致事务混乱，Zab算法保证：&lt;/p&gt;

&lt;p&gt;1、新事务开启时，leader必须提交上个epoch期间提交的所有事务&lt;/p&gt;

&lt;p&gt;2、任何时候都不会有两个leader同时获得足够多的支持者。&lt;/p&gt;

&lt;p&gt;一个新leader的起始状态需要大多数server同意&lt;/p&gt;

&lt;p&gt;六、observer&lt;/p&gt;

&lt;p&gt;zk里的第三种角色，观察者和follower的区别就是没有选举权。它主要是1、为系统的读请求扩展性存在 2、满足多机房部署需求，中心机房部署leader、follower，其他机房部署observer，读取配置优先读本地。&lt;/p&gt;

&lt;p&gt;七、总结&lt;/p&gt;

&lt;p&gt;我认为zookeeper只能说是受paxos算法影响，角色划分类似，提案通过方式类似，实现更为简单直观。选主基于voteid(server-id)和zxid做大小优先级排序，信息同步则使用两阶段提交，leader获取follower的全部同意后才提交事务，更新状态。observer角色则是为了增加系统吞吐和满足跨机房部署。&lt;/p&gt;

&lt;p&gt;参考文献&lt;/p&gt;

&lt;p&gt;[1] Reed, B., &amp;amp; Junqueira, F. P. (2008). A simple totally ordered broadcast protocol. Second
Workshop on Large-Scale Distributed Systems and Middleware (LADIS 2008). Yorktown
Heights, NY: ACM. ISBN: 978-1-60558-296-2.
[2] Lamport, L. Paxos made simple. ACM SIGACT News 32, 4 (Dec. 2001), 1825.
[3] F. Junqueira, Y. Mao, and K. Marzullo. Classic paxos vs. fast paxos: caveat emptor. In
Proceedings of the 3rd USENIX/IEEE/IFIP Workshop on Hot Topics in System Dependability
(HotDep.07). Citeseer, 2007.&lt;/p&gt;

&lt;p&gt;[4]O’Reilly.ZooKeeper.Distributed process coordination.2013&lt;/p&gt;

&lt;p&gt;[5] http://agapple.iteye.com/blog/1184023  zookeeper项目使用几点小结
1.1 基本定义
算法中的参与者主要分为三个角色，同时每个参与者又可兼领多个角色:&lt;/p&gt;

&lt;p&gt;⑴proposer 提出提案，提案信息包括提案编号和提议的value;&lt;/p&gt;

&lt;p&gt;⑵acceptor 收到提案后可以接受(accept)提案;&lt;/p&gt;

&lt;p&gt;⑶learner 只能”学习”被批准的提案;&lt;/p&gt;

&lt;p&gt;算法保重一致性的基本语义:&lt;/p&gt;

&lt;p&gt;⑴决议(value)只有在被proposers提出后才能被批准(未经批准的决议称为”提案(proposal)”);&lt;/p&gt;

&lt;p&gt;⑵在一次Paxos算法的执行实例中，只批准(chosen)一个value;&lt;/p&gt;

&lt;p&gt;⑶learners只能获得被批准(chosen)的value;&lt;/p&gt;

&lt;p&gt;有上面的三个语义可演化为四个约束:&lt;/p&gt;

&lt;p&gt;⑴P1:一个acceptor必须接受(accept)第一次收到的提案;&lt;/p&gt;

&lt;p&gt;⑵P2a:一旦一个具有value v的提案被批准(chosen)，那么之后任何acceptor 再次接受(accept)的提案必须具有value v;&lt;/p&gt;

&lt;p&gt;⑶P2b:一旦一个具有value v的提案被批准(chosen)，那么以后任何 proposer 提出的提案必须具有value v;&lt;/p&gt;

&lt;p&gt;⑷P2c:如果一个编号为n的提案具有value v，那么存在一个多数派，要么他们中所有人都没有接受(accept)编号小于n的任何提案，要么他们已经接受(accpet)的所有编号小于n的提案中编号最大的那个提案具有value v;&lt;/p&gt;

&lt;p&gt;1.2 基本算法(basic paxos)
算法(决议的提出与批准)主要分为两个阶段:&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;prepare阶段：&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;(1). 当Porposer希望提出方案V1，首先发出prepare请求至大多数Acceptor。Prepare请求内容为序列号&lt;SN1&gt;;&lt;/SN1&gt;&lt;/p&gt;

&lt;p&gt;(2). 当Acceptor接收到prepare请求&lt;SN1&gt;时，检查自身上次回复过的prepare请求&lt;SN2&gt;&lt;/SN2&gt;&lt;/SN1&gt;&lt;/p&gt;

&lt;p&gt;a). 如果SN2&amp;gt;SN1，则忽略此请求，直接结束本次批准过程;&lt;/p&gt;

&lt;p&gt;b). 否则检查上次批准的accept请求&amp;lt;SNx，Vx&amp;gt;，并且回复&amp;lt;SNx，Vx&amp;gt;；如果之前没有进行过批准，则简单回复&lt;OK&gt;;&lt;/OK&gt;&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;accept批准阶段：&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;(1a). 经过一段时间，收到一些Acceptor回复，回复可分为以下几种:&lt;/p&gt;

&lt;p&gt;a). 回复数量满足多数派，并且所有的回复都是&lt;OK&gt;，则Porposer发出accept请求，请求内容为议案&amp;lt;SN1，V1&amp;gt;;&lt;/OK&gt;&lt;/p&gt;

&lt;p&gt;b). 回复数量满足多数派，但有的回复为：&amp;lt;SN2，V2&amp;gt;，&amp;lt;SN3，V3&amp;gt;……则Porposer找到所有回复中超过半数的那个，假设为&amp;lt;SNx，Vx&amp;gt;，则发出accept请求，请求内容为议案&amp;lt;SN1，Vx&amp;gt;;&lt;/p&gt;

&lt;p&gt;c). 回复数量不满足多数派，Proposer尝试增加序列号为SN1+，转1继续执行;&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;     (1b). 经过一段时间，收到一些Acceptor回复，回复可分为以下几种:
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;a). 回复数量满足多数派，则确认V1被接受;&lt;/p&gt;

&lt;p&gt;b). 回复数量不满足多数派，V1未被接受，Proposer增加序列号为SN1+，转1继续执行;&lt;/p&gt;

&lt;p&gt;(2). 在不违背自己向其他proposer的承诺的前提下，acceptor收到accept 请求后即接受并回复这个请求。&lt;/p&gt;

&lt;p&gt;1.3 算法优化(fast paxos)
Paxos算法在出现竞争的情况下，其收敛速度很慢，甚至可能出现活锁的情况，例如当有三个及三个以上的proposer在发送prepare请求后，很难有一个proposer收到半数以上的回复而不断地执行第一阶段的协议。因此，为了避免竞争，加快收敛的速度，在算法中引入了一个Leader这个角色，在正常情况下同时应该最多只能有一个参与者扮演Leader角色，而其它的参与者则扮演Acceptor的角色，同时所有的人又都扮演Learner的角色。&lt;/p&gt;

&lt;p&gt;在这种优化算法中，只有Leader可以提出议案，从而避免了竞争使得算法能够快速地收敛而趋于一致，此时的paxos算法在本质上就退变为两阶段提交协议。但在异常情况下，系统可能会出现多Leader的情况，但这并不会破坏算法对一致性的保证，此时多个Leader都可以提出自己的提案，优化的算法就退化成了原始的paxos算法。&lt;/p&gt;

&lt;p&gt;一个Leader的工作流程主要有分为三个阶段：&lt;/p&gt;

&lt;p&gt;(1).学习阶段 向其它的参与者学习自己不知道的数据(决议);&lt;/p&gt;

&lt;p&gt;(2).同步阶段 让绝大多数参与者保持数据(决议)的一致性;&lt;/p&gt;

&lt;p&gt;(3).服务阶段 为客户端服务，提议案;&lt;/p&gt;

&lt;p&gt;1.3.1 学习阶段
当一个参与者成为了Leader之后，它应该需要知道绝大多数的paxos实例，因此就会马上启动一个主动学习的过程。假设当前的新Leader早就知道了1-134、138和139的paxos实例，那么它会执行135-137和大于139的paxos实例的第一阶段。如果只检测到135和140的paxos实例有确定的值，那它最后就会知道1-135以及138-140的paxos实例。&lt;/p&gt;

&lt;p&gt;1.3.2 同步阶段
此时的Leader已经知道了1-135、138-140的paxos实例，那么它就会重新执行1-135的paxos实例，以保证绝大多数参与者在1-135的paxos实例上是保持一致的。至于139-140的paxos实例，它并不马上执行138-140的paxos实例，而是等到在服务阶段填充了136、137的paxos实例之后再执行。这里之所以要填充间隔，是为了避免以后的Leader总是要学习这些间隔中的paxos实例，而这些paxos实例又没有对应的确定值。&lt;/p&gt;

&lt;p&gt;1.3.4 服务阶段
Leader将用户的请求转化为对应的paxos实例，当然，它可以并发的执行多个paxos实例，当这个Leader出现异常之后，就很有可能造成paxos实例出现间断。&lt;/p&gt;

&lt;p&gt;1.3.5 问题
(1).Leader的选举原则&lt;/p&gt;

&lt;p&gt;(2).Acceptor如何感知当前Leader的失败，客户如何知道当前的Leader&lt;/p&gt;

&lt;p&gt;(3).当出现多Leader之后，如何kill掉多余的Leader&lt;/p&gt;

&lt;p&gt;(4).如何动态的扩展Acceptor&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;Zookeeper
2.1 整体架构
在Zookeeper集群中，主要分为三者角色，而每一个节点同时只能扮演一种角色，这三种角色分别是：&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;(1). Leader 接受所有Follower的提案请求并统一协调发起提案的投票，负责与所有的Follower进行内部的数据交换(同步);&lt;/p&gt;

&lt;p&gt;(2). Follower 直接为客户端服务并参与提案的投票，同时与Leader进行数据交换(同步);&lt;/p&gt;

&lt;p&gt;(3). Observer 直接为客户端服务但并不参与提案的投票，同时也与Leader进行数据交换(同步);&lt;/p&gt;

&lt;p&gt;2.2 QuorumPeer的基本设计&lt;/p&gt;

&lt;p&gt;Zookeeper对于每个节点QuorumPeer的设计相当的灵活，QuorumPeer主要包括四个组件：客户端请求接收器(ServerCnxnFactory)、数据引擎(ZKDatabase)、选举器(Election)、核心功能组件(Leader/Follower/Observer)。其中：&lt;/p&gt;

&lt;p&gt;(1). ServerCnxnFactory负责维护与客户端的连接(接收客户端的请求并发送相应的响应);&lt;/p&gt;

&lt;p&gt;(2). ZKDatabase负责存储/加载/查找数据(基于目录树结构的KV+操作日志+客户端Session);&lt;/p&gt;

&lt;p&gt;(3). Election负责选举集群的一个Leader节点;&lt;/p&gt;

&lt;p&gt;(4). Leader/Follower/Observer一个QuorumPeer节点应该完成的核心职责;&lt;/p&gt;

&lt;p&gt;2.3 QuorumPeer工作流程&lt;/p&gt;

&lt;p&gt;2.3.1 Leader职责&lt;/p&gt;

&lt;p&gt;Follower确认: 等待所有的Follower连接注册，若在规定的时间内收到合法的Follower注册数量，则确认成功；否则，确认失败。&lt;/p&gt;

&lt;p&gt;2.3.2 Follower职责&lt;/p&gt;

&lt;p&gt;2.4 选举算法
2.4.1 LeaderElection选举算法&lt;/p&gt;

&lt;p&gt;选举线程由当前Server发起选举的线程担任，他主要的功能对投票结果进行统计，并选出推荐的Server。选举线程首先向所有Server发起一次询问(包括自己)，被询问方，根据自己当前的状态作相应的回复，选举线程收到回复后，验证是否是自己发起的询问(验证xid 是否一致)，然后获取对方的id(myid)，并存储到当前询问对象列表中，最后获取对方提议 的&lt;/p&gt;

&lt;p&gt;leader 相关信息(id,zxid)，并将这些 信息存储到当次选举的投票记录表中，当向所有Serve r&lt;/p&gt;

&lt;p&gt;都询问完以后，对统计结果进行筛选并进行统计，计算出当次询问后获胜的是哪一个Server，并将当前zxid最大的Server 设置为当前Server要推荐的Server(有可能是自己，也有可以是其它的Server，根据投票结果而定，但是每一个Server在第一次投票时都会投自己)，如果此时获胜的Server获得n/2 + 1的Server票数，设置当前推荐的leader为获胜的Server。根据获胜的Server相关信息设置自己的状态。每一个Server都重复以上流程直到选举出Leader。&lt;/p&gt;

&lt;p&gt;初始化选票(第一张选票): 每个quorum节点一开始都投给自己;&lt;/p&gt;

&lt;p&gt;收集选票: 使用UDP协议尽量收集所有quorum节点当前的选票(单线程/同步方式)，超时设置200ms;&lt;/p&gt;

&lt;p&gt;统计选票: 1).每个quorum节点的票数;&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;     2).为自己产生一张新选票(zxid、myid均最大);
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;选举成功: 某一个quorum节点的票数超过半数;&lt;/p&gt;

&lt;p&gt;更新选票: 在本轮选举失败的情况下，当前quorum节点会从收集的选票中选取合适的选票(zxid、myid均最大)作为自己下一轮选举的投票;&lt;/p&gt;

&lt;p&gt;异常问题的处理&lt;/p&gt;

&lt;p&gt;1). 选举过程中，Server的加入&lt;/p&gt;

&lt;p&gt;当一个Server启动时它都会发起一次选举，此时由选举线程发起相关流程，那么每个 Serve r都会获得当前zxi d最大的哪个Serve r是谁，如果当次最大的Serve r没有获得n/2+1 个票数，那么下一次投票时，他将向zxid最大的Server投票，重复以上流程，最后一定能选举出一个Leader。&lt;/p&gt;

&lt;p&gt;2). 选举过程中，Server的退出&lt;/p&gt;

&lt;p&gt;只要保证n/2+1个Server存活就没有任何问题，如果少于n/2+1个Server 存活就没办法选出Leader。&lt;/p&gt;

&lt;p&gt;3). 选举过程中，Leader死亡&lt;/p&gt;

&lt;p&gt;当选举出Leader以后，此时每个Server应该是什么状态(FLLOWING)都已经确定，此时由于Leader已经死亡我们就不管它，其它的Fllower按正常的流程继续下去，当完成这个流程以后，所有的Fllower都会向Leader发送Ping消息，如果无法ping通，就改变自己的状为(FLLOWING ==&amp;gt; LOOKING)，发起新的一轮选举。&lt;/p&gt;

&lt;p&gt;4). 选举完成以后，Leader死亡&lt;/p&gt;

&lt;p&gt;处理过程同上。&lt;/p&gt;

&lt;p&gt;5). 双主问题&lt;/p&gt;

&lt;p&gt;Leader的选举是保证只产生一个公认的Leader的，而且Follower重新选举与旧Leader恢复并退出基本上是同时发生的，当Follower无法ping同Leader是就认为Leader已经出问题开始重新选举，Leader收到Follower的ping没有达到半数以上则要退出Leader重新选举。&lt;/p&gt;

&lt;p&gt;2.4.2 FastLeaderElection选举算法
FastLeaderElection是标准的fast paxos的实现，它首先向所有Server提议自己要成为leader，当其它Server收到提议以后，解决 epoch 和 zxid 的冲突，并接受对方的提议，然后向对方发送接受提议完成的消息。&lt;/p&gt;

&lt;p&gt;FastLeaderElection算法通过异步的通信方式来收集其它节点的选票，同时在分析选票时又根据投票者的当前状态来作不同的处理，以加快Leader的选举进程。&lt;/p&gt;

&lt;p&gt;每个Server都一个接收线程池和一个发送线程池, 在没有发起选举时，这两个线程池处于阻塞状态，直到有消息到来时才解除阻塞并处理消息，同时每个Serve r都有一个选举线程(可以发起选举的线程担任)。&lt;/p&gt;

&lt;p&gt;1). 主动发起选举端(选举线程)的处理&lt;/p&gt;

&lt;p&gt;首先自己的 logicalclock加1，然后生成notification消息，并将消息放入发送队列中， 系统中配置有几个Server就生成几条消息，保证每个Server都能收到此消息，如果当前Server 的状态是LOOKING就一直循环检查接收队列是否有消息，如果有消息，根据消息中对方的状态进行相应的处理。&lt;/p&gt;

&lt;p&gt;2).主动发送消息端(发送线程池)的处理&lt;/p&gt;

&lt;p&gt;将要发送的消息由Notification消息转换成ToSend消息，然后发送对方，并等待对方的回复。&lt;/p&gt;

&lt;p&gt;3). 被动接收消息端(接收线程池)的处理&lt;/p&gt;

&lt;p&gt;将收到的消息转换成Notification消息放入接收队列中，如果对方Server的epoch小于logicalclock则向其发送一个消息(让其更新epoch)；如果对方Server处于Looking状态，自己则处于Following或Leading状态，则也发送一个消息(当前Leader已产生，让其尽快收敛)。&lt;/p&gt;

&lt;p&gt;2.4.3 AuthFastLeaderElection选举算法
AuthFastLeaderElection算法同FastLeaderElection算法基本一致，只是在消息中加入了认证信息，该算法在最新的Zookeeper中也建议弃用。
2.6 Zookeeper中的请求处理流程
2.6.1 Follower节点处理用户的读写请求&lt;/p&gt;

&lt;p&gt;2.6.2 Leader节点处理写请求&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;值得注意的是， Follower/Leader上的读操作时并行的，读写操作是串行的，当CommitRequestProcessor处理一个写请求时，会阻塞之后所有的读写请求。
&lt;/code&gt;&lt;/pre&gt;

</description>
        <pubDate>Thu, 04 Jan 2018 00:00:00 +0800</pubDate>
        <link>https://xiazemin.github.io/MyBlog/spark/2018/01/04/zookeeper.html</link>
        <guid isPermaLink="true">https://xiazemin.github.io/MyBlog/spark/2018/01/04/zookeeper.html</guid>
        
        
        <category>spark</category>
        
      </item>
    
  </channel>
</rss>
