<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>泽民博客</title>
    <description>夏泽民的个人主页，学习笔记。</description>
    <link>https://xiazemin.github.io/MyBlog/</link>
    <atom:link href="https://xiazemin.github.io/MyBlog/feed.xml" rel="self" type="application/rss+xml"/>
    <pubDate>Wed, 11 Oct 2017 13:12:33 +0800</pubDate>
    <lastBuildDate>Wed, 11 Oct 2017 13:12:33 +0800</lastBuildDate>
    <generator>Jekyll v3.6.0.pre.beta1</generator>
    
      <item>
        <title>scala_list</title>
        <description>&lt;!-- more --&gt;
&lt;p&gt;一、常用操作符（操作符其实也是函数）&lt;/p&gt;

&lt;p&gt;++ ++&lt;a href=&quot;that: GenTraversableOnce[B]&quot;&gt;B&lt;/a&gt;: List[B] 从列表的尾部添加另外一个列表&lt;/p&gt;

&lt;p&gt;++: ++:&lt;a href=&quot;that: collection.Traversable[B]&quot;&gt;B &amp;gt;: A, That&lt;/a&gt;(implicit bf: CanBuildFrom[List[A], B, That]): That 在列表的头部添加一个列表&lt;/p&gt;

&lt;p&gt;+: +:(elem: A): List[A] 在列表的头部添加一个元素&lt;/p&gt;

&lt;p&gt;:+ :+(elem: A): List[A] 在列表的尾部添加一个元素&lt;/p&gt;

&lt;p&gt;:: ::(x: A): List[A] 在列表的头部添加一个元素&lt;/p&gt;

&lt;p&gt;::: :::(prefix: List[A]): List[A] 在列表的头部添加另外一个列表&lt;/p&gt;

&lt;p&gt;:\ :&lt;a href=&quot;z: B&quot;&gt;B&lt;/a&gt;(op: (A, B) ⇒ B): B 与foldRight等价&lt;/p&gt;

&lt;p&gt;val left = List(1,2,3)
val right = List(4,5,6)&lt;/p&gt;

&lt;p&gt;//以下操作等价
left ++ right   // List(1,2,3,4,5,6)
left ++: right  // List(1,2,3,4,5,6)
right.++:(left)    // List(1,2,3,4,5,6)
right.:::(left)  // List(1,2,3,4,5,6)&lt;/p&gt;

&lt;p&gt;//以下操作等价
0 +: left    //List(0,1,2,3)
left.+:(0)   //List(0,1,2,3)&lt;/p&gt;

&lt;p&gt;//以下操作等价
left :+ 4    //List(1,2,3,4)
left.:+(4)   //List(1,2,3,4)&lt;/p&gt;

&lt;p&gt;//以下操作等价
0 :: left      //List(0,1,2,3)
left.::(0)     //List(0,1,2,3)
看到这里大家应该跟我一样有一点晕吧，怎么这么多奇怪的操作符，这里给大家一个提示，任何以冒号结果的操作符，都是右绑定的，即 0 :: List(1,2,3) = List(1,2,3).::(0) = List(0,1,2,3) 从这里可以看出操作::其实是右边List的操作符，而非左边Int类型的操作符&lt;/p&gt;

&lt;p&gt;二、常用变换操作&lt;/p&gt;

&lt;p&gt;1.map&lt;/p&gt;

&lt;p&gt;map&lt;a href=&quot;f: (A) ⇒ B&quot;&gt;B&lt;/a&gt;: List[B]&lt;/p&gt;

&lt;p&gt;定义一个变换,把该变换应用到列表的每个元素中,原列表不变，返回一个新的列表数据&lt;/p&gt;

&lt;p&gt;Example1 平方变换&lt;/p&gt;

&lt;p&gt;val nums = List(1,2,3)
val square = (x: Int) =&amp;gt; x&lt;em&gt;x &lt;br /&gt;
val squareNums1 = nums.map(num =&amp;gt; num&lt;/em&gt;num)    //List(1,4,9)
val squareNums2 = nums.map(math.pow(_,2))    //List(1,4,9)
val squareNums3 = nums.map(square)            //List(1,4,9)&lt;/p&gt;

&lt;p&gt;Example2 保存文本数据中的某几列&lt;/p&gt;

&lt;p&gt;val text = List(“Homeway,25,Male”,”XSDYM,23,Female”)
val usersList = text.map(_.split(“,”)(0))  &lt;br /&gt;
val usersWithAgeList = text.map(line =&amp;gt; {
    val fields = line.split(“,”)
    val user = fields(0)
    val age = fields(1).toInt
    (user,age)
})
2.flatMap, flatten&lt;/p&gt;

&lt;p&gt;flatten: flatten[B]: List[B] 对列表的列表进行平坦化操作 flatMap: flatMap&lt;a href=&quot;f: (A) ⇒ GenTraversableOnce[B]&quot;&gt;B&lt;/a&gt;: List[B] map之后对结果进行flatten&lt;/p&gt;

&lt;p&gt;定义一个变换f, 把f应用列表的每个元素中，每个f返回一个列表，最终把所有列表连结起来。&lt;/p&gt;

&lt;p&gt;val text = List(“A,B,C”,”D,E,F”)
val textMapped = text.map(&lt;em&gt;.split(“,”).toList) // List(List(“A”,”B”,”C”),List(“D”,”E”,”F”))
val textFlattened = textMapped.flatten          // List(“A”,”B”,”C”,”D”,”E”,”F”)
val textFlatMapped = text.flatMap(&lt;/em&gt;.split(“,”).toList) // List(“A”,”B”,”C”,”D”,”E”,”F”)&lt;/p&gt;

&lt;p&gt;3.reduce&lt;/p&gt;

&lt;p&gt;reduce&lt;a href=&quot;op: (A1, A1) ⇒ A1&quot;&gt;A1 &amp;gt;: A&lt;/a&gt;: A1&lt;/p&gt;

&lt;p&gt;定义一个变换f, f把两个列表的元素合成一个，遍历列表，最终把列表合并成单一元素&lt;/p&gt;

&lt;p&gt;Example 列表求和&lt;/p&gt;

&lt;p&gt;val nums = List(1,2,3)
val sum1 = nums.reduce((a,b) =&amp;gt; a+b)   //6
val sum2 = nums.reduce(&lt;em&gt;+&lt;/em&gt;)            //6
val sum3 = nums.sum                 //6&lt;/p&gt;

&lt;p&gt;4.reduceLeft,reduceRight&lt;/p&gt;

&lt;p&gt;reduceLeft: reduceLeft&lt;a href=&quot;f: (B, A) ⇒ B&quot;&gt;B &amp;gt;: A&lt;/a&gt;: B&lt;/p&gt;

&lt;p&gt;reduceRight: reduceRight&lt;a href=&quot;op: (A, B) ⇒ B&quot;&gt;B &amp;gt;: A&lt;/a&gt;: B&lt;/p&gt;

&lt;p&gt;reduceLeft从列表的左边往右边应用reduce函数，reduceRight从列表的右边往左边应用reduce函数&lt;/p&gt;

&lt;p&gt;Example&lt;/p&gt;

&lt;p&gt;val nums = List(2.0,2.0,3.0)
val resultLeftReduce = nums.reduceLeft(math.pow)  // = pow( pow(2.0,2.0) , 3.0) = 64.0
val resultRightReduce = nums.reduceRight(math.pow) // = pow(2.0, pow(2.0,3.0)) = 256.0&lt;/p&gt;

&lt;p&gt;5.fold,foldLeft,foldRight&lt;/p&gt;

&lt;p&gt;fold: fold&lt;a href=&quot;z: A1&quot;&gt;A1 &amp;gt;: A&lt;/a&gt;(op: (A1, A1) ⇒ A1): A1 带有初始值的reduce,从一个初始值开始，从左向右将两个元素合并成一个，最终把列表合并成单一元素。&lt;/p&gt;

&lt;p&gt;foldLeft: foldLeft&lt;a href=&quot;z: B&quot;&gt;B&lt;/a&gt;(f: (B, A) ⇒ B): B 带有初始值的reduceLeft&lt;/p&gt;

&lt;p&gt;foldRight: foldRight&lt;a href=&quot;z: B&quot;&gt;B&lt;/a&gt;(op: (A, B) ⇒ B): B 带有初始值的reduceRight&lt;/p&gt;

&lt;p&gt;val nums = List(2,3,4)
val sum = nums.fold(1)(&lt;em&gt;+&lt;/em&gt;)  // = 1+2+3+4 = 9&lt;/p&gt;

&lt;p&gt;val nums = List(2.0,3.0)
val result1 = nums.foldLeft(4.0)(math.pow) // = pow(pow(4.0,2.0),3.0) = 4096
val result2 = nums.foldRight(1.0)(math.pow) // = pow(1.0,pow(2.0,3.0)) = 8.0&lt;/p&gt;

&lt;p&gt;6.sortBy,sortWith,sorted&lt;/p&gt;

&lt;p&gt;sortBy: sortBy&lt;a href=&quot;f: (A) ⇒ B&quot;&gt;B&lt;/a&gt;(implicit ord: math.Ordering[B]): List[A] 按照应用函数f之后产生的元素进行排序&lt;/p&gt;

&lt;p&gt;sorted： sorted&lt;a href=&quot;implicit ord: math.Ordering[B]&quot;&gt;B &amp;gt;: A&lt;/a&gt;: List[A] 按照元素自身进行排序&lt;/p&gt;

&lt;p&gt;sortWith： sortWith(lt: (A, A) ⇒ Boolean): List[A] 使用自定义的比较函数进行排序&lt;/p&gt;

&lt;p&gt;val nums = List(1,3,2,4)
val sorted = nums.sorted  //List(1,2,3,4)&lt;/p&gt;

&lt;p&gt;val users = List((“HomeWay”,25),(“XSDYM”,23))
val sortedByAge = users.sortBy{case(user,age) =&amp;gt; age}  //List((“XSDYM”,23),(“HomeWay”,25))
val sortedWith = users.sortWith{case(user1,user2) =&amp;gt; user1._2 &amp;lt; user2._2} //List((“XSDYM”,23),(“HomeWay”,25))&lt;/p&gt;

&lt;p&gt;7.filter, filterNot&lt;/p&gt;

&lt;p&gt;filter: filter(p: (A) ⇒ Boolean): List[A]&lt;/p&gt;

&lt;p&gt;filterNot: filterNot(p: (A) ⇒ Boolean): List[A]&lt;/p&gt;

&lt;p&gt;filter 保留列表中符合条件p的列表元素 ， filterNot，保留列表中不符合条件p的列表元素&lt;/p&gt;

&lt;p&gt;val nums = List(1,2,3,4)
val odd = nums.filter( _ % 2 != 0) // List(1,3)
val even = nums.filterNot( _ % 2 != 0) // List(2,4)&lt;/p&gt;

&lt;p&gt;8.count&lt;/p&gt;

&lt;p&gt;count(p: (A) ⇒ Boolean): Int&lt;/p&gt;

&lt;p&gt;计算列表中所有满足条件p的元素的个数，等价于 filter(p).length&lt;/p&gt;

&lt;p&gt;val nums = List(-1,-2,0,1,2) val plusCnt1 = nums.count( &amp;gt; 0) val plusCnt2 = nums.filter( &amp;gt; 0).length&lt;/p&gt;
&lt;ol&gt;
  &lt;li&gt;diff, union, intersect&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;diff:diff(that: collection.Seq[A]): List[A] 保存列表中那些不在另外一个列表中的元素，即从集合中减去与另外一个集合的交集&lt;/p&gt;

&lt;p&gt;union : union(that: collection.Seq[A]): List[A] 与另外一个列表进行连结&lt;/p&gt;

&lt;p&gt;intersect: intersect(that: collection.Seq[A]): List[A] 与另外一个集合的交集&lt;/p&gt;

&lt;p&gt;val nums1 = List(1,2,3)
val nums2 = List(2,3,4)
val diff1 = nums1 diff nums2   // List(1)
val diff2 = nums2.diff(num1)   // List(4)
val union1 = nums1 union nums2  // List(1,2,3,2,3,4)
val union2 = nums2 ++ nums1        // List(2,3,4,1,2,3)
val intersection = nums1 intersect nums2  //List(2,3)&lt;/p&gt;

&lt;p&gt;10.distinct&lt;/p&gt;

&lt;p&gt;distinct: List[A] 保留列表中非重复的元素，相同的元素只会被保留一次&lt;/p&gt;

&lt;p&gt;val list = List(“A”,”B”,”C”,”A”,”B”) val distincted = list.distinct // List(“A”,”B”,”C”)
1
11.groupBy, grouped&lt;/p&gt;

&lt;p&gt;groupBy : groupBy&lt;a href=&quot;f: (A) ⇒ K&quot;&gt;K&lt;/a&gt;: Map[K, List[A]] 将列表进行分组，分组的依据是应用f在元素上后产生的新元素 
grouped: grouped(size: Int): Iterator[List[A]] 按列表按照固定的大小进行分组&lt;/p&gt;

&lt;p&gt;val data = List((“HomeWay”,”Male”),(“XSDYM”,”Femail”),(“Mr.Wang”,”Male”))
val group1 = data.groupBy(_._2) // = Map(“Male” -&amp;gt; List((“HomeWay”,”Male”),(“Mr.Wang”,”Male”)),”Female” -&amp;gt; List((“XSDYM”,”Femail”)))
val group2 = data.groupBy{case (name,sex) =&amp;gt; sex} // = Map(“Male” -&amp;gt; List((“HomeWay”,”Male”),(“Mr.Wang”,”Male”)),”Female” -&amp;gt; List((“XSDYM”,”Femail”)))
val fixSizeGroup = data.grouped(2).toList // = Map(“Male” -&amp;gt; List((“HomeWay”,”Male”),(“XSDYM”,”Femail”)),”Female” -&amp;gt; List((“Mr.Wang”,”Male”)))&lt;/p&gt;

&lt;p&gt;12.scan&lt;/p&gt;

&lt;p&gt;scan&lt;a href=&quot;z: B&quot;&gt;B &amp;gt;: A, That&lt;/a&gt;(op: (B, B) ⇒ B)(implicit cbf: CanBuildFrom[List[A], B, That]): That&lt;/p&gt;

&lt;p&gt;由一个初始值开始，从左向右，进行积累的op操作，这个比较难解释，具体的看例子吧。&lt;/p&gt;

&lt;p&gt;val nums = List(1,2,3)
val result = nums.scan(10)(&lt;em&gt;+&lt;/em&gt;)   // List(10,10+1,10+1+2,10+1+2+3) = List(10,11,12,13)&lt;/p&gt;

&lt;p&gt;13.scanLeft,scanRight&lt;/p&gt;

&lt;p&gt;scanLeft: scanLeft&lt;a href=&quot;z: B&quot;&gt;B, That&lt;/a&gt;(op: (B, A) ⇒ B)(implicit bf: CanBuildFrom[List[A], B, That]): That&lt;/p&gt;

&lt;p&gt;scanRight: scanRight&lt;a href=&quot;z: B&quot;&gt;B, That&lt;/a&gt;(op: (A, B) ⇒ B)(implicit bf: CanBuildFrom[List[A], B, That]): That&lt;/p&gt;

&lt;p&gt;scanLeft: 从左向右进行scan函数的操作，scanRight：从右向左进行scan函数的操作&lt;/p&gt;

&lt;p&gt;val nums = List(1.0,2.0,3.0)
val result = nums.scanLeft(2.0)(math.pow)   // List(2.0,pow(2.0,1.0), pow(pow(2.0,1.0),2.0),pow(pow(pow(2.0,1.0),2.0),3.0) = List(2.0,2.0,4.0,64.0)
val result = nums.scanRight(2.0)(math.pow)  // List(2.0,pow(3.0,2.0), pow(2.0,pow(3.0,2.0)), pow(1.0,pow(2.0,pow(3.0,2.0))) = List(1.0,512.0,9.0,2.0)&lt;/p&gt;

&lt;p&gt;14.take,takeRight,takeWhile&lt;/p&gt;

&lt;p&gt;take : takeRight(n: Int): List[A] 提取列表的前n个元素 takeRight: takeRight(n: Int): List[A] 提取列表的最后n个元素 takeWhile: takeWhile(p: (A) ⇒ Boolean): List[A] 从左向右提取列表的元素，直到条件p不成立&lt;/p&gt;

&lt;p&gt;val nums = List(1,1,1,1,4,4,4,4)
val left = nums.take(4)   // List(1,1,1,1)
val right = nums.takeRight(4) // List(4,4,4,4)
val headNums = nums.takeWhile( _ == nums.head)  // List(1,1,1,1)&lt;/p&gt;

&lt;p&gt;15.drop,dropRight,dropWhile&lt;/p&gt;

&lt;p&gt;drop: drop(n: Int): List[A] 丢弃前n个元素，返回剩下的元素 dropRight: dropRight(n: Int): List[A] 丢弃最后n个元素，返回剩下的元素 dropWhile: dropWhile(p: (A) ⇒ Boolean): List[A] 从左向右丢弃元素，直到条件p不成立&lt;/p&gt;

&lt;p&gt;val nums = List(1,1,1,1,4,4,4,4)
val left = nums.drop(4)   // List(4,4,4,4)
val right = nums.dropRight(4) // List(1,1,1,1)
val tailNums = nums.dropWhile( _ == nums.head)  // List(4,4,4,4)&lt;/p&gt;

&lt;p&gt;16.span, splitAt, partition&lt;/p&gt;

&lt;p&gt;span : span(p: (A) ⇒ Boolean): (List[A], List[A]) 从左向右应用条件p进行判断，直到条件p不成立，此时将列表分为两个列表&lt;/p&gt;

&lt;p&gt;splitAt: splitAt(n: Int): (List[A], List[A]) 将列表分为前n个，与，剩下的部分&lt;/p&gt;

&lt;p&gt;partition: partition(p: (A) ⇒ Boolean): (List[A], List[A]) 将列表分为两部分，第一部分为满足条件p的元素，第二部分为不满足条件p的元素&lt;/p&gt;

&lt;p&gt;val nums = List(1,1,1,2,3,2,1)
val (prefix,suffix) = nums.span( _ == 1) // prefix = List(1,1,1), suffix = List(2,3,2,1)
val (prefix,suffix) = nums.splitAt(3)  // prefix = List(1,1,1), suffix = List(2,3,2,1)
val (prefix,suffix) = nums.partition( _ == 1) // prefix = List(1,1,1,1), suffix = List(2,3,2)&lt;/p&gt;

&lt;p&gt;17.padTo&lt;/p&gt;

&lt;p&gt;padTo(len: Int, elem: A): List[A]&lt;/p&gt;

&lt;p&gt;将列表扩展到指定长度，长度不够的时候，使用elem进行填充，否则不做任何操作。&lt;/p&gt;

&lt;p&gt;val nums = List(1,1,1)
 val padded = nums.padTo(6,2)   // List(1,1,1,2,2,2)&lt;/p&gt;

&lt;p&gt;18.combinations,permutations&lt;/p&gt;

&lt;p&gt;combinations: combinations(n: Int): Iterator[List[A]] 取列表中的n个元素进行组合，返回不重复的组合列表，结果一个迭代器&lt;/p&gt;

&lt;p&gt;permutations: permutations: Iterator[List[A]] 对列表中的元素进行排列，返回不重得的排列列表，结果是一个迭代器&lt;/p&gt;

&lt;p&gt;val nums = List(1,1,3)
val combinations = nums.combinations(2).toList //List(List(1,1),List(1,3))
val permutations = nums.permutations.toList        // List(List(1,1,3),List(1,3,1),List(3,1,1))&lt;/p&gt;

&lt;p&gt;19.zip, zipAll, zipWithIndex, unzip,unzip3&lt;/p&gt;

&lt;p&gt;zip: zip&lt;a href=&quot;that: GenIterable[B]&quot;&gt;B&lt;/a&gt;: List[(A, B)] 与另外一个列表进行拉链操作，将对应位置的元素组成一个pair，返回的列表长度为两个列表中短的那个&lt;/p&gt;

&lt;p&gt;zipAll: zipAll&lt;a href=&quot;that: collection.Iterable[B], thisElem: A, thatElem: B&quot;&gt;B&lt;/a&gt;: List[(A, B)] 与另外一个列表进行拉链操作，将对应位置的元素组成一个pair，若列表长度不一致，自身列表比较短的话使用thisElem进行填充，对方列表较短的话使用thatElem进行填充&lt;/p&gt;

&lt;p&gt;zipWithIndex：zipWithIndex: List[(A, Int)] 将列表元素与其索引进行拉链操作，组成一个pair&lt;/p&gt;

&lt;p&gt;unzip: unzip&lt;a href=&quot;implicit asPair: (A) ⇒ (A1, A2)&quot;&gt;A1, A2&lt;/a&gt;: (List[A1], List[A2]) 解开拉链操作&lt;/p&gt;

&lt;p&gt;unzip3: unzip3&lt;a href=&quot;implicit asTriple: (A) ⇒ (A1, A2, A3)&quot;&gt;A1, A2, A3&lt;/a&gt;: (List[A1], List[A2], List[A3]) 3个元素的解拉链操作&lt;/p&gt;

&lt;p&gt;val alphabet = List(“A”,B”,”C”)
val nums = List(1,2)
val zipped = alphabet zip nums   // List((“A”,1),(“B”,2))
val zippedAll = alphabet.zipAll(nums,”*”,-1)   // List((“A”,1),(“B”,2),(“C”,-1))
val zippedIndex = alphabet.zipWithIndex  // List((“A”,0),(“B”,1),(“C”,3))
val (list1,list2) = zipped.unzip        // list1 = List(“A”,”B”), list2 = List(1,2)
val (l1,l2,l3) = List((1, “one”, ‘1’),(2, “two”, ‘2’),(3, “three”, ‘3’)).unzip3   // l1=List(1,2,3),l2=List(“one”,”two”,”three”),l3=List(‘1’,’2’,’3’)&lt;/p&gt;

&lt;p&gt;20.slice&lt;/p&gt;

&lt;p&gt;slice(from: Int, until: Int): List[A] 提取列表中从位置from到位置until(不含该位置)的元素列表&lt;/p&gt;

&lt;p&gt;val nums = List(1,2,3,4,5)
val sliced = nums.slice(2,4)  //List(3,4)&lt;/p&gt;

&lt;p&gt;21.sliding&lt;/p&gt;

&lt;p&gt;sliding(size: Int, step: Int): Iterator[List[A]] 将列表按照固定大小size进行分组，步进为step，step默认为1,返回结果为迭代器&lt;/p&gt;

&lt;p&gt;val nums = List(1,1,2,2,3,3,4,4)
val groupStep2 = nums.sliding(2,2).toList  //List(List(1,1),List(2,2),List(3,3),List(4,4))
val groupStep1 = nums.sliding(2).toList //List(List(1,1),List(1,2),List(2,2),List(2,3),List(3,3),List(3,4),List(4,4))&lt;/p&gt;

&lt;p&gt;22.updated&lt;/p&gt;

&lt;p&gt;updated(index: Int, elem: A): List[A] 对列表中的某个元素进行更新操作&lt;/p&gt;

&lt;p&gt;val nums = List(1,2,3,3)
val fixed = nums.updated(3,4)  // List(1,2,3,4)&lt;/p&gt;
</description>
        <pubDate>Wed, 11 Oct 2017 00:00:00 +0800</pubDate>
        <link>https://xiazemin.github.io/MyBlog/spark/2017/10/11/scala_list.html</link>
        <guid isPermaLink="true">https://xiazemin.github.io/MyBlog/spark/2017/10/11/scala_list.html</guid>
        
        
        <category>spark</category>
        
      </item>
    
      <item>
        <title>spark-session-context</title>
        <description>&lt;!-- more --&gt;
&lt;p&gt;初始化Spark
一个Spark程序首先必须要做的是创建一个SparkContext对象，这个对象告诉Spark如何访问一个集群。为了创建一个SparkContext，你首先需要构建一个包含了关于你的应用的信息的SparkConf对象。&lt;/p&gt;

&lt;p&gt;只有一个SparkContext可以激活一个JVM。你必须在创建一个新的SparkContext之前stop()掉这个激活的SparkContext。&lt;/p&gt;

&lt;p&gt;val conf = new SparkConf().setAppName(appName).setMaster(master)
new SparkContext(conf)
参数appName是在集群UI上展示的你的应用的名字。master是一个Spark，Mesos或者YARN集群的URL，或者是表示以本地模式运行的一个特定的字符串”local”。在实践中，当运行在集群上时，你是不会想在程序中硬编码master的，而是通过spark-submit启动应用并指定master的。然而，对于本地测试和单元测试，你可以通过传递”local”来在进程内运行Spark。&lt;/p&gt;

&lt;p&gt;使用shell
在Spark shell中，一个特殊的SparkContext已经为你创建好了，变量名是sc。如果再创建你自己的SparkContext就不起作用了。你可以使用参数–master来设置context连接到哪个master，还可以通过给参数–jars传递逗号分隔的列表来给classpath增加JARs。你还可以通过给参数–packages提供逗号分隔的Maven坐标来给你的shell会话增加依赖（例如Spark包）。任何可能存在依赖的附加库（例如Sonatype）都可以被传递给参数–repositories&lt;/p&gt;

&lt;p&gt;　在Spark的早期版本，sparkContext是进入Spark的切入点。我们都知道RDD是Spark中重要的API，然而它的创建和操作得使用sparkContext提供的API；对于RDD之外的其他东西，我们需要使用其他的Context。比如对于流处理来说，我们得使用StreamingContext；对于SQL得使用sqlContext；而对于hive得使用HiveContext。然而DataSet和Dataframe提供的API逐渐称为新的标准API，我们需要一个切入点来构建它们，所以在 Spark 2.0中我们引入了一个新的切入点(entry point)：SparkSession&lt;/p&gt;

&lt;p&gt;　　SparkSession实质上是SQLContext和HiveContext的组合（未来可能还会加上StreamingContext），所以在SQLContext和HiveContext上可用的API在SparkSession上同样是可以使用的。SparkSession内部封装了sparkContext，所以计算实际上是由sparkContext完成的。&lt;/p&gt;

&lt;p&gt;创建SparkSession&lt;/p&gt;

&lt;p&gt;　　SparkSession的设计遵循了工厂设计模式（factory design pattern），下面代码片段介绍如何创建SparkSession
[python] view plain copy
val sparkSession = SparkSession.builder.&lt;br /&gt;
      master(“local”)&lt;br /&gt;
      .appName(“spark session example”)&lt;br /&gt;
      .getOrCreate()&lt;br /&gt;
上面代码类似于创建一个SparkContext，master设置为local，然后创建了一个SQLContext封装它。如果你想创建hiveContext，可以使用下面的方法来创建SparkSession，以使得它支持Hive：
[python] view plain copy
val sparkSession = SparkSession.builder.&lt;br /&gt;
      master(“local”)&lt;br /&gt;
      .appName(“spark session example”)&lt;br /&gt;
      .enableHiveSupport()&lt;br /&gt;
      .getOrCreate()&lt;br /&gt;
enableHiveSupport 函数的调用使得SparkSession支持hive，类似于HiveContext。&lt;/p&gt;

&lt;p&gt;spark2.0 主要变化
1 更容易的SQL和Streamlined APIs&lt;/p&gt;

&lt;p&gt;Spark 2.0主要聚焦于两个方面：（1）、对标准的SQL支持（2）、统一DataFrame和Dataset API。&lt;/p&gt;

&lt;p&gt;　　在SQL方面，Spark 2.0已经显著地扩大了它的SQL功能，比如引进了一个新的ANSI SQL解析器和对子查询的支持。现在Spark 2.0已经可以运行TPC-DS所有的99个查询，这99个查询需要SQL 2003的许多特性。因为SQL是Spark应用程序的主要接口之一，Spark 2.0 SQL的扩展大幅减少了应用程序往Spark迁移的代价。&lt;/p&gt;

&lt;p&gt;　　在编程API方面，我们对API进行了精简。&lt;/p&gt;

&lt;p&gt;　　1、统一Scala和Java中DataFrames和Datasets的API：从Spark 2.0开始，DataFrame仅仅是Dataset的一个别名。有类型的方法(typed methods)（比如：map, filter, groupByKey）和无类型的方法(untyped methods)(比如：select, groupBy)目前在Dataset类上可用。同样，新的Dataset接口也在Structured Streaming中使用。因为编译时类型安全(compile-time type-safety)在Python和R中并不是语言特性，所以Dataset的概念并不在这些语言中提供相应的API。而DataFrame仍然作为这些语言的主要编程抽象。&lt;/p&gt;

&lt;p&gt;　　2、SparkSession：一个新的切入点，用于替代旧的SQLContext和HiveContext。对于那些使用DataFrame API的用户，一个常见的困惑就是我们正在使用哪个context？现在我们可以使用SparkSession了，其涵括了SQLContext和HiveContext，仅仅提供一个切入点。需要注意的是为了向后兼容，旧的SQLContext和HiveContext目前仍然可以使用。&lt;/p&gt;

&lt;p&gt;　　3、简单以及性能更好的Accumulator API：Spark 2.0中设计出一种新的Accumulator API，它拥有更加简洁的类型层次，而且支持基本类型。为了向后兼容，旧的Accumulator API仍然可以使用。&lt;/p&gt;

&lt;p&gt;　　4、基于DataFrame的Machine Learning API可以作为主要的ML API了：在Spark 2.0中， spark.ml包以其pipeline API将会作为主要的机器学习API了，而之前的spark.mllib仍然会保存，将来的开发会聚集在基于DataFrame的API上。&lt;/p&gt;

&lt;p&gt;　　5、Machine learning pipeline持久化：现在用户可以保存和加载Spark支持所有语言的Machine learning pipeline和models。&lt;/p&gt;

&lt;p&gt;　　6、R的分布式算法：在R语言中添加支持了Generalized Linear Models (GLM), Naive Bayes, Survival Regression, and K-Means。
　　
2 更快：Spark作为编译器&lt;/p&gt;

&lt;p&gt;Spark 2.0中附带了第二代Tungsten engine，这一代引擎是建立在现代编译器和MPP数据库的想法上，并且把它们应用于数据的处理过程中。主要想法是通过在运行期间优化那些拖慢整个查询的代码到一个单独的函数中，消除虚拟函数的调用以及利用CPU寄存器来存放那些中间数据。我们把这些技术称为”整段代码生成”(whole-stage code generation)。&lt;/p&gt;

&lt;p&gt;3 更加智能：Structured Streaming&lt;/p&gt;

</description>
        <pubDate>Fri, 06 Oct 2017 00:00:00 +0800</pubDate>
        <link>https://xiazemin.github.io/MyBlog/spark/2017/10/06/spark-session-context.html</link>
        <guid isPermaLink="true">https://xiazemin.github.io/MyBlog/spark/2017/10/06/spark-session-context.html</guid>
        
        
        <category>spark</category>
        
      </item>
    
      <item>
        <title>scala_main_class</title>
        <description>&lt;!-- more --&gt;
&lt;p&gt;解决
错误: 找不到或无法加载主类 SparkTest.SparkSessionTest&lt;/p&gt;

&lt;p&gt;project-&amp;gt;buildin path-&amp;gt; configure build in path 
-&amp;gt;scala compiler -&amp;gt;use project settings -&amp;gt;scala installation
-&amp;gt; dixed scala installation 2.11.8 built in&lt;/p&gt;
</description>
        <pubDate>Fri, 29 Sep 2017 00:00:00 +0800</pubDate>
        <link>https://xiazemin.github.io/MyBlog/spark/2017/09/29/scala_main_class.html</link>
        <guid isPermaLink="true">https://xiazemin.github.io/MyBlog/spark/2017/09/29/scala_main_class.html</guid>
        
        
        <category>spark</category>
        
      </item>
    
      <item>
        <title>alibaba_fast_json</title>
        <description>&lt;!-- more --&gt;
&lt;p&gt;Fastjson是一个Java语言编写的高性能功能完善的JSON库。将解析json的性能提升到极致，是目前Java语言中最快的JSON库。Fastjson接口简单易用，已经被广泛使用在缓存序列化、协议交互、Web输出、Android客户端等多种应用场景。&lt;/p&gt;

&lt;p&gt;GitHub下载地址: 
https://github.com/alibaba/fastjson&lt;/p&gt;

&lt;p&gt;最新发布版本jar包 1.2.23 下载地址: https://search.maven.org/remote_content?g=com.alibaba&amp;amp;a=fastjson&amp;amp;v=LATEST&lt;/p&gt;

&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-scala&quot; data-lang=&quot;scala&quot;&gt;&lt;span&gt;&lt;/span&gt;&lt;span class=&quot;lineno&quot;&gt;1 &lt;/span&gt;&lt;span class=&quot;k&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;com.alibaba.fastjson.JSON&lt;/span&gt;
&lt;span class=&quot;lineno&quot;&gt;2 &lt;/span&gt;&lt;span class=&quot;k&quot;&gt;object&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;FastJsonExp&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;{&lt;/span&gt;
&lt;span class=&quot;lineno&quot;&gt;3 &lt;/span&gt;  &lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;main&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;args&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;kt&quot;&gt;Array&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;kt&quot;&gt;String&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;]){&lt;/span&gt;
&lt;span class=&quot;lineno&quot;&gt;4 &lt;/span&gt;  &lt;span class=&quot;k&quot;&gt;val&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;json&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&amp;quot;{\&amp;quot;name\&amp;quot;:\&amp;quot;chenggang\&amp;quot;,\&amp;quot;age\&amp;quot;:24}&amp;quot;&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;;&lt;/span&gt;
&lt;span class=&quot;lineno&quot;&gt;5 &lt;/span&gt; &lt;span class=&quot;c1&quot;&gt;//反序列化&lt;/span&gt;
&lt;span class=&quot;lineno&quot;&gt;6 &lt;/span&gt; &lt;span class=&quot;k&quot;&gt;var&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;userInfo&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;nc&quot;&gt;JSON&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;parseObject&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;json&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;);&lt;/span&gt;
&lt;span class=&quot;lineno&quot;&gt;7 &lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;System&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;out&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;println&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&amp;quot;name:&amp;quot;&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;+&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;userInfo&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;get&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&amp;quot;name&amp;quot;&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)+&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&amp;quot;, age:&amp;quot;&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;+&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;userInfo&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;get&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&amp;quot;age&amp;quot;&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;));&lt;/span&gt;
&lt;span class=&quot;lineno&quot;&gt;8 &lt;/span&gt;  &lt;span class=&quot;o&quot;&gt;}&lt;/span&gt;
&lt;span class=&quot;lineno&quot;&gt;9 &lt;/span&gt;&lt;span class=&quot;o&quot;&gt;}&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;
</description>
        <pubDate>Fri, 29 Sep 2017 00:00:00 +0800</pubDate>
        <link>https://xiazemin.github.io/MyBlog/spark/2017/09/29/alibaba_fast_json.html</link>
        <guid isPermaLink="true">https://xiazemin.github.io/MyBlog/spark/2017/09/29/alibaba_fast_json.html</guid>
        
        
        <category>spark</category>
        
      </item>
    
      <item>
        <title>gorpc</title>
        <description>&lt;!-- more --&gt;
&lt;p&gt;gRPC初体验
96  作者 CZ_Golang 关注
2016.03.11 16:38 字数 1629 阅读 16506评论 2喜欢 29
gRPC是由Google主导开发的RPC框架，使用HTTP/2协议并用ProtoBuf作为序列化工具。其客户端提供Objective-C、Java接口，服务器侧则有Java、Golang、C++等接口，从而为移动端（iOS/Androi）到服务器端通讯提供了一种解决方案。 当然在当下的环境下，这种解决方案更热门的方式是RESTFull API接口。该方式需要自己去选择编码方式、服务器架构、自己搭建框架（JSON-RPC）。gRPC官方对REST的声音是：&lt;/p&gt;

&lt;p&gt;和REST一样遵循HTTP协议(明确的说是HTTP/2)，但是gRPC提供了全双工流
和传统的REST不同的是gRPC使用了静态路径，从而提高性能
用一些格式化的错误码代替了HTTP的状态码更好的标示错误
至于是否要选择用gRPC。对于已经有一套方案的团队，可以参考下。如果是从头来做，可以考虑下gRPC提供的从客户端到服务器的整套解决方案，这样不用客户端去实现http的请求会话，JSON等的解析，服务器端也有现成的框架用。从15年3月到现在gRPC也发展了一年了，慢慢趋于成熟。下面我们就以gRPC的Golang版本看下其在golang上面的表现。至于服务端的RPC，感觉golang标准库的RPC框架基本够用了,没必要再去用另一套方案。&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;安装protobuf&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;虽然gRPC也支持protobuf2.x，但是建议还是使用protobuf3.x，尽管还没有正式版本，不过golang版本基本没有什么问题，另外3.x官方支持了Objective-C，这也是我们使用gRPC的初衷：提供一个移动端到服务器的解决方案。去到Protocol Buffers下载最新版本（Version3.0.0 beta2），然后解压到本地。本地需要已经安装好autoconf automake libtool.rpm系列（fedora/centos/redheat）可以用yum安装。Mac上可以用brew进行安装&lt;/p&gt;

&lt;p&gt;brew install autoconf automake libtool
然后执行&lt;/p&gt;

&lt;p&gt;./configure –prefix=your_pb_install_path
接着&lt;/p&gt;

&lt;p&gt;make 
make install
set your_pb_install_path to your $PATH
检查是否安装完成&lt;/p&gt;

&lt;p&gt;protoc –version
libprotoc 3.0.0
然后安装golang protobuf直接使用golang的get即可&lt;/p&gt;

&lt;p&gt;go get -u github.com/golang/protobuf/proto // golang protobuf 库
go get -u github.com/golang/protobuf/protoc-gen-go //protoc –go_out 工具&lt;/p&gt;
&lt;ol&gt;
  &lt;li&gt;安装gRPC-go&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;gRPC-go可以通过golang 的get命令直接安装，非常方便。&lt;/p&gt;

&lt;p&gt;go get google.golang.org/grpc
这里大家可能比较奇怪，为什么gRPC-go在github的地址是”https://github.com/grpc/grpc-go”,但是为什么要用“google.golang.org/grpc”进行安装呢？应该grpc原本是google内部的项目，归属golang，就放在了google.golang.org下面了，后来对外开放，又将其迁移到github上面了，又因为golang比较坑爹的import路径规则，所以就都没有改路径名了。&lt;/p&gt;

&lt;p&gt;但是这样就有个问题了。要如何去管理版本呢？这个目前我还没有什么比较好的方法，希望知道的朋友一起分享下。目前想到一个方法是手动下载某个版本，然后写个脚本统一修改代码中的import里面的路径.&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;示例程序&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;3.1 protobuf&lt;/p&gt;

&lt;p&gt;该示例源自gRPC-go的examples的helloworld。先看PB的描述：&lt;/p&gt;

&lt;p&gt;syntax = “proto3”;&lt;/p&gt;

&lt;p&gt;option objc_class_prefix = “HLW”;&lt;/p&gt;

&lt;p&gt;package helloworld;&lt;/p&gt;

&lt;p&gt;// The greeting service definition.
service Greeter {
  // Sends a greeting
  rpc SayHello (HelloRequest) returns (HelloReply) {}
}&lt;/p&gt;

&lt;p&gt;// The request message containing the user’s name.
message HelloRequest {
  string name = 1;
}&lt;/p&gt;

&lt;p&gt;// The response message containing the greetings
message HelloReply {
  string message = 1;
}
这里定义了一个服务Greeter，其中有个API SayHello。其接受参数为HelloRequest类型，返回HelloReply类型。这里HelloRequest和HelloReply就是普通的PB定义&lt;/p&gt;

&lt;p&gt;服务定义为：&lt;/p&gt;

&lt;p&gt;// The greeting service definition.
service Greeter {
  // Sends a greeting
  rpc SayHello (HelloRequest) returns (HelloReply) {}
}
service定义了一个server。其中的接口可以是四种类型&lt;/p&gt;

&lt;p&gt;rpc GetFeature(Point) returns (Feature) {}
类似普通的函数调用，客户端发送请求Point到服务器，服务器返回相应Feature.
rpc ListFeatures(Rectangle) returns (stream Feature) {}
客户端发起一次请求，服务器端返回一个流式数据，比如一个数组中的逐个元素
rpc RecordRoute(stream Point) returns (RouteSummary) {}
客户端发起的请求是一个流式的数据，比如数组中的逐个元素，服务器返回一个相应
rpc RouteChat(stream RouteNote) returns (stream RouteNote) {}
客户端发起的请求是一个流式数据，比如数组中的逐个元素，二服务器返回的也是一个类似的数据结构
后面三种可以参考官方的route_guide示例。&lt;/p&gt;

&lt;p&gt;使用protoc命令生成相关文件：&lt;/p&gt;

&lt;p&gt;protoc –go_out=plugins=grpc:. helloworld.proto
ls
helloworld.pb.go    helloworld.proto
生成对应的pb.go文件。这里用了plugins选项，提供对grpc的支持，否则不会生成Service的接口。&lt;/p&gt;

&lt;p&gt;3.2 服务器端程序&lt;/p&gt;

&lt;p&gt;然后编辑服务器端程序：&lt;/p&gt;

&lt;p&gt;package main&lt;/p&gt;

&lt;p&gt;import (
    “log”
    “net”&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;pb &quot;your_path_to_gen_pb_dir/helloworld&quot;
&quot;golang.org/x/net/context&quot;
&quot;google.golang.org/grpc&quot; )
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;const (
    port = “:50051”
)&lt;/p&gt;

&lt;p&gt;// server is used to implement helloworld.GreeterServer.
type server struct{}&lt;/p&gt;

&lt;p&gt;// SayHello implements helloworld.GreeterServer
func (s &lt;em&gt;server) SayHello(ctx context.Context, in *pb.HelloRequest) (&lt;/em&gt;pb.HelloReply, error) {
    return &amp;amp;pb.HelloReply{Message: “Hello “ + in.Name}, nil
}&lt;/p&gt;

&lt;p&gt;func main() {
    lis, err := net.Listen(“tcp”, port)
    if err != nil {
        log.Fatalf(“failed to listen: %v”, err)
    }
    s := grpc.NewServer()
    pb.RegisterGreeterServer(s, &amp;amp;server{})
    s.Serve(lis)
}
这里首先定义一个server结构，然后实现SayHello的接口，其定义在“your_path_to_gen_pb_dir/helloworld”&lt;/p&gt;

&lt;p&gt;SayHello(context.Context, &lt;em&gt;HelloRequest) (&lt;/em&gt;HelloReply, error)
然后调用grpc.NewServer() 创建一个server s。接着注册这个server s到结构server上面 pb.RegisterGreeterServer(s, &amp;amp;server{}) 最后将创建的net.Listener传给s.Serve()。就可以开始监听并服务了，类似HTTP的ListenAndServe。&lt;/p&gt;

&lt;p&gt;3.3 客户端程序&lt;/p&gt;

&lt;p&gt;客户端程序：&lt;/p&gt;

&lt;p&gt;package main&lt;/p&gt;

&lt;p&gt;import (
    “log”
    “os”&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;pb &quot;your_path_to_gen_pb_dir/helloworld&quot;
&quot;golang.org/x/net/context&quot;
&quot;google.golang.org/grpc&quot; )
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;const (
    address     = “localhost:50051”
    defaultName = “world”
)&lt;/p&gt;

&lt;p&gt;func main() {
    // Set up a connection to the server.
    conn, err := grpc.Dial(address, grpc.WithInsecure())
    if err != nil {
        log.Fatalf(“did not connect: %v”, err)
    }
    defer conn.Close()
    c := pb.NewGreeterClient(conn)&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;// Contact the server and print out its response.
name := defaultName
if len(os.Args) &amp;gt; 1 {
    name = os.Args[1]
}
r, err := c.SayHello(context.Background(), &amp;amp;pb.HelloRequest{Name: name})
if err != nil {
    log.Fatalf(&quot;could not greet: %v&quot;, err)
}
log.Printf(&quot;Greeting: %s&quot;, r.Message) } 这里通过pb.NewGreeterClient()传入一个conn创建一个client，然后直接调用client上面对应的服务器的接口
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;SayHello(context.Context, &lt;em&gt;HelloRequest) (&lt;/em&gt;HelloReply, error)
接口，返回*HelloReply 对象。&lt;/p&gt;

&lt;p&gt;先运行服务器，在运行客户端，可以看到。&lt;/p&gt;

&lt;p&gt;./greeter_server &amp;amp;&lt;/p&gt;

&lt;p&gt;./greeter_client
2016/03/10 21:42:19 Greeting: Hello world&lt;/p&gt;
</description>
        <pubDate>Mon, 25 Sep 2017 00:00:00 +0800</pubDate>
        <link>https://xiazemin.github.io/MyBlog/jekyll/2017/09/25/gorpc.html</link>
        <guid isPermaLink="true">https://xiazemin.github.io/MyBlog/jekyll/2017/09/25/gorpc.html</guid>
        
        
        <category>jekyll</category>
        
      </item>
    
      <item>
        <title>spark-kafka</title>
        <description>&lt;!-- more --&gt;
&lt;p&gt;参考文档：
https://spark.apache.org/docs/latest/structured-streaming-kafka-integration.html&lt;/p&gt;

&lt;p&gt;Reading Data from Kafka
Creating a Kafka Source for Streaming Queries
Scala
Java
Python
// Subscribe to 1 topic
val df = spark
  .readStream
  .format(“kafka”)
  .option(“kafka.bootstrap.servers”, “host1:port1,host2:port2”)
  .option(“subscribe”, “topic1”)
  .load()
df.selectExpr(“CAST(key AS STRING)”, “CAST(value AS STRING)”)
  .as[(String, String)]&lt;/p&gt;

&lt;p&gt;// Subscribe to multiple topics
val df = spark
  .readStream
  .format(“kafka”)
  .option(“kafka.bootstrap.servers”, “host1:port1,host2:port2”)
  .option(“subscribe”, “topic1,topic2”)
  .load()
df.selectExpr(“CAST(key AS STRING)”, “CAST(value AS STRING)”)
  .as[(String, String)]&lt;/p&gt;

&lt;p&gt;// Subscribe to a pattern
val df = spark
  .readStream
  .format(“kafka”)
  .option(“kafka.bootstrap.servers”, “host1:port1,host2:port2”)
  .option(“subscribePattern”, “topic.*”)
  .load()
df.selectExpr(“CAST(key AS STRING)”, “CAST(value AS STRING)”)
  .as[(String, String)]&lt;/p&gt;

&lt;p&gt;Writing Data to Kafka&lt;/p&gt;

&lt;p&gt;Creating a Kafka Sink for Streaming Queries
Scala
Java
Python
// Write key-value data from a DataFrame to a specific Kafka topic specified in an option
val ds = df
  .selectExpr(“CAST(key AS STRING)”, “CAST(value AS STRING)”)
  .writeStream
  .format(“kafka”)
  .option(“kafka.bootstrap.servers”, “host1:port1,host2:port2”)
  .option(“topic”, “topic1”)
  .start()&lt;/p&gt;

&lt;p&gt;// Write key-value data from a DataFrame to Kafka using a topic specified in the data
val ds = df
  .selectExpr(“topic”, “CAST(key AS STRING)”, “CAST(value AS STRING)”)
  .writeStream
  .format(“kafka”)
  .option(“kafka.bootstrap.servers”, “host1:port1,host2:port2”)
  .start()
Writing the output of Batch Queries to Kafka
Scala
Java
Python
// Write key-value data from a DataFrame to a specific Kafka topic specified in an option
df.selectExpr(“CAST(key AS STRING)”, “CAST(value AS STRING)”)
  .write
  .format(“kafka”)
  .option(“kafka.bootstrap.servers”, “host1:port1,host2:port2”)
  .option(“topic”, “topic1”)
  .save()&lt;/p&gt;

&lt;p&gt;// Write key-value data from a DataFrame to Kafka using a topic specified in the data
df.selectExpr(“topic”, “CAST(key AS STRING)”, “CAST(value AS STRING)”)
  .write
  .format(“kafka”)
  .option(“kafka.bootstrap.servers”, “host1:port1,host2:port2”)
  .save()&lt;/p&gt;
</description>
        <pubDate>Fri, 22 Sep 2017 00:00:00 +0800</pubDate>
        <link>https://xiazemin.github.io/MyBlog/spark/2017/09/22/spark-kafka.html</link>
        <guid isPermaLink="true">https://xiazemin.github.io/MyBlog/spark/2017/09/22/spark-kafka.html</guid>
        
        
        <category>spark</category>
        
      </item>
    
      <item>
        <title>mysqldump</title>
        <description>&lt;!-- more --&gt;
&lt;p&gt;mysqldump  -P端口  -hIP -u用户名 -p密码 表名 库名 &amp;gt; 目标文件.sql&lt;/p&gt;

&lt;p&gt;mysqldump: [Warning] Using a password on the command line interface can be insecure.&lt;/p&gt;

&lt;p&gt;mysqldump  -P端口  -hIP -u用户名 -p 表名 库名 &amp;gt; 目标文件.sql&lt;/p&gt;

&lt;p&gt;然后输入密码&lt;/p&gt;
</description>
        <pubDate>Wed, 20 Sep 2017 00:00:00 +0800</pubDate>
        <link>https://xiazemin.github.io/MyBlog/web/2017/09/20/mysqldump.html</link>
        <guid isPermaLink="true">https://xiazemin.github.io/MyBlog/web/2017/09/20/mysqldump.html</guid>
        
        
        <category>web</category>
        
      </item>
    
      <item>
        <title>mysql-time</title>
        <description>&lt;!-- more --&gt;
&lt;p&gt;MySQL 获得当前日期时间 函数
获得当前日期+时间（date + time）函数：now()&lt;/p&gt;

&lt;p&gt;复制代码
mysql&amp;gt; select now();&lt;/p&gt;

&lt;p&gt;+———————+
| now() |
+———————+
| 2008-08-08 22:20:46 |
+———————+
复制代码
获得当前日期+时间（date + time）函数：sysdate()
sysdate() 日期时间函数跟 now() 类似，不同之处在于：now() 在执行开始时值就得到了， sysdate() 在函数执行时动态得到值。看下面的例子就明白了：&lt;/p&gt;

&lt;p&gt;复制代码
mysql&amp;gt; select now(), sleep(3), now();&lt;/p&gt;

&lt;p&gt;+———————+———-+———————+
| now() | sleep(3) | now() |
+———————+———-+———————+
| 2008-08-08 22:28:21 | 0 | 2008-08-08 22:28:21 |
+———————+———-+———————+
复制代码
sysdate() 日期时间函数，一般情况下很少用到。&lt;/p&gt;

&lt;p&gt;MySQL 获得当前时间戳函数：current_timestamp, current_timestamp()&lt;/p&gt;

&lt;p&gt;复制代码
mysql&amp;gt; select current_timestamp, current_timestamp();&lt;/p&gt;

&lt;p&gt;+———————+———————+
| current_timestamp | current_timestamp() |
+———————+———————+
| 2008-08-09 23:22:24 | 2008-08-09 23:22:24 |
+———————+———————+
复制代码&lt;/p&gt;

&lt;p&gt;MySQL 日期转换函数、时间转换函数
MySQL Date/Time to Str（日期/时间转换为字符串）函数：date_format(date,format), time_format(time,format)&lt;/p&gt;

&lt;p&gt;复制代码
mysql&amp;gt; select date_format(‘2008-08-08 22:23:01’, ‘%Y%m%d%H%i%s’);&lt;/p&gt;

&lt;p&gt;+—————————————————-+
| date_format(‘2008-08-08 22:23:01’, ‘%Y%m%d%H%i%s’) |
+—————————————————-+
| 20080808222301 |
+—————————————————-+
复制代码
MySQL 日期、时间转换函数：date_format(date,format), time_format(time,format) 能够把一个日期/时间转换成各种各样的字符串格式。它是 str_to_date(str,format) 函数的 一个逆转换。&lt;/p&gt;

&lt;p&gt;MySQL Str to Date （字符串转换为日期）函数：str_to_date(str, format)&lt;/p&gt;

&lt;p&gt;select str_to_date(‘08/09/2008’, ‘%m/%d/%Y’); – 2008-08-09
select str_to_date(‘08/09/08’ , ‘%m/%d/%y’); – 2008-08-09
select str_to_date(‘08.09.2008’, ‘%m.%d.%Y’); – 2008-08-09
select str_to_date(‘08:09:30’, ‘%h:%i:%s’); – 08:09:30
select str_to_date(‘08.09.2008 08:09:30’, ‘%m.%d.%Y %h:%i:%s’); – 2008-08-09 08:09:30
可以看到，str_to_date(str,format) 转换函数，可以把一些杂乱无章的字符串转换为日期格式。另外，它也可以转换为时间。“format” 可以参看 MySQL 手册。&lt;/p&gt;

&lt;p&gt;MySQL （日期、天数）转换函数：to_days(date), from_days(days)&lt;/p&gt;

&lt;p&gt;select to_days(‘0000-00-00’); – 0
select to_days(‘2008-08-08’); – 733627&lt;/p&gt;

&lt;p&gt;MySQL （时间、秒）转换函数：time_to_sec(time), sec_to_time(seconds)&lt;/p&gt;

&lt;p&gt;select time_to_sec(‘01:00:05’); – 3605
select sec_to_time(3605); – ‘01:00:05’&lt;/p&gt;

&lt;p&gt;MySQL 拼凑日期、时间函数：makdedate(year,dayofyear), maketime(hour,minute,second)&lt;/p&gt;

&lt;p&gt;select makedate(2001,31); – ‘2001-01-31’
select makedate(2001,32); – ‘2001-02-01’
select maketime(12,15,30); – ‘12:15:30’&lt;/p&gt;

&lt;p&gt;MySQL （Unix 时间戳、日期）转换函数&lt;/p&gt;

&lt;p&gt;unix_timestamp(),
unix_timestamp(date),
from_unixtime(unix_timestamp),
from_unixtime(unix_timestamp,format)&lt;/p&gt;

&lt;p&gt;下面是示例：&lt;/p&gt;

&lt;p&gt;复制代码
select unix_timestamp(); – 1218290027
select unix_timestamp(‘2008-08-08’); – 1218124800
select unix_timestamp(‘2008-08-08 12:30:00’); – 1218169800&lt;/p&gt;

&lt;p&gt;select from_unixtime(1218290027); – ‘2008-08-09 21:53:47’
select from_unixtime(1218124800); – ‘2008-08-08 00:00:00’
select from_unixtime(1218169800); – ‘2008-08-08 12:30:00’&lt;/p&gt;

&lt;p&gt;select from_unixtime(1218169800, ‘%Y %D %M %h:%i:%s %x’); – ‘2008 8th August 12:30:00 2008’
复制代码&lt;/p&gt;

&lt;p&gt;MySQL 日期时间计算函数&lt;/p&gt;

&lt;p&gt;MySQL 为日期增加一个时间间隔：date_add()&lt;/p&gt;

&lt;p&gt;复制代码
set @dt = now();&lt;/p&gt;

&lt;p&gt;select date_add(@dt, interval 1 day); – add 1 day
select date_add(@dt, interval 1 hour); – add 1 hour
select date_add(@dt, interval 1 minute); – …
select date_add(@dt, interval 1 second);
select date_add(@dt, interval 1 microsecond);
select date_add(@dt, interval 1 week);
select date_add(@dt, interval 1 month);
select date_add(@dt, interval 1 quarter);
select date_add(@dt, interval 1 year);&lt;/p&gt;

&lt;p&gt;select date_add(@dt, interval -1 day); – sub 1 day
复制代码&lt;/p&gt;

&lt;p&gt;MySQL adddate(), addtime()函数，可以用 date_add() 来替代。下面是 date_add() 实现 addtime() 功能示例：&lt;/p&gt;

&lt;p&gt;复制代码
mysql&amp;gt; set @dt = ‘2008-08-09 12:12:33’;&lt;/p&gt;

&lt;p&gt;mysql&amp;gt;
mysql&amp;gt; select date_add(@dt, interval ‘01:15:30’ hour_second);&lt;/p&gt;

&lt;p&gt;+————————————————+
| date_add(@dt, interval ‘01:15:30’ hour_second) |
+————————————————+
| 2008-08-09 13:28:03 |
+————————————————+&lt;/p&gt;

&lt;p&gt;mysql&amp;gt; select date_add(@dt, interval ‘1 01:15:30’ day_second);&lt;/p&gt;

&lt;p&gt;+————————————————-+
| date_add(@dt, interval ‘1 01:15:30’ day_second) |
+————————————————-+
| 2008-08-10 13:28:03 |
+————————————————-+
复制代码&lt;/p&gt;

&lt;p&gt;MySQL 为日期减去一个时间间隔：date_sub()&lt;/p&gt;

&lt;p&gt;复制代码
mysql&amp;gt; select date_sub(‘1998-01-01 00:00:00’, interval ‘1 1:1:1’ day_second);&lt;/p&gt;

&lt;p&gt;+—————————————————————-+
| date_sub(‘1998-01-01 00:00:00’, interval ‘1 1:1:1’ day_second) |
+—————————————————————-+
| 1997-12-30 22:58:59 |
+—————————————————————-+
复制代码
MySQL date_sub() 日期时间函数 和 date_add() 用法一致，不再赘述。&lt;/p&gt;

&lt;p&gt;MySQL 日期、时间相减函数：datediff(date1,date2), timediff(time1,time2)&lt;/p&gt;

&lt;p&gt;MySQL datediff(date1,date2)：两个日期相减 date1 - date2，返回天数。
select datediff(‘2008-08-08’, ‘2008-08-01’); – 7
select datediff(‘2008-08-01’, ‘2008-08-08’); – -7
MySQL timediff(time1,time2)：两个日期相减 time1 - time2，返回 time 差值。&lt;/p&gt;

&lt;p&gt;select timediff(‘2008-08-08 08:08:08’, ‘2008-08-08 00:00:00’); – 08:08:08
select timediff(‘08:08:08’, ‘00:00:00’); – 08:08:08
注意：timediff(time1,time2) 函数的两个参数类型必须相同。&lt;/p&gt;

&lt;p&gt;MySQL 时间戳（timestamp）转换、增、减函数：&lt;/p&gt;

&lt;p&gt;timestamp(date) – date to timestamp
timestamp(dt,time) – dt + time
timestampadd(unit,interval,datetime_expr) –
timestampdiff(unit,datetime_expr1,datetime_expr2) –
请看示例部分：&lt;/p&gt;

&lt;p&gt;复制代码
select timestamp(‘2008-08-08’); – 2008-08-08 00:00:00
select timestamp(‘2008-08-08 08:00:00’, ‘01:01:01’); – 2008-08-08 09:01:01
select timestamp(‘2008-08-08 08:00:00’, ‘10 01:01:01’); – 2008-08-18 09:01:01&lt;/p&gt;

&lt;p&gt;select timestampadd(day, 1, ‘2008-08-08 08:00:00’); – 2008-08-09 08:00:00
select date_add(‘2008-08-08 08:00:00’, interval 1 day); – 2008-08-09 08:00:00&lt;/p&gt;

&lt;p&gt;MySQL timestampadd() 函数类似于 date_add()。
select timestampdiff(year,’2002-05-01’,’2001-01-01’); – -1
select timestampdiff(day ,’2002-05-01’,’2001-01-01’); – -485
select timestampdiff(hour,’2008-08-08 12:00:00’,’2008-08-08 00:00:00’); – -12&lt;/p&gt;

&lt;p&gt;select datediff(‘2008-08-08 12:00:00’, ‘2008-08-01 00:00:00’); – 7
复制代码
MySQL timestampdiff() 函数就比 datediff() 功能强多了，datediff() 只能计算两个日期（date）之间相差的天数。&lt;/p&gt;

&lt;p&gt;MySQL 时区（timezone）转换函数
convert_tz(dt,from_tz,to_tz)&lt;/p&gt;

&lt;p&gt;select convert_tz(‘2008-08-08 12:00:00’, ‘+08:00’, ‘+00:00’); – 2008-08-08 04:00:00
时区转换也可以通过 date_add, date_sub, timestampadd 来实现。&lt;/p&gt;

&lt;p&gt;select date_add(‘2008-08-08 12:00:00’, interval -8 hour); – 2008-08-08 04:00:00
select date_sub(‘2008-08-08 12:00:00’, interval 8 hour); – 2008-08-08 04:00:00
select timestampadd(hour, -8, ‘2008-08-08 12:00:00’); – 2008-08-08 04:00:00&lt;/p&gt;

</description>
        <pubDate>Wed, 20 Sep 2017 00:00:00 +0800</pubDate>
        <link>https://xiazemin.github.io/MyBlog/jekyll/2017/09/20/mysql-time.html</link>
        <guid isPermaLink="true">https://xiazemin.github.io/MyBlog/jekyll/2017/09/20/mysql-time.html</guid>
        
        
        <category>jekyll</category>
        
      </item>
    
      <item>
        <title>mac 安装 sshfs</title>
        <description>
&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-bash&quot; data-lang=&quot;bash&quot;&gt;&lt;span&gt;&lt;/span&gt;&lt;span class=&quot;lineno&quot;&gt;1 &lt;/span&gt;&lt;span class=&quot;nv&quot;&gt;$brew&lt;/span&gt; cask install osxfuse
&lt;span class=&quot;lineno&quot;&gt;2 &lt;/span&gt;&lt;span class=&quot;nv&quot;&gt;$brew&lt;/span&gt; install sshfs&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;

&lt;!-- more --&gt;
&lt;p&gt;挂载(如果配上ssh key就可以完全自动化了):
sshfs root@192.168.9.109:/opt /opt/s109
卸载:
fusermount -u /opt/s109&lt;/p&gt;
</description>
        <pubDate>Mon, 18 Sep 2017 00:00:00 +0800</pubDate>
        <link>https://xiazemin.github.io/MyBlog/jekyll/2017/09/18/sshfs.html</link>
        <guid isPermaLink="true">https://xiazemin.github.io/MyBlog/jekyll/2017/09/18/sshfs.html</guid>
        
        
        <category>jekyll</category>
        
      </item>
    
      <item>
        <title>jupyter</title>
        <description>&lt;p&gt;Jupyter Notebook（此前被称为 IPython notebook）是一个交互式笔记本，支持运行 40 多种编程语言。
Jupyter Notebook 的本质是一个 Web 应用程序，便于创建和共享文学化程序文档，支持实时代码，数学方程，可视化和 markdown。 用途包括：数据清理和转换，数值模拟，统计建模，机器学习等等
&lt;!-- more --&gt;&lt;/p&gt;

&lt;p&gt;官网：https://github.com/jupyter?language=python&lt;/p&gt;

&lt;p&gt;mac 安装：
pip install jupyter&lt;/p&gt;

&lt;p&gt;使用：
$jupyter notebook&lt;/p&gt;

&lt;p&gt;此时浏览器中会弹出notebook窗口（http://localhost:8888/tree）&lt;/p&gt;

&lt;p&gt;问题：
出现404&lt;/p&gt;

&lt;p&gt;修改配置文件端口&lt;/p&gt;

&lt;p&gt;$jupyter  notebook –generate-config –allow-root&lt;/p&gt;

&lt;p&gt;/Users/didi/.jupyter/jupyter_notebook_config.py&lt;/p&gt;

&lt;p&gt;$vi /Users/didi/.jupyter/jupyter_notebook_config.py&lt;/p&gt;

&lt;p&gt;把端口改为8866&lt;/p&gt;

&lt;p&gt;0 active kernels&lt;/p&gt;

&lt;p&gt;The Jupyter Notebook is running at: http://localhost:8866/?token=2d6&lt;/p&gt;

&lt;p&gt;成功
&lt;img src=&quot;https://xiazemin.github.io/MyBlog/img/jupyter.png&quot; /&gt;&lt;/p&gt;

&lt;p&gt;Files下面列出了当前用户目录下所有的文件，结合右上角的upload和new你可以方便地进行文件操作。你先选择一个目录，在该目录下，new一个python2，这样当前目录即会出现一个“.ipynb”文件，同时，浏览器会弹新的标签页让你编辑该“.ipynb”文件。&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://xiazemin.github.io/MyBlog/img/jupyter_use.png&quot; alt=&quot;jupyter_use&quot; /&gt;&lt;/p&gt;

&lt;p&gt;在该界面下，每输入一行代码Enter后不会运行当前代码，而是换行让你输入下一行代码，当你键入Shift + Enter后，将运行刚刚你输入的那几行代码。&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://xiazemin.github.io/MyBlog/img/jupyter_use1.png&quot; alt=&quot;jupyter_use&quot; /&gt;&lt;/p&gt;

&lt;p&gt;还可以new一个Terminal，如下图所示。&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://xiazemin.github.io/MyBlog/img/jupyter_use2.png&quot; alt=&quot;jupyter_use&quot; /&gt;&lt;/p&gt;

&lt;p&gt;mac 截图：
下载snipmac&lt;/p&gt;

</description>
        <pubDate>Sun, 17 Sep 2017 00:00:00 +0800</pubDate>
        <link>https://xiazemin.github.io/MyBlog/deep_learning/2017/09/17/jupyter.html</link>
        <guid isPermaLink="true">https://xiazemin.github.io/MyBlog/deep_learning/2017/09/17/jupyter.html</guid>
        
        
        <category>deep_learning</category>
        
      </item>
    
  </channel>
</rss>
