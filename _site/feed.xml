<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>泽民博客</title>
    <description>夏泽民的个人主页，学习笔记。</description>
    <link>https://xiazemin.github.io/MyBlog/</link>
    <atom:link href="https://xiazemin.github.io/MyBlog/feed.xml" rel="self" type="application/rss+xml"/>
    <pubDate>Sun, 31 Dec 2017 17:37:31 +0800</pubDate>
    <lastBuildDate>Sun, 31 Dec 2017 17:37:31 +0800</lastBuildDate>
    <generator>Jekyll v3.6.0.pre.beta1</generator>
    
      <item>
        <title>单播、多播和广播</title>
        <description>&lt;!-- more --&gt;
&lt;p&gt;　　单播在网络中得到了广泛的应用，网络上绝大部分的数据都是以单播的形式传输的，只是一般网络用户不知道而已。例如，你在收发电子邮件、浏览网页时，必须与邮件服务器、Web服务器建立连接，此时使用的就是单播数据传输方式。但是通常使用“点对点通信”（Point to Point）代替“单播”，因为“单播”一般与“多播”和“广播”相对应使用
　　　“多播”也可以称为“组播”，在网络技术的应用并不是很多，网上视频会议、网上视频点播特别适合采用多播方式。因为如果采用单播方式，逐个节点传输，有多少个目标节点，就会有多少次传送过程，这种方式显然效率极低，是不可取的；如果采用不区分目标、全部发送的广播方式，虽然一次可以传送完数据，但是显然达不到区分特定数据接收对象的目的。采用多播方式，既可以实现一次传送所有目标节点的数据，也可以达到只对特定对象传送数据的目的。&lt;/p&gt;

&lt;p&gt;　　IP网络的多播一般通过多播IP地址来实现。多播IP地址就是D类IP地址，即224.0.0.0至239.255.255.255之间的IP地址。Windows 2000中的DHCP管理器支持多播IP地址的自动分配。
　　
　　“广播”在网络中的应用较多，如客户机通过DHCP自动获得IP地址的过程就是通过广播来实现的。但是同单播和多播相比，广播几乎占用了子网内网络的所有带宽。拿开会打一个比方吧，在会场上只能有一个人发言，想象一下如果所有的人同时都用麦克风发言，那会场上就会乱成一锅粥。&lt;/p&gt;

&lt;p&gt;　　在网络中不能长时间出现大量的广播包，否则就会出现所谓的“广播风暴”。广播风暴就是网络长时间被大量的广播数据包所占用，正常的点对点通信无法正常进行，外在表现为网络速度奇慢无比。出现广播风暴的原因有很多，一块有故障的网卡，就可能长时间向网络上发送广播包而导致广播风暴。
一、单播：&lt;/p&gt;

&lt;p&gt;主机之间“一对一”的通讯模式，网络中的交换机和路由器对数据只进行转发不进行复制。如果10个客户机需要相同的数据，则服务器需要逐一传送，重复10次相同的工作。但由于其能够针对每个客户的及时响应，所以现在的网页浏览全部都是采用IP单播协议。网络中的路由器和交换机根据其目标地址选择传输路径，将 IP单播数据传送到其指定的目的地。
单播的优点：&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;
    &lt;p&gt;服务器及时响应客户机的请求&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;服务器针对每个客户不通的请求发送不通的数据，容易实现个性化服务。&lt;/p&gt;
  &lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;单播的缺点：&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;
    &lt;p&gt;服务器针对每个客户机发送数据流，服务器流量＝客户机数量×客户机流量；在客户数量大、每个客户机流量大的流媒体应用中服务器不堪重负。&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;现有的网络带宽是金字塔结构，城际省际主干带宽仅仅相当于其所有用户带宽之和的5％。如果全部使用单播协议，将造成网络主干不堪重负。现在的P2P应用就已经使主干经常阻塞，只要有5％的客户在全速使用网络，其他人就不要玩了。而将主干扩展20倍几乎是不可能。&lt;/p&gt;
  &lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;二、 广播：&lt;/p&gt;

&lt;p&gt;主机之间“一对所有”的通讯模式，网络对其中每一台主机发出的信号都进行无条件复制并转发，所有主机都可以接收到所有信息（不管你是否需要），由于其不用路径选择，所以其网络成本可以很低廉。有线电视网就是典型的广播型网络，我们的电视机实际上是接受到所有频道的信号，但只将一个频道的信号还原成画面。在数据网络中也允许广播的存在，但其被限制在二层交换机的局域网范围内，禁止广播数据穿过路由器，防止广播数据影响大面积的主机。
广播的优点：&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;
    &lt;p&gt;网络设备简单，维护简单，布网成本低廉&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;由于服务器不用向每个客户机单独发送数据，所以服务器流量负载极低。&lt;/p&gt;
  &lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;广播的缺点：&lt;/p&gt;

&lt;p&gt;1.无法针对每个客户的要求和时间及时提供个性化服务。&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;
    &lt;p&gt;网络允许服务器提供数据的带宽有限，客户端的最大带宽＝服务总带宽。例如有线电视的客户端的线路支持100个频道（如果采用数字压缩技术，理论上可以提供 500个频道），即使服务商有更大的财力配置更多的发送设备、改成光纤主干，也无法超过此极限。也就是说无法向众多客户提供更多样化、更加个性化的服务。&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;广播禁止在Internet宽带网上传输。&lt;/p&gt;
  &lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;三、组播：&lt;/p&gt;

&lt;p&gt;主机之间“一对一组”的通讯模式，也就是加入了同一个组的主机可以接受到此组内的所有数据，网络中的交换机和路由器只向有需求者复制并转发其所需数据。主机可以向路由器请求加入或退出某个组，网络中的路由器和交换机有选择的复制并传输数据，即只将组内数据传输给那些加入组的主机。这样既能一次将数据传输给多个有需要（加入组）的主机，又能保证不影响其他不需要（未加入组）的主机的其他通讯。
组播的优点：&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;
    &lt;p&gt;需要相同数据流的客户端加入相同的组共享一条数据流，节省了服务器的负载。具备广播所具备的优点。&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;由于组播协议是根据接受者的需要对数据流进行复制转发，所以服务端的服务总带宽不受客户接入端带宽的限制。IP协议允许有2亿6千多万个（268435456）组播，所以其提供的服务可以非常丰富。&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;此协议和单播协议一样允许在Internet宽带网上传输。&lt;/p&gt;
  &lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;组播的缺点：&lt;/p&gt;

&lt;p&gt;1．与单播协议相比没有纠错机制，发生丢包错包后难以弥补，但可以通过一定的容错机制和QOS加以弥补。&lt;/p&gt;

&lt;p&gt;2．现行网络虽然都支持组播的传输，但在客户认证、QOS等方面还需要完善，这些缺点在理论上都有成熟的解决方案，只是需要逐步推广应用到现存网络当中&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;    二层交换机是数据链路层的设备，它能够读取数据包中的MAC地址信息并根据MAC地址来进行交换。交换机内部有一个地址表，这个地址表标明了MAC地址和交换机端口的对应关系.二层交换机对广播包是不做限制的，把广播包复制到所有端口上。

 广播分二层广播和三层广播，二层广播是FFFF.FFFF.FFFF(MAC地址)，二层交换机遇到这种包就会泛洪到所有同VLAN的端口，不会过滤掉，因为如果二层交换机过滤这种包，arp广播怎么正常工作呢？没有arp，同网段的PC如何通信呢？路由器可以过滤二层广播是因为路由器是三层设备，如果路由器不过滤这种包，任何人发起的二层广播包就会到达Internet的整个范围，这样还要路由器做什么呢？路由器就是为了划分广播域用的阿。

 对于三层广播还有本地广播255.255.255.255和特定子网广播比如192.168.1.255/24之分，255.255.255.255这种本地广播是肯定没发跨越路由器的，因为一旦这种广播能跨越路由器的话，同样任何人发起的这种广播就会跑到Internet的任何角落。然而对于特定子网的广播是可以配置为允许跨路由器或者不允许跨路由器的，如果允许的话，我就可以跨越路由器对特定的子网发起三层广播。通常不要允许这类广播，因为你一旦允许了很容易造成icmp sumrf攻击的。
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;交换机或是路由器的复制功能猜想是：首先接收到数据，进行处理，再进行相应接口的转发，（存储一份转发多份即为复制）&lt;/p&gt;

&lt;p&gt;三层交换机接收到数据的处理流程：&lt;/p&gt;

&lt;p&gt;使用IP的设备A————————三层交换机————————使用IP的设备B&lt;/p&gt;

&lt;p&gt;　　比如A要给B发送数据，已知目的IP，那么A就用子网掩码取得网络地址，判断目的IP是否与自己在同一网段。&lt;/p&gt;

&lt;p&gt;　　如果在同一网段，但不知道转发数据所需的MAC地址，A就发送一个ARP请求，B返回其MAC地址，A用此MAC封装数据包并发送给交换机，交换机起用二层交换模块，查找MAC地址表，将数据包转发到相应的端口。&lt;/p&gt;

&lt;p&gt;　　如果目的IP地址显示不是同一网段的，那么A要实现和B的通讯，在流缓存条目中没有对应MAC地址条目，就将第一个正常数据包发送向一个缺省网关，这个缺省网关一般在操作系统中已经设好，对应第三层路由模块，所以可见对于不是同一子网的数据，最先在MAC表中放的是缺省网关的MAC地址；然后就由三层模块接收到此数据包，查询路由表以确定到达B的路由，将构造一个新的帧头，其中以缺省网关的MAC地址为源MAC地址，以主机B的MAC地址为目的MAC地址。通过一定的识别触发机制，确立主机A与B的MAC地址及转发端口的对应关系，并记录进流缓存条目表，以后的A到B的数据，就直接交由二层交换模块完成。这就通常所说的一次路由多次转发。&lt;/p&gt;

&lt;p&gt;　　 表面上看，第三层交换机是第二层交换器与路由器的合二而一，然而这种结合并非简单的物理结合，而是各取所长的逻辑结合。其重要表现是，当某一信息源的第一个数据流进行第三层交换后，其中的路由系统将会产生一个MAC地址与IP地址的映射表，并将该表存储起来，当同一信息源的后续数据流再次进入交换环境时，交换机将根据第一次产生并保存的地址映射表，直接从第二层由源地址传输到目的地址，不再经过第三路由系统处理，从而消除了路由选择时造成的网络延迟，提高了数据包的转发效率，解决了网间传输信息时路由产生的速率瓶颈。所以说，第三层交换机既可完成第二层交换机的端口交换功能，又可完成部分路由器的路由功能。即第三层交换机的交换机方案，实际上是一个能够支持多层次动态集成的解决方案，虽然这种多层次动态集成功能在某些程度上也能由传统路由器和第二层交换机搭载完成，但这种搭载方案与采用三层交换机相比，不仅需要更多的设备配置、占用更大的空间、设计更多的布线和花费更高的成本，而且数据传输性能也要差得多，因为在海量数据传输中，搭载方案中的路由器无法克服路由传输速率瓶颈。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;   主机开机组播接收程序时，会向TCP/IP协议注册一个组播IP地址，所以当收到目的IP地址是这个组播组的地址时，主机就会接收。  同时它又向工作在数据链路层的网卡也注册了一个二层MAC地址，这样的话，当主机接收到一个组播报文的时候，就可以  直接现在网卡上判断是否是自己所需要的组播报文。  IGMP：Internet组管理协议，用于主机与路由器之间交互信息的一种协议。所有要加入组播组的主机和所有连接到有组播主机的子网中 的路由器都必须使用IGMP。IGMP消息不能被路由转发，只能限制在本地网段内部。IGMP的TTL参数永远是1，保证了IGMP的使用  范围。
  组播路由协议的主要功能是将组播数据从一台路由器跨越一个网络传送到另外一台路由器上。  组播路由协议分为域内组播路由协议及域间组播路由协议。
  http://wenku.baidu.com/view/b30740553c1ec5da50e27015.html
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;组播的转发技术：
在单播里面，数据转发的依据是数据包的目的地址，这个目的地址明确表示了一个主机的位置，但是组播数据包并不是基于ip数据包的目的地址的，它没有唯一性，因此它需要采用一种叫RTF(Reverse Path Forwarding逆向路径转发)的方式来转发数据包，它是针对转发的时候做检查，这个检查会决定是否转发还是丢弃输入的信息包，那么它的检查过程是什么样的呢？
首先要了解的是，RPF跟单播协议密切相关，所谓的逆向路径转发是基于察看有关组播源在什么地方，组播源是一个IP的单播地址，因此呢，路由器检查到达的数据包的源地址，然后查看路由表，看这个源地址可以通过哪个接口可达，如果信息包是在可返回原站点的接口上到达，那就说明这个组播数据流是从正确的方向过来的，则RPF检查成功，信息包被转发，但如果说这个数据包的原地址不是从这个接口到达的，那就说明这个组播数据包不是从最佳路经过来的，应该丢弃该数据包。
因为RPF是要结合单播路由表的，因此在构件组播之前应该事先完成有关IP单播路由表的实现。&lt;/p&gt;

&lt;p&gt;无组播功能交换机转发组播数据包：
对一些网桥，一些二层设备，他没办法实现路由，也没办法实现RPF，对于一个不能识别组播数据流的二层交换机来说，它收到一个组播数据包会按照广播数据包得处理方法处理。&lt;/p&gt;

&lt;p&gt;二层交换机的组播功能实现：
因为无组播功能的交换机在转发组播数据包的时候是跟广播一样，这样就达不到组播的目的了。因此，现在很多二层交换机增加了组播功能，增加了组播功能后就可以识别组播流，并且可以针对组播流来建立有关组播地址和端口的映射。
能识别组播的交换机在它的转发表里面，都会增加一项MAC地址是组播地址，然后端口包含以希望接收组播数据的主机所相连的所有端口。&lt;/p&gt;

&lt;p&gt;引言&lt;/p&gt;

&lt;p&gt;广播和多播仅应用于UDP，因为TCP是面向连接的协议（IP地址确定）&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;   单播：以太网帧仅发往单个目的主机，目的地址指明单个接收接口。该模式下，任意两主机通信不会影响网内其他主机（争夺共享信道情况除外）

   广播：主机向网上的所有其他主机发送帧。但是只有ARP和RARP可以看到该过程。

   组播：帧传送给属于多播组的多个主机。
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;主机对帧过滤过程：&lt;/p&gt;

&lt;p&gt;网卡查看由信道传送过来的帧，确定是否接收该帧。若接收则将它传往设备驱动程序。通常网卡接收目的地址为网卡物理地址或广播地址的帧。多数接口均被设置为混合模式，这种模式能接收每个帧的一个复制。      大多数网卡经过配置，都能接收目的地址为多播地址或某些子网多播地址的帧。对于以太网，当地址中最高字节的最低位设置为1时表示该地址是一个多播地址。用十六进制可表示为01：00：00：00：00：00。（广播地址ff:ff:ff:ff:ff）
网卡收到帧后传递给设备驱动程序（如果帧检验和错，网卡将丢弃该帧）。设备驱动程序会进行另外的帧过滤。首先，帧类型中必须指定要使用的协议（IP、ARP等）。其次，进行组播过滤来检测该主机是否属于多播地址说明的多播组
设备驱动程序将数据帧传送给下一层，比如，当帧类型指定为IP数据报时，就传给IP层。IP根据IP地址中的源地址和目的地址进行更多的过滤监测。若正常，则将数据报传送给下一层（TCP或UDP）
UDP或这IP收到传送来的数据报，就根据目的端口号，有时还有源端口号进行数据报过滤。若当前没有进程使用该目的端口号，就丢弃数据报，并产生ICMP不可达报文。若UDP数据报存在检验和错，则会被丢弃。
多播的作用：减少对广播内容不感兴趣主机的处理负荷。&lt;/p&gt;

&lt;p&gt;使用多播，主机可加入一个或多个多播组。&lt;/p&gt;

&lt;p&gt;2、广播
2.1 受限广播 ——————-系统初始启动时使用&lt;/p&gt;

&lt;p&gt;受限广播地址为255.255.255.255。该地址用于主机配置过程中IP数据报的目的地址。原因：此时主机还不知道自己所在网络的网络掩码，和自己的IP地址。&lt;/p&gt;

&lt;p&gt;任何情况下，路由器都不转发目的地址为受限广播地址的数据报，这样的数据报仅出现在本地网络中。&lt;/p&gt;

&lt;p&gt;2.2 指向网络的广播&lt;/p&gt;

&lt;p&gt;指向网络的广播地址是主机号全为1的地址。例如A类网络广播地址为netid.255.255.255，其中netid为A类网络的网络号。&lt;/p&gt;

&lt;p&gt;一个路由器必须转发指向网络的广播，但它也必须有一个不进行转发的选择。&lt;/p&gt;

&lt;p&gt;2.3 指向子网的广播  ——————最常用&lt;/p&gt;

&lt;p&gt;指向子网的广播地址为主机号为全1且有特定子网号的地址。作为子网直接广播地址的IP地址需要了解子网的掩码。&lt;/p&gt;

&lt;p&gt;2.4 指向所有子网的广播
指向所有子网的广播也需要了解目的网络的子网掩码，以便与指向网络的广播地址区分开。&lt;/p&gt;

&lt;p&gt;指向所有子网的广播地址的子网号以及主机号全为1。例如，若目的子网掩码为255.255.255.0，则IP地址128.1.255.255是一个指向所有子网的广播地址。然而，如果网络没有划分子网，则这就是一个指向网络的广播。&lt;/p&gt;

&lt;p&gt;3、多播&lt;/p&gt;

&lt;p&gt;3.1 多播提供两类服务&lt;/p&gt;

&lt;p&gt;向多个目的地址传送数据，例如交互式会议系统和想多个接收者分发邮件或新闻。然而，即使使用多播，某些应用可能继续采用TCP来保证它的可靠性（？）
客户对服务器的请求。例如无盘工作组需要确定启动引导服务器
3.2 多播组地址
分配的28bit均作为多播组号&lt;/p&gt;

&lt;p&gt;多播组地址范围是224.0.0.0 到239.255.255.255&lt;/p&gt;

&lt;p&gt;能够接收发往一个特定多播组地址数据的主机集合称为主机组。一个主机组可跨越多个网络。主机组中成员可随时加入或离开主机组。主机组中对主机的数量没有限制，同时不属于某一主机组的主机可以向该组发送信息。&lt;/p&gt;

&lt;p&gt;注：一些多播组地址被IANA确定为知名地址。他们被当作永久主机组，这些多播地址所代表的组是永久组，他们的组成员却不是永久的。例如：224.0.0.1表示该子网内的所有系统组&lt;/p&gt;

&lt;p&gt;3.3 多播组地址到以太网地址的转换&lt;/p&gt;

&lt;p&gt;IANA拥有高位24bit为00:00:5e的以太网地址块，即该地址块所拥有的地址范围是从00:00:5e:00:00:00到00:00:5e:ff:ff:ff。IANA将其中一半分为i多播地址。任何以太网地址首字节为01的，为一个多播地址。因此，IP多播相对应的以太网地址范围从01:00:5e:00:00:00到01:00:5e:7f:ff:ff（为什么是7f）。&lt;/p&gt;

&lt;p&gt;这种地址分配将使以太网多播地址中的23bit与IP多播组号对应起来。通过将多播组号中的低23bit映射到以太网中的低位23bit实现。
由于多播组号中的最高5bit在映射过程中被忽略，因此每个以太网多播地址对应的多播组是不唯一的。32（2^5）个不同的多播组号被映射为一个以太网地址。&lt;/p&gt;

&lt;p&gt;由于地址映射是不唯一的，因此设备驱动程序或IP层需要对数据报进行过滤。因为网卡可能接收到主机不想接收的多播数据帧。若网卡不提供足够的多播数据帧过滤功能，设备驱动就必须接收所有多播数据帧，并对它们进行过滤。&lt;/p&gt;

&lt;p&gt;局域网网卡趋向两种处理类型：一种是网卡根据对多播地址的散列值实行多播过滤，可能会接收到不想接收的多播数据；另一种是网卡只接收一些固定数目的多播地址，当主机想接收超过网卡预先支持多播地址外的多播地址时，必须将网卡设置为“多播混杂”模式。这两种类型的网卡人需要设备驱动程序检查收到的帧是否为主机所需要的。&lt;/p&gt;

&lt;p&gt;多播传送接收过程&lt;/p&gt;

&lt;p&gt;多播进程将目的IP地址指明为多播地址，设备驱动程序将它转化为相应的以太网地址，然后把数据发出去。而这些接收进程需要通知他们的IP层，他们想接收的发往给定多播地址的数据报，并且设备驱动程序必须能够接收这些多播帧。这个过程就是“加入一个多播组”（在同一个主机或多个主机上存在多个接收者）。当一个主机收到多播数据报时，他必须向属于那个多播组的每个进程均传送一个复制，这和单个进程收到单播UDP数据报的UDP不同。使用多播，一个主机上可能存在多个属于同一多播组的进程。&lt;/p&gt;

&lt;p&gt;当把多播扩展到单个物理网络以外需要通过路由器转发多播数据时，需要一个协议让多播路由器了解确定网络中属于确定多播组的任何一个主机，此协议为IGMP协议（Internet组管理协议）&lt;/p&gt;

&lt;p&gt;3.4 FDDI和令牌环网络中的多播&lt;/p&gt;

&lt;p&gt;FDDI网络使用相同的D类IP地址到48bit FDDI地址的映射过程。令牌环网络通常使用不同的地址映射方法。&lt;/p&gt;

&lt;p&gt;使用UDP协议进行信息的传输之前不需要建议连接。换句话说就是客户端向服务器发送信息，客户端只需要给出服务器的ip地址和端口号，然后将信息封装到一个待发送的报文中并且发送出去。至于服务器端是否存在，或者能否收到该报文，客户端根本不用管。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt; 单播用于两个主机之间的端对端通信，广播用于一个主机对整个局域网上所有主机上的数据通信。单播和广播是两个极端，要么对一个主机进行通信，要么对整个局域网上的主机进行通信。实际情况下，经常需要对一组特定的主机进行通信，而不是整个局域网上的所有主机，这就是多播的用途。
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;　　通常我们讨论的udp的程序都是一对一的单播程序。本章将讨论一对多的服务：广播（broadcast）、多播（multicast）。对于广播，网络中的所有主机都会接收一份数据副本。对于多播，消息只是发送到一个多播地址，网络知识将数据分发给哪些表示想要接收发送到该多播地址的数据的主机。总得来说，只有UDP套接字允许广播或多播。&lt;/p&gt;

&lt;p&gt;回到顶部(go to top)
一、UDP广播
　　广播UDP与单播UDP的区别就是IP地址不同，广播使用广播地址255.255.255.255，将消息发送到在同一广播网络上的每个主机。值得强调的是：本地广播信息是不会被路由器转发。当然这是十分容易理解的，因为如果路由器转发了广播信息，那么势必会引起网络瘫痪。这也是为什么IP协议的设计者故意没有定义互联网范围的广播机制。&lt;/p&gt;

&lt;p&gt;广播地址通常用于在网络游戏中处于同一本地网络的玩家之间交流状态信息等。&lt;/p&gt;

&lt;p&gt;　　其实广播顾名思义，就是想局域网内所有的人说话，但是广播还是要指明接收者的端口号的，因为不可能接受者的所有端口都来收听广播。
　　
　　1、多播（组播）的概念
　　多播，也称为“组播”，将网络中同一业务类型主机进行了逻辑上的分组，进行数据收发的时候其数据仅仅在同一分组中进行，其他的主机没有加入此分组不能收发对应的数据。&lt;/p&gt;

&lt;p&gt;　　在广域网上广播的时候，其中的交换机和路由器只向需要获取数据的主机复制并转发数据。主机可以向路由器请求加入或退出某个组，网络中的路由器和交换机有选择地复制并传输数据，将数据仅仅传输给组内的主机。多播的这种功能，可以一次将数据发送到多个主机，又能保证不影响其他不需要（未加入组）的主机的其他通 信。&lt;/p&gt;

&lt;p&gt;相对于传统的一对一的单播，多播具有如下的优点：&lt;/p&gt;

&lt;p&gt;　　1、具有同种业务的主机加入同一数据流，共享同一通道，节省了带宽和服务器的优点，具有广播的优点而又没有广播所需要的带宽。&lt;/p&gt;

&lt;p&gt;　　2、服务器的总带宽不受客户端带宽的限制。由于组播协议由接收者的需求来确定是否进行数据流的转发，所以服务器端的带宽是常量，与客户端的数量无关。&lt;/p&gt;

&lt;p&gt;　　3、与单播一样，多播是允许在广域网即Internet上进行传输的，而广播仅仅在同一局域网上才能进行。&lt;/p&gt;

&lt;p&gt;组播的缺点：&lt;/p&gt;

&lt;p&gt;　　1、多播与单播相比没有纠错机制，当发生错误的时候难以弥补，但是可以在应用层来实现此种功能。&lt;/p&gt;

&lt;p&gt;　　2、多播的网络支持存在缺陷，需要路由器及网络协议栈的支持。&lt;/p&gt;

&lt;p&gt;　　3、多播的应用主要有网上视频、网上会议等。&lt;/p&gt;

&lt;p&gt;2、广域网的多播
　　多播的地址是特定的，D类地址用于多播。D类IP地址就是多播IP地址，即224.0.0.0至239.255.255.255之间的IP地址，并被划分为局部连接多播地址、预留多播地址和管理权限多播地址3类：&lt;/p&gt;

&lt;p&gt;　　1、局部多播地址：在224.0.0.0～224.0.0.255之间，这是为路由协议和其他用途保留的地址，路由器并不转发属于此范围的IP包。&lt;/p&gt;

&lt;p&gt;　　2、预留多播地址：在224.0.1.0～238.255.255.255之间，可用于全球范围（如Internet）或网络协议。&lt;/p&gt;

&lt;p&gt;　　3、管理权限多播地址：在239.0.0.0～239.255.255.255之间，可供组织内部使用，类似于私有IP地址，不能用于Internet，可限制多播范围。&lt;/p&gt;

&lt;p&gt;　　多播的程序设计使用setsockopt()函数和getsockopt()函数来实现，组播的选项是IP层的，其选项值和含义参见11.5所示。&lt;/p&gt;

&lt;p&gt;　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　表11.5 多播相关的选项&lt;/p&gt;

&lt;p&gt;getsockopt()/setsockopt()的选项&lt;/p&gt;

&lt;p&gt;含 义&lt;/p&gt;

&lt;p&gt;IP_MULTICAST_TTL&lt;/p&gt;

&lt;p&gt;设置多播组数据的TTL值&lt;/p&gt;

&lt;p&gt;IP_ADD_MEMBERSHIP&lt;/p&gt;

&lt;p&gt;在指定接口上加入组播组&lt;/p&gt;

&lt;p&gt;IP_DROP_MEMBERSHIP&lt;/p&gt;

&lt;p&gt;退出组播组&lt;/p&gt;

&lt;p&gt;IP_MULTICAST_IF&lt;/p&gt;

&lt;p&gt;获取默认接口或设置接口&lt;/p&gt;

&lt;p&gt;IP_MULTICAST_LOOP&lt;/p&gt;

&lt;p&gt;禁止组播数据回送&lt;/p&gt;

&lt;p&gt;3、多播程序设计的框架
要进行多播的编程，需要遵从一定的编程框架。多播程序框架主要包含套接字初始化、设置多播超时时间、加入多播组、发送数据、接收数据以及从多播组中离开几个方面。其步骤如下：&lt;/p&gt;

&lt;p&gt;（1）建立一个socket。&lt;/p&gt;

&lt;p&gt;（2）然后设置多播的参数，例如超时时间TTL、本地回环许可LOOP等。&lt;/p&gt;

&lt;p&gt;（3）加入多播组。&lt;/p&gt;

&lt;p&gt;（4）发送和接收数据。&lt;/p&gt;

&lt;p&gt;（5）从多播组离开&lt;/p&gt;

&lt;p&gt;三、UDP广播与单播
广播与单播的比较
　　广播和单播的处理过程是不同的，单播的数据只是收发数据的特定主机进行处理，而广播的数据整个局域网都进行处理。&lt;/p&gt;

&lt;p&gt;　　例如在一个以太网上有3个主机，主机的配置如表11.4所示。&lt;/p&gt;

&lt;p&gt;　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　表11.4 某局域网中主机的配置情况&lt;/p&gt;

&lt;p&gt;主 机&lt;/p&gt;

&lt;p&gt;A&lt;/p&gt;

&lt;p&gt;B&lt;/p&gt;

&lt;p&gt;C&lt;/p&gt;

&lt;p&gt;IP地址&lt;/p&gt;

&lt;p&gt;192.168.1.150&lt;/p&gt;

&lt;p&gt;192.168.1.151&lt;/p&gt;

&lt;p&gt;192.168.1.158&lt;/p&gt;

&lt;p&gt;MAC地址&lt;/p&gt;

&lt;p&gt;00:00:00:00:00:01&lt;/p&gt;

&lt;p&gt;00:00:00:00:00:02&lt;/p&gt;

&lt;p&gt;00:00:00:00:00:03&lt;/p&gt;

&lt;p&gt;　　单播流程：主机A向主机B发送UDP数据报，发送的目的IP为192.168.1.151，端口为 80，目的MAC地址为00:00:00:00:00:02。此数据经过UDP层、IP层，到达数据链路层，数据在整个以太网上传播，在此层中其他主机会 判断目的MAC地址。主机C的MAC地址为00:00:00:00:00:03，与目的MAC地址00:00:00:00:00:02不匹配，数据链路层 不会进行处理，直接丢弃此数据。&lt;/p&gt;

&lt;p&gt;　　主机B的MAC地址为00:00:00:00:00:02，与目的MAC地址00:00:00:00:00:02一致，此数据会经过IP层、UDP层，到达接收数据的应用程序。&lt;/p&gt;

&lt;p&gt;　　广播的流程：主机A向整个网络发送广播数据，发送的目的IP为192.168.1.255，端口为 80，目的MAC地址为FF:FF:FF:FF:FF:FF。此数据经过UDP层、IP层，到达数据链路层，数据在整个以太网上传播，在此层中其他主机会 判断目的MAC地址。由于目的MAC地址为FF:FF:FF:FF:FF:FF，主机C和主机B会忽略MAC地址的比较（当然，如果协议栈不支持广播，则 仍然比较MAC地址），处理接收到的数据。&lt;/p&gt;

&lt;p&gt;　　主机B和主机C的处理过程一致，此数据会经过IP层、UDP层，到达接收数据的应用程序&lt;/p&gt;
</description>
        <pubDate>Sat, 30 Dec 2017 00:00:00 +0800</pubDate>
        <link>https://xiazemin.github.io/MyBlog/linux/2017/12/30/broad_cast.html</link>
        <guid isPermaLink="true">https://xiazemin.github.io/MyBlog/linux/2017/12/30/broad_cast.html</guid>
        
        
        <category>linux</category>
        
      </item>
    
      <item>
        <title>arp</title>
        <description>&lt;p&gt;地址解析协议，即ARP（Address Resolution Protocol），是根据IP地址获取物理地址的一个TCP/IP协议。主机发送信息时将包含目标IP地址的ARP请求广播到网络上的所有主机，并接收返回消息，以此确定目标的物理地址；收到返回消息后将该IP地址和物理地址存入本机ARP缓存中并保留一定时间，下次请求时直接查询ARP缓存以节约资源。地址解析协议是建立在网络中各个主机互相信任的基础上的，网络上的主机可以自主发送ARP应答消息，其他主机收到应答报文时不会检测该报文的真实性就会将其记入本机ARP缓存；由此攻击者就可以向某一主机发送伪ARP应答报文，使其发送的信息无法到达预期的主机或到达错误的主机，这就构成了一个ARP欺骗。ARP命令可用于查询本机ARP缓存中IP地址和MAC地址的对应关系、添加或删除静态对应关系等。相关协议有RARP、代理ARP。NDP用于在IPv6中代替地址解析协议。
&lt;!-- more --&gt;
工作过程
主机A的IP地址为192.168.1.1，MAC地址为0A-11-22-33-44-01；
主机B的IP地址为192.168.1.2，MAC地址为0A-11-22-33-44-02；
当主机A要与主机B通信时，地址解析协议可以将主机B的IP地址（192.168.1.2）解析成主机B的MAC地址，以下为工作流程：
第1步：根据主机A上的路由表内容，IP确定用于访问主机B的转发IP地址是192.168.1.2。然后A主机在自己的本地ARP缓存中检查主机B的匹配MAC地址。
第2步：如果主机A在ARP缓存中没有找到映射，它将询问192.168.1.2的硬件地址，从而将ARP请求帧广播到本地网络上的所有主机。源主机A的IP地址和MAC地址都包括在ARP请求中。本地网络上的每台主机都接收到ARP请求并且检查是否与自己的IP地址匹配。如果主机发现请求的IP地址与自己的IP地址不匹配，它将丢弃ARP请求。
第3步：主机B确定ARP请求中的IP地址与自己的IP地址匹配，则将主机A的IP地址和MAC地址映射添加到本地ARP缓存中。
第4步：主机B将包含其MAC地址的ARP回复消息直接发送回主机A。
第5步：当主机A收到从主机B发来的ARP回复消息时，会用主机B的IP和MAC地址映射更新ARP缓存。本机缓存是有生存期的，生存期结束后，将再次重复上面的过程。主机B的MAC地址一旦确定，主机A就能向主机B发送IP通信了。
ARP缓存是个用来储存IP地址和MAC地址的缓冲区，其本质就是一个IP地址–&amp;gt;MAC地址的对应表，表中每一个条目分别记录了网络上其他主机的IP地址和对应的MAC地址。每一个以太网或令牌环网络适配器都有自己单独的表。当地址解析协议被询问一个已知IP地址节点的MAC地址时，先在ARP缓存中查看，若存在，就直接返回与之对应的MAC地址，若不存在，才发送ARP请求向局域网查询。
为使广播量最小，ARP维护IP地址到MAC地址映射的缓存以便将来使用。ARP缓存可以包含动态和静态项目。动态项目随时间推移自动添加和删除。每个动态ARP缓存项的潜在生命周期是10分钟。新加到缓存中的项目带有时间戳，如果某个项目添加后2分钟内没有再使用，则此项目过期并从ARP缓存中删除；如果某个项目已在使用，则又收到2分钟的生命周期；如果某个项目始终在使用，则会另外收到2分钟的生命周期，一直到10分钟的最长生命周期。静态项目一直保留在缓存中，直到重新启动计算机为止。&lt;/p&gt;

&lt;p&gt;ARP命令
ARP命令
ARP命令
ARP缓存中包含一个或多个表，它们用于存储IP地址及其经过解析的MAC地址。ARP命令用于查询本机ARP缓存中IP地址–&amp;gt;MAC地址的对应关系、添加或删除静态对应关系等。如果在没有参数的情况下使用，ARP命令将显示帮助信息。
常见用法
arp -a或arp –g
用于查看缓存中的所有项目。-a和-g参数的结果是一样的，多年来-g一直是UNIX平台上用来显示ARP缓存中所有项目的选项，而Windows用的是arp -a（-a可被视为all，即全部的意思），但它也可以接受比较传统的-g选项。
arp -a Ip
如果有多个网卡，那么使用arp -a加上接口的IP地址，就可以只显示与该接口相关的ARP缓存项目。
arp -s Ip 物理地址
可以向ARP缓存中人工输入一个静态项目。该项目在计算机引导过程中将保持有效状态，或者在出现错误时，人工配置的物理地址将自动更新该项目。
arp -d Ip
使用该命令能够人工删除一个静态项目。&lt;/p&gt;

&lt;p&gt;地址解析协议工作在一个网段中，而代理ARP（Proxy ARP，也被称作混杂ARP（Promiscuous ARP）[9-10]  ）工作在不同的网段间，其一般被像路由器这样的设备使用，用来代替处于另一个网段的主机回答本网段主机的ARP请求。
例如，主机PC1（192.168.20.66/24）需要向主机PC2（192.168.20.20/24）发送报文，因为主机PC1不知道子网的存在且和目标主机PC2在同一主网络网段，所以主机PC1将发送ARP协议请求广播报文请求192.168.20.20的MAC地址。这时，路由器将识别出报文的目标地址属于另一个子网（注意，路由器的接口IP地址配置的是28位的掩码），因此向请求主机回复自己的硬件地址（0004.dd9e.cca0）。之后，PC1将发往PC2的数据包都发往MAC地址0004.dd9e.cca0（路由器的接口E0/0），由路由器将数据包转发到目标主机PC2。（接下来路由器将为PC2做同样的代理发送数据包的工作）。代理ARP协议使得子网化网络拓扑对于主机来说时透明的（或者可以说是路由器以一个不真实的PC2的MAC地址欺骗了源主机PC1）。[11] 
NDP
地址解析协议是IPv4中必不可少的协议，但在IPv6中将不再存在地址解析协议。在IPv6中，地址解析协议的功能将由NDP（邻居发现协议，Neighbor Discovery Protocol）实现，它使用一系列IPv6控制信息报文（ICMPv6）来实现相邻节点（同一链路上的节点）的交互管理，并在一个子网中保持网络层地址和数据链路层地址之间的映射。邻居发现协议中定义了5种类型的信息：路由器宣告、路由器请求、路由重定向、邻居请求和邻居宣告。与ARP相比，NDP可以实现路由器发现、前缀发现、参数发现、地址自动配置、地址解析（代替ARP和RARP）、下一跳确定、邻居不可达检测、重复地址检测、重定向等更多功能。
NDP与ARP的区别
IPv4中地址解析协议是独立的协议，负责IP地址到MAC地址的转换，对不同的数据链路层协议要定义不同的地址解析协议。IPv6中NDP包含了ARP的功能，且运行于因特网控制信息协议ICMPv6上，更具有一般性，包括更多的内容，而且适用于各种数据链路层协议；
地址解析协议以及ICMPv4路由器发现和ICMPv4重定向报文基于广播，而NDP的邻居发现报文基于高效的组播和单播。&lt;/p&gt;

&lt;p&gt;ARP攻击就是通过伪造IP地址和MAC地址实现ARP欺骗，能够在网络中产生大量的ARP通信量使网络阻塞，攻击者只要持续不断的发出伪造的ARP响应包就能更改目标主机ARP缓存中的IP-MAC条目，造成网络中断或中间人攻击。
ARP攻击主要是存在于局域网网络中，局域网中若有一台计算机感染ARP木马，则感染该ARP木马的系统将会试图通过“ARP欺骗”手段截获所在网络内其它计算机的通信信息，并因此造成网内其它计算机的通信故障。
攻击者向电脑A发送一个伪造的ARP响应，告诉电脑A：电脑B的IP地址192.168.0.2对应的MAC地址是00-aa-00-62-c6-03，电脑A信以为真，将这个对应关系写入自己的ARP缓存表中，以后发送数据时，将本应该发往电脑B的数据发送给了攻击者。同样的，攻击者向电脑B也发送一个伪造的ARP响应，告诉电脑B：电脑A的IP地址192.168.0.1对应的MAC地址是00-aa-00-62-c6-03，电脑B也会将数据发送给攻击者。
至此攻击者就控制了电脑A和电脑B之间的流量，他可以选择被动地监测流量，获取密码和其他涉密信息，也可以伪造数据，改变电脑A和电脑B之间的通信内容。
为了解决ARP攻击问题，可以在网络中的交换机上配置802.1x协议。
IEEE 802.1x是基于端口的访问控制协议，它对连接到交换机的用户进行认证和授权。在交换机上配置802.1x协议后，攻击者在连接交换机时需要进行身份认证（结合MAC、端口、帐户、VLAN和密码等），只有通过认证后才能向网络发送数据。攻击者未通过认证就不能向网络发送伪造的ARP报文。
arp命令网络测试
arp命令用于操作主机的arp缓冲区，它可以显示arp缓冲区中的所有条目、删除指定的条目或者添加静态的ip地址与MAC地址对应关系。&lt;/p&gt;

&lt;p&gt;语法
arp(选项)(参数)
选项
-a&lt;主机&gt;：显示arp缓冲区的所有条目；
-H&lt;地址类型&gt;：指定arp指令使用的地址类型；
-d&lt;主机&gt;：从arp缓冲区中删除指定主机的arp条目；
-D：使用指定接口的硬件地址；
-e：以Linux的显示风格显示arp缓冲区中的条目；
-i&lt;接口&gt;：指定要操作arp缓冲区的网络接口；
-s&lt;主机&gt;&lt;MAC地址&gt;：设置指定的主机的IP地址与MAC地址的静态映射；
-n：以数字方式显示arp缓冲区中的条目；
-v：显示详细的arp缓冲区条目，包括缓冲区条目的统计信息；
-f&lt;文件&gt;：设置主机的IP地址与MAC地址的静态映射。&lt;/文件&gt;&lt;/MAC地址&gt;&lt;/主机&gt;&lt;/接口&gt;&lt;/主机&gt;&lt;/地址类型&gt;&lt;/主机&gt;&lt;/p&gt;
</description>
        <pubDate>Sat, 30 Dec 2017 00:00:00 +0800</pubDate>
        <link>https://xiazemin.github.io/MyBlog/linux/2017/12/30/arp.html</link>
        <guid isPermaLink="true">https://xiazemin.github.io/MyBlog/linux/2017/12/30/arp.html</guid>
        
        
        <category>linux</category>
        
      </item>
    
      <item>
        <title>json_shell</title>
        <description>&lt;!-- more --&gt;
&lt;p&gt;解析简单json&lt;/p&gt;

&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-shell&quot; data-lang=&quot;shell&quot;&gt;&lt;span&gt;&lt;/span&gt;&lt;span class=&quot;lineno&quot;&gt;1 &lt;/span&gt; &lt;span class=&quot;c1&quot;&gt;#!/bin/bash&lt;/span&gt;
&lt;span class=&quot;lineno&quot;&gt;2 &lt;/span&gt;&lt;span class=&quot;nv&quot;&gt;s&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&amp;quot;{\&amp;quot;rv\&amp;quot;:0,\&amp;quot;flag\&amp;quot;:1,\&amp;quot;url\&amp;quot;:\&amp;quot;http://www.jinhill.com\&amp;quot;,\&amp;quot;msg\&amp;quot;:\&amp;quot;test\&amp;quot;}&amp;quot;&lt;/span&gt;
&lt;span class=&quot;lineno&quot;&gt;3 &lt;/span&gt;parse_json&lt;span class=&quot;o&quot;&gt;(){&lt;/span&gt;
&lt;span class=&quot;lineno&quot;&gt;4 &lt;/span&gt; &lt;span class=&quot;c1&quot;&gt;#echo &amp;quot;$1&amp;quot; | sed &amp;quot;s/.*\&amp;quot;$2\&amp;quot;:\([^,}]*\).*/\1/&amp;quot;&lt;/span&gt;
&lt;span class=&quot;lineno&quot;&gt;5 &lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;echo&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;&amp;quot;&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;${&lt;/span&gt;&lt;span class=&quot;nv&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;//&lt;/span&gt;&lt;span class=&quot;se&quot;&gt;\&amp;quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;/&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&amp;quot;&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;|&lt;/span&gt; sed &lt;span class=&quot;s2&quot;&gt;&amp;quot;s/.*&lt;/span&gt;&lt;span class=&quot;nv&quot;&gt;$2&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;:\([^,}]*\).*/\1/&amp;quot;&lt;/span&gt;
&lt;span class=&quot;lineno&quot;&gt;6 &lt;/span&gt;&lt;span class=&quot;o&quot;&gt;}&lt;/span&gt;
&lt;span class=&quot;lineno&quot;&gt;7 &lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;echo&lt;/span&gt; &lt;span class=&quot;nv&quot;&gt;$s&lt;/span&gt;
&lt;span class=&quot;lineno&quot;&gt;8 &lt;/span&gt;&lt;span class=&quot;nv&quot;&gt;value&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;$(&lt;/span&gt;parse_json &lt;span class=&quot;nv&quot;&gt;$s&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;&amp;quot;url&amp;quot;&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;lineno&quot;&gt;9 &lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;echo&lt;/span&gt; &lt;span class=&quot;nv&quot;&gt;$value&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;

&lt;p&gt;解析URL Query&lt;/p&gt;

&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-shell&quot; data-lang=&quot;shell&quot;&gt;&lt;span&gt;&lt;/span&gt;&lt;span class=&quot;lineno&quot;&gt;1 &lt;/span&gt; &lt;span class=&quot;c1&quot;&gt;#!/bin/bash&lt;/span&gt;
&lt;span class=&quot;lineno&quot;&gt;2 &lt;/span&gt;&lt;span class=&quot;nv&quot;&gt;s&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&amp;quot;http://www.zonetec.cn/WlanAuth/portal.do?appid=aaaa&amp;amp;apidx=0&amp;quot;&lt;/span&gt;
&lt;span class=&quot;lineno&quot;&gt;3 &lt;/span&gt;parse&lt;span class=&quot;o&quot;&gt;(){&lt;/span&gt;
&lt;span class=&quot;lineno&quot;&gt;4 &lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;echo&lt;/span&gt; &lt;span class=&quot;nv&quot;&gt;$1&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;|&lt;/span&gt; sed &lt;span class=&quot;s1&quot;&gt;&amp;#39;s/.*&amp;#39;&lt;/span&gt;&lt;span class=&quot;nv&quot;&gt;$2&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;&amp;#39;=\([[:alnum:]]*\).*/\1/&amp;#39;&lt;/span&gt;
&lt;span class=&quot;lineno&quot;&gt;5 &lt;/span&gt;&lt;span class=&quot;o&quot;&gt;}&lt;/span&gt;
&lt;span class=&quot;lineno&quot;&gt;6 &lt;/span&gt;&lt;span class=&quot;nv&quot;&gt;value&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;$(&lt;/span&gt;parse &lt;span class=&quot;nv&quot;&gt;$s&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;&amp;quot;appid&amp;quot;&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;lineno&quot;&gt;7 &lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;echo&lt;/span&gt; &lt;span class=&quot;nv&quot;&gt;$value&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;

</description>
        <pubDate>Wed, 27 Dec 2017 00:00:00 +0800</pubDate>
        <link>https://xiazemin.github.io/MyBlog/web/2017/12/27/json_shell.html</link>
        <guid isPermaLink="true">https://xiazemin.github.io/MyBlog/web/2017/12/27/json_shell.html</guid>
        
        
        <category>web</category>
        
      </item>
    
      <item>
        <title>ioctl</title>
        <description>&lt;!-- more --&gt;
&lt;p&gt;ioctl函数详细说明（网络）
ioctl 函数
本函数影响由fd 参数引用的一个打开的文件。
 #include&lt;unistd.h&gt;&lt;/unistd.h&gt;&lt;/p&gt;

&lt;p&gt;int ioctl( int fd, int request, …/* void *arg */ );&lt;/p&gt;

&lt;p&gt;返回0 ：成功    -1 ：出错&lt;/p&gt;

&lt;p&gt;第三个参数总是一个指针，但指针的类型依赖于request 参数。&lt;/p&gt;

&lt;p&gt;我们可以把和网络相关的请求划分为6 类：&lt;/p&gt;

&lt;p&gt;套接口操作&lt;/p&gt;

&lt;p&gt;文件操作&lt;/p&gt;

&lt;p&gt;接口操作&lt;/p&gt;

&lt;p&gt;ARP 高速缓存操作&lt;/p&gt;

&lt;p&gt;路由表操作&lt;/p&gt;

&lt;p&gt;流系统&lt;/p&gt;

&lt;p&gt;下表列出了网络相关ioctl 请求的request 参数以及arg 地址必须指向的数据类型：&lt;/p&gt;

&lt;p&gt;类别&lt;/p&gt;

&lt;p&gt;Request&lt;/p&gt;

&lt;p&gt;说明&lt;/p&gt;

&lt;p&gt;数据类型&lt;/p&gt;

&lt;p&gt;套&lt;/p&gt;

&lt;p&gt;接&lt;/p&gt;

&lt;p&gt;口&lt;/p&gt;

&lt;p&gt;SIOCATMARK&lt;/p&gt;

&lt;p&gt;SIOCSPGRP&lt;/p&gt;

&lt;p&gt;SIOCGPGRP&lt;/p&gt;

&lt;p&gt;是否位于带外标记&lt;/p&gt;

&lt;p&gt;设置套接口的进程ID 或进程组ID&lt;/p&gt;

&lt;p&gt;获取套接口的进程ID 或进程组ID&lt;/p&gt;

&lt;p&gt;int&lt;/p&gt;

&lt;p&gt;int&lt;/p&gt;

&lt;p&gt;int&lt;/p&gt;

&lt;p&gt;文&lt;/p&gt;

&lt;p&gt;件&lt;/p&gt;

&lt;p&gt;FIONBIN&lt;/p&gt;

&lt;p&gt;FIOASYNC&lt;/p&gt;

&lt;p&gt;FIONREAD&lt;/p&gt;

&lt;p&gt;FIOSETOWN&lt;/p&gt;

&lt;p&gt;FIOGETOWN&lt;/p&gt;

&lt;p&gt;设置/ 清除非阻塞I/O 标志&lt;/p&gt;

&lt;p&gt;设置/ 清除信号驱动异步I/O 标志&lt;/p&gt;

&lt;p&gt;获取接收缓存区中的字节数&lt;/p&gt;

&lt;p&gt;设置文件的进程ID 或进程组ID&lt;/p&gt;

&lt;p&gt;获取文件的进程ID 或进程组ID&lt;/p&gt;

&lt;p&gt;int&lt;/p&gt;

&lt;p&gt;int&lt;/p&gt;

&lt;p&gt;int&lt;/p&gt;

&lt;p&gt;int&lt;/p&gt;

&lt;p&gt;int&lt;/p&gt;

&lt;p&gt;接&lt;/p&gt;

&lt;p&gt;口&lt;/p&gt;

&lt;p&gt;SIOCGIFCONF&lt;/p&gt;

&lt;p&gt;SIOCSIFADDR&lt;/p&gt;

&lt;p&gt;SIOCGIFADDR&lt;/p&gt;

&lt;p&gt;SIOCSIFFLAGS&lt;/p&gt;

&lt;p&gt;SIOCGIFFLAGS&lt;/p&gt;

&lt;p&gt;SIOCSIFDSTADDR&lt;/p&gt;

&lt;p&gt;SIOCGIFDSTADDR&lt;/p&gt;

&lt;p&gt;SIOCGIFBRDADDR&lt;/p&gt;

&lt;p&gt;SIOCSIFBRDADDR&lt;/p&gt;

&lt;p&gt;SIOCGIFNETMASK&lt;/p&gt;

&lt;p&gt;SIOCSIFNETMASK&lt;/p&gt;

&lt;p&gt;SIOCGIFMETRIC&lt;/p&gt;

&lt;p&gt;SIOCSIFMETRIC&lt;/p&gt;

&lt;p&gt;SIOCGIFMTU&lt;/p&gt;

&lt;p&gt;SIOCxxx&lt;/p&gt;

&lt;p&gt;获取所有接口的清单&lt;/p&gt;

&lt;p&gt;设置接口地址&lt;/p&gt;

&lt;p&gt;获取接口地址&lt;/p&gt;

&lt;p&gt;设置接口标志&lt;/p&gt;

&lt;p&gt;获取接口标志&lt;/p&gt;

&lt;p&gt;设置点到点地址&lt;/p&gt;

&lt;p&gt;获取点到点地址&lt;/p&gt;

&lt;p&gt;获取广播地址&lt;/p&gt;

&lt;p&gt;设置广播地址&lt;/p&gt;

&lt;p&gt;获取子网掩码&lt;/p&gt;

&lt;p&gt;设置子网掩码&lt;/p&gt;

&lt;p&gt;获取接口的测度&lt;/p&gt;

&lt;p&gt;设置接口的测度&lt;/p&gt;

&lt;p&gt;获取接口MTU&lt;/p&gt;

&lt;p&gt;（还有很多取决于系统的实现）&lt;/p&gt;

&lt;p&gt;struct ifconf&lt;/p&gt;

&lt;p&gt;struct ifreq&lt;/p&gt;

&lt;p&gt;struct ifreq&lt;/p&gt;

&lt;p&gt;struct ifreq&lt;/p&gt;

&lt;p&gt;struct ifreq&lt;/p&gt;

&lt;p&gt;struct ifreq&lt;/p&gt;

&lt;p&gt;struct ifreq&lt;/p&gt;

&lt;p&gt;struct ifreq&lt;/p&gt;

&lt;p&gt;struct ifreq&lt;/p&gt;

&lt;p&gt;struct ifreq&lt;/p&gt;

&lt;p&gt;struct ifreq&lt;/p&gt;

&lt;p&gt;struct ifreq&lt;/p&gt;

&lt;p&gt;struct ifreq&lt;/p&gt;

&lt;p&gt;struct ifreq&lt;/p&gt;

&lt;p&gt;ARP&lt;/p&gt;

&lt;p&gt;SIOCSARP&lt;/p&gt;

&lt;p&gt;SIOCGARP&lt;/p&gt;

&lt;p&gt;SIOCDARP&lt;/p&gt;

&lt;p&gt;创建/ 修改ARP 表项&lt;/p&gt;

&lt;p&gt;获取ARP 表项&lt;/p&gt;

&lt;p&gt;删除ARP 表项&lt;/p&gt;

&lt;p&gt;struct arpreq&lt;/p&gt;

&lt;p&gt;struct arpreq&lt;/p&gt;

&lt;p&gt;struct arpreq&lt;/p&gt;

&lt;p&gt;路&lt;/p&gt;

&lt;p&gt;由&lt;/p&gt;

&lt;p&gt;SIOCADDRT&lt;/p&gt;

&lt;p&gt;SIOCDELRT&lt;/p&gt;

&lt;p&gt;增加路径&lt;/p&gt;

&lt;p&gt;删除路径&lt;/p&gt;

&lt;p&gt;struct rtentry&lt;/p&gt;

&lt;p&gt;struct rtentry&lt;/p&gt;

&lt;p&gt;流&lt;/p&gt;

&lt;p&gt;I_xxx&lt;/p&gt;

&lt;p&gt;套接口操作：&lt;/p&gt;

&lt;p&gt;明确用于套接口操作的ioctl 请求有三个, 它们都要求ioctl 的第三个参数是指向某个整数的一个指针。&lt;/p&gt;

&lt;p&gt;SIOCATMARK:    如果本套接口的的度指针当前位于带外标记，那就通过由第三个参数指向的整数返回一个非0 值；否则返回一个0 值。POSIX 以函数sockatmark 替换本请求。&lt;/p&gt;

&lt;p&gt;SIOCGPGRP ：       通过第三个参数指向的整数返回本套接口的进程ID 或进程组ID ，该ID 指定针对本套接口的SIGIO 或SIGURG 信号的接收进程。本请求和fcntl 的F_GETOWN 命令等效，POSIX 标准化的是fcntl 函数。&lt;/p&gt;

&lt;p&gt;SIOCSPGRP ：     把本套接口的进程ID 或者进程组ID 设置成第三个参数指向的整数，该ID 指定针对本套接口的SIGIO 或SIGURG 信号的接收进程，本请求和fcntl 的F_SETOWN 命令等效，POSIX 标准化的是fcntl 操作。&lt;/p&gt;

&lt;p&gt;文件操作：&lt;/p&gt;

&lt;p&gt;以下5 个请求都要求ioctl 的第三个参数指向一个整数。&lt;/p&gt;

&lt;p&gt;FIONBIO ：        根据ioctl 的第三个参数指向一个0 或非0 值分别清除或设置本套接口的非阻塞标志。本请求和O_NONBLOCK 文件状态标志等效，而该标志通过fcntl 的F_SETFL 命令清除或设置。&lt;/p&gt;

&lt;p&gt;FIOASYNC ：      根据iocl 的第三个参数指向一个0 值或非0 值分别清除或设置针对本套接口的信号驱动异步I/O 标志，它决定是否收取针对本套接口的异步I/O 信号（SIGIO ）。本请求和O_ASYNC 文件状态标志等效，而该标志可以通过fcntl 的F_SETFL 命令清除或设置。&lt;/p&gt;

&lt;p&gt;FIONREAD ：     通过由ioctl 的第三个参数指向的整数返回当前在本套接口接收缓冲区中的字节数。本特性同样适用于文件，管道和终端。&lt;/p&gt;

&lt;p&gt;FIOSETOWN ：    对于套接口和SIOCSPGRP 等效。&lt;/p&gt;

&lt;p&gt;FIOGETOWN ：    对于套接口和SIOCGPGRP 等效。&lt;/p&gt;

&lt;p&gt;接口配置：&lt;/p&gt;

&lt;p&gt;得到系统中所有接口由SIOCGIFCONF 请求完成，该请求使用ifconf 结构，ifconf 又使用ifreq&lt;/p&gt;

&lt;p&gt;结构，如下所示：&lt;/p&gt;

&lt;p&gt;Struct ifconf{&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;int ifc_len;                 // 缓冲区的大小

union{

    caddr_t ifcu_buf;        // input from user-&amp;gt;kernel

    struct ifreq *ifcu_req;    // return of structures returned

}ifc_ifcu;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;};&lt;/p&gt;

&lt;p&gt;#define  ifc_buf  ifc_ifcu.ifcu_buf    //buffer address&lt;/p&gt;

&lt;p&gt;#define  ifc_req  ifc_ifcu.ifcu_req    //array of structures returned
 #define  IFNAMSIZ  16
struct ifreq{&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;char ifr_name[IFNAMSIZ];           // interface name, e.g., “le0”

union{

    struct sockaddr ifru_addr;

    struct sockaddr ifru_dstaddr;

    struct sockaddr ifru_broadaddr;

    short ifru_flags;

    int ifru_metric;

    caddr_t ifru_data;

}ifr_ifru;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;};&lt;/p&gt;

&lt;p&gt;#define ifr_addr     ifr_ifru.ifru_addr            // address
 #define ifr_dstaddr   ifr_ifru.ifru_dstaddr         // otner end of p-to-p link&lt;/p&gt;

&lt;p&gt;#define ifr_broadaddr ifr_ifru.ifru_broadaddr    // broadcast address&lt;/p&gt;

&lt;p&gt;#define ifr_flags     ifr_ifru.ifru_flags        // flags&lt;/p&gt;

&lt;p&gt;#define ifr_metric    ifr_ifru.ifru_metric      // metric&lt;/p&gt;

&lt;p&gt;#define ifr_data      ifr_ifru.ifru_data        // for use by interface&lt;/p&gt;

&lt;p&gt;再调用ioctl 前我们必须先分撇一个缓冲区和一个ifconf 结构，然后才初始化后者。如下图&lt;/p&gt;

&lt;p&gt;展示了一个ifconf 结构的初始化结构，其中缓冲区的大小为1024 ，ioctl 的第三个参数指向&lt;/p&gt;

&lt;p&gt;这样一个ifconf 结构。&lt;/p&gt;

&lt;p&gt;ifc_len&lt;/p&gt;

&lt;p&gt;Ifc_buf&lt;/p&gt;

&lt;p&gt;1024&lt;/p&gt;

&lt;p&gt;———————&amp;gt; 缓存&lt;/p&gt;

&lt;p&gt;假设内核返回2 个ifreq 结构，ioctl 返回时通过同一个ifconf 结构缓冲区填入了那2 个ifreq 结构，ifconf 结构的ifc_len 成员也被更新，以反映存放在缓冲区中的信息量&lt;/p&gt;

&lt;p&gt;一般来讲ioctl在用户程序中的调用是：
ioctl(int fd,int command, (char*)argstruct)
ioctl调用与网络编程有关（本文只讨论这一点），文件描述符fd实际上是由socket()系统调用返回的。参数command的取值由/usr/include/linux/sockios.h 所规定。这些command的由于功能的不同，可分为以下几个小类：
• 改变路由表 (例如 SIOCADDRT, SIOCDELRT), 
• 读/更新 ARP/RARP 缓存(如：SIOCDARP, SIOCSRARP), 
• 一般的与网络接口有关的(例如 SIOCGIFNAME, SIOCSIFADDR 等等) 
在 Gooodies目录下有很多样例程序展示了如何使用ioctl。当你看这些程序时，注意参数argstruct是与参数command相关的。例如，与 路由表相关的ioctl使用rtentry这种结构，rtentry定义在/usr/include/linux/route.h（参见例子 adddefault.c）。与ARP有关的ioctl调用使用arpreq结构，arpreq定义在/usr/include/linux /if_arp.h（参见例子arpread.c）
与网络接口有关的ioctl调用使用的command参数通常看起来像SIOCxIFyyyy的形式，这里x要 么是S（设定set，写write），要么是G（得到get，读read）。在getifinfo.c程序中就使用了这种形式的command参数来读 IP地址，硬件地址，广播地址和得到与网络接口有关的一些标志（flag）。在这些ioctl调用中，第三个参数是ifreq结构，它在/usr /include/linux/if.h中定义。在某些情况下， ioctrl调用可能会使用到在sockios.h之外的新的定义。&lt;/p&gt;
</description>
        <pubDate>Wed, 27 Dec 2017 00:00:00 +0800</pubDate>
        <link>https://xiazemin.github.io/MyBlog/linux/2017/12/27/ioctl.html</link>
        <guid isPermaLink="true">https://xiazemin.github.io/MyBlog/linux/2017/12/27/ioctl.html</guid>
        
        
        <category>linux</category>
        
      </item>
    
      <item>
        <title>inetd</title>
        <description>&lt;p&gt;inetd是监视一些网络请求的守护进程，其根据网络请求来调用相应的服务进程来处理连接请求。它可以为多种服务管理连接，当 inetd 接到连接时，它能够确定连接所需的程序，启动相应的进程，并把 socket 交给它 （服务 socket 会作为程序的标准输入、 输出和错误输出描述符）。 使用 inetd 来运行那些负载不重的服务有助于降低系统负载，因为它不需要为每个服务都启动独立的服务程序。
&lt;!-- more --&gt;
inetd是通过rc系统启动的。inetd_enable选项默认设为NO，但可以在安装系统时，由用户根据需要sysinstall通过来打开。
inetd.conf则是inetd的配置文件。inetd.conf文件告诉inetd监听哪些网络端口，为每个端口启动哪个服务。在任何的网络环境中使用Linux系统，第一件要做的事就是了解一下服务器到底要提供哪些服务。不需要的那些服务应该被禁止掉，最好卸载掉，这样黑客就少了一些攻击系统的机会。查看“/etc/inetd.conf”文件，了解一下inetd提供哪些服务。用加上注释的方法（在一行的开头加上#号），禁止任何不需要的服务，再给inetd进程发一个SIGHUP信号。&lt;/p&gt;

&lt;p&gt;从理论上说，UNIX® 是内核，或者说低层软件，它控制对文件系统、内存和处理器等计算机资源的访问。但是，用更通俗的话来说，UNIX 是指在操作系统上运行的一整套软件。实际上，通常说的 “它是一台 UNIX 机器” 是指系统的基础功能：UNIX 机器通常提供 shell 界面、并行访问、强大的安全性和各种连网的服务。
实际上，UNIX（内核等）被选用的原因通常是它的连网应用。FTP、POP、SMTP 和 HTTP 最初都是在 UNIX 上实现的，而且一直在 UNIX 上使用。UNIX 系统还通过运行服务（常常称为守护进程 ）实现各种功能，包括与中心时钟执行同步（网络时间协议）、交换新闻（网络新闻传输协议）、把主机名解析为 IP 地址（DNS）等。在大多数 UNIX 机器上的 /etc/services 中可以找到常用的一部分服务。这个文件与 清单 1 相似。&lt;/p&gt;

&lt;p&gt;清单 1. /etc/services（UNIX 网络服务目录）中常见的条目
ftp             21/tcp
fsp             21/udp          fspd
ssh             22/tcp                       &lt;br /&gt;
ssh             22/udp
telnet          23/tcp
smtp            25/tcp          mail
/etc/services 中的每个条目列出服务的名称；服务使用的端口号和协议（TCP 或 UDP）；服务的别名（可能没有，也可能有多个别名）。每个系统守护进程都通过检查 /etc/services 寻找它提供服务时要使用的端口和协议。&lt;/p&gt;

&lt;p&gt;例如，处理入站电子邮件的守护进程会寻找 “smtp”（服务名称）或 “mail”（别名之一），在端口 25 上监听到达的 TCP 连接。类似地，远程登录守护进程在文件中搜索 “ssh”，在端口 22 上监听到达的 TCP 连接。&lt;/p&gt;

&lt;p&gt;小公司的服务器可能运行多个服务，分别负责与世界时钟同步、提供 Web 页面、传输电子邮件、支持远程 shell 访问、打印页面、传输文件、连接数据库、监视系统的稳定性、提供域名以及通过 NFS 共享文件。这种配置并不少见，这主要是因为守护进程的开销不大。守护进程通常设计为在空闲时休眠，等待请求。当服务请求出现时，守护进程醒来，响应并处理请求，然后继续休眠。&lt;/p&gt;

&lt;p&gt;尽管如此，大量休眠的进程仍然会影响系统性能。因此，如果预期会经常请求某一服务，比如有稳定的 Web 访问请求，那么有必要具有一个长期运行的守护进程。否则，最好把守护进程重新配置为根据需要执行。&lt;/p&gt;

&lt;p&gt;但是，系统如何提供随时可用的服务并在需要的时候启动？解决方案是使用代理服务，它预测到达的各种请求，根据后续处理的需要启动适当的服务。在 UNIX 和 Linux® 系统上，这个代理称为 inetd。
给定一个服务列表，inetd 会监视对这些服务的端口和协议的请求。当发生活动时，inetd 把入站请求映射到标准输入 (stdin)、标准输出 (stdout) 和标准错误 (stderr)，并启动适当的守护进程。服务处理数据并终止。inetd 把资源消耗保持在最低水平，并且让守护进程更容易编写。&lt;/p&gt;

&lt;p&gt;inetd 监听许多端口并在接收到请求时启动服务。服务处理请求并退出。有一些服务例外。例如，传输电子邮件的 SMTP 服务器通常独立地运行。&lt;/p&gt;

&lt;p&gt;根据它的作用，inetd 常常被称为 “超级服务员”。在近几年，inetd 已经被它的变体 xinetd 替代了。这两个软件的用途是相同的，但是后者更安全并提供许多特性，可以在系统负载过重时限制访问。inetd 和 xinetd 的配置相似，但是不完全相同。系统可以运行 inetd 或 xinetd，但是不能同时运行两者。因为后者更安全，它是首选的，所以本文后面一直使用它。&lt;/p&gt;

&lt;p&gt;xinetd 是开放源码的，很容易构建在 UNIX 以及 OpenBSD 和 Linux 等变体上。到 2009 年 10 月底，xinetd 的最新版本是 2.3.14，可以从 xinetd 主页获取它（参见 参考资料）。下载 xinetd 的源代码之后，解压压缩文件，运行配置脚本）并构建软件。在安装 xinetd 之前，一定要备份 inetd 配置（如果有的话），然后禁用和/或删除 inetd。禁用 inetd 的步骤取决于使用的 UNIX 变体；参见系统的 inetd 手册页。执行这个修改很可能需要超级用户访问权。&lt;/p&gt;

&lt;p&gt;无论如何安装和启用 xinetd，如果以前运行过 inetd，就必须把 inetd 配置文件 inetd.conf 转换为与 xinetd 兼容的文件。可以手工地执行转换，也可以使用 xinetd 提供的转换脚本替您修改文件：&lt;/p&gt;

&lt;p&gt;1
2
$ xconv.pl &amp;lt; /etc/inetd.conf &amp;gt; /etc/xinetd.conf
$ mv /etc/inetd.conf /etc/inetd.conf.sav
Xconv.pl 是 xinetd 提供的 Perl 脚本。后一个步骤（把 inetd 配置文件转移到标准位置之外）只是一项预防措施。&lt;/p&gt;

&lt;p&gt;可以完全在 /etc/xinetd.conf 中配置 xinetd。但是，按照惯例，通常在这个文件中提供默认设置，并在特殊目录 /etc/xinetd.d 中包含多个配置文件 — 每个服务一个文件。例如，下面是 Ubuntu 上安装的 xinetd 配置文件：&lt;/p&gt;

&lt;p&gt;1
2
3
4
5
6
defaults
{
    log_type = SYSLOG daemon info
}&lt;/p&gt;

&lt;p&gt;includedir /etc/xinetd.d
defaults 提供 xinetd 控制的所有 服务的值。服务可以覆盖这些全局默认值。在这里，log_type 的默认值指定每个守护进程应该把日志条目发送到哪里（如果启用日志的话）。SYSLOG 选项把输出发送到 syslog（中心系统日志）。info 要求只记录信息性消息。其他值包括 emerg、alert、crit、err、warning、notice 和 debug。第一个值 emerg 从 xinetd 生成最少的输出；最后一个值 debug 提供最详细的输出。如果在从 xinetd 启动某个服务时遇到了问题，可以启用更详细的日志选项以帮助判断问题的原因。&lt;/p&gt;

&lt;p&gt;/etc/xinetd.d 中的文件采用与 xinetd.conf 相同的格式。其中有一个操作，包含零个、一个或更多操作数，还有一组放在大括号 ({}) 中的变量和值。例如，清单 3 是 /etc/xinetd.d/imap，这是用于 IMAP 服务的条目。（IMAP 是用于读取和管理电子邮件的邮箱协议。它与 POP 相比有一个重要的优点：IMAP 邮箱可以跨任意数量的系统保持同步。）&lt;/p&gt;

&lt;p&gt;虽然有一些小差异，但是这个片段看起来应该很熟悉。这个脚本作为用户 martin 运行，因为它不需要特殊的特权。一般来说，应该提供尽可能少的特权 — 不仅是在这里，在授予对任何系统资源的访问权时都应该这样。对于 TCP 协议服务，必须设置 wait=no。server 指向要运行的脚本或可执行程序，log_type 指定更高的日志记录级别，这有助于解决服务中的任何问题。&lt;/p&gt;

&lt;p&gt;重新启动 xinetd，或者向它的进程发送一个重新设置信号。要想重新启动 xinetd，应该在 /etc/init.d 或系统保存启动脚本的地方寻找控制脚本。运行下面这样的命令：&lt;/p&gt;

&lt;p&gt;$ sudo /etc/init.d/xinetd restart
另一种方法是向 xinetd 守护进程发送重新设置信号。信号 SIGHUP 让 xinetd 重新读取它的配置，并且根据新的参数，可能会关闭连接。使用的命令是：&lt;/p&gt;

&lt;p&gt;$ sudo pkill -SIGHUP xinetd
如果系统没有 pkill（它根据进程名寻找进程 ID），那么使用 ps aux | grep xinetd 寻找进程号，然后使用 sudo kill -SIGHUP pid，其中的 pid 是进程 ID。&lt;/p&gt;

&lt;p&gt;为了测试这个新服务，创建一个名为 /tmp/xinetd 的目录，创建 Ruby 脚本并把它保存在 /tmp/xinetd/find.rb 中。用 chmod +x /tmp/xinetd/find.rb 把这个文件设置为可执行的。接下来，创建一些目录和文本文件：&lt;/p&gt;

&lt;p&gt;$ mkdir a b c
$ touch a/d.txt b/e.txt
现在可以测试新服务。当端口 11000 上出现入站连接时，xinetd 启动 Ruby 脚本。发送到标准输出的任何脚本输出会被发送到发出请求的机器上的标准输出。这个脚本不需要输入，但是如果需要，发出请求的机器上的标准输入会被传递给脚本。Telnet 提供一种连接任何服务的简便方法：&lt;/p&gt;

&lt;p&gt;$ telnet localhost 11000
Trying 127.0.0.1…
Connected to localhost.
Escape character is ‘^]’.
/tmp/xinetd/b/e.txt
/tmp/xinetd/a/d.txt
Connection closed by foreign host.
成功了！端口打开了，控制被传递给脚本，脚本生成了预期的输出。&lt;/p&gt;

&lt;p&gt;运行 xinetd 的更多原因
xinetd 有许多优点。它只在需要时运行守护进程，这可以节省资源。它提供一个额外的安全层，可以通过 “修改根目录” 把服务隔离在一个目录中。最重要的是，它实际上可以把任何脚本或程序转换为服务。但是要注意一点：如果您的服务非常受欢迎，应该考虑用 C 等高效的语言重写它。处理请求越快，性能就越好。&lt;/p&gt;

&lt;p&gt;inetd 是一个守护程序，通过一个集中的配置文件（inetd.conf）来管理大多数入网连接。xinetd 守护程序是 inetd 的替代，它提供许多改进的或新的特性，以及更容易的配置。Ted 解释了 inetd 背后的概念，并且给出了在您自己的站点上设置 xinetd 的示例。
经典的 inetd 守护程序已经存在很久了。有几种替换 inetd 的功能的方法，但是最灵活、最简便的方法似乎是 xinetd。inetd 能做的，xinetd 也能做，并且 xinetd 还能做更多的事情。譬如，TCP 封装、模块化配置、连接重定向和入站连接的负载限制，而这些只是使得 xinetd 成为系统管理员良好选择的部分特性。&lt;/p&gt;

&lt;p&gt;本文是为从初学者到中级系统管理员这样的读者而准备的，并且文中的说明和示例并不尝试假设您已经熟悉 inetd。在本文中，我们将研究 xinetd 的一些简单用法，从安装到安全性策略的实现。&lt;/p&gt;

&lt;p&gt;开始之前
为实现本文的目的，您的系统最好安装了最近的主流（2000 或更新）UNIX（Linux、Solaris、BSD）。这些示例在 Perl 和 UNIX（以及其它操作系统）的早期版本上也可以运行，但是它们功能方面的障碍应该由读者作为练习来解决。给定的特定示例是用于 Red Hat Linux 的，但是它们在其它系统上应该也可以运行（除 chkconfig 以外）。&lt;/p&gt;

&lt;p&gt;inetd 到底是什么
对于 UNIX 系统管理员，inetd 和 cp/rm/mv 命令一样基本。它总是存在，并准备着处理入站连接。但它到底是什么？它用来做什么？&lt;/p&gt;

&lt;p&gt;首先从 TCP/IP （它也包括 UDP，但我们目前还不考虑）开始回答。当您建立与一台主机的连接时，实际上是创建了一个 TCP/IP 连接（通常是一个套接字） — 这好象是在您和主机之间打了一个电话。TCP/IP 连接由起始主机和接收主机唯一地定义，但还有其它标识。如果我们都连接到一台服务器，它如何区分 webserver、telnet、SSH、FTP 和其它连接呢？套接字也通过建立连接所使用的端口来定义。例如，端口 21 是入站 FTP、端口 22 是 SSH、端口 23 是 TELNET（有关其它大多数端口，可以查看 UNIX 系统上的 /etc/services）。&lt;/p&gt;

&lt;p&gt;一旦建立了连接，某人就在另一端拿起了电话。这可以是接线员或直线。直线表示您直接连接到了服务器，而接线员是涉及 inetd 的方法。接线员实际上处理一组入站直线（主机上的端口），并亲自将它们交给负责的程序（服务器）。&lt;/p&gt;

&lt;p&gt;UDP 是另一种连接方法。象 TCP 一样，UDP 基本上是和某人的对话，但是不保证它是可靠的。UDP（继续使用电话的比喻）就象将消息扔到传送带上，让接收者站到另一端。您可以从传送带得到许多消息，但是如果消息太多（网络流量高）或者读取消息费时太久（服务器忙），则接收者可能会丢失一些消息。&lt;/p&gt;

&lt;p&gt;如果使用 inetd，在执行一些检查后，您被重定向到特定服务器。只有一个配置文件 — inetd.conf，管理所有入站连接。因而在系统上添加、删除、更改或复查服务变得更为简单。例如，在 Solaris 系统上使用 TCP 封装器将 ftp 定义如下：&lt;/p&gt;

&lt;p&gt;清单 1，FTP 服务的 inetd.conf 定义 ftp stream tcp nowait root /usr/sbin/tcpd in.ftpd&lt;/p&gt;

&lt;p&gt;这些是创建一个 FTP 连接所需的全部参数。简单地说，我们以面向流（stream）的方式使用 TCP/IP（tcp）时，同时允许多个 FTP 连接（nowait）、作为 root 运行以及调用 FTP（接下来，TCP 封装器将调用 FTP 守护程序）。&lt;/p&gt;

&lt;p&gt;用一上午的时间解析很困难吗？绝对困难。有必要这么复杂吗？不。xinetd 继承了 inetd 的设计并将它模块化，这意味着每个服务都可以存在于它自己的配置文件中。xinetd 还添加了一些象 TCP 封装器之类的功能部件，使得配置更加简单。&lt;/p&gt;

&lt;p&gt;xinetd 保持了中央配置（接线员）方法，将所有配置文件存储到单一位置，通常是 /etc/xinetd.conf 和 /etc/xinetd.d/*，使系统管理员可以更容易地获得。模块化配置意味着，您可以通过将服务复制到 xinetd.d 目录来向多台机器上分发该服务，也可以用同类的手段除去它。甚至可以指定额外的包含目录。&lt;/p&gt;

&lt;p&gt;最后，xinetd FAQ（请参阅本文后面的参考资料）声明了 RPC 程序在 xinetd 下运行得不太好。不过没问题，对 RPC 使用 inetd，并对其它所有服务使用 xinetd。这就象雇了两个接线员，一个说西班牙语，另一个说所有其它语言。&lt;/p&gt;

&lt;p&gt;xinetd 简介
那么 xinetd 是什么？一句话，它就是个程序。处理入站网络连接没什么神奇。可以使用 Perl、Python 或 Java 来处理。Xinetd 是用 C 编写的，而且它和它的前辈 inetd 一样快，如果不是更快的话（例如，TCP 封装器不必为每个入站连接而执行；它们在启动时装入内存）。&lt;/p&gt;

&lt;p&gt;xinetd 正在开发中。（您的版本可能过时了，所以请务必到主页上查找最新的版本；请参阅参考资料。）因为它正在开发中，所以 xinetd 的安全漏洞得以迅速弥补，而不象 inetd 那样薄弱，通常要很长时间才能弥补。当然，xinetd 是随源代码一起交付的，所以您可以复查源代码并自己找到可能存在弱点的地方。&lt;/p&gt;

&lt;p&gt;如何使用 xinetd 定义服务呢？编写一个服务文件，它除了指定 /etc/xinetd.conf 中所指定的一般参数之外，还指定特定配置。所以，如果 /etc/xinetd.conf 是这样的：&lt;/p&gt;

&lt;p&gt;清单 2，样本 xinetd.conf（标准的 Red Hat 7.1） defaults
{
instances = 60
log_type = SYSLOG authpriv
log_on_success = HOST PID
log_on_failure = HOST
cps = 25 30
}&lt;/p&gt;

&lt;p&gt;service telnet
{
flags = REUSE
socket_type = stream 
wait = no
user = root
server = /usr/sbin/in.telnetd
log_on_failure += USERID
disable = yes
}&lt;/p&gt;

&lt;p&gt;includedir /etc/xinetd.d&lt;/p&gt;

&lt;p&gt;您放到 /etc/xinetd.d 中的每个服务文件都会继承这些缺省值，并指定它自己的参数。这里，telnet 服务在顶级定义，而不是在子目录中定义。这太棒了，这种模块性允许复杂的配置。&lt;/p&gt;

&lt;p&gt;要使 xinetd 重新读取配置文件，不必重新启动它。只要向它发送 USR2 信号即可。&lt;/p&gt;

&lt;p&gt;那些参数表示什么意思？让我们通读整个清单。您也可以在命令行下使用 man xinetd.conf 来查看列表（如果那个帮助页面正确安装的话），但这个概述试图用更简单的术语来解释参数，并不假定您已经知道关于套接字和服务的所有信息。一些参数（rpc_version、rpc_number）被跳过。&lt;/p&gt;

&lt;p&gt;常规参数&lt;/p&gt;

&lt;p&gt;id 
该服务的唯一名称。服务名称在花括号之前指定，但是 ID 使逻辑上相同的服务可能拥有多个协议。这是对于临时用户的受限使用。例如，NFS 服务可以在 UDP 或 TCP 传输协议上运行。在 Red Hat Linux 7.1 上，TCP 版本（在 /etc/xinetd.d/time 中）和 UDP 版本（在 /etc/xinetd.d/time-udp中）中提供了对于 xinetd 来说内部的时间服务。&lt;/p&gt;

&lt;p&gt;type 
这实际上应该称为“特殊类型”，因为它只适用于特殊服务。它可以是以下几种类型的组合：“RPC”，用于 RPC 服务（由 SUN 引入的远程过程调用，导致了很多安全性问题，最好避免使用）；“INTERNAL”，用于构建到 xinetd 内部的服务，譬如时间服务；“UNLISTED”，用于在系统列表（/etc/services 或用于 RPC 服务的 /etc/rpc）中找不到的非标准服务。&lt;/p&gt;

&lt;p&gt;flags 
这里放置着所有额外标志。列表很长并且技术性很强；我们感兴趣的标志包括 REUSE（用于套接字重用，譬如 telnet）、NAMEINARGS/NOLIBWRAP（如果您希望手工调用 TCP 封装器或者完全地避免使用封装器）、NODELAY/KEEPALIVE（用于调整 TCP 套接字）、DISABLE（覆盖顶级“disable”参数）以及 SENSOR（用于检测和防止某些类型的“拒绝服务（denial-of-service）”网络攻击）。&lt;/p&gt;

&lt;p&gt;disable 
除非您希望禁用某项服务，否则总是把它设成“no”。Red Hat Linux 的 chkconfig 程序将为您打开或关闭“disable”参数；在 Red Hat 上，用 chkconfig 启用和禁用特定服务可能比手工方式简单些。请注意，chkconfig 预期在 /etc/xinetd.d/SERVICE 中找到服务文件。所以对于上面清单 2 中的示例，chkconfig 将不会在请求时打开或关闭 telnet。可以将它认为是一个错误或特性，取决于您的观点。&lt;/p&gt;

&lt;p&gt;socket_type 
通常您希望这个参数设置成“stream”，除非使用 UDP 服务，此时设置成“dgram”。该参数也可以设置成“raw”和“seqpacket”，但极少见。&lt;/p&gt;

&lt;p&gt;protocol 
这是连接所用的协议，通常是“tcp”或“udp”，但是在理论上您可以使用来自 /etc/protocols 的任何值。&lt;/p&gt;

&lt;p&gt;wait 
如果设置成“no”，xinetd 将为每个连接上的服务启动一个新的处理程序。如果是“yes”，xinetd 预期该处理程序处理所有后续连接直到它死亡。在大多数情况下，这个参数是“no”。&lt;/p&gt;

&lt;p&gt;server, server_args 
处理程序的程序名，以及它应当获得的参数。处理程序名不应该象在 inetd 环境下那样，出现在参数中。&lt;/p&gt;

&lt;p&gt;port 
服务的端口。通常不需要，因为端口通过 /etc/services 文件来映射到服务。&lt;/p&gt;

&lt;p&gt;redirect 
允许 xinetd 将所有服务的流量发送给另一台主机。因此，受防火墙保护的主机可以通过中央 xinetd 转发器接受安全流量，而不必建立与外部网络的连接。在某些工作中，可以采用这个特征来在两台主机间执行故障转移服务。&lt;/p&gt;

&lt;p&gt;banner, banner_success, banner_fail 
一个将要在“任意/一个成功/一个不成功”连接上打印的来自文件的定制文本块。&lt;/p&gt;

&lt;p&gt;enabled 
在全局级别上补充“disabled”参数和 DISABLE 标志。&lt;/p&gt;

&lt;p&gt;include, includedir 
告诉 xinetd 要包含文件或目录。&lt;/p&gt;

&lt;p&gt;环境参数&lt;/p&gt;

&lt;p&gt;user, group, umask, groups 
当启动服务处理程序时，xinetd 应该扮演的 UNIX 属性。这主要用于非安全服务。&lt;/p&gt;

&lt;p&gt;nice 
确定该服务对于系统有多重要的 UNIX 优先级级别。可以针对您的系统调整它，请查看“nice”的 man 页面。&lt;/p&gt;

&lt;p&gt;env 
用于服务处理程序的环境变量。&lt;/p&gt;

&lt;p&gt;passenv 
应该向下传递到服务处理程序的 xinetd 中的环境变量。&lt;/p&gt;

&lt;p&gt;资源管理参数&lt;/p&gt;

&lt;p&gt;instances 
可以同时启动的处理程序数。可以调整这个参数以防止拒绝服务攻击。如果您希望缺省（无限制）行为，将它设置成“UNLIMITED”。&lt;/p&gt;

&lt;p&gt;max_load 
I: ) 如果系统过载，停止接受连接。负载数取决于系统，仅当您确实知道自己在做什么时才能调整它。&lt;/p&gt;

&lt;p&gt;rlimit_as, rlmist_cpu, rlimit_data, rlimit_rss, rlimit_stack 
rlimit 参数指定用于服务处理程序的资源限制（内存、CPU 以及特定内存区域）。&lt;/p&gt;

&lt;p&gt;特定于安全性的参数&lt;/p&gt;

&lt;p&gt;only_from, no_access 
对 TCP 封装器的补充，这是阻挡主机建立与我们的连接的方法之一。请注意，缺省值是允许对任何人的访问，除非 TCP 封装器（其规则通常在 /etc/hosts.allow 中）另有规定。&lt;/p&gt;

&lt;p&gt;access_times 
一天中服务可用的时间。例如，“6:00-23:00”意味着服务从上午 6 点到晚上 11:01 可用。&lt;/p&gt;

&lt;p&gt;log_type, log_on_success, log_on_failure 
各种日志记录选项。USERID 标志可能特别麻烦，因为它向连接的主机询问关于与我们连接的用户，这使得处理变慢。尽可能避免使用 USERID。&lt;/p&gt;

&lt;p&gt;bind 
允许服务特定于接口，通常是出于安全性考虑。例如，在网络内部的 FTP 服务只是 FTP，而外部 FTP 连接将生成入侵者警报。“id”参数在这里很有用。&lt;/p&gt;

&lt;p&gt;per_source 
指定来自源 IP 的服务的最大实例数。对于处理“单源拒绝服务（single-source denial-of-service）”攻击或出错程序建立的过多连接非常有用。&lt;/p&gt;

&lt;p&gt;cps 
每秒允许的最大连接数，以及服务再度启用之前的秒数。“30 45”表示“每秒 30 个入站连接，如果超过限制，则等待 45 秒”。主要用于对付拒绝服务攻击。&lt;/p&gt;

&lt;p&gt;deny_time 
对引发 SENSOR 标志的人拒绝服务的时间。&lt;/p&gt;

&lt;p&gt;替换 TCP 封装器
经典的 TCP 封装器软件包是个非常有用的工具。通过一个集中式的文件（通常是 /etc/hosts.allow 和 /etc/hosts.deny），针对每个服务，根据需要来允许或拒绝对任何主机的访问。不幸的是，TCP 封装器库不太了解系统负载、资源限制、多重攻击之类的情况。xinetd 合并了 TCP 封装器功能性（通过 libwrap 库），所以您可以顺利地迁移到 xinted，并继续使用和以前相同的配置文件。&lt;/p&gt;

&lt;p&gt;这差不多就是迁移所要做的全部工作了。保持旧的 hosts.deny 和 hosts.allow 文件，xinetd 将乐意遵循它们。但是，请牢记，xinetd 有许多在 TCP 封装器基础上改进的连接控制选项。例如，限制每秒连接数或过载时的连接数，可以成为对服务器管理极有价值的帮助。&lt;/p&gt;

&lt;p&gt;确保您是使用 libwrap 选项编译 xinetd 的，否则，它将不知道 TCP 封装器。如果 xinetd 来自于 Red Hat Linux 上的 RPM，确保您在开放机器“之前”，测试 TCP 封装器文件是否正常运行。&lt;/p&gt;

&lt;p&gt;高级用途：故障转移
尽管可以有多种方法使用 xinetd，redirect 参数为我们提供了最有趣的使用方法。众所周知，故障转移很难实现，并且硬件故障转移很昂贵。这里所描述的方法（通过简单的软件）既便宜又有效。它具有单故障点 — 重定向点，所以您应该考虑该方式是否可接受。如果不能接受，那么，硬件故障转移就贵得有道理了。&lt;/p&gt;

&lt;p&gt;首先，确定一种方法从两台或者更多的机器中选出一台“活动的”机器。假设您通过一个脚本 set_active.pl 来完成（我们将为 telnet 服务完成该步，但是它对任何其他服务也有效，只要能保持服务切换到其他服务器而不带来不良影响）。脚本将采用我们用来设置新故障转移的机器名，以及给我们适当的用于编辑的 /etc/xinetd.d/SERVICE 文件的服务名。请随意定制脚本以编辑不同文件，或使用不同参数。可以用一行“perl -p -i -e”脚本执行这个作业，但您可以在将来对这种方法作许多扩展，并可以对参数执行错误检查。&lt;/p&gt;

&lt;p&gt;这太简单了。现在只要决定调用这个脚本的过程即可 — 可以是手工、通过一个 cron 作业、或者由另一个程序触发。此时，它成为体系结构决策。别忘了在这时向 xinetd 发送 USR2 信号，如果愿意，也可以重新启动它。在 Red Hat Linux 上可以用“pkill -USR2 xinetd”完成信号的自动化，而重新启动 xinetd 只要使用“/etc/rc.d/init.d/xinetd restart”（在 Linux 上）或者其它类似命令（在大多数 UNIX 系统上）。&lt;/p&gt;

&lt;p&gt;这种故障转移将“不会”对数据库连通性生效，除非在数据库端做许多额外工作。建议您最好将它用于诸如 rsync、ssh、ftp 和 telnet 之类的协议，其中，故障转移机器彼此没有相互依赖性。&lt;/p&gt;

&lt;p&gt;Linux inetd 有多个服务
1， 开启方式   命令行输入 inetd。&lt;/p&gt;

&lt;p&gt;2， 开启服务选择  /etc/inetd.conf       ftp  telnet   etc.&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;
    &lt;p&gt;开启服务对应程序建立软连接  指向 busybox 对应程序     busybox cp .&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;开启对应端口 /etc/server&lt;/p&gt;
  &lt;/li&gt;
&lt;/ol&gt;
</description>
        <pubDate>Wed, 27 Dec 2017 00:00:00 +0800</pubDate>
        <link>https://xiazemin.github.io/MyBlog/linux/2017/12/27/inetd.html</link>
        <guid isPermaLink="true">https://xiazemin.github.io/MyBlog/linux/2017/12/27/inetd.html</guid>
        
        
        <category>linux</category>
        
      </item>
    
      <item>
        <title>Django_nginx_uwsgi</title>
        <description>&lt;!-- more --&gt;
&lt;p&gt;安装Python包管理
easy_install 包 https://pypi.python.org/pypi/distribute
wget https://pypi.python.org/packages/source/d/distribute/distribute-0.6.49.tar.gz
tar xf distribute-0.6.49.tar.gz
cd distribute-0.6.49
python2.7 setup.py install
easy_install –version
安装 uwsgi
uwsgi:https://pypi.python.org/pypi/uWSGI&lt;/p&gt;

&lt;p&gt;uwsgi 参数详解：http://uwsgi-docs.readthedocs.org/en/latest/Options.html&lt;/p&gt;

&lt;p&gt;pip install uwsgi
uwsgi –version    # 查看 uwsgi 版本
测试 uwsgi 是否正常：&lt;/p&gt;

&lt;p&gt;新建 test.py 文件，内容如下：&lt;/p&gt;

&lt;p&gt;def application(env, start_response):
    start_response(‘200 OK’, [(‘Content-Type’,’text/html’)])
    return “Hello World”
然后在终端运行：&lt;/p&gt;

&lt;p&gt;uwsgi –http :8001 –wsgi-file test.py&lt;/p&gt;

&lt;p&gt;在浏览器内输入：http://127.0.0.1:8001，查看是否有”Hello World”输出，若没有输出，请检查你的安装过程。&lt;/p&gt;

&lt;p&gt;安装 Django
pip install django
测试 django 是否正常，运行：&lt;/p&gt;

&lt;p&gt;django-admin.py startproject demosite
cd demosite
python2.7 manage.py runserver 0.0.0.0:8002
在浏览器内输入：http://127.0.0.1:8002，检查django是否运行正常。&lt;/p&gt;

&lt;p&gt;安装 Nginx
安装命令如下：&lt;/p&gt;

&lt;p&gt;cd ~
wget http://nginx.org/download/nginx-1.5.6.tar.gz
tar xf nginx-1.5.6.tar.gz
cd nginx-1.5.6
./configure –prefix=/usr/local/nginx-1.5.6 \
–with-http_stub_status_module \
–with-http_gzip_static_module
make &amp;amp;&amp;amp; make install
你可以阅读 Nginx 安装配置 了解更多内容。&lt;/p&gt;

&lt;p&gt;uwsgi 配置
uwsgi支持ini、xml等多种配置方式，本文以 ini 为例， 在/ect/目录下新建uwsgi9090.ini，添加如下配置：&lt;/p&gt;

&lt;p&gt;[uwsgi]
socket = 127.0.0.1:9090
master = true         //主进程
vhost = true          //多站模式
no-site = true        //多站模式时不设置入口模块和文件
workers = 2           //子进程数
reload-mercy = 10   &lt;br /&gt;
vacuum = true         //退出、重启时清理文件
max-requests = 1000 &lt;br /&gt;
limit-as = 512
buffer-size = 30000
pidfile = /var/run/uwsgi9090.pid    //pid文件，用于下面的脚本启动、停止该进程
daemonize = /website/uwsgi9090.log
Nginx 配置
找到nginx的安装目录（如：/usr/local/nginx/），打开conf/nginx.conf文件，修改server配置：&lt;/p&gt;

&lt;p&gt;server {
        listen       80;
        server_name  localhost;&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;    location / {            
        include  uwsgi_params;
        uwsgi_pass  127.0.0.1:9090;              //必须和uwsgi中的设置一致
        uwsgi_param UWSGI_SCRIPT demosite.wsgi;  //入口文件，即wsgi.py相对于项目根目录的位置，“.”相当于一层目录
        uwsgi_param UWSGI_CHDIR /demosite;       //项目根目录
        index  index.html index.htm;
        client_max_body_size 35m;
    }
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;WSGI是Web Server Gateway Interface的缩写。以层的角度来看，WSGI所在层的位置低于CGI。但与CGI不同的是WSGI具有很强的伸缩性且能运行于多线程或多进程的环境下，这是因为WSGI只是一份标准并没有定义如何去实现。实际上WSGI并非CGI，因为其位于web应用程序与web服务器之间，而web服务器可以是CGI，mod_python（注：现通常使用mod_wsgi代替），FastCGI或者是一个定义了WSGI标准的web服务器就像python标准库提供的独立WSGI服务器称为wsgiref。&lt;/p&gt;

&lt;p&gt;Python Paste - WSGI底层工具集. 包括多线程, SSL和 基于Cookies, sessions等的验证(authentication)库. 可以用Paste方便地搭建自己的Web框架。
WSGI:Python Web Server Gateway Interface v1.0
它是 PEP3333中定义的（PEP3333的目标建立一个简单的普遍适用的服务器与Web框架之间的接口）
WSGI是Python应用程序或框架和Web服务器之间的一种接口&lt;/p&gt;
</description>
        <pubDate>Wed, 27 Dec 2017 00:00:00 +0800</pubDate>
        <link>https://xiazemin.github.io/MyBlog/web/2017/12/27/Django_nginx_uwsgi.html</link>
        <guid isPermaLink="true">https://xiazemin.github.io/MyBlog/web/2017/12/27/Django_nginx_uwsgi.html</guid>
        
        
        <category>web</category>
        
      </item>
    
      <item>
        <title>UNIX下的5种IO模型</title>
        <description>&lt;!-- more --&gt;
&lt;p&gt;套接字的IO操作，如recvfrom，分为两个阶段：&lt;/p&gt;

&lt;p&gt;（1）等待内核中的接收缓冲区中有数据可读。&lt;/p&gt;

&lt;p&gt;（2）将接收缓冲区中的数据复制进应用缓冲区。&lt;/p&gt;

&lt;p&gt;1，阻塞式IO&lt;/p&gt;

&lt;p&gt;文件描述符open时，如果没有指定flags为O_NONBLOCK，或者open后，没有使用fcntl设置O_NONBLOCK，默认文件描述符为阻塞模式。&lt;/p&gt;

&lt;p&gt;阻塞式IO在等待接收缓冲区数据到来时，会阻塞；&lt;/p&gt;

&lt;p&gt;数据到来，进行数据复制时，也会阻塞。&lt;/p&gt;

&lt;p&gt;2，非阻塞式IO&lt;/p&gt;

&lt;p&gt;如上所述，可以通过open或者fcntl设置文件描述符为非阻塞模式。&lt;/p&gt;

&lt;p&gt;非阻塞式IO，当内核缓冲区没有数据时，不会阻塞，会立即返回一个错误——EAGAIN或者EWOULDBLOCK。EAGAIN表示需要再次调用recvfrom，以判断数据是否准备好，这也是非阻塞式IO的用法，不断的调用recvfrom，以判断是否可以读。EWOULDBLOCK是虚拟语气，表示“本应该阻塞”，其实没有阻塞。由于并不确定返回EAGAIN还是EWOULDBLOCK，因此需要对这两个值都进行判断。&lt;/p&gt;

&lt;p&gt;从接收缓冲区向应用缓冲区复制数据阶段，调用进程阻塞。&lt;/p&gt;

&lt;p&gt;3，IO复用&lt;/p&gt;

&lt;p&gt;在阻塞式IO中，如果接收缓冲区没有数据，调用进程阻塞于recvfrom操作。使用select或者poll，可以在此情况下使进程阻塞于select或者poll操作（因此要把文件描述符设置为非阻塞式），而且可以同时检测多个文件描述符是否可读，即检测这些描述符对应的内核中的接收缓冲区是否有数据。&lt;/p&gt;

&lt;p&gt;从接收缓冲区向应用缓冲区复制数据阶段，调用进程阻塞。&lt;/p&gt;

&lt;p&gt;4，信号驱动式IO&lt;/p&gt;

&lt;p&gt;信号驱动式IO与上述三个IO模型相比，即不像阻塞式IO那样阻塞于recvfrom操作，也不像非阻塞式IO那样需要多次调用甚至轮询recvfrom才能得知是否有数据，也不像IO复用那样阻塞于select或者poll，而是当内核接收缓冲区有数据时向调用进程发送一个信号。&lt;/p&gt;

&lt;p&gt;从接收缓冲区向应用缓冲区复制数据阶段，调用进程阻塞。&lt;/p&gt;

&lt;p&gt;5，异步IO&lt;/p&gt;

&lt;p&gt;上述4种IO模型，其不同点在于当接收缓冲区没有数据时，如何判断数据已经到来：阻塞式IO中recvfrom会阻塞直到接收缓冲区有数据；非阻塞式IO通过轮询recvfrom以判断接收缓冲区是否有数据；IO复用中使用select或者poll以判断接收缓冲区是否有数据；信号驱动IO通过信号通知接收缓冲区是否有数据。&lt;/p&gt;

&lt;p&gt;其相同点在于，IO操作的第二个阶段，即从内核接收缓冲区向应用缓冲区复制数据时，调用recvfrom的进程会阻塞。&lt;/p&gt;

&lt;p&gt;可见，上述4种IO模型都会使进程阻塞，直到IO操作的两个阶段都完成才能执行其他操作，因此称为同步IO。&lt;/p&gt;

&lt;p&gt;异步IO模型中，IO操作的两个阶段都不阻塞，因此称为异步IO。&lt;/p&gt;

&lt;p&gt;阻塞IO
这是我们熟悉的IO模型，一个进程在作IO操作时，非要等到数据从内核空间拷贝到用户进程空间，才会返回。这个模型的优点就是简单，而且在阻塞的时候，CPU还可以进行调度，去执行别的进程。
非阻塞IO
一开始我看是非阻塞IO，觉得应该要比阻塞IO模型先进，可是当我一看使用方法的时候，就知道这个模型是不会被实际使用的，仅仅只能作为理论上存在的IO模型。这个模型的观点是：进行IO操作的时候，不阻塞，如果没有数据准备好，就直接返回错误码（或者是别的代码）。因此，使用者就只能不断进行轮询来调用IO函数。这样的后果就是，不仅在宏观上形成了与阻塞IO一共的“阻塞”效果，而且在微观上，CPU一直被用来轮询，造成了CPU的浪费。所以，这个模型还不如阻塞IO模型实用。
IO复用
对于IO复用，我的理解有三点：
在一次系统调用中，实现了询问多个描述符的IO准备情况 —— 根据事件通知
为了实现第一点，就需要把阻塞的地方进行转移。把一次系统调用，分为两次系统调用。第一次系统调用可以询问多个描述符的IO准备情况，在这个地方进行阻塞；而第二次系统调用，是针对已经准备好IO的描述符进行调用，此时，理论上（按照我的理解），也是会发生阻塞的，只不过是此时内核已经把数据准备好了，阻塞的时间可以忽略不计罢了。
本质上，还是阻塞的。
信号IO
我们都知道，信号是UNIX提供了进程间进行通信的一种方式。我们常用的 kill -9 命令（kill是向进程传递信号量，9只是众多信号中的一个代号），或者是 Ctrl + C 的时候，就是向某个进程发出终止的信号，这样进程就退出了。
而对于信号IO的模型，我是这么理解的：进程在发起IO操作，系统调用之后，直接访问，内核会在IO数据准备好之后，以某个信号通知发起IO操作的进程，从而使得该进程的信号处理函数可以读取IO数据的操作。
本质上，这也是阻塞的IO模型，因为在信号处理函数中，同样也是要进行阻塞的，只是在在这个时候发起系统系统，内核已经把数据准备好了。
异步IO
这是真正的异步IO了。实现的机制是：用户在发起异步IO的系统调用时，会把相应的数据处理函数作为回调函数，等到IO数据准备好，内核会主动调用此回调函数。可以看出，用户进程在这种模型下，只调用了一次系统调用，而且是立即返回的，因此，就不会出现让进程阻塞的情况，也就符合了POSIX中异步IO的定义。
其实我理解起来，思路是和信号IO差不多的，唯一不同的地方，对于IO数据的操作，异步IO是由内核主动发起的，而信号IO是由用户进程发起的。&lt;/p&gt;

&lt;p&gt;进程切换
为了控制进程的执行，内核必须有能力挂起正在CPU上运行的进程，并恢复以前挂起的某个进程的执行。这种行为被称为进程切换。因此可以说，任何进程都是在操作系统内核的支持下运行的，是与内核紧密相关的。&lt;/p&gt;

&lt;p&gt;从一个进程的运行转到另一个进程上运行，这个过程中经过下面这些变化：&lt;/p&gt;
&lt;ol&gt;
  &lt;li&gt;保存处理机上下文，包括程序计数器和其他寄存器。&lt;/li&gt;
  &lt;li&gt;更新PCB信息。&lt;/li&gt;
  &lt;li&gt;把进程的PCB移入相应的队列，如就绪、在某事件阻塞等队列。&lt;/li&gt;
  &lt;li&gt;选择另一个进程执行，并更新其PCB。&lt;/li&gt;
  &lt;li&gt;更新内存管理的数据结构。&lt;/li&gt;
  &lt;li&gt;恢复处理机上下文。&lt;/li&gt;
&lt;/ol&gt;
</description>
        <pubDate>Sun, 24 Dec 2017 00:00:00 +0800</pubDate>
        <link>https://xiazemin.github.io/MyBlog/linux/2017/12/24/unix_io5.html</link>
        <guid isPermaLink="true">https://xiazemin.github.io/MyBlog/linux/2017/12/24/unix_io5.html</guid>
        
        
        <category>linux</category>
        
      </item>
    
      <item>
        <title>用户空间实现线程 内核实现线程 线程的调度</title>
        <description>&lt;!-- more --&gt;
&lt;p&gt;1、在用户空间中实现线程&lt;/p&gt;

&lt;p&gt;（1）特点：把整个线程包放在用户空间，内核对线程包一无所知。从内核角度考虑，就是按正常的方式管理，即单线程进程（存在运行时系统）&lt;/p&gt;

&lt;p&gt;（2）优点：&lt;/p&gt;

&lt;p&gt;1、用户级线程包可以在不支持线程的操作系统上实现。&lt;/p&gt;

&lt;p&gt;2、线程切换至少要比陷入内核要快一个数量级。在线程完成运行时，它调用thread_yield可以把该线程的信息保存在线程表中；进而，它可以调用线程调度程序来选择另一个要运行的线程。保存该线程状态的过程和调度程序都只是本地过程，所以启动它们比进行内核调用效率更高。另一方面，不需要陷阱，不需要上下文切换，也不需要对内存高速缓存进行刷新，这使得线程调度非常快捷。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt; 在用户空间管理线程时，每个进程都需要有其专用的线程表，用来跟踪该进程中的线程。与进程表类似，线程表记录各个线程的属性，如每个线程的程序计数器，堆栈指针，寄存器和状态等，线程表由运行时系统管理，当一个线程转换到就绪状态或阻塞状态是，在该线程表中存放重新启动该线程所需的信息，与内核在进程表中存放进程的信息完全一样。
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;当某个线程做了一些会引起在本地阻塞的事情之后，例如等待进程中另一个线程完成某些工作，它调用一个运行时系统的过程，这个过程检查该线程是否必须进入阻塞状态。如果是，它在线程表中保持该线程的寄存器，并查看表中可运行的就绪线程，并把新线程的保存值重新装入机器的寄存器中。只要堆栈指针和程序计数器一被切换，新线程就又自动投入运行。&lt;/p&gt;

&lt;p&gt;(3) 允许每个进程有自己定制的调度算法。&lt;/p&gt;

&lt;p&gt;(4) 具有较好的可扩展性，这是因为在内核空间中内核线程需要一些固定表格空间和堆栈空间，当内核线程的数量非常大，就会出现问题。&lt;/p&gt;

&lt;p&gt;（3）缺点：&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;   线程发生I/O或页面故障引起的阻塞时，如果调用阻塞系统调用则内核由于不知道有多线程的存在，而会阻塞整个进程从而阻塞所有线程。注（阻塞调用是指调用结果返回之前，当前线程会被挂起。函数只有在得到结果之后才会返回。）
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;在一个单独的进程内部，没有时钟中断，所以不能用轮转调度的方式调度线程。如果一个线程开始运行，那么在该进程中的其他线程就不能运行，除非第一个线程自动放弃CPU。&lt;/p&gt;

&lt;p&gt;下面是线程包实现图&lt;/p&gt;

&lt;p&gt;2、在内核中实现线程&lt;/p&gt;

&lt;p&gt;（1）特点：&lt;/p&gt;

&lt;p&gt;在内核中实现线程，此时不再需要运行时系统。另外，每个进程中也没有线程表，相反，在内核中用来记录系统中所有线程的线程表。当一个线程阻塞时，内核可以根据其选择，可以运行同一个进程中的另一个线程，或者运行另一个进程中的线程。而在用户级线程中，运行时系统始终运行自己进程中的线程，直到内核剥夺它的CPU为止。当某个线程希望创建一个新线程或撤销一个已有线程时，它进行一个系统调用。在内核中实现线程时，内核必须维护两个表，传统的进程表以便跟踪进程的状态和线程表。&lt;/p&gt;

&lt;p&gt;（2）优点：&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;    内核线程不需要任何新的，非阻塞系统调用。另外，如果某个进程中的线程引起了页面故障，内核可以很方便地检查该进程是否有任何其他可运行的线程，如果有，在等待所需要的页面从磁盘读入时，就选择一个可运行的线程运行。
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;（3）内核级线程的缺点是：应用程序线程在用户态运行，而线程调度和管理在内核实现。在同一进程中，控制权从一个线程转移到另一个线程，需要用户态-内核态-用户态的模式切换，系统开销较大。（应用程序线程和线程调度管理，都在同一进程内）&lt;/p&gt;

&lt;p&gt;综上：用户级线程和内核级线程之间的差别在于性能。用户级线程的切换需要少量的机器指令，而内核级线程需要完整的上下文切换，修改内存映像，使高速缓存失效，这导致了若干数量级的延迟。另一方面，在使用内核级线程时，一旦线程阻塞在I/O就不需要像在用户级线程中那样将整个进程挂起。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;   所有能够阻塞线程的调用都以系统调用的形式实现，代价可观。当一个线程阻塞时，内核根据选择可以运行另一个进程的线程，而用户空间实现的线程中，运行时系统始终运行自己进程中的线程。说明：由于内核创建线程代价大，故有线程回收。
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;线程调度&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;  当若干进程都有多个线程时，存在两个层次的并行，进程和线程。这样的系统中调度处理有本质的区别，是用户级线程还是内核级线程。

  对于用户级线程，内核并不知道有线程存在，所以内核还是和以前一样地操作，选取一个进程，假设为A，并给予A时间片控制，A的线程调度程序决定哪个线程运行，假设为A1。由于多道线程不存在时钟中断，所以，这个线程可以按其意愿任意运行多长时间。如果该线程用完了进程的全部时间片，内核就会选择另一个进程运行。

  在线程A终于又一次运行时，线程A1会接着运行。该线程会继续耗费A进程的所有时间，直到它完成工作。不过，该线程的这种不合群的行为不会影响到其他的进程。其他进程会得到调度程序所分配的合适份额，不会考虑进程A内部所发生的事。但是，用户级线程缺乏一个时钟将运行过长的线程加以中断。

   对于内核级线程而言，内核选择一个特定的线程运行，它不用考虑该线程属于哪个进程，不过，如果有必要的话，它可以这样做。对被选择的线程赋予一个时间片，而且，如果超过了时间片，就会强制挂起该线程。
&lt;/code&gt;&lt;/pre&gt;
</description>
        <pubDate>Sun, 24 Dec 2017 00:00:00 +0800</pubDate>
        <link>https://xiazemin.github.io/MyBlog/linux/2017/12/24/thread_namespace.html</link>
        <guid isPermaLink="true">https://xiazemin.github.io/MyBlog/linux/2017/12/24/thread_namespace.html</guid>
        
        
        <category>linux</category>
        
      </item>
    
      <item>
        <title>进程切换</title>
        <description>&lt;p&gt;为了控制进程的执行，内核必须有能力挂起正在CPU上运行的进程，并恢复以前挂起的某个进程的执行。这种行为被称为进程切换（process switch）、任务切换（task switch）或上下文切换（content switch）。&lt;/p&gt;

&lt;p&gt;硬件上下文
尽管每个进程都有自己的地址空间，但所有进程必须共享CPU寄存器。因此，在恢复一个进程的执行之前，内核必须确保每个寄存器装载了挂起进程时所需要的值。&lt;/p&gt;

&lt;p&gt;进程恢复执行前必须装入寄存器的一组数据成为硬件上下文（hardware context）。硬件上下文是进程可执行上下文的一个自己，因为可执行上下文包含进程执行时所需要的所有信息。在Linux中，进程硬件上下午的一部分存放在TSS段，而剩余部分存放在内核态堆栈中。&lt;/p&gt;

&lt;p&gt;在下面描述中，假定用prev局部变量表示切换出的进程描述符，next表示切换进的进程描述符。因此，我们把进程切换定义为这样的行为：保存prev硬件上下文，用next硬件上下文代替prev。因为进程切换经常发生，因此减少保存和装入硬件上下文所话费的时间是非常重要的。&lt;/p&gt;

&lt;p&gt;早期Linux版本利用80x86体系结构所需提供的硬件支持，并通过far jmp1指令跳到next进程TSS描述符的选择符来执行进程切换。当执行这条指令时，CPU通过自动保存原来的硬件上下文，装入新的硬件上下文来执行硬件上下文切换。但Linux2.6使用软件执行进程切换，原因有：&lt;/p&gt;

&lt;p&gt;通过一组mov指令逐步执行切换，这样能较好地控制所装入的数据的合法性，一面被恶意用户伪造。far jmp指令不会有这样的检查。
旧方法和新方法所需时间大致相同。
进程切换值发生在内核态，在执行进程切换之前，用户态进程使用的所有寄存器内容已保存在内核堆栈上，这也包括ss和esp这对寄存器的内容。&lt;/p&gt;

&lt;p&gt;任务状态段
80x86体系结构包含了一个特殊的段类型，叫任务状态段（Task State Segment，TSS）来存放硬件上下文，尽管Linux并不使用硬件上下文切换，但是强制它为系统中每个不同的CPU创建一个TSS，这样做主要有两个理由：&lt;/p&gt;

&lt;p&gt;当80x86的一个CPU从用户态切换到内核态时，它就从TSS中后去内核态堆栈的地址。
当用户态进程试图通过in或out指令访问一个I/O端口时，CPU需要访问存放在TSS中的I/O许可位图以检查该进程是否有访问端口的权利。
更确切的说，当进程在用户态执行in或out指令时，控制单元执行下列操作：&lt;/p&gt;

&lt;p&gt;检查eflags寄存器中的2位IOPL字段，如果字段的值为3，控制单元就执行I/O指令。否则，执行下一个检查。
访问tr寄存器以确定当前的TSS和相应的I/O许可权位图。
检查I/O指令中指定的I/O端口在I/O许可权位图中对应的位，如果该位清，这条指令就执行，否则控制单元产生一个异常。
tss_struct结构描述TSS的格式，init_tss数组为系统上每个不同的CPU存放一个TSS。在每次进程切换时，内核都更新TSS的某些字段以便相应的CPU控制单元可以安全地检索到它需要的信息。因此，TSS反映了CPU上当前进程的特权级，但不必为没有在运行的进程保留TSS。&lt;/p&gt;

&lt;p&gt;每个TSS有它自己8字节的任务状态段描述符（Task State Segment Descriptor，TSSD）。这个描述符包括指向TSS起始地址的32位Base字段，20位Limit字段。TSSD的S标志位被清0，以表示相应的TSS时系统段的事实。&lt;/p&gt;

&lt;p&gt;Type字段被置位11或9以表示这个段实际上是一个TSS。在Intel的原始设计中，系统中的每个进程都应当指向自己的TSS；Type字段的第二个有效位叫Busy位；如果进程正由CPU执行，则该位置1，否则为0。在Linux的设计中，每个CPU只有一个TSS，因此Busy位总是为1.&lt;/p&gt;

&lt;p&gt;由Linux创建的TSSD存放在全局描述符表（GDT）中，GDT的基地址存放在每个CPU的gdtr寄存器中。每个CPU的tr寄存器包含相应TSS的TSSD选择符，也包含了两个隐藏的非编程字段：TSSD的Base字段和Limit字段。这样，处理器就能够直接TSS寻址而不需要从GDT中检索TSS地址。&lt;/p&gt;

&lt;p&gt;thread字段
在每次进程切换时，被替换的进程的硬件上下文必须保存在别处。不能像Intel原始设计那样保存在TSS中，因为Linux为每个处理器而不是为每个进程使用TSS。&lt;/p&gt;

&lt;p&gt;因此，每个进程描述符包含一个类型为thread_struct的thread字段，只要进程被切换出去，内核就把其硬件上下文保存在这个结构中。随后可以看到，这个数据结构包含的字段涉及大部分CPU寄存器，但不包括eax、ebx等等这些通用寄存器。它们的值保留在内核堆栈中。&lt;/p&gt;

&lt;p&gt;执行进程切换
进程切换可能只发生在精心定义的点：schedule()函数，这个函数很长，会在以后更长的篇幅里讲解。。这里，只关注内核如何执行一个进程切换。&lt;/p&gt;

&lt;p&gt;进程切换由两步组成：&lt;/p&gt;

&lt;p&gt;切换页全局目录以安装一个新的地址空间。
切换内核态堆栈和硬件上下文，因为硬件上下文提供了内核执行新进程所需要的所有信息，包含CPU寄存器。
switch_to宏
进程切换的第二步由switch_to宏执行。它是内核中与硬件关系最为密切的例程之一，必须下很多功夫了解。&lt;/p&gt;

&lt;p&gt;&amp;lt;include/asm-generic/system.h&amp;gt;
/* context switching is now performed out-of-line in switch_to.S */
extern struct task_struct *__switch_to(struct task_struct *,
        struct task_struct *);
#define switch_to(prev, next, last)\
    do {\
        ((last) = __switch_to((prev), (next)));\
    } while (0)
首先，该宏有三个参数，prev、next和last，prev和next的作用仅是局部变量prev和next的占位符，即它们是输入参数，分别表示被替换进程和新进程描述符的地址在内存中的位置。&lt;/p&gt;

&lt;p&gt;在任何进程切换中，涉及到的是三个进程而不是两个。假设内核决定暂停进程A而激活进程B，在schedule()函数中，prev指向A的描述符，而next指向B的进程描述符。switch_to宏一旦使A暂停，A的执行流就被冻结。&lt;/p&gt;

&lt;p&gt;随后，当内核想再次激活A，就必须暂停另一个进程C，因为这通常不是B，因为B有可能被其他进程比如C切换。于是就要用prev指向C而next指向A来执行另一个switch_to宏。当A恢复它执行的流时，就会找到它原来的内核栈，于是prev局部变量还是指向A的描述符而next指向B的描述符。此时，代表进程A执行的内核就失去了对C的任何引用。但引用对于完成进程切换是有用的，所以需要保留。&lt;/p&gt;

&lt;p&gt;switch_to宏的最后一个参数是输出参数，它表示宏把进程C的描述符地址写在内存的什么位置了，不过，这个是在恢复A执行之后完成的。在进程切换之前，宏把第一个输入参数prev表示的变量存入CPU的eax寄存器。在完成进程切换，A已经恢复执行时，宏把CPU的eax寄存器的内容写入由第三个参数last所指示的A在内存中的位置。因为CPU寄存器不会在切换点发生变化，所以C的描述符地址也存在内存的这个位置。在schedule()执行过程中，last参数指向A的局部变量prev，所以prev被C的地址覆盖。&lt;/p&gt;

&lt;p&gt;__switch_to()函数
__switch_to()函数执行大多数开始于switch_to()宏的进程切换。这个函数作用于prev_p和next_p参数，这两个参数表示前一个进程和新进程。这个函数的调用不同于一般的函数调用。因为__switch_to()从eax和edx取参数prev_p和next_p，而不像大多数函数一样从栈中取参数。&lt;/p&gt;

&lt;p&gt;&amp;lt;arch/x86/kernel/process_32.c&amp;gt;
__switch_to(
    struct task_struct *prev_p,
    struct task_struct *next_p)
{
    struct thread_struct *prev = &amp;amp;prev_p-&amp;gt;thread,
                 *next = &amp;amp;next_p-&amp;gt;thread;
    int cpu = smp_processor_id();
    struct tss_struct *tss = &amp;amp;per_cpu(init_tss, cpu);
    bool preload_fpu;&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;preload_fpu = tsk_used_math(next_p) &amp;amp;&amp;amp; next_p-&amp;gt;fpu_counter &amp;gt; 5;

__unlazy_fpu(prev_p);

if (preload_fpu)
    prefetch(next-&amp;gt;xstate);

load_sp0(tss, next);

lazy_save_gs(prev-&amp;gt;gs);

load_TLS(next, cpu);

if (get_kernel_rpl() &amp;amp;&amp;amp; unlikely(prev-&amp;gt;iopl != next-&amp;gt;iopl))
    set_iopl_mask(next-&amp;gt;iopl);

if (unlikely(task_thread_info(prev_p)-&amp;gt;flags 
    &amp;amp; _TIF_WORK_CTXSW_PREV
    || task_thread_info(next_p)-&amp;gt;flags
    &amp;amp; _TIF_WORK_CTXSW_NEXT))
    __switch_to_xtra(prev_p, next_p, tss);

if (preload_fpu)
    clts();

arch_end_context_switch(next_p);

if (preload_fpu)
    __math_state_restore();
if (prev-&amp;gt;gs | next-&amp;gt;gs)
    lazy_load_gs(next-&amp;gt;gs);

percpu_write(current_task, next_p);

return prev_p; } 这个函数执行步骤如下：
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;执行由__unlay_fpu()宏代码产生的代码，以有选择地保存prev_p进程的FPU、MMX以及XMM寄存器的内容。&lt;/p&gt;

&lt;p&gt;执行smp_processor_id()宏获得本地CPU的下表，即执行代码的CPU。该宏从当前进程的thread_info结构的cpu字段获得下标并保存到cpu局部变量。&lt;/p&gt;

&lt;p&gt;把next_p-&amp;gt;thread.esp0装入对应于本地CPU的TSS的esp0字段。其实，任何由sysenter汇编指令产生的从用户态到内核态的特权级转换将把这个地址拷贝到esp寄存器中。&lt;/p&gt;

&lt;p&gt;把next_p进程使用的线程局部存储（TLS）段装载入本地CPU的全局描述符表。&lt;/p&gt;

&lt;p&gt;把fs和gs段寄存器的内容分别存放在prev_p-&amp;gt;thread.fs和prev_p-&amp;gt;thread.gs中。esi寄存器指向prev_p-&amp;gt;thread结构。&lt;/p&gt;

&lt;p&gt;如果fs或gs段寄存器已经被prev_p或next_p进程中的任意一个使用，则将next_p进程的thread_struct描述符中保存的值装入这些寄存器。&lt;/p&gt;

&lt;p&gt;用next_p-&amp;gt;thread.debugreg数组内容装载dr0…dr7中的6个调试寄存器。只有在next_p被挂起时正在使用调试寄存器，这种操作才能进行。&lt;/p&gt;

&lt;p&gt;如果必要，则更新TSS中的I/O位图。然后终止，prev_p参数被拷贝到eax，因为缺省情况下任何C函数的返回值被传给eax寄存器。所以eax的值在调用__switch_to()的过程中被保护起来；这很重要，因为调用该函数时会假定eax总是用来存放将被替换的进程描述符地址。&lt;/p&gt;

&lt;p&gt;汇编语言指令ret把栈定保存的返回地址装入eip程序计数器。不过，__swtich_to()函数时通过简单的跳转被调用的。因此，ret汇编指令在栈中找到标号为1的指令地址，其中标号为1的地址是由switch_to()宏推入堆栈的。&lt;/p&gt;
</description>
        <pubDate>Sun, 24 Dec 2017 00:00:00 +0800</pubDate>
        <link>https://xiazemin.github.io/MyBlog/linux/2017/12/24/thread.html</link>
        <guid isPermaLink="true">https://xiazemin.github.io/MyBlog/linux/2017/12/24/thread.html</guid>
        
        
        <category>linux</category>
        
      </item>
    
      <item>
        <title>IO多路复用之select、poll、epoll</title>
        <description>&lt;!-- more --&gt;
&lt;pre&gt;&lt;code&gt; 目前支持I/O多路复用的系统调用有 select，pselect，poll，epoll，I/O多路复用就是通过一种机制，一个进程可以监视多个描述符，一旦某个描述符就绪（一般是读就绪或者写就绪），能够通知程序进行相应的读写操作。但select，pselect，poll，epoll本质上都是同步I/O，因为他们都需要在读写事件就绪后自己负责进行读写，也就是说这个读写过程是阻塞的，而异步I/O则无需自己负责进行读写，异步I/O的实现会负责把数据从内核拷贝到用户空间。
 与多进程和多线程技术相比，I/O多路复用技术的最大优势是系统开销小，系统不必创建进程/线程，也不必维护这些进程/线程，从而大大减小了系统的开销。
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;一、使用场景
IO多路复用是指内核一旦发现进程指定的一个或者多个IO条件准备读取，它就通知该进程。IO多路复用适用如下场合：
　　1）当客户处理多个描述符时（一般是交互式输入和网络套接口），必须使用I/O复用。
　　2）当一个客户同时处理多个套接口时，这种情况是可能的，但很少出现。
　　3）如果一个TCP服务器既要处理监听套接口，又要处理已连接套接口，一般也要用到I/O复用。
　　4）如果一个服务器即要处理TCP，又要处理UDP，一般要使用I/O复用。
　　5）如果一个服务器要处理多个服务或多个协议，一般要使用I/O复用。&lt;/p&gt;

&lt;p&gt;二、select、poll、epoll简介
　　epoll跟select都能提供多路I/O复用的解决方案。在现在的Linux内核里有都能够支持，其中epoll是Linux所特有，而select则应该是POSIX所规定，一般操作系统均有实现。
1、select
基本原理：select 函数监视的文件描述符分3类，分别是writefds、readfds、和exceptfds。调用后select函数会阻塞，直到有描述符就绪（有数据 可读、可写、或者有except），或者超时（timeout指定等待时间，如果立即返回设为null即可），函数返回。当select函数返回后，可以通过遍历fdset，来找到就绪的描述符。&lt;/p&gt;

&lt;p&gt;基本流程，如图所示：
	&lt;img src=&quot;https://xiazemin.github.io/MyBlog/img/ioMutex.png&quot; /&gt;&lt;/p&gt;

&lt;p&gt;　　select目前几乎在所有的平台上支持，其良好跨平台支持也是它的一个优点。select的一个缺点在于单个进程能够监视的文件描述符的数量存在最大限制，在Linux上一般为1024，可以通过修改宏定义甚至重新编译内核的方式提升这一限制，但是这样也会造成效率的降低。&lt;/p&gt;

&lt;p&gt;select本质上是通过设置或者检查存放fd标志位的数据结构来进行下一步处理。这样所带来的缺点是：
1、select最大的缺陷就是单个进程所打开的FD是有一定限制的，它由FD_SETSIZE设置，默认值是1024。
　　一般来说这个数目和系统内存关系很大，具体数目可以cat /proc/sys/fs/file-max察看。32位机默认是1024个。64位机默认是2048.
2、对socket进行扫描时是线性扫描，即采用轮询的方法，效率较低。
　　当套接字比较多的时候，每次select()都要通过遍历FD_SETSIZE个Socket来完成调度，不管哪个Socket是活跃的，都遍历一遍。这会浪费很多CPU时间。如果能给套接字注册某个回调函数，当他们活跃时，自动完成相关操作，那就避免了轮询，这正是epoll与kqueue做的。
3、需要维护一个用来存放大量fd的数据结构，这样会使得用户空间和内核空间在传递该结构时复制开销大。&lt;/p&gt;

&lt;p&gt;2、poll
基本原理：poll本质上和select没有区别，它将用户传入的数组拷贝到内核空间，然后查询每个fd对应的设备状态，如果设备就绪则在设备等待队列中加入一项并继续遍历，如果遍历完所有fd后没有发现就绪设备，则挂起当前进程，直到设备就绪或者主动超时，被唤醒后它又要再次遍历fd。这个过程经历了多次无谓的遍历。&lt;/p&gt;

&lt;p&gt;它没有最大连接数的限制，原因是它是基于链表来存储的，但是同样有一个缺点：
1）大量的fd的数组被整体复制于用户态和内核地址空间之间，而不管这样的复制是不是有意义。
2）poll还有一个特点是“水平触发”，如果报告了fd后，没有被处理，那么下次poll时会再次报告该fd。&lt;/p&gt;

&lt;p&gt;注意：从上面看，select和poll都需要在返回后，通过遍历文件描述符来获取已经就绪的socket。事实上，同时连接的大量客户端在一时刻可能只有很少的处于就绪状态，因此随着监视的描述符数量的增长，其效率也会线性下降。&lt;/p&gt;

&lt;p&gt;3、epoll
　　epoll是在2.6内核中提出的，是之前的select和poll的增强版本。相对于select和poll来说，epoll更加灵活，没有描述符限制。epoll使用一个文件描述符管理多个描述符，将用户关系的文件描述符的事件存放到内核的一个事件表中，这样在用户空间和内核空间的copy只需一次。&lt;/p&gt;

&lt;p&gt;基本原理：epoll支持水平触发和边缘触发，最大的特点在于边缘触发，它只告诉进程哪些fd刚刚变为就绪态，并且只会通知一次。还有一个特点是，epoll使用“事件”的就绪通知方式，通过epoll_ctl注册fd，一旦该fd就绪，内核就会采用类似callback的回调机制来激活该fd，epoll_wait便可以收到通知。&lt;/p&gt;

&lt;p&gt;epoll的优点：
1、没有最大并发连接的限制，能打开的FD的上限远大于1024（1G的内存上能监听约10万个端口）。
2、效率提升，不是轮询的方式，不会随着FD数目的增加效率下降。
　　只有活跃可用的FD才会调用callback函数；即Epoll最大的优点就在于它只管你“活跃”的连接，而跟连接总数无关，因此在实际的网络环境中，Epoll的效率就会远远高于select和poll。
3、内存拷贝，利用mmap()文件映射内存加速与内核空间的消息传递；即epoll使用mmap减少复制开销。&lt;/p&gt;

&lt;p&gt;epoll对文件描述符的操作有两种模式：LT（level trigger）和ET（edge trigger）。LT模式是默认模式，LT模式与ET模式的区别如下：
LT模式：当epoll_wait检测到描述符事件发生并将此事件通知应用程序，应用程序可以不立即处理该事件。下次调用epoll_wait时，会再次响应应用程序并通知此事件。
ET模式：当epoll_wait检测到描述符事件发生并将此事件通知应用程序，应用程序必须立即处理该事件。如果不处理，下次调用epoll_wait时，不会再次响应应用程序并通知此事件。
1、LT模式
　　LT(level triggered)是缺省的工作方式，并且同时支持block和no-block socket。在这种做法中，内核告诉你一个文件描述符是否就绪了，然后你可以对这个就绪的fd进行IO操作。如果你不作任何操作，内核还是会继续通知你的。
2、ET模式
　　ET(edge-triggered)是高速工作方式，只支持no-block socket。在这种模式下，当描述符从未就绪变为就绪时，内核通过epoll告诉你。然后它会假设你知道文件描述符已经就绪，并且不会再为那个文件描述符发送更多的就绪通知，直到你做了某些操作导致那个文件描述符不再为就绪状态了(比如，你在发送，接收或者接收请求，或者发送接收的数据少于一定量时导致了一个EWOULDBLOCK 错误）。但是请注意，如果一直不对这个fd作IO操作(从而导致它再次变成未就绪)，内核不会发送更多的通知(only once)。
　　ET模式在很大程度上减少了epoll事件被重复触发的次数，因此效率要比LT模式高。epoll工作在ET模式的时候，必须使用非阻塞套接口，以避免由于一个文件句柄的阻塞读/阻塞写操作把处理多个文件描述符的任务饿死。
3、在select/poll中，进程只有在调用一定的方法后，内核才对所有监视的文件描述符进行扫描，而epoll事先通过epoll_ctl()来注册一个文件描述符，一旦基于某个文件描述符就绪时，内核会采用类似callback的回调机制，迅速激活这个文件描述符，当进程调用epoll_wait()时便得到通知。(此处去掉了遍历文件描述符，而是通过监听回调的的机制。这正是epoll的魅力所在。)
注意：如果没有大量的idle-connection或者dead-connection，epoll的效率并不会比select/poll高很多，但是当遇到大量的idle-connection，就会发现epoll的效率大大高于select/poll。&lt;/p&gt;

&lt;p&gt;三、select、poll、epoll区别
1、支持一个进程所能打开的最大连接数
 	&lt;img src=&quot;https://xiazemin.github.io/MyBlog/img/selectPoolConnect.png&quot; /&gt;
2、FD剧增后带来的IO效率问题
 	&lt;img src=&quot;https://xiazemin.github.io/MyBlog/img/selectPollFd.png&quot; /&gt;
3、消息传递方式
 	&lt;img src=&quot;https://xiazemin.github.io/MyBlog/img/selectPollMmap.png&quot; /&gt;&lt;/p&gt;

&lt;p&gt;综上，在选择select，poll，epoll时要根据具体的使用场合以及这三种方式的自身特点：
1、表面上看epoll的性能最好，但是在连接数少并且连接都十分活跃的情况下，select和poll的性能可能比epoll好，毕竟epoll的通知机制需要很多函数回调。
2、select低效是因为每次它都需要轮询。但低效也是相对的，视情况而定，也可通过良好的设计改善。&lt;/p&gt;

&lt;p&gt;select() 在BSD中被引入，而poll()是SysV STREAM流控制的产物。因此，这里就有了平台移植上的考虑：纯粹的BSD系统可 能仍然缺少poll()，而早一些的SVR3系统中可能没有select()，尽管在SVR4中将其加入。目前两者都是POSIX. 1g标准，（译者 注：因此在Linux上两者都存在）&lt;/p&gt;

&lt;p&gt;select()和poll()本质上来讲做的是同一件事，只是完成的方法不一样。两者都通过检验一组文件描述符来检测是否有特定的时间将在上面发生并在一定的时间内等待其发生。&lt;/p&gt;

&lt;p&gt;[重要事项：无论select()还是poll()都不对普通文件起很大效用，它们着重用于套接口(socket)、管道(pipe)、伪终端(pty)、终端设备(tty)和其他一些字符设备，但是这些操作都是系统相关(system-dependent)的。]&lt;/p&gt;

&lt;p&gt;select()函数的接口主要是建立在一种叫’fd_set’类型的基础上。它(‘fd_set’) 是一组文件描述符(fd)的集合。由于fd_set类型的长度在不同平台上不同，因此应该用一组标准的宏定义来处理此类变量：&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;fd_set set;
FD_ZERO(&amp;amp;set);       /* 将set清零 */
FD_SET(fd, &amp;amp;set);    /* 将fd加入set */
FD_CLR(fd, &amp;amp;set);    /* 将fd从set中清除 */
FD_ISSET(fd, &amp;amp;set);  /* 如果fd在set中则真　*/
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;在 过去，一个fd_set通常只能包含少于等于32个文件描述符，因为fd_set其实只用了一个int的比特矢量来实现，在大多数情况下，检查 fd_set能包括任意值的文件描述符是系统的责任，但确定你的fd_set到底能放多少有时你应该检查/修改宏FD_SETSIZE的值。&lt;em&gt;这个值是系 统相关的&lt;/em&gt;，同时检查你的系统中的select() 的man手册。有一些系统对多于1024个文件描述符的支持有问题。[译者注： Linux就是这样 的系统！你会发现sizeof(fd_set)的结果是128(*8 = FD_SETSIZE=1024)　尽管很少你会遇到这种情况。]&lt;/p&gt;

&lt;p&gt;select的基本接口十分简单：&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;int select(int nfds, fd_set *readset, fd_set *writeset,
           fd_set *exceptset, struct timeval *timeout);
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;其中：&lt;/p&gt;

&lt;p&gt;nfds   &lt;br /&gt;
     需要检查的文件描述符个数，数值应该比是三组fd_set中最大数
     更大，而不是实际文件描述符的总数。
readset  &lt;br /&gt;
     用来检查可读性的一组文件描述符。
writeset
     用来检查可写性的一组文件描述符。
exceptset
     用来检查意外状态的文件描述符。(注：错误并不是意外状态)
timeout
     NULL指针代表无限等待，否则是指向timeval结构的指针，代表最
     长等待时间。(如果其中tv_sec和tv_usec都等于0, 则文件描述符
     的状态不被影响，但函数并不挂起)&lt;/p&gt;

&lt;p&gt;函数将返回响应操作的对应操作文件描述符的总数，且三组数据均在恰当位置被修改，只有响应操作的那一些没有修改。接着应该用FD_ISSET宏来查找返回的文件描述符组。&lt;/p&gt;

&lt;p&gt;poll ()接受一个指向结构’struct pollfd’列表的指针，其中包括了你想测试的文件描述符和事件。事件由一个在结构中事件域的比特掩码确定。当前 的结构在调用后将被填写并在事件发生后返回。在SVR4(可能更早的一些版本)中的 “poll.h”文件中包含了用于确定事件的一些宏定义。事件的等待 时间精确到毫秒 (但令人困惑的是等待时间的类型却是int)，当等待时间为0时，poll()函数立即返回，-1则使poll()一直挂起直到一个指定 事件发生。下面是pollfd的结构。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt; struct pollfd {
     int fd;        /* 文件描述符 */
     short events;  /* 等待的事件 */
     short revents; /* 实际发生了的事件 */
 };
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;于select()十分相似，当返回正值时，代表满足响应事件的文件描述符的个数，如果返回0则代表在规定事件内没有事件发生。如发现返回为负则应该立即查看 errno，因为这代表有错误发生。&lt;/p&gt;

&lt;p&gt;如果没有事件发生，revents会被清空，所以你不必多此一举。&lt;/p&gt;
</description>
        <pubDate>Sun, 24 Dec 2017 00:00:00 +0800</pubDate>
        <link>https://xiazemin.github.io/MyBlog/linux/2017/12/24/select_poll.html</link>
        <guid isPermaLink="true">https://xiazemin.github.io/MyBlog/linux/2017/12/24/select_poll.html</guid>
        
        
        <category>linux</category>
        
      </item>
    
  </channel>
</rss>
