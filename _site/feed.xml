<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>泽民博客</title>
    <description>夏泽民的个人主页，学习笔记。</description>
    <link>https://xiazemin.github.io/MyBlog/</link>
    <atom:link href="https://xiazemin.github.io/MyBlog/feed.xml" rel="self" type="application/rss+xml"/>
    <pubDate>Sun, 11 Feb 2018 21:06:49 +0800</pubDate>
    <lastBuildDate>Sun, 11 Feb 2018 21:06:49 +0800</lastBuildDate>
    <generator>Jekyll v3.6.0.pre.beta1</generator>
    
      <item>
        <title>netty</title>
        <description>&lt;!-- more --&gt;
&lt;p&gt;1.为什么选择Netty
Socket通信（IO/NIO/AIO）编程仅仅是一个模型，如果想把这些真正的用于实际工作中，那么还需要不断的完善、扩展和优化。比如经典的TCP读包写包问题，或者是数据接收的大小，实际的通信处理与应答的处理逻辑等等一些细节问题需要认真的去思考，而这些都需要大量的时间和经历，以及丰富的经验。所以想学好Socket通信不是件容易事，那么接下来就来学习一下新的技术Netty，为什么会选择Netty？因为它简单！使用Netty不必编写复杂的逻辑代码去实现通信，再也不需要去考虑性能问题，不需要考虑编码问题，半包读写等问题。强大的Netty已经帮我们实现好了，我们只需要使用即可。&lt;/p&gt;

&lt;p&gt;Netty是最流行的NIO框架，它的健壮性、功能、性能、可定制性和可扩展性在同类框架都是首屈一指的。它已经得到成百上千的商业/商用项目验证，如Hadoop的RPC框架Avro、RocketMQ以及主流的分布式通信框架Dubbox等等。&lt;/p&gt;

&lt;p&gt;2.Netty简介&lt;/p&gt;

&lt;p&gt;Netty是基于Java NIO client-server的网络应用框架，使用Netty可以快速开发网络应用，例如服务器和客户端协议。Netty提供了一种新的方式来开发网络应用程序，这种新的方式使它很容易使用和具有很强的扩展性。Netty的内部实现是很复杂的，但是Netty提供了简单易用的API从网络处理代码中解耦业务逻辑。Netty是完全基于NIO实现的，所以整个Netty都是异步的。&lt;/p&gt;

&lt;p&gt;网络应用程序通常需要有较高的可扩展性，无论是Netty还是其他的基于Java Nio的框架，都会提供可扩展性的解决方案。Netty中一个关键组成部分是它的异步特性，本片文章将讨论同步（阻塞）和异步（非阻塞）的IO来说明为什么使用异步代码解决扩展性问题以及如何使用异步。&lt;/p&gt;

&lt;p&gt;3.Netty架构组成（借用一下网上的图片）&lt;/p&gt;

&lt;p&gt;Netty实现原理浅析，写的很不错，感兴趣的可以看一下。&lt;/p&gt;

&lt;p&gt;4.Helloworld入门&lt;/p&gt;

&lt;p&gt;在学习Netty之前，先来回顾一下NIO的通信步骤：&lt;/p&gt;

&lt;p&gt;①创建ServerSocketChannel，为其配置非阻塞模式。&lt;/p&gt;

&lt;p&gt;②绑定监听，配置TCP参数，录入backlog大小等。&lt;/p&gt;

&lt;p&gt;③创建一个独立的IO线程，用于轮询多路复用器Selector。&lt;/p&gt;

&lt;p&gt;④创建Selector，将之前创建的ServerSocketChannel注册到Selector上，并设置监听标识位SelectionKey.OP_ACCEPT。&lt;/p&gt;

&lt;p&gt;⑤启动IO线程，在循环体中执行Selector.select()方法，轮询就绪的通道。&lt;/p&gt;

&lt;p&gt;⑥当轮询到处于就绪状态的通道时，需要进行操作位判断，如果是ACCEPT状态，说明是新的客户端接入，则调用accept方法接收新的客户端。&lt;/p&gt;

&lt;p&gt;⑦设置新接入客户端的一些参数，如非阻塞，并将其继续注册到Selector上，设置监听标识位等。&lt;/p&gt;

&lt;p&gt;⑧如果轮询的通道标识位是READ，则进行读取，构造Buffer对象等。&lt;/p&gt;

&lt;p&gt;⑨更细节的问题还有数据没发送完成继续发送的问题……&lt;/p&gt;

&lt;p&gt;好啦，开始学习Netty了。先去http://netty.io/上下载所有的Netty包。&lt;/p&gt;

&lt;p&gt;Netty通信的步骤：&lt;/p&gt;

&lt;p&gt;①创建两个NIO线程组，一个专门用于网络事件处理（接受客户端的连接），另一个则进行网络通信的读写。&lt;/p&gt;

&lt;p&gt;②创建一个ServerBootstrap对象，配置Netty的一系列参数，例如接受传出数据的缓存大小等。&lt;/p&gt;

&lt;p&gt;③创建一个用于实际处理数据的类ChannelInitializer，进行初始化的准备工作，比如设置接受传出数据的字符集、格式以及实际处理数据的接口。&lt;/p&gt;

&lt;p&gt;④绑定端口，执行同步阻塞方法等待服务器端启动即可。&lt;/p&gt;

&lt;p&gt;强烈推荐读一读Netty官方翻译文档。&lt;/p&gt;

&lt;p&gt;好了，说了那么多，下面就来HelloWorld入门吧！&lt;/p&gt;

&lt;p&gt;服务器端：&lt;/p&gt;

&lt;p&gt;[java] view plain copy print?
public class Server {&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;private int port;  
  
public Server(int port) {  
    this.port = port;  
}  
  
public void run() {  
    EventLoopGroup bossGroup = new NioEventLoopGroup(); //用于处理服务器端接收客户端连接  
    EventLoopGroup workerGroup = new NioEventLoopGroup(); //进行网络通信（读写）  
    try {  
        ServerBootstrap bootstrap = new ServerBootstrap(); //辅助工具类，用于服务器通道的一系列配置  
        bootstrap.group(bossGroup, workerGroup) //绑定两个线程组  
                .channel(NioServerSocketChannel.class) //指定NIO的模式  
                .childHandler(new ChannelInitializer&amp;lt;SocketChannel&amp;gt;() { //配置具体的数据处理方式  
                    @Override  
                    protected void initChannel(SocketChannel socketChannel) throws Exception {  
                        socketChannel.pipeline().addLast(new ServerHandler());  
                    }  
                })  
                /** 
                 * 对于ChannelOption.SO_BACKLOG的解释： 
                 * 服务器端TCP内核维护有两个队列，我们称之为A、B队列。客户端向服务器端connect时，会发送带有SYN标志的包（第一次握手），服务器端 
                 * 接收到客户端发送的SYN时，向客户端发送SYN ACK确认（第二次握手），此时TCP内核模块把客户端连接加入到A队列中，然后服务器接收到 
                 * 客户端发送的ACK时（第三次握手），TCP内核模块把客户端连接从A队列移动到B队列，连接完成，应用程序的accept会返回。也就是说accept 
                 * 从B队列中取出完成了三次握手的连接。 
                 * A队列和B队列的长度之和就是backlog。当A、B队列的长度之和大于ChannelOption.SO_BACKLOG时，新的连接将会被TCP内核拒绝。 
                 * 所以，如果backlog过小，可能会出现accept速度跟不上，A、B队列满了，导致新的客户端无法连接。要注意的是，backlog对程序支持的 
                 * 连接数并无影响，backlog影响的只是还没有被accept取出的连接 
                 */  
                .option(ChannelOption.SO_BACKLOG, 128) //设置TCP缓冲区  
                .option(ChannelOption.SO_SNDBUF, 32 * 1024) //设置发送数据缓冲大小  
                .option(ChannelOption.SO_RCVBUF, 32 * 1024) //设置接受数据缓冲大小  
                .childOption(ChannelOption.SO_KEEPALIVE, true); //保持连接  
        ChannelFuture future = bootstrap.bind(port).sync();  
        future.channel().closeFuture().sync();  
    } catch (Exception e) {  
        e.printStackTrace();  
    } finally {  
        workerGroup.shutdownGracefully();  
        bossGroup.shutdownGracefully();  
    }  
}  
  
public static void main(String[] args) {  
    new Server(8379).run();  
}   }  
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;ServerHandler类：&lt;/p&gt;

&lt;p&gt;[java] view plain copy print?
public class ServerHandler  extends ChannelHandlerAdapter {&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;@Override  
public void channelRead(ChannelHandlerContext ctx, Object msg) throws Exception {  
  
        //do something msg  
        ByteBuf buf = (ByteBuf)msg;  
        byte[] data = new byte[buf.readableBytes()];  
        buf.readBytes(data);  
        String request = new String(data, &quot;utf-8&quot;);  
        System.out.println(&quot;Server: &quot; + request);  
        //写给客户端  
        String response = &quot;我是反馈的信息&quot;;  
        ctx.writeAndFlush(Unpooled.copiedBuffer(&quot;888&quot;.getBytes()));  
        //.addListener(ChannelFutureListener.CLOSE);  
          
  
}  
  
@Override  
public void exceptionCaught(ChannelHandlerContext ctx, Throwable cause) throws Exception {  
    cause.printStackTrace();  
    ctx.close();  
}  
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;}&lt;/p&gt;

&lt;p&gt;客户端：&lt;/p&gt;

&lt;p&gt;[java] view plain copy print?
public class Client {&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;public static void main(String[] args) throws InterruptedException {  
    EventLoopGroup workerGroup = new NioEventLoopGroup();  
    Bootstrap bootstrap = new Bootstrap();  
    bootstrap.group(workerGroup)  
            .channel(NioSocketChannel.class)  
            .handler(new ChannelInitializer&amp;lt;SocketChannel&amp;gt;() {  
                @Override  
                protected void initChannel(SocketChannel socketChannel) throws Exception {  
                    socketChannel.pipeline().addLast(new ClientHandler());  
                }  
            });  
    ChannelFuture future = bootstrap.connect(&quot;127.0.0.1&quot;, 8379).sync();  
    future.channel().writeAndFlush(Unpooled.copiedBuffer(&quot;777&quot;.getBytes()));  
    future.channel().closeFuture().sync();  
    workerGroup.shutdownGracefully();  
}  
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;}&lt;/p&gt;

&lt;p&gt;ClientHandler类：
[java] view plain copy print?
public class ClientHandler extends ChannelHandlerAdapter {&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;@Override  
public void channelRead(ChannelHandlerContext ctx, Object msg) throws Exception {  
    try {  
        ByteBuf buf = (ByteBuf) msg;  
        byte[] data = new byte[buf.readableBytes()];  
        buf.readBytes(data);  
        System.out.println(&quot;Client：&quot; + new String(data).trim());  
    } finally {  
        ReferenceCountUtil.release(msg);  
    }  
}  
  
  
@Override  
public void exceptionCaught(ChannelHandlerContext ctx, Throwable cause) throws Exception {  
    cause.printStackTrace();  
    ctx.close();  
}  
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;}&lt;/p&gt;

&lt;p&gt;运行结果：&lt;/p&gt;

&lt;p&gt;5.TCP粘包、拆包问题&lt;/p&gt;

&lt;p&gt;熟悉TCP编程的可能都知道，无论是服务器端还是客户端，当我们读取或者发送数据的时候，都需要考虑TCP底层的粘包/拆包机制。&lt;/p&gt;

&lt;p&gt;TCP是一个“流”协议，所谓流就是没有界限的遗传数据。大家可以想象一下，如果河水就好比数据，他们是连成一片的，没有分界线，TCP底层并不了解上层业务数据的具体含义，它会根据TCP缓冲区的具体情况进行包的划分，也就是说，在业务上一个完整的包可能会被TCP分成多个包进行发送，也可能把多个小包封装成一个大的数据包发送出去，这就是所谓的粘包/拆包问题。&lt;/p&gt;

&lt;p&gt;解决方案：&lt;/p&gt;

&lt;p&gt;①消息定长，例如每个报文的大小固定为200个字节，如果不够，空位补空格。&lt;/p&gt;

&lt;p&gt;②在包尾部增加特殊字符进行分割，例如加回车等。&lt;/p&gt;

&lt;p&gt;③将消息分为消息头和消息体，在消息头中包含表示消息总长度的字段，然后进行业务逻辑的处理。&lt;/p&gt;

&lt;p&gt;Netty中解决TCP粘包/拆包的方法：&lt;/p&gt;

&lt;p&gt;①分隔符类：DelimiterBasedFrameDecoder（自定义分隔符）&lt;/p&gt;

&lt;p&gt;②定长：FixedLengthFrameDecoder&lt;/p&gt;

&lt;p&gt;6.Netty编解码技术&lt;/p&gt;

&lt;p&gt;通常我们也习惯将编码（Encode）成为序列化，它将数据序列化为字节数组，用于网络传输、数据持久化或者其他用途。反之，解码（Decode）/反序列化（deserialization）&lt;/p&gt;

&lt;p&gt;把从网络、磁盘等读取的字节数组还原成原始对象（通常是原始对象的拷贝），以方便后续的业务逻辑操作。进行远程跨进程服务调用时（例如RPC调用），需要使用特定的编解码技术，对需要进行网络传输的对象做编码或者解码，以便完成远程调用。&lt;/p&gt;

&lt;p&gt;主流的编解码框架：&lt;/p&gt;

&lt;p&gt;①JBoss的Marshalling包&lt;/p&gt;

&lt;p&gt;②google的Protobuf&lt;/p&gt;

&lt;p&gt;③基于Protobuf的Kyro&lt;/p&gt;

&lt;p&gt;④MessagePack框架&lt;/p&gt;

&lt;p&gt;上代码，一读就懂，注意红色字体部分。&lt;/p&gt;

&lt;p&gt;服务器端：&lt;/p&gt;

&lt;p&gt;public class Server {&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;public Server(int port) {

    EventLoopGroup bossGroup = newNioEventLoopGroup();

    EventLoopGroup workerGroup = newNioEventLoopGroup();

    try {

        ServerBootstrap bootstrap = newServerBootstrap();

        bootstrap.group(bossGroup, workerGroup)

               .channel(NioServerSocketChannel.class)

                .handler(newLoggingHandler(LogLevel.INFO))

                .childHandler(newChannelInitializer&amp;lt;SocketChannel&amp;gt;() {

                    @Override

                    protected voidinitChannel(SocketChannel socketChannel) throws Exception {

                        socketChannel.pipeline().addLast(MarshallingCodeCFactory.buildMarshallingDecoder());

                        socketChannel.pipeline().addLast(MarshallingCodeCFactory.buildMarshallingEncoder());

                       socketChannel.pipeline().addLast(new ServerHandler());

                    }

                })

                .option(ChannelOption.SO_BACKLOG,1024)

               .option(ChannelOption.SO_RCVBUF, 32 * 1024)

               .option(ChannelOption.SO_SNDBUF, 32 * 1024)

               .option(ChannelOption.SO_KEEPALIVE, true);

        ChannelFuture future = bootstrap.bind(port).sync();

       future.channel().closeFuture().sync();

    } catch (Exception e) {

        e.printStackTrace();

    } finally {

        bossGroup.shutdownGracefully();

        workerGroup.shutdownGracefully();

    }

}

 

public static void main(String[] args) {

    new Server(8765);

}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;}&lt;/p&gt;

&lt;p&gt;ServerHandler类：&lt;/p&gt;

&lt;p&gt;public classServerHandler extends ChannelHandlerAdapter {&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;@Override

public voidexceptionCaught(ChannelHandlerContext ctx, Throwable cause) throws Exception {

    cause.printStackTrace();

    ctx.close();

}

 

@Override

public voidchannelActive(ChannelHandlerContext ctx) throws Exception {

    super.channelActive(ctx);

}

 

@Override

public void channelRead(ChannelHandlerContextctx, Object msg) throws Exception {

    Request request = (Request) msg;

    System.out.println(&quot;Server:&quot;+ request.getId() + &quot;,&quot; + request.getName() + &quot;,&quot; +request.getReqeustMessag());

 

    Response response = new Response();

    response.setId(request.getId());

    response.setName(&quot;response &quot;+ request.getId());

    response.setResponseMessage(&quot;响应内容：&quot; +request.getReqeustMessag());

    byte[] unGizpData =GzipUtils.unGzip(request.getAttachment());

    char separator = File.separatorChar;

    FileOutputStream outputStream = newFileOutputStream(System.getProperty(&quot;user.dir&quot;) + separator +&quot;recieve&quot; + separator + &quot;1.png&quot;);

    outputStream.write(unGizpData);

    outputStream.flush();

    outputStream.close();

    ctx.writeAndFlush(response);

}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;}&lt;/p&gt;

&lt;p&gt;客户端：&lt;/p&gt;

&lt;p&gt;public class Client {&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;public static void main(String[] args) {

    EventLoopGroup workerGroup = newNioEventLoopGroup();

    try {

        Bootstrap bootstrap = new Bootstrap();

        bootstrap.group(workerGroup)

                .handler(newLoggingHandler(LogLevel.INFO))

               .channel(NioSocketChannel.class)

                .handler(newChannelInitializer&amp;lt;SocketChannel&amp;gt;() {

                    @Override

                    protected voidinitChannel(SocketChannel socketChannel) throws Exception {

                        socketChannel.pipeline().addLast(MarshallingCodeCFactory.buildMarshallingEncoder());

                        socketChannel.pipeline().addLast(MarshallingCodeCFactory.buildMarshallingDecoder());

                       socketChannel.pipeline().addLast(new ClientHandler());

                    }

                });

        ChannelFuture future =bootstrap.connect(new InetSocketAddress(&quot;127.0.01&quot;, 8765)).sync();

        for(int i=1; i&amp;lt;=5; i++) {

            Request request = newRequest();

            request.setId(i);

            request.setName(&quot;pro&quot;+ i);

           request.setReqeustMessag(&quot;数据信息&quot; + i);

            //传输图片

            char separator =File.separatorChar;

            File file = newFile(System.getProperty(&quot;user.dir&quot;) + separator + &quot;source&quot;+ separator + &quot;2.jpg&quot;);

            FileInputStream inputStream = newFileInputStream(file);

            byte[] data = newbyte[inputStream.available()];

            inputStream.read(data);

            inputStream.close();

            byte[] gzipData =GzipUtils.gzip(data);

           request.setAttachment(gzipData);

           future.channel().writeAndFlush(request);

        }

 

       future.channel().closeFuture().sync();

    } catch (Exception e) {

        e.printStackTrace();

    } finally {

        workerGroup.shutdownGracefully();

    }

}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;}&lt;/p&gt;

&lt;p&gt;ClientHandler类：&lt;/p&gt;

&lt;p&gt;public classClientHandler extends ChannelHandlerAdapter {&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;@Override

public voidexceptionCaught(ChannelHandlerContext ctx, Throwable cause) throws Exception {

    super.exceptionCaught(ctx, cause);

}

 

@Override

public voidchannelActive(ChannelHandlerContext ctx) throws Exception {

    super.channelActive(ctx);

}

 

@Override

public voidchannelRead(ChannelHandlerContext ctx, Object msg) throws Exception {

    Response response = (Response) msg;

    System.out.println(&quot;Client:&quot;+ response.getId() + &quot;,&quot; + response.getName() + &quot;,&quot; +response.getResponseMessage());

}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;}&lt;/p&gt;

&lt;p&gt;Marshalling工具类：&lt;/p&gt;

&lt;p&gt;public final classMarshallingCodeCFactory {&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;/**

 * 创建Jboss Marshalling解码器MarshallingDecoder

 * @return MarshallingDecoder

 */

public static MarshallingDecoderbuildMarshallingDecoder() {

      //首先通过Marshalling工具类的精通方法获取Marshalling实例对象 参数serial标识创建的是java序列化工厂对象。

              final MarshallerFactorymarshallerFactory =Marshalling.getProvidedMarshallerFactory(&quot;serial&quot;);

              //创建了MarshallingConfiguration对象，配置了版本号为5

              final MarshallingConfigurationconfiguration = new MarshallingConfiguration();

              configuration.setVersion(5);

              //根据marshallerFactory和configuration创建provider

              UnmarshallerProvider provider= new DefaultUnmarshallerProvider(marshallerFactory, configuration);

              //构建Netty的MarshallingDecoder对象，俩个参数分别为provider和单个消息序列化后的最大长度

              MarshallingDecoder decoder =new MarshallingDecoder(provider, 1024 * 1024);

              return decoder;

}

 

/**

 * 创建Jboss Marshalling编码器MarshallingEncoder

 * @return MarshallingEncoder

 */

public static MarshallingEncoderbuildMarshallingEncoder() {

              final MarshallerFactorymarshallerFactory =Marshalling.getProvidedMarshallerFactory(&quot;serial&quot;);

              final MarshallingConfigurationconfiguration = new MarshallingConfiguration();

              configuration.setVersion(5);

              MarshallerProvider provider =new DefaultMarshallerProvider(marshallerFactory, configuration);

              //构建Netty的MarshallingEncoder对象，MarshallingEncoder用于实现序列化接口的POJO对象序列化为二进制数组

              MarshallingEncoder encoder =new MarshallingEncoder(provider);

              return encoder;

}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;}&lt;/p&gt;

&lt;p&gt;Gizp压缩与解压缩工具类：&lt;/p&gt;

&lt;p&gt;public classGzipUtils {&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;public static byte[] gzip(byte[] val)throws IOException {

    ByteArrayOutputStream bos = newByteArrayOutputStream(val.length);

    GZIPOutputStream gos = null;

    try {

        gos = new GZIPOutputStream(bos);

        gos.write(val, 0, val.length);

        gos.finish();

        gos.flush();

        bos.flush();

        val = bos.toByteArray();

    } finally {

        if (gos != null)

            gos.close();

        if (bos != null)

            bos.close();

    }

    return val;

}

 

public static byte[] unGzip(byte[] buf)throws IOException {

    GZIPInputStream gzi = null;

    ByteArrayOutputStream bos = null;

    try {

        gzi = new GZIPInputStream(newByteArrayInputStream(buf));

        bos = newByteArrayOutputStream(buf.length);

        int count = 0;

        byte[] tmp = new byte[2048];

        while ((count = gzi.read(tmp)) !=-1) {

            bos.write(tmp, 0, count);

        }

        buf = bos.toByteArray();

    } finally {

        if (bos != null) {

            bos.flush();

            bos.close();

        }

        if (gzi != null)

            gzi.close();

    }

    return buf;

}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;}&lt;/p&gt;

&lt;p&gt;7.最佳实践&lt;/p&gt;

&lt;p&gt;（1）数据通信&lt;/p&gt;

&lt;p&gt;我们需要了解在真正项目中如何使用Netty，大体上对于一些参数设置都是根据服务器性能决定的。我们需要考虑的问题是两台机器（甚至多台）使用Netty怎样进行通信。&lt;/p&gt;

&lt;p&gt;大体上分为三种：
     ①使用长连接通道不断开的形式进行通信，也就是服务器和客户端的通道一直处于开启状态，如果服务器性能足够好，并且客户端数量也比较上的情况下，推荐这种方式。
     ②一次性批量提交数据，采用短连接方式。也就是说先把数据保存到本地临时缓存区或者临时表，当达到界值时进行一次性批量提交，又或者根据定时任务轮询提交，&lt;/p&gt;

&lt;p&gt;这种情况的弊端是做不到实时性传输，对实时性要求不高的应用程序中推荐使用。
     ③使用一种特殊的长连接，在某一指定时间段内，服务器与某台客户端没有任何通信，则断开连接。下次连接则是客户端向服务器发送请求的时候，再次建立连接。
     在这里将介绍使用Netty实现第三种方式的连接，但是我们需要考虑两个因素：
     ①如何在超时（即服务器和客户端没有任何通信）后关闭通道？关闭通道后又如何再次建立连接？
     ②客户端宕机时，我们无需考虑，下次重启客户端之后就可以与服务器建立连接，但服务器宕机时，客户端如何与服务器端通信？&lt;/p&gt;

&lt;p&gt;服务器端：增加了红色框部分&lt;/p&gt;

&lt;p&gt;客户端（注意红色字体部分）：&lt;/p&gt;

&lt;p&gt;public class Client {&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;private static class SingleHodler {

    static final Client client = newClient();

}

 

public static Client getInstance() {

    return SingleHodler.client;

}

 

private EventLoopGroup workerGroup;

private Bootstrap bootstrap;

private ChannelFuture future;

 

private Client() {

    workerGroup = new NioEventLoopGroup();

    bootstrap = new Bootstrap();

    bootstrap.group(workerGroup)

           .channel(NioSocketChannel.class)

            .handler(newChannelInitializer&amp;lt;SocketChannel&amp;gt;() {

                @Override

                protected voidinitChannel(SocketChannel socketChannel) throws Exception {

                   socketChannel.pipeline().addLast(MarshallingCodeCFactory.buildMarshallingEncoder());

                   socketChannel.pipeline().addLast(MarshallingCodeCFactory.buildMarshallingDecoder());

                    socketChannel.pipeline().addLast(newReadTimeoutHandler(5)); //5秒后未与服务器通信，则断开连接。

                   socketChannel.pipeline().addLast(new ClientHandler());

                }

            });

}

 

public void connect() {

    try {

        future =bootstrap.connect(&quot;127.0.0.1&quot;, 8765).sync();

    } catch (InterruptedException e) {

        e.printStackTrace();

    }

}

 

public ChannelFuture getFuture() {

    if(future == null ||!future.channel().isActive()) {

        this.connect();

    }

    return future;

}

 

public static void main(String[] args)throws InterruptedException {

    Client client = getInstance();

    ChannelFuture future = client.getFuture();

 

    for(int i=1; i&amp;lt;=3; i++) {

        Message message = new Message(i,&quot;pro&quot; + i, &quot;数据信息&quot; + i);

       future.channel().writeAndFlush(message);

        Thread.sleep(4000);  //休眠4秒后再发送数据

    }

 

    future.channel().closeFuture().sync();

 

    new Thread(() -&amp;gt; {

        try {

            System.out.println(&quot;子线程开始....&quot;);

            ChannelFuture f =client.getFuture();

            Message message = newMessage(4, &quot;pro&quot; + 4, &quot;数据信息&quot; + 4);

            f.channel().writeAndFlush(message);

           f.channel().closeFuture().sync();

        } catch (Exception e) {

            e.printStackTrace();

        }

    }).start();

 

    System.out.println(&quot;主线程退出......&quot;);

}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;}&lt;/p&gt;

&lt;p&gt;其他的类与之前的一样，没有变化。&lt;/p&gt;

&lt;p&gt;运行结果：&lt;/p&gt;

&lt;p&gt;（2）心跳检测&lt;/p&gt;

&lt;p&gt;我们使用Socket通信一般经常会处理多个服务器之间的心跳检测，一般来讲我们去维护服务器集群，肯定要有一台或多台服务器主机（Master），然后还应该有N台（Slave），那么我们的主机肯定要时时刻刻知道自己下面的从服务器的各方面情况，然后进行实时监控的功能。这个在分布式架构里交做心跳检测或者心跳监控。最佳处理方案是使用一些通信框架进行实现，Netty就可以做这样的事。&lt;/p&gt;

&lt;p&gt;这个例子需要使用Sigar，不熟悉的可以看这篇文章。&lt;/p&gt;

&lt;p&gt;Server&lt;/p&gt;

&lt;p&gt;public class Server {&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;public Server(int port) {

    EventLoopGroup bossGroup = newNioEventLoopGroup();

    EventLoopGroup workerGroup = newNioEventLoopGroup();

    try {

        ServerBootstrap bootstrap = newServerBootstrap();

        bootstrap.group(bossGroup,workerGroup)

               .channel(NioServerSocketChannel.class)

                .childHandler(newChannelInitializer&amp;lt;SocketChannel&amp;gt;() {

                    @Override

                    protected voidinitChannel(SocketChannel sc) throws Exception {

                       sc.pipeline().addLast(MarshallingCodeCFactory.buildMarshallingEncoder());

                        sc.pipeline().addLast(MarshallingCodeCFactory.buildMarshallingDecoder());

                       sc.pipeline().addLast(new ServerHeartBeatHandler());

                    }

                })

                .handler(newLoggingHandler(LogLevel.INFO))

               .option(ChannelOption.SO_BACKLOG, 1024);

        ChannelFuture future =bootstrap.bind(new InetSocketAddress(&quot;127.0.0.1&quot;, port)).sync();

       future.channel().closeFuture().sync();

    } catch (Exception e) {

        e.printStackTrace();

    } finally {

        bossGroup.shutdownGracefully();

        workerGroup.shutdownGracefully();

    }

}

 

public static void main(String[] args) {

    new Server(8765);

}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;}&lt;/p&gt;

&lt;p&gt;ServerHeartBeatHandler类：&lt;/p&gt;

&lt;p&gt;public classServerHeartBeatHandler extends ChannelHandlerAdapter {&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;private static Map&amp;lt;String, String&amp;gt;AUTH_IP_MAP = new HashMap&amp;lt;&amp;gt;();

private static final String SUCCESS_KEY =&quot;auth_success_key&quot;;

 

static {

    AUTH_IP_MAP.put(&quot;192.168.3.176&quot;,&quot;1234&quot;);

}

 

private boolean auth(ChannelHandlerContextctx, Object msg) {

    String[] rets = ((String)msg).split(&quot;,&quot;);

    String auth = AUTH_IP_MAP.get(rets[0]);

    if(auth != null &amp;amp;&amp;amp;auth.equals(rets[1])) {

        ctx.writeAndFlush(SUCCESS_KEY);

        return true;

    } else {

        ctx.writeAndFlush(&quot;authfailure!&quot;).addListener(ChannelFutureListener.CLOSE);

        return false;

    }

}

 

@Override

public void channelRead(ChannelHandlerContextctx, Object msg) throws Exception {

    if(msg instanceof String) {

        auth(ctx, msg);

    } else if(msg instanceof RequestInfo) {

        RequestInfo info = (RequestInfo)msg;

        System.out.println(&quot;----------------------------------------------&quot;);

        System.out.println(&quot;当前主机ip：&quot; +info.getIp());

        System.out.println(&quot;当前主机cpu：情况&quot;);

        Map&amp;lt;String, Object&amp;gt; cpuMap =info.getCpuPercMap();

        System.out.println(&quot;总使用率：&quot; +  cpuMap.get(&quot;combined&quot;));

        System.out.println(&quot;用户使用率：&quot; +cpuMap.get(&quot;user&quot;));

        System.out.println(&quot;系统使用率：&quot; +cpuMap.get(&quot;sys&quot;));

        System.out.println(&quot;等待率：&quot; +cpuMap.get(&quot;wait&quot;));

        System.out.println(&quot;空闲率：&quot; +cpuMap.get(&quot;idle&quot;));

        System.out.println(&quot;当前主机memory情况：&quot;);

        Map&amp;lt;String, Object&amp;gt; memMap =info.getMemoryMap();

        System.out.println(&quot;内存总量：&quot; +memMap.get(&quot;total&quot;));

        System.out.println(&quot;当前内存使用量：&quot; +memMap.get(&quot;used&quot;));

        System.out.println(&quot;当前内存剩余量：&quot; +memMap.get(&quot;free&quot;));

       System.out.println(&quot;-----------------------------------------------&quot;);

        ctx.writeAndFlush(&quot;inforeceived!&quot;);

    } else {

        ctx.writeAndFlush(&quot;connectfailure&quot;).addListener(ChannelFutureListener.CLOSE);

    }

}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;}&lt;/p&gt;

&lt;p&gt;Client类：&lt;/p&gt;

&lt;p&gt;public class Client {&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;public static void main(String[] args) {

    EventLoopGroup workerGroup = newNioEventLoopGroup();

    try {

        Bootstrap bootstrap = newBootstrap();

        bootstrap.group(workerGroup)

               .channel(NioSocketChannel.class)

                .handler(newChannelInitializer&amp;lt;SocketChannel&amp;gt;() {

                    @Override

                    protected void initChannel(SocketChannelsc) throws Exception {

                       sc.pipeline().addLast(MarshallingCodeCFactory.buildMarshallingDecoder());

                       sc.pipeline().addLast(MarshallingCodeCFactory.buildMarshallingEncoder());

                       sc.pipeline().addLast(new ClientHeartBeatHandler());

                    }

                });

        ChannelFuture future =bootstrap.connect(new InetSocketAddress(&quot;127.0.0.1&quot;, 8765)).sync();

        future.channel().closeFuture().sync();

    } catch (Exception e) {

        e.printStackTrace();

    } finally {

        workerGroup.shutdownGracefully();

    }

}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;}&lt;/p&gt;

&lt;p&gt;ClientHeartBeatHandler类：&lt;/p&gt;

&lt;p&gt;public classClientHeartBeatHandler extends ChannelHandlerAdapter {&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;private ScheduledExecutorService scheduled= Executors.newScheduledThreadPool(1);

private ScheduledFuture&amp;lt;?&amp;gt; heartBeat;

private InetAddress address;

private static final String SUCCESS_KEY =&quot;auth_success_key&quot;;

 

@Override

public voidchannelActive(ChannelHandlerContext ctx) throws Exception {

    address = InetAddress.getLocalHost();

    String ip = address.getHostAddress();

    String key = &quot;1234&quot;;

    String auth = ip + &quot;,&quot; + key;

    ctx.writeAndFlush(auth);

}

 

@Override

public voidexceptionCaught(ChannelHandlerContext ctx, Throwable cause) throws Exception {

    cause.printStackTrace();

    if(heartBeat != null) {

        heartBeat.cancel(true);

        heartBeat = null;

    }

    ctx.fireExceptionCaught(cause);

}

 

@Override

public voidchannelRead(ChannelHandlerContext ctx, Object msg) throws Exception {

    try {

        if(msg instanceof String) {

            String data = (String) msg;

            if(SUCCESS_KEY.equals(data)) {

                heartBeat =scheduled.scheduleWithFixedDelay(new HeartBeatTask(ctx), 0, 5,TimeUnit.SECONDS);

                System.out.println(msg);

            } else {

                System.out.println(msg);

            }

        }

    } finally {

        ReferenceCountUtil.release(msg);

    }

}

 

private class HeartBeatTask implements Runnable{

    private final ChannelHandlerContextctx;

 

    publicHeartBeatTask(ChannelHandlerContext ctx) {

        this.ctx = ctx;

    }

 

    @Override

    public void run() {

        try {

            RequestInfo requestInfo = newRequestInfo();

           requestInfo.setIp(address.getHostAddress());

            Sigar sigar = new Sigar();

            CpuPerc cpuPerc =sigar.getCpuPerc();

            Map&amp;lt;String, Object&amp;gt;cpuPercMap = new HashMap&amp;lt;&amp;gt;();

            cpuPercMap.put(&quot;combined&quot;,cpuPerc.getCombined());

           cpuPercMap.put(&quot;user&quot;, cpuPerc.getUser());

            cpuPercMap.put(&quot;sys&quot;,cpuPerc.getSys());

           cpuPercMap.put(&quot;wait&quot;, cpuPerc.getWait());

            cpuPercMap.put(&quot;idle&quot;,cpuPerc.getIdle());

 

            Mem mem = sigar.getMem();

            Map&amp;lt;String, Object&amp;gt;memoryMap = new HashMap&amp;lt;&amp;gt;();

           memoryMap.put(&quot;total&quot;, mem.getTotal() / (1024 * 1024));

            memoryMap.put(&quot;used&quot;,mem.getUsed() / (1024 * 1024));

            memoryMap.put(&quot;free&quot;,mem.getFree() / (1024 * 1024));

 

           requestInfo.setCpuPercMap(cpuPercMap);

           requestInfo.setMemoryMap(memoryMap);

 

            ctx.writeAndFlush(requestInfo);

        } catch (Exception e) {

            e.printStackTrace();

        }

    }

}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;}&lt;/p&gt;

&lt;p&gt;RequestInfo类：&lt;/p&gt;

&lt;p&gt;public classRequestInfo implements Serializable {&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;     private String ip ;

     private Map&amp;lt;String, Object&amp;gt;cpuPercMap ;

     private Map&amp;lt;String, Object&amp;gt;memoryMap;

     //.. other field

 

     public String getIp() {

              return ip;

     }

 

     public void setIp(String ip) {

              this.ip = ip;

     }

 

     public Map&amp;lt;String, Object&amp;gt;getCpuPercMap() {

              return cpuPercMap;

     }

 

     public voidsetCpuPercMap(Map&amp;lt;String, Object&amp;gt; cpuPercMap) {

              this.cpuPercMap = cpuPercMap;

     }

 

     public Map&amp;lt;String, Object&amp;gt;getMemoryMap() {

              return memoryMap;

     }

 

     public void setMemoryMap(Map&amp;lt;String,Object&amp;gt; memoryMap) {

              this.memoryMap = memoryMap;

     }
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;}&lt;/p&gt;

&lt;p&gt;MarshallingCodeCFactory类就不贴出来了，跟之前的一样。
每5秒发送一次数据到服务器端，这样主服务器就可以知道每台从服务器的状态了。当然，这只是一个简单的小例子，真实环境中肯定需要更严格的校验。&lt;/p&gt;

&lt;p&gt;作者：郭无心
链接：https://www.zhihu.com/question/24322387/answer/78947405
来源：知乎
著作权归作者所有。商业转载请联系作者获得授权，非商业转载请注明出处。&lt;/p&gt;

&lt;p&gt;Netty是什么？1）本质：JBoss做的一个Jar包2）目的：快速开发高性能、高可靠性的网络服务器和客户端程序3）优点：提供异步的、事件驱动的网络应用程序框架和工具通俗的说：一个好使的处理Socket的东东如果没有Netty？远古：java.net + java.io
近代：java.nio
其他：Mina，Grizzly
与Mina相比有什么优势？1、都是Trustin Lee的作品，Netty更晚；2、Mina将内核和一些特性的联系过于紧密，使得用户在不需要这些特性的时候无法脱离，相比下性能会有所下降，Netty解决了这个设计问题；3、Netty的文档更清晰，很多Mina的特性在Netty里都有；4、Netty更新周期更短，新版本的发布比较快；5、它们的架构差别不大，Mina靠apache生存，而Netty靠jboss，和jboss的结合度非常高，Netty有对google protocal buf的支持，有更完整的ioc容器支持(spring,guice,jbossmc和osgi)；6、Netty比Mina使用起来更简单，Netty里你可以自定义的处理upstream events 或/和 downstream events，可以使用decoder和encoder来解码和编码发送内容；7、Netty和Mina在处理UDP时有一些不同，Netty将UDP无连接的特性暴露出来；而Mina对UDP进行了高级层次的抽象，可以把UDP当成”面向连接”的协议，而要Netty做到这一点比较困难。—————————————————————————————————————————————–Netty的特性1）设计统一的API，适用于不同的协议（阻塞和非阻塞）基于灵活、可扩展的事件驱动模型高度可定制的线程模型可靠的无连接数据Socket支持（UDP）2）性能更好的吞吐量，低延迟更省资源尽量减少不必要的内存拷贝3）安全完整的SSL/TLS和STARTTLS的支持能在Applet与Android的限制环境运行良好4）健壮性不再因过快、过慢或超负载连接导致OutOfMemoryError不再有在高速网络环境下NIO读写频率不一致的问题5）易用完善的JavaDoc，用户指南和样例简洁简单仅信赖于JDK1.5——————————————————————————————————————————————-Netty 在哪些行业得到了应用？互联网行业：随着网站规模的不断扩大，系统并发访问量也越来越高，传统基于 Tomcat 等 Web 容器的垂直架构已经无法满足需求，需要拆分应用进行服务化，以提高开发和维护效率。从组网情况看，垂直的架构拆分之后，系统采用分布式部署，各个节点之间需要远程服务调用，高性能的 RPC 框架必不可少，Netty 作为异步高性能的通信框架，往往作为基础通信组件被这些 RPC 框架使用。　　典型的应用有：阿里分布式服务框架 Dubbo 的 RPC 框架使用 Dubbo 协议进行节点间通信，Dubbo 协议默认使用 Netty 作为基础通信组件，用于实现各进程节点之间的内部通信。
    服务提供者和服务消费者之间，服务提供者、服务消费者和性能统计节点之间使用 Netty 进行异步/同步通信。　　除了 Dubbo 之外，淘宝的消息中间件 RocketMQ 的消息生产者和消息消费者之间，也采用 Netty 进行高性能、异步通信。　　除了阿里系和淘宝系之外，很多其它的大型互联网公司或者电商内部也已经大量使用 Netty 构建高性能、分布式的网络服务器。游戏行业：无论是手游服务端、还是大型的网络游戏，Java 语言得到了越来越广泛的应用。Netty 作为高性能的基础通信组件，它本身提供了 TCP/UDP 和 HTTP 协议栈，非常方便定制和开发私有协议栈。账号登陆服务器、地图服务器之间可以方便的通过 Netty 进行高性能的通信，架构示意图如下：&lt;img src=&quot;https://pic2.zhimg.com/50/9adabad98edc4b4e9001e2fc63d6da87_hd.jpg&quot; data-rawwidth=&quot;494&quot; data-rawheight=&quot;196&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;494&quot; data-original=&quot;https://pic2.zhimg.com/9adabad98edc4b4e9001e2fc63d6da87_r.jpg&quot; /&gt;　　图1-2 Netty 在游戏服务器架构中的应用大数据领域：经典的 Hadoop 的高性能通信和序列化组件 Avro 的 RPC 框架，默认采用 Netty 进行跨节点通信，它的 Netty Service 基于 Netty 框架二次封装实现。　　大数据计算往往采用多个计算节点和一个/N个汇总节点进行分布式部署，各节点之间存在海量的数据交换。由于 Netty 的综合性能是目前各个成熟 NIO 框架中最高的，因此，往往会被选中用作大数据各节点间的通信。企业软件：企业和 IT 集成需要 ESB，Netty 对多协议支持、私有协议定制的简洁性和高性能是 ESB RPC 框架的首选通信组件。事实上，很多企业总线厂商会选择 Netty 作为基础通信组件，用于企业的 IT 集成。通信行业：Netty 的异步高性能、高可靠性和高成熟度的优点，使它在通信行业得到了大量的应用。&lt;/p&gt;

&lt;p&gt;作者：知乎用户
链接：https://www.zhihu.com/question/24322387/answer/282001188
来源：知乎
著作权归作者所有。商业转载请联系作者获得授权，非商业转载请注明出处。&lt;/p&gt;

&lt;p&gt;作为一个学Java的，如果没有研究过Netty，那么你对Java语言的使用和理解仅仅停留在表面水平，会点SSH，写几个MVC，访问数据库和缓存，这些只是初等Java程序员干的事。如果你要进阶，想了解Java服务器的深层高阶知识，Netty绝对是一个必须要过的门槛。有了Netty，你可以实现自己的HTTP服务器，FTP服务器，UDP服务器，RPC服务器，WebSocket服务器，Redis的Proxy服务器，MySQL的Proxy服务器等等。如果你想知道Nginx是怎么写出来的，如果你想知道Tomcat和Jetty是如何实现的，如果你也想实现一个简单的Redis服务器，那都应该好好理解一下Netty，它们高性能的原理都是类似的。我们回顾一下传统的HTTP服务器的原理创建一个ServerSocket，监听并绑定一个端口一系列客户端来请求这个端口服务器使用Accept，获得一个来自客户端的Socket连接对象启动一个新线程处理连接读Socket，得到字节流解码协议，得到Http请求对象处理Http请求，得到一个结果，封装成一个HttpResponse对象编码协议，将结果序列化字节流写Socket，将字节流发给客户端继续循环步骤3HTTP服务器之所以称为HTTP服务器，是因为编码解码协议是HTTP协议，如果协议是Redis协议，那它就成了Redis服务器，如果协议是WebSocket，那它就成了WebSocket服务器，等等。使用Netty你就可以定制编解码协议，实现自己的特定协议的服务器。上面我们说的是一个传统的多线程服务器，这个也是Apache处理请求的模式。在高并发环境下，线程数量可能会创建太多，操作系统的任务调度压力大，系统负载也会比较高。那怎么办呢？于是NIO诞生了，NIO并不是Java独有的概念，NIO代表的一个词汇叫着IO多路复用。它是由操作系统提供的系统调用，早期这个操作系统调用的名字是select，但是性能低下，后来渐渐演化成了Linux下的epoll和Mac里的kqueue。我们一般就说是epoll，因为没有人拿苹果电脑作为服务器使用对外提供服务。而Netty就是基于Java NIO技术封装的一套框架。为什么要封装，因为原生的Java NIO使用起来没那么方便，而且还有臭名昭著的bug，Netty把它封装之后，提供了一个易于操作的使用模式和接口，用户使用起来也就便捷多了。那NIO究竟是什么东西呢？NIO的全称是NoneBlocking IO，非阻塞IO，区别与BIO，BIO的全称是Blocking IO，阻塞IO。那这个阻塞是什么意思呢？Accept是阻塞的，只有新连接来了，Accept才会返回，主线程才能继Read是阻塞的，只有请求消息来了，Read才能返回，子线程才能继续处理Write是阻塞的，只有客户端把消息收了，Write才能返回，子线程才能继续读取下一个请求所以传统的多线程服务器是BlockingIO模式的，从头到尾所有的线程都是阻塞的。这些线程就干等在哪里，占用了操作系统的调度资源，什么事也不干，是浪费。那么NIO是怎么做到非阻塞的呢。它用的是事件机制。它可以用一个线程把Accept，读写操作，请求处理的逻辑全干了。如果什么事都没得做，它也不会死循环，它会将线程休眠起来，直到下一个事件来了再继续干活，这样的一个线程称之为NIO线程。while true {
    events = takeEvents(fds)  // 获取事件，如果没有事件，线程就休眠
    for event in events {
        if event.isAcceptable {
            doAccept() // 新链接来了
        } elif event.isReadable {
            request = doRead() // 读消息
            if request.isComplete() {
                doProcess()
            }
        } elif event.isWriteable {
            doWrite()  // 写消息
        }
    }
}
NIO的流程大致就是上面的伪代码描述的过程，跟实际真实的代码有较多差异，不过对于初学者，这样理解也是足够了。Netty是建立在NIO基础之上，Netty在NIO之上又提供了更高层次的抽象。在Netty里面，Accept连接可以使用单独的线程池去处理，读写操作又是另外的线程池来处理。Accept连接和读写操作也可以使用同一个线程池来进行处理。而请求处理逻辑既可以使用单独的线程池进行处理，也可以跟放在读写线程一块处理。线程池中的每一个线程都是NIO线程。用户可以根据实际情况进行组装，构造出满足系统需求的并发模型。Netty提供了内置的常用编解码器，包括行编解码器［一行一个请求］，前缀长度编解码器［前N个字节定义请求的字节长度］，可重放解码器［记录半包消息的状态］，HTTP编解码器，WebSocket消息编解码器等等Netty提供了一些列生命周期回调接口，当一个完整的请求到达时，当一个连接关闭时，当一个连接建立时，用户都会收到回调事件，然后进行逻辑处理。Netty可以同时管理多个端口，可以使用NIO客户端模型，这些对于RPC服务是很有必要的。Netty除了可以处理TCP Socket之外，还可以处理UDP Socket。在消息读写过程中，需要大量使用ByteBuffer，Netty对ByteBuffer在性能和使用的便捷性上都进行了优化和抽象。总之，Netty是Java程序员进阶的必备神奇。如果你知其然，还想知其所以然，一定要好好研究下Netty。如果你觉得Java枯燥无谓，Netty则是重新开启你对Java兴趣大门的钥匙。&lt;/p&gt;
</description>
        <pubDate>Sat, 10 Feb 2018 00:00:00 +0800</pubDate>
        <link>https://xiazemin.github.io/MyBlog/web/2018/02/10/netty.html</link>
        <guid isPermaLink="true">https://xiazemin.github.io/MyBlog/web/2018/02/10/netty.html</guid>
        
        
        <category>web</category>
        
      </item>
    
      <item>
        <title>Tachyon</title>
        <description>&lt;p&gt;Tachyon是分布式文件系统，也就是说Tachyon实现了文件的存储结构，比如inode节点，数据block，以及文件查询的API，比如某个文件在哪个block上面，并且能以文件流的形式对数据进行读写，可以理解为这个是和NTFS、EXT4这些进行比较的，只是Tacyon的数据都放在内存中，不在硬盘中，快快快！而Redis就是个内存数据库，是的，是个数据库，数据库是构建在存储系统之上的，Redis用了内存和文件系统，和Tachyon不在一个层次上。Redis和Tachyon都是可以作为分布式cache层对系统进行加速，唯一不同在于Redis是kv接口，Tachyon是文件系统接口&lt;/p&gt;

&lt;p&gt;Tachyon是Spark生态系统内快速崛起的一个新项目。 本质上， Tachyon是个分布式的内存文件系统， 它在减轻Spark内存压力的同时，也赋予了Spark内存快速大量数据读写的能力。Tachyon把内存存储的功能从Spark中分离出来， 使Spark可以更专注计算的本身， 以求通过更细的分工达到更高的执行效率。 本文将先向读者介绍Tachyon在Spark生态系统中的使用， 也将分享百度在大数据平台上利用Tachyon取得的性能改善的用例，以及在实际使用Tachyon过程中遇到的一些问题和解决方案。最后我们将介绍一下Tachyon的一些新功能。&lt;/p&gt;

&lt;p&gt;Tachyon简介
Spark平台以分布式内存计算的模式达到更高的计算性能，在最近引起了业界的广泛关注，其开源社区也十分活跃。以百度为例，在百度内部计算平台已经搭建并运行了千台规模的Spark计算集群，百度也通过其BMR的开放云平台对外提供Spark计算平台服务。然而，分布式内存计算的模式也是一柄双刃剑，在提高性能的同时不得不面对分布式数据存储所产生的问题，具体问题主要有以下几个：&lt;/p&gt;

&lt;p&gt;当两个Spark作业需要共享数据时，必须通过写磁盘操作。比如：作业1要先把生成的数据写入HDFS，然后作业2再从HDFS把数据读出来。在此，磁盘的读写可能造成性能瓶颈。
由于Spark会利用自身的JVM对数据进行缓存，当Spark程序崩溃时，JVM进程退出，所缓存数据也随之丢失，因此在工作重启时又需要从HDFS把数据再次读出。
当两个Spark作业需操作相同的数据时，每个作业的JVM都需要缓存一份数据，不但造成资源浪费，也极易引发频繁的垃圾收集，造成性能的降低。
仔细分析这些问题后，可以确认问题的根源来自于数据存储，由于计算平台尝试自行进行存储管理，以至于Spark不能专注于计算本身，造成整体执行效率的降低。Tachyon的提出就是为了解决这些问题：本质上，Tachyon是个分布式的内存文件系统，它在减轻Spark内存压力的同时赋予了Spark内存快速大量数据读写的能力。Tachyon把存储与数据读写的功能从Spark中分离，使得Spark更专注在计算的本身，以求通过更细的分工达到更高的执行效率。
&lt;img src=&quot;https://xiazemin.github.io/MyBlog/img/Tachyon1.jpg&quot; /&gt;
图1: Tachyon的部署&lt;/p&gt;

&lt;p&gt;图1显示了Tachyon的部署结构。Tachyon被部署在计算平台（Spark，MR）之下以及存储平台（HDFS， S3）之上，通过全局地隔离计算平台与存储平台， Tachyon可以有效地解决上文列举的几个问题，：&lt;/p&gt;

&lt;p&gt;当两个Spark作业需要共享数据时，无需再通过写磁盘，而是借助Tachyon进行内存读写，从而提高计算效率。
在使用Tachyon对数据进行缓存后，即便在Spark程序崩溃JVM进程退出后，所缓存数据也不会丢失。这样，Spark工作重启时可以直接从Tachyon内存读取数据了。
当两个Spark作业需要操作相同的数据时，它们可以直接从Tachyon获取，并不需要各自缓存一份数据，从而降低JVM内存压力，减少垃圾收集发生的频率。
Tachyon系统架构
在上一章我们介绍了Tachyon的设计，本章我们来简单看看Tachyon的系统架构以及实现。 图2显示了Tachyon在Spark平台的部署：总的来说，Tachyon有三个主要的部件：Master， Client，与Worker。在每个Spark Worker节点上，都部署了一个Tachyon Worker，Spark Worker通过Tachyon Client访问Tachyon进行数据读写。所有的Tachyon Worker都被Tachyon Master所管理，Tachyon Master通过Tachyon Worker定时发出的心跳来判断Worker是否已经崩溃以及每个Worker剩余的内存空间量。
	&lt;img src=&quot;https://xiazemin.github.io/MyBlog/img/Tachyon2.jpg&quot; /&gt;
图2: Tachyon在Spark平台的部署&lt;/p&gt;

&lt;p&gt;图3显示了Tachyon Master的结构，其主要功能如下：首先，Tachyon Master是个主管理器，处理从各个Client发出的请求，这一系列的工作由Service Handler来完成。这些请求包括：获取Worker的信息，读取File的Block信息， 创建File等等；其次，Tachyon Master是个Name Node，存放着所有文件的信息，每个文件的信息都被封装成一个Inode，每个Inode都记录着属于这个文件的所有Block信息。在Tachyon中，Block是文件系统存储的最小单位，假设每个Block是256MB，如果有一个文件的大小是1GB，那么这个文件会被切为4个Block。每个Block可能存在多个副本，被存储在多个Tachyon Worker中，因此Master里面也必须记录每个Block被存储的Worker地址；第三，Tachyon Master同时管理着所有的Worker，Worker会定时向Master发送心跳通知本次活跃状态以及剩余存储空间。Master是通过Master Worker Info去记录每个Worker的上次心跳时间，已使用的内存空间，以及总存储空间等信息。 
	&lt;img src=&quot;https://xiazemin.github.io/MyBlog/img/Tachyon3.jpg&quot; /&gt;
	图3: Tachyon的Master设计&lt;/p&gt;

&lt;p&gt;图4显示了Tachyon Worker的结构，它主要负责存储管理：首先，Tachyon Worker的Service Handler处理来自Client发来的请求，这些请求包括：读取某个Block的信息，缓存某个Block，锁住某个Block，向本地内存存储要求空间等等。第二，Tachyon Worker的主要部件是Worker Storage，其作用是管理Local Data（本地的内存文件系统）以及Under File System（Tachyon以下的磁盘文件系统，比如HDFS）。第三，Tachyon Worker还有个Data Server以便处理其他的Client对其发起的数据读写请求。当由请求达到时，Tachyon会先在本地的内存存储找数据，如果没有找到则会尝试去其他的Tachyon Worker的内存存储中进行查找。如果数据完全不在Tachyon里，则需要通过Under File System的接口去磁盘文件系统（HDFS）中读取。
	&lt;img src=&quot;https://xiazemin.github.io/MyBlog/img/Tachyon4.jpg&quot; /&gt;
	图4: Tachyon的Worker设计&lt;/p&gt;

&lt;p&gt;图5显示了Tachyon Client的结构，它主要功能是向用户抽象一个文件系统接口以屏蔽掉底层实现细节。首先，Tachyon Client会通过Master Client部件跟Tachyon Master交互，比如可以向Tachyon Master查询某个文件的某个Block在哪里。Tachyon Client也会通过Worker Client部件跟Tachyon Worker交互， 比如向某个Tachyon Worker请求存储空间。在Tachyon Client实现中最主要的是Tachyon File这个部件。在Tachyon File下实现了Block Out Stream，其主要用于写本地内存文件；实现了Block In Stream主要负责读内存文件。在Block In Stream内包含了两个不同的实现：Local Block In Stream主要是用来读本地的内存文件，而Remote Block In Stream主要是读非本地的内存文件。请注意，非本地可以是在其它的Tachyon Worker的内存文件里，也可以是在Under File System的文件里。
	&lt;img src=&quot;https://xiazemin.github.io/MyBlog/img/Tachyon5.jpg&quot; /&gt;
图5: Tachyon的Client设计&lt;/p&gt;

&lt;p&gt;现在我们通过一个简单的场景把各个部件都串起来：假设一个Spark作业发起了一个读请求，它首先会通过Tachyon Client去Tachyon Master查询所需要的Block所在的位置。如果所在的Block不在本地的Tachyon Worker里，此Client则会通过Remote Block In Stream向别的Tachyon Worker发出读请求，同时在Block读入的过程中，Client也会通过Block Out Stream把Block写入到本地的内存存储里，这样就可以保证下次同样的请求可以由本机完成。&lt;/p&gt;

&lt;p&gt;Tachyon在百度内部的使用
在百度内部，我们使用Spark SQL进行大数据分析工作, 由于Spark是个基于内存的计算平台，我们预计绝大部分的数据查询应该在几秒或者十几秒完成以达到互动查询的目的。可是在Spark计算平台的运行中，我们却发现查询都需要上百秒才能完成，其原因如图6所示：我们的计算资源(Data Center 1)与数据仓库(Data Center 2)可能并不在同一个数据中心里面，在这种情况下，我们每一次数据查询都可能需要从远端的数据中心读取数据，由于数据中心间的网络带宽以及延时的问题，导致每次查询都需要较长的时间（&amp;gt;100秒）才能完成。更糟糕的是，很多查询的重复性很高，同样的数据很可能会被查询多次，如果每次都从远端的数据中心读取，必然造成资源浪费。&lt;/p&gt;

&lt;p&gt;为了解决这个问题，我们借助Tachyon把数据缓存在本地，尽量避免跨数据中心调数据。当Tachyon被部署到Spark所在的数据中心后，每次数据冷查询时，我们还是从远端数据仓库拉数据，但是当数据再次被查询时，Spark将从同一数据中心的Tachyon中读取数据，从而提高查询性能。实验表明：如果从非本机的Tachyon读取数据，耗时降到10到15秒，比原来的性能提高了10倍；最好的情况下，如果从本机的Tachyon读数据，查询仅需5秒，比原来的性能提高了30倍，效果相当明显。&lt;/p&gt;

&lt;p&gt;在使用了这个优化后，热查询性能达到了互动查询的要求，可是冷查询的用户体验还是很差。分析了用户行为后，我们发现用户查询的模式比较固定：比如很多用户每天都会跑同一个查询，只是所使用过滤数据的日期会发生改变。借助这次特性，我们可以根据用户的需求进行线下预查询，提前把所需要的数据导入Tachyon，从而避免用户冷查询。
	&lt;img src=&quot;https://xiazemin.github.io/MyBlog/img/Tachyon6.jpg&quot; /&gt;
图6: Tachyon在百度大数据平台的部署&lt;/p&gt;

&lt;p&gt;在使用Tachyon过程中，我们也遇到了一些问题：在刚开始部署Tachyon的时候， 我们发现数据完全不能被缓存，第一次与后续的查询耗时是一样的。如图7的源代码所示：只有整个数据Block被读取后，这个Block才会被缓存住；否则缓存的操作会被取消。比如一个Block是256MB，如果你读了其中的255MB，这个Block还是不会被缓存，因为它只需读取整个block中的部分数据。在百度内部，我们很多数据是用行列式存储的，比如ORC与Parquet文件，每次查询只会读其中的某几列， 因此不会读取完整的Block, 以致block缓存失败。为了解决这个问题，我们对Tachyon进行了修改，如果数据Block不是太大的话，冷查询时即使用户请求的只是其中几列，我们也会把整个Block都读进来，保证整个Block能被缓存住，然后再次查询的话就可以直接从Tachyon读取了。在使用了修改的版本后，Tachyon达到了我们期待的效果，大部分查询可以在10秒内完成。 
	&lt;img src=&quot;https://xiazemin.github.io/MyBlog/img/Tachyon7.jpg&quot; /&gt;
图7: Tachyon缓存数据逻辑&lt;/p&gt;

&lt;p&gt;Tachyon的一些新功能
我们把Tachyon当作缓存来使用，但是每台机器的内存有限，内存很快会被用完。 如果我们有50台机器，每台分配20GB的内存给Tachyon，那么总共也只有1TB的缓存空间，远远不能满足我们的需要。在Tachyon最新版本有一个新的功能： Hierarchical Storage,即使用不同的存储媒介对数据分层次缓存。如图8所示，它类于CPU的缓存设计：内存的读写速度最快所以可以用于第0级缓存，然后SSD可以用于第1级缓存，最后本地磁盘可以作为底层缓存。这样的设计可以为我们提供更大的缓存空间，同样50台机器，现在我们每台可贡献出20TB的缓存空间，使总缓存空间达到1PB，基本可以满足我们的储存需求。与CPU缓存类似，如果Tachyon的block Replacement Policy设计得当，99%的请求可以被第0级缓存（内存）所满足，从而在绝大部分时间可以做到秒级响应。
	&lt;img src=&quot;https://xiazemin.github.io/MyBlog/img/Tachyon8.jpg&quot; /&gt;
图8: Tachyon Hierarchical Storage&lt;/p&gt;

&lt;p&gt;当Tachyon收到读请求时，它首先检查数据是否在第0层，如果命中，直接返回数据，否则它会查询下一层缓存，直到找到被请求的数据为止。数据找到后会直接返回给用户，同时也会被Promote到第0层缓存，然后第0层被替换的数据Block会被LRU算法置换到下一层缓存。如此一来，如果用户再次请求相同的数据就会直接从第0层快速得到，从而充分发挥缓存的Locality特性。&lt;/p&gt;

&lt;p&gt;当Tachyon收到写请求时，它首先检查第0层是否有足够空间，如果有，则直接写入数据后返回。否则它会查询下一层缓存，直到找到一层缓存有足够空间，然后把上一层的一个Block用LRU算法推到下一层，如此类推，直到把第0层有足够空间以写入新的数据，然后再返回。这么做的目的是保证数据被写入第0层，如果读请求马上发生在写请求后，数据可以快速被读取。可是，这样做的话写的性能有可能变的很差：比如头两层缓存都满的话，它需要把一个Block从第1层丢到第2层，再把一个Block从第0层丢到第1层，然后才能写数据到第0层，再返回给用户。&lt;/p&gt;

&lt;p&gt;对此我们做了个优化， 与其层层类推腾出空间，我们的算法直接把数据写入有足够空间的缓存层，然后快速返回给用户。如果缓存全满，则把底层的一个Block置换掉，然后把数据写入底层缓存后返回。经过实验，我们发现优化后的做法会把写延时降低约50%，大大的提高了写的效率。但是读的效率又如何呢，由于在TACHYON里，写是通过Memory-Mapped File进行的，所以是先写入内存，再Flush到磁盘，如果读是马上发生在写之后的话，其实会从操作系统的Buffer，也就是内存里读数据，因此读的性能也不会下降。&lt;/p&gt;

&lt;p&gt;Hierarchical Storage很好地解决了我们缓存不够用的问题，下一步我们将继续对其进行优化。比如，现在它只有LRU一种置换算法，并不能满足所有的应用场景， 我们将针对不同的场景设计更高效的置换算法，尽量提高缓存命中率。&lt;/p&gt;

&lt;p&gt;结语
我个人相信更细的分工会达到更高的效率，Spark作为一个内存计算平台，如果使用过多的资源去缓存数据，会引发频繁的垃圾收集，造成系统的不稳定，或者影响性能。在我们使用Spark的初期，系统不稳定是我们面临的最大挑战，而频繁的垃圾收集正是引起系统不稳定最大的原因。比如当一次垃圾收集耗时过长时，Spark Worker变的响应非常不及时，很容易被误认为已经崩溃，导致任务重新执行。Tachyon通过把内存存储的功能从Spark中分离出来，让Spark更专注在计算本身，从而很好的解决了这个问题。随着内存变的越来越便宜，我们可以预期未来一段时间里，我们的服务器里可使用的内存会不断增长，Tachyon会在大数据平台中发挥越来越重要的作用。现在还是Tachyon发展的初期，在本文完成时Tachyon才准备发布0.6版，还有很多功能亟需完善，这也是一个好机遇，有兴趣的同学们可以多关注Tachyon，到社区里进行技术讨论以及功能开发。
&lt;!-- more --&gt;
Tachyon是一个以内存为核心的开源分布式存储系统，也是目前发展最迅速的开源大数据项目之一。Tachyon为不同的大数据计算框架（如Apache Spark，Hadoop MapReduce, Apache Flink等）提供可靠的内存级的数据共享服务。此外，Tachyon还能够整合众多现有的存储系统（如Amazon S3, Apache HDFS, RedHat GlusterFS, OpenStack Swift等），为用户提供统一的、易用的、高效的数据访问平台。本文首先向读者介绍Tachyon项目的诞生背景和目前发展的情况；然后详解Tachyon系统的基本架构以及目前一些重要的功能；最后，分享一个Tachyon在百度大数据生产环境下的几个应用案例。&lt;/p&gt;

&lt;p&gt;1.Tachyon简介
随着技术的发展，内存的吞吐量在不断地提高，单位容量的内存价格在不断降低，这为“内存计算”提供可能。在大数据计算平台领域，采用分布式内存计算模式的Spark验证了这一点。Spark相比于MapReduce大大提升了大数据的计算性能，受到了业界和社区的广泛关注。然而，还是有很多问题在计算框架层难以解决，如：不同的Spark应用或不同计算框架（Spark，MapReduce，Presto）间仍需通过基于磁盘的存储系统（如HDFS，Amazon S3等）交换数据；当Spark计算任务崩溃，JVM缓存的数据会丢失； JVM中大量缓存的数据增加了Java垃圾回收的压力。&lt;/p&gt;

&lt;p&gt;Tachyon最初出现是为了有效地解决了上述问题，它计划构建一个独立的存储层来快速共享不同计算框架的数据，实现方式上将数据置于堆外(off-heap)内存以避免大量垃圾回收开销。例如，对应Spark应用而言，可以带来以下作用：&lt;/p&gt;

&lt;p&gt;不同Spark应用，甚至不同计算平台上的应用需要数据共享时，通过Tachyon进行内存读写，避免缓慢的磁盘操作。
使用Tachyon进行数据缓存，当Spark任务崩溃，数据仍缓存在Tachyon内存中，任务重启后能够直接从Tachyon中读取数据。
多个Spark应用理论上甚至可以共享同一份Tachyon缓存的数据，避免内存资源的浪费，减轻Java垃圾回收的压力。
图片描述&lt;/p&gt;

&lt;p&gt;图1. Tachyon在生态系统的位置
图1给出了Tachyon部署时所处的位置。Tachyon被部署在计算平台之下和现有的存储系统之上，能够在不同计算框架间共享数据。同时，现有的海量数据不需要进行迁移，上层的计算作业仍能通过Tachyon访问到底层存储平台上的数据。Tachyon作为一个以内存为中心的中间存储层，不仅能极大地提升上层计算平台的性能，还能充分利用不同特性的底层存储系统，更可以有效地整合两者的优势。&lt;/p&gt;

&lt;p&gt;Tachyon最初是由李浩源博士发起的源自UC Berkeley AMPLab的研究项目（该实验室也是Mesos和Spark的发源地）。自2013年4月开源以来，Tachyon社区不断壮大，已经成为发展速度最快的开源大数据项目之一，目前已有来自超过50个组织机构的200多人参与到了对Tachyon项目的贡献中，也有超过100家公司部署了Tachyon。于此同时，Tachyon的核心创建者和开发人员创立了Tachyon Nexus公司，其中不乏UC Berkeley、CMU等博士以及Google, Palantir, Yahoo!等前员工。 2015年3月美国华尔街日报报道了Tachyon Nexus获得硅谷著名风投Andreessen Horowitz 的750万美元A轮投资。&lt;/p&gt;

&lt;p&gt;图片描述&lt;/p&gt;

&lt;p&gt;图2. Tachyon项目贡献者的增长情况
在学术界， 国内的南京大学PASA大数据实验室一直积极关注并参与到Tachyon项目的开发中，共向Tachyon社区贡献了100多个PR，近300次commit，包括为Tachyon实现性能测试框架tachyon-perf，增加LFU、LRFU等多个替换策略，改进WebUI页面，以及其他一些性能优化的工作。此外，我们还撰写了Tachyon相关的中文博客，以便中文读者和用户能够更深入地了解和使用Tachyon。&lt;/p&gt;

&lt;p&gt;在工业界，百度也把Tachyon运用到其大数据系统中， Tachyon在过去一年中稳定的支持着百度的可交互式查询业务，令百度的交互式查询提速30倍。在验证了Tachyon的高性能以及可靠性后，百度在内部使用Tachyon的0.9版成功部署了1000个worker的世界最大Tachyon集群，总共提供50TB的内存存储。此集群在百度内部已经稳定运行了一个月，也验证的Tachyon的可扩展性。于此同时，百度的另外一个Tachyon部署中用Tachyon层次化数据管理了2PB数据。&lt;/p&gt;

&lt;p&gt;2.Tachyon系统架构
这一章中我们简介Tachyon系统的基本架构，包括Tachyon的基本组件及其功能。&lt;/p&gt;

&lt;p&gt;图片描述&lt;/p&gt;

&lt;p&gt;图3. Tachyon的系统架构
图2是Tachyon系统的基本架构，主要包括4个基本组件：Master、Worker和Client，以及可插拔的底层存储系统（Underlayer Storage System）。每个组件的具体功能职责如下：&lt;/p&gt;

&lt;p&gt;Tachyon Master主要负责管理两类重要信息。第一，Tachyon Master中记录了所有数据文件的元数据信息，包括整个Tachyon命名空间（namespace）的组织结构，所有文件和数据块的基本信息等。第二，Tachyon Master监管着整个Tachyon系统的状态，包括整个系统的存储容量使用情况，所有Tachyon Worker的运行状态等。&lt;/p&gt;

&lt;p&gt;Tachyon Worker负责管理本地节点上的存储资源，包括内存、SSD和HDD等。Tachyon中的所有数据文件被划分为一系列数据块，Tachyon Worker以块为粒度进行存储和管理，如：为新的数据块分配空间、将热数据块从SSD或HDD移至内存、实时或定期备份数据块到底层存储系统。同时，Tachyon Worker定时向Tachyon Master发送心跳（heartbeat）以告知自身的状态信息。&lt;/p&gt;

&lt;p&gt;Tachyon Client是上层应用访问Tachyon数据的入口。访问过程可以包括如下几步：①Client向Master询问数据文件的基本信息，包括文件位置，数据块大小等；②Client尝试从本地Worker中读取对应数据块，若本地不存在Worker或者数据块不在本地Worker中，则尝试从远程Worker中读取；③若数据还未被缓存到Tachyon中，则Client会从底层存储系统中读取对应数据。此外，Tachyon Client会向所有建立连接的Tachyon Master和Tachyon Worker定时发送心跳以表示仍处于连接租期中，中断连接后Tachyon Master和Tachyon Worker会回收对应Client的临时空间。&lt;/p&gt;

&lt;p&gt;底层存储系统既可以被Tachyon用来备份数据，也可以作为Tachyon缓存数据的来源，上层应用在使用Tachyon Client时也能直接访问底层存储系统上的数据。底层存储系统保证了Tachyon Worker在发生故障而崩溃后不会导致数据丢失，同时也使得上层应用在迁移到Tachyon的同时不需要进行底层数据的迁移。目前Tachyon支持的底层存储系统有HDFS，GlusterFS，Amazon S3，OpenStack Swift以及本地文件系统，且能够比较容易地嵌入更多的现有存储系统。&lt;/p&gt;

&lt;p&gt;在实际部署时， Tachyon Master通常部署在单个主节点上（Tachyon也支持多个节点上部署Tachyon Master，并通过使用ZooKeeper来防止单点故障）；将Tachyon Worker部署在多个从节点；Tachyon Client和应用相关，可以位于任何一个节点上。&lt;/p&gt;

&lt;p&gt;3.Tachyon的特色功能
本节我们简介Tachyon面向上层应用的特色功能。&lt;/p&gt;

&lt;p&gt;3.1 支持多种部署方式&lt;/p&gt;

&lt;p&gt;作为大数据系统中的存储层，Tachyon为用户提供了不同的启动模式、对资源管理框架的支持、以及目标运行环境，能够部署多种大数据平台环境中：&lt;/p&gt;

&lt;p&gt;启动模式：以正常模式启动单个Tachyon Master；以高级容错模式启动多个Tachyon Master，并使用ZooKeeper进行管理；
资源管理框架：以Standalone方式直接运行在操作系统之上；运行在Apache Mesos之上；运行在Apache Hadoop Yarn之上；
目标运行环境：部署在本地集群环境中；部署在Virtual Box虚拟机中；部署在容器（如Docker）中；部署在Amazon EC2云平台上（Tachyon社区正在开发支持Tachyon部署在阿里云OSS上）
用户可以自由选择不同的启动模式、资源管理框架和目标运行环境，Tachyon为多种组合都提供了相应的启动脚本，能够很方便地将Tachyon部署在用户的环境中。&lt;/p&gt;

&lt;p&gt;3.2 层次化存储&lt;/p&gt;

&lt;p&gt;Tachyon的层次化存储充分利用了每个Tachyon Worker上的本地存储资源，将Tachyon中的数据块按不同热度存放在了不同的存储层中。目前Tachyon所使用的本地存储资源包括MEM（Memory，内存）、SSD（Solid State Drives，固态硬盘）和HDD（Hard Disk Drives，磁盘）。在Tachyon Worker中，每一类存储资源被视作一层（Storage Tier），每一层又可以由多个目录（Storage Directory）组成，并且用户可以设置每个存储目录的容量。&lt;/p&gt;

&lt;p&gt;在读写Tachyon数据时，分配器（Allocator）负责为新的数据块选择目标存储目录，替换器（Evictor）负责将冷数据从内存剔至SSD和HDD，同时将热数据从SSD和HDD提升至内存中。目前分配器所使用的分配策略包括Greedy、MaxFree和RoundRobin。替换器所使用的替换策略包括Greedy、LRU/PartialLRU、LRFU。额外地，Tachyon还为用户提供了Pin功能，支持用户将所需要的数据始终存放在内存中。关于如何配置Tachyon层次化存储，可以进一步参考Tachyon官方文档。&lt;/p&gt;

&lt;p&gt;3.3 灵活的读写机制&lt;/p&gt;

&lt;p&gt;为了充分利用多层次的存储资源和底层存储系统，Tachyon为用户提供了不同的读写类型（ReadType/WriteType）API，用于灵活控制读写数据时的行为方式，不同的读写类型及其含义如表1所示。&lt;/p&gt;

&lt;p&gt;表1. 读写类型（ReadType/WriteType）的取值及其含义
图片描述&lt;/p&gt;

&lt;p&gt;除了上述的读写类型外，Tachyon还提供了另一套控制方式：TachyonStorageType和UnderStorageType，用于分别控制在Tachyon存储和底层存储系统上的读写行为，具体取值及其含义如表2所示。实际上，这种控制方式是Tachyon-0.8之后新增的，控制粒度更细，功能也更多，因此推荐用户采用这种方式控制读写行为。&lt;/p&gt;

&lt;p&gt;表2. TachyonStorageType/UnderStorageType的值及其含义
图片描述&lt;/p&gt;

&lt;p&gt;3.4 文件系统层的Lineage容错机制&lt;/p&gt;

&lt;p&gt;在Tachyon中，Lineage表示了两个或多个文件之间的世系关系，即输出文件集B是由输入文件集A通过怎样的操作得到的。有了Lineage信息后，在文件数据意外丢失时，Tachyon就会启动重计算作业，根据现有的文件重新执行同样的操作，以恢复丢失的数据。图3给出了一个Lineage示例，文件集A通过一个Spark作业生成文件集B；文件集C通过另一个Spark作业生成文件集D；B和D作为同一个MapReduce作业的输入，输出为文件集E。那么，如果文件集E意外丢失，并且没有备份，那么Tachyon就会重新启动对应的MapReduce作业，再次生成E。&lt;/p&gt;

&lt;p&gt;图片描述
图4. Tachyon的Lineage机制
3.5 统一命名空间&lt;/p&gt;

&lt;p&gt;对于Tachyon的用户而言，通过Tachyon提供的接口所访问到的是Tachyon文件系统的命名空间。当用户需要访问Tachyon以外的文件和数据时，Tachyon提供了Mount接口，能够将外部存储系统的文件或目录挂载到Tachyon的命名空间中。这样用户就能够在统一的Tachyon命名空间中，使用相同或者自定义的路径，访问其他存储系统上的文件和数据。&lt;/p&gt;

&lt;p&gt;图片描述&lt;/p&gt;

&lt;p&gt;图5. Tachyon的统一命名空间
3.6 HDFS兼容接口&lt;/p&gt;

&lt;p&gt;在Tachyon出现之前，诸如Hadoop MapReduce以及Apache Spark的应用大多使用HDFS、Amazon S3等存储文件。Tachyon为这些应用提供了一套HDFS兼容的接口（确切地说，是兼容了org.apache.hadoop.fs.FileSystem的接口），用户可以在不改动应用源码的情况下，通过以下3个步骤，将目标文件系统更改为Tachyon：&lt;/p&gt;

&lt;p&gt;1.将对应版本Tachyon Client的jar包添加至运行环境的CLASSPATH中； 
2.添加Hadoop配置项&amp;lt;“fs.tachyon.impl”, “tachyon.hadoop.TFS”&amp;gt;； 
3.将原先的”hdfs://ip:port/file/X”路径更改为”tachyon://ip:port/file/X”。&lt;/p&gt;

&lt;p&gt;通常，用户可以结合使用“HDFS兼容接口”和“统一命名空间”这两个特性，将原先的大数据应用直接运行在Tachyon之上，而不需要进行任何代码和数据的迁移。&lt;/p&gt;

&lt;p&gt;3.7 丰富的命令行式工具&lt;/p&gt;

&lt;p&gt;Tachyon自带了一个名为 “tfs”的命令行工具，能够让用户以命令行的方式与Tachyon交互，而不需要编写源码来查看、新建、删除Tachyon文件。例如：&lt;/p&gt;

&lt;p&gt;图片描述&lt;/p&gt;

&lt;p&gt;“tfs”工具提供的全部命令使用方式详见Tachyon官方文档。&lt;/p&gt;

&lt;p&gt;3.8 方便管理的WebUI&lt;/p&gt;

&lt;p&gt;除了“tfs”工具外，Tachyon还在Tachyon Master和每个Tachyon Worker节点上启动了一个网页管理页面，用户可以通过浏览器打开对应的WebUI（默认为http://:19999和http://:30000）。WebUI上列举了整个Tachyon系统的基本信息、所有Tachyon Worker的运行状态、以及当前Tachyon系统的配置信息。同时，用户可以直接在WebUI上浏览整个Tachyon文件系统、预览文件内容、甚至下载具体的某个文件。&lt;/p&gt;

&lt;p&gt;图片描述&lt;/p&gt;

&lt;p&gt;图6. Tachyon的WebUI
3.9 实时指标监控系统&lt;/p&gt;

&lt;p&gt;图片描述&lt;/p&gt;

&lt;p&gt;图片描述
图7. Tachyon监控的实时指标（WebUI模式、JSON格式）
对于高级用户和系统管理人员，Tachyon提供了一套实时指标监控系统，实时地记录和管理了Tachyon中一些重要的统计信息，包括存储容量使用情况、现有Tachyon文件数、对文件的操作次数、现有的数据块数、对数据块的操作次数、总共读写的字节数等。根据用户的配置，这些指标能够以多种方式进行输出：标准控制台输出、以CSV格式保存为文件、输出到JMX控制台、输出到Graphite服务器以及输出到Tachyon的WebUI。&lt;/p&gt;

&lt;p&gt;3.10支持Linux FUSE&lt;/p&gt;

&lt;p&gt;Tachyon-FUSE是Tachyon最新开发版的新特性，由Tachyon Nexus和IBM共同主导开发。在Linux系统中，FUSE（Filesystem in Userspace，用户空间文件系统）模块使得用户能将其他文件系统挂载到本地文件系统的某一目录下，然后以统一的方式进行访问。Tachyon-FUSE的出现使得用户同样可以将Tachyon文件系统挂载到本地文件系统中。通过Tachyon-FUSE，用户/应用可以使用访问本地文件系统的方式来访问Tachyon。这更加方便了用户对Tachyon的管理和使用，以及现有基于FUSE接口的应用通过Tachyon进行内存加速或者数据共享。&lt;/p&gt;

&lt;p&gt;4.Tachyon在百度大数据平台的应用案例
在百度，我们从2014年底开始关注Tachyon。当时我们使用Spark SQL进行大数据分析工作，由于Spark是个基于内存的计算平台，我们预计绝大部分的数据查询应该在几秒或者十几秒完成以达到交互查询的体验。然而，我们却发现实际查询几乎都需要上百秒才能完成，其原因在于我们的计算资源与数据仓库可能并不在同一个数据中心。 在这种情况下，我们每一次数据查询都可能需要从远端的数据中心读取数据，由于数据中心间的网络带宽以及延时的问题，导致每次查询都需要较长的时间（&amp;gt;100秒）才能完成。更糟糕的是，很多查询的重复性或相似性很高，同样的数据很可能会被查询多次，如果每次都从远端的数据中心读取，必然造成资源浪费。&lt;/p&gt;

&lt;p&gt;为了解决这个问题，在一年前我们借助Tachyon管理远程及本地数据读取和调度，尽量避免跨数据中心读数据。 当Tachyon被部署到Spark所在的数据中心后，每次数据冷查询时，我们还是从远端数据仓库拉数据，但是当数据再次被查询时， Spark将直接从同一数据中心的Tachyon中读取数据， 从而提高查询性能。在我们的环境和应用中实验表明：如果是从非本机的Tachyon读取数据的话，耗时降到10到15秒，比原来的性能提高了10倍； 最好的情况下，如果从本机的Tachyon读数据，查询仅需5秒，比原来的性能提高了30倍， 效果很明显。除了性能的提高，更难能可贵的是Tachyon运行稳定，在过去一年中很好的支持着百度的交互式查询业务， 而且社区在每一版迭代更新中都不断提供更多的功能以及不断提高系统的稳定性，让业界对Tachyon系统更有信心。&lt;/p&gt;

&lt;p&gt;在过去一个月，百度在为大规模使用Tachyon做准备，验证Tachyon的可扩展性。我们使用Tachyon的最新版成功部署了1000个worker的Tachyon集群，在本文完成时这应该是世界最大的Tachyon集群。此集群总共提供超过50TB的内存存储，在百度内部已经稳定运行了一个月，现在有不同的百度业务在上面试运行以及压力测试。在百度的图搜变现业务上，我们与社区合作在Tachyon上搭建了一个高性能的Key/Value存储，提供线上图片服务。同时由于图片直接存在Tachyon里，我们的线下计算可以直接从Tachyon中读取图片。 这使得我们将线上以及线下系统整合成一个系统，既简化了开发流程，也节省了存储资源，达到了事半功倍的效果。本文篇幅有限，期待在后期给大家详细介绍百度是1000 worker的Tachyon 集群的实用案例，包括如何使用Tachyon整合线上线下的存储资源等。&lt;/p&gt;

&lt;p&gt;5.结语
作为一个以内存为中心、统一的分布式存储系统，Tachyon极大地增强了大数据生态中存储层的功能。虽然Tachyon项目相对还比较年轻，但已经很成熟稳定，并且已经在学术界以及工业界取得了成功。随着整个计算机产业的发展，内存变的越来越便宜，在计算集群中可使用的内存容量会不断增长，我们相信Tachyon也必将会在大数据平台中发挥越来越重要的作用。&lt;/p&gt;

&lt;p&gt;现在Tachyon项目发展迅速，更多的功能也在逐步得到完善，应用前景也颇为广阔。Tachyon正不断地在支持更多的底层存储系统（特别地，社区中已经有人正在实施支持阿里云OSS存储系统以及百度开放云平台，这对国内的用户和开发者来说是个很好的机会）；同时Tachyon也在实现安全性相关的支持，以充分满足业界生成环境的需要；更进一步地，Tachyon目前更多地被视为文件系统，而作为一个统一存储系统，Tachyon也将支持更多的数据结构，以满足不同计算框架的需要。在本文完成时Tachyon已经准备发布下一版，有兴趣的读者们可以多关注Tachyon，到社区里进行技术讨论以及功能开发。&lt;/p&gt;

&lt;p&gt;版本选择
Tachyon目前的最新发布版为0.5.0，最新开发版为0.6.0-SNAPSHOT。由于两者向上层提供的API有了不小的差异，这里以最新的0.6.0-SNAPSHOT开发版为基础进行介绍。它具有更多功能，更多新特性，更方便用户使用。在介绍时，我们也会标注出那些和0.5.0版本兼容的部分，让大家能够同时Hold住不同的版本。&lt;/p&gt;

&lt;p&gt;官方资料： Tachyon-0.5.0； 最新开发版。（本文章介绍的Tachyon基于的版本是0.6.0-SNAPSHOT，2014-12-27）&lt;/p&gt;
&lt;ol&gt;
  &lt;li&gt;Tachyon的安装
由于目前Tachyon使用了RamFS作为内存层，因此推荐在Linux环境下安装Tachyon。&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;第①步——下载&amp;amp;编译
对于已经发布的版本，如Tachyon-0.5.0或更早的版本，可以直接下载已经编译好的包，并解压。下载地址为https://github.com/amplab/tachyon/releases&lt;/p&gt;

&lt;p&gt;为了更好地契合用户的本地环境，如java版本、hadoop版本或其他一些软件包的版本，可以下载Tachyon源码自行编译。Tachyon开源在GitHub上，可以很方便地获得其不同版本的源码：Tachyon-0.5.0；最新开发版。Tachyon项目采用Maven进行管理，因此可以采用 mvn package 命令进行编译打包。在Tachyon-0.6.0-SNAPSHOT版本中，默认依赖的java版本为1.6，默认依赖的hadoop版本为1.0.4，如果要更改这些依赖的版本号可以在编译时加入选项，如：&lt;/p&gt;

&lt;p&gt;1
mvn clean package -Djava.version=1.7 -Dhadoop.version=2.3.0 -DskipTests
完成这一步后，我们就得到了能够运行在用户本地环境的Tachyon，下面我们分别介绍如何在单机和分布式环境下配置和启动Tachyon。&lt;/p&gt;

&lt;p&gt;1.1 单机安装Tachyon
这里要注意一点，Tachyon在单机（local）模式下启动时会自动挂载RamFS，所以请保证使用的账户具有sudo权限。&lt;/p&gt;

&lt;p&gt;第②步——配置
在conf/workers文件中配置需要启动TachyonWorker的节点，默认是localhost，所以在单机模式下不用更改。（在Tachyon-0.5.0版本中，该文件为conf/slaves）&lt;/p&gt;

&lt;p&gt;将conf/tachyon-env.sh.template复制为conf/tachyon-env.sh，并在conf/tachyon-env.sh中修改具体配置，下面列举了一些重要的配置项，稍后会详细地介绍更多的配置项。&lt;/p&gt;

&lt;p&gt;JAVA_HOME —— 系统中java的安装路径
TACHYON_MASTER_ADDRESS —— 启动TachyonMaster的地址，默认为localhost，所以在单机模式下不用更改
TACHYON_UNDERFS_ADDRESS —— Tachyon使用的底层文件系统的路径，在单机模式下可以直接使用本地文件系统，如”/tmp/tachyon”，也可以使用HDFS，如”hdfs://ip:port”
TACHYON_WORKER_MEMORY_SIZE —— 每个TachyonWorker使用的RamFS大小&lt;/p&gt;

&lt;p&gt;第③步——启动
完成配置后，即可以单机模式启动Tachyon，格式化、启动和停止Tachyon的命令分别为：&lt;/p&gt;

&lt;p&gt;1
2
3
bin/tachyon format
bin/tachyon-start.sh local
bin/tachyon-stop.sh
1.2 分布式安装Tachyon
这里我们以一个三个节点的集群为例，分别为slave201，slave202和slave203。三个节点都运行TachyonWorker，slave201运行TachyonMaster。&lt;/p&gt;

&lt;p&gt;第②步——配置（该过程在TachyonMaster节点，即slave201上完成）
在conf/workers文件中配置需要启动TachyonWorker的节点，即&lt;/p&gt;

&lt;p&gt;1
2
3
slave201
slave202
slave203
将conf/tachyon-env.sh.template复制为conf/tachyon-env.sh，并在conf/tachyon-env.sh中修改具体配置。不同于单机模式，这里需要修改TachyonMaster地址以及底层文件系统路径&lt;/p&gt;

&lt;p&gt;1
2
export TACHYON_MASTER_ADDRESS=slave201
export TACHYON_UNDERFS_ADDRESS=hdfs://slave201:9000
完成配置文件的修改后，将整个tachyon文件夹复制到每个节点的相同路径下&lt;/p&gt;

&lt;p&gt;1
2
scp –r tachyon-master slave202:/home/…/
scp –r tachyon-master slave203:/home/…/&lt;/p&gt;

&lt;p&gt;第③步——启动 
在分布式模式下，格式化和停止Tachyon的命令仍然为：&lt;/p&gt;

&lt;p&gt;1
2
bin/tachyon format
bin/tachyon-stop.sh
但启动Tachyon有了更多的选项：&lt;/p&gt;

&lt;p&gt;bin/tachyon-start.sh all Mount #在启动前自动挂载TachyonWorker所使用的RamFS，然后启动TachyonMaster和所有TachyonWorker。由于直接使用mount命令，所以需要用户为root
bin/tachyon-start.sh all SudoMount #在启动前自动挂载TachyonWorker所使用的RamFS，然后启动TachyonMaster和所有TachyonWorker。由于使用sudo mount命令，所以需要用户有sudo权限
bin/tachyon-start.sh all NoMount #认为RamFS已经挂载好，不执行挂载操作，只启动TachyonMaster和所有TachyonWorker
因此，如果不想每次启动Tachyon都挂载一次RamFS，可以先使用命令 bin/tachyon-mount.sh Mount workers 或 bin/tachyon-mount.sh SudoMount workers 挂载好所有RamFS，然后使用 bin/tachyon-start.sh all NoMount 命令启动Tachyon。&lt;/p&gt;

&lt;p&gt;单机和分布式模式的区别就在于配置和启动步骤，事实上，也可以在分布式模式下只设置一个TachyonWorker（伪分布式），在这种情况下两者就基本一样了。&lt;/p&gt;

&lt;p&gt;第④步——查看&amp;amp;测试
启动Tachyon后，可以用 jps 命令查看TachyonMaster和TachyonWorker进程是否存在&lt;/p&gt;

&lt;p&gt;也可以在浏览器内打开Tachyon的WebUI，如 http://slave201:19999 ，查看整个Tachyon的状态，各个TachyonWorker的运行情况，各项配置信息，浏览文件系统等。&lt;/p&gt;

&lt;p&gt;此外，还能在任一启动了TachyonWorker的节点上执行 bin/tachyon runTests 命令来测试Tachyon是否运行正常。&lt;/p&gt;

&lt;p&gt;步骤①-④即完成了Tachyon的安装和启动，之后我们也会给出具体地如何使用Tachyon。&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;Tachyon的配置
Tachyon的可配置项远不止上面步骤②的配置文件中的那些，用户可以根据自己的需求更改Tachyon的各项配置。这里以0.6.0-SNAPSHOT版本为例，介绍Tachyon中可配置参数的具体含义。（Tachyon-0.5.0的可配置项基本上是Tachyon-0.6.0-SNAPSHOT的一个子集）&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;Tachyon中的可配置项分为两类，一种是系统环境变量，用于在不同脚本间共享配置信息；另一种是程序运行参数，通过-D选项传入运行Tachyon的JVM中。程序运行参数又分为通用配置（Common Configuration）、TachyonMaster配置（Master Configuration）、TachyonWorker配置（Worker Configuration）和用户配置（User Configuration）。要修改或添加这些可配置项，请修改conf/tachyon-env.sh文件。&lt;/p&gt;

&lt;p&gt;2.1 Tachyon环境变量
JAVA_HOME：系统中java的安装路径
TACHYON_RAM_FOLDER：配置ramfs挂载的文件目录，默认为/mnt/ramdisk。
TACHYON_MASTER_ADDRESS：启动TachyonMaster的地址，默认为localhost，所以在单机模式下不用更改
TACHYON_UNDERFS_ADDRESS：Tachyon使用的底层文件系统的路径，本地文件系统（单机模式下），如”/tmp/tachyon”，或HDFS，如”hdfs://ip:port”
TACHYON_WORKER_MEMORY_SIZE：每个TachyonWorker使用的RamFS大小，默认为1GB
2.2 通用配置
tachyon.underfs.address：Tachyon在底层文件系统的的路径，默认为$TACHYON_UNDERFS_ADDRESS
tachyon.home：Tachyon的安装路径，启动Tachyon时为当前 tachyon 文件夹的路径
tachyon.data.folder：Tachyon数据在底层文件系统的存放路径，默认为$TACHYON_UNDERFS_ADDRESS/tmp/tachyon/data
tachyon.workers.folder：TachyonWorkers在底层文件系统的工作路径，默认为$TACHYON_UNDERFS_ADDRESS/tmp/tachyon/workers
tachyon.usezookeeper：TachyonMaster是否使用ZooKeeper容错，默认为false。
tachyon.zookeeper.adress：如果启用，ZooKeeper的地址
tachyon.zookeeper.election.path：如果启用，Zookeeper的election文件夹路径，默认为/election
tachyon.zookeeper.leader.path：如果启用，Zookeeper的leader文件夹路径，默认为/leader
tachyon.underfs.hdfs.impl：实现HDFS的类，默认org.apache.hadoop.hdfs,DistributedFileSystem
tachyon.max.columns：Tachyon中RawTable允许的最大列数，默认为1000
tachyon.table.metadata.byte：Tachyon中RawTable元数据允许存储的最大字节数，默认为5242880，即5MB
tachyon.underfs.glusterfs.impl：如果使用GlusterFS为底层文件系统，实现GlusterFS的类，默认为org.apache.hadoop.fs.glusterfs.GlusterFileSystem
tachyon.underfs.glusterfs.mounts：如果使用GlusterFS为底层文件系统，GlusterFS卷的挂载目录
tachyon.underfs.glusterfs.volumes：如果使用GlusterFS为底层文件系统，GlusterFS的卷名
tachyon.underfs.glusterfs.mapred.system.dir：如果使用GlusterFS为底层文件系统，GlusterFS用于存放MapReduce中间数据的可选子目录，默认为glusterfs:///mapred/system
tachyon.web.resources：Tachyon WebUI可用的资源，默认为$tachyon.home/core/src/main/webapp
tachyon.async.enabled：是否启用异步模式，默认为false
tachyon.underfs.hadoop.prefixes：底层使用hadoop文件系统的前缀列表，默认为”hdfs://”，”s3://”，”s3n://”，”glusterfs:///”
tachyon.test.mode：是否启用测试模式，默认为false
tachyon.master.retry：连接重试次数，默认为29&lt;/p&gt;

&lt;p&gt;2.3 TachyonMaster配置
tachyon.master.worker.timeout.ms：TachyonMaster和TachyonWorker心跳包失效时长，默认为60000ms
tachyon.master.journal.folder：TachyonMaster的journal日志存放路径，默认为$TACHYON_HOME/journal/
tachyon.master.hostname：TachyonMaster的主机名
tachyon.master.port：TachyonMaster的远程调用通讯端口，默认为19998
tachyon.master.web.port：TachyonMaster的WebUI端口，默认为19999
tachyon.master.web.threads：TachyonMaster的WebUI线程数，默认为9
tachyon.master.whitelist：可缓存的路径前缀列表，列表以逗号隔开，表示该路径下的文件能够被缓存至内存，默认为/，即根目录
tachyon.master.temporary.folder：TachyonMaster的临时文件夹，默认为/tmp
tachyon.master.heartbeat.interval.ms：TachyonMaster心跳包间隔时间，默认为1000ms
tachyon.master.selector.threads：TachyonMaster的thrift监听线程数，默认为3
tachyon.master.queue.size.per.selector：TachyonMaster的thrift消息队列长度，默认为3000
tachyon.master.server.threads：TachyonMaster节点的thrift服务线程数，默认为CPU核数的2倍
tachyon.master.pinlist：常驻内存的文件列表，以逗号隔开，表示该路径下的文件不会从内存中剔除，默认为null
2.4 TachyonWorker配置
tachyon.worker.data.folder：TachyonWorker在RamFS中的工作路径，默认为$TACHYON_RAM_FOLDER/tachyonworker/
tachyon.work.port：TachyonWorker的远程调用通讯端口，默认为29998
tachyon.worker.data.port：TachyonWorker的数据传输服务的端口，默认为29999
tachyon.worker.memory.size：TachyonWorker所使用的RamFS大小，默认为$TACHYON_WORKER_MEMORY_SIZE
tachyon.worker.heartbeat.timeout.ms：TachyonWorker心跳包失效的时长，默认为10000ms
tachyon.worker.to.master.heartbeat.interval.ms：TachyonWorker向TachyonMaster发送心跳包的时间间隔，默认为1000ms
tachyon.worker.selector.threads：TachyonWorker的thrift监听线程数，默认为3
tachyon.worker.queue.size.per.selector：TachyonWorker的thrift消息队列长度，默认为3000
tachyon.worker.server.threads：TachyonWorker的thrift服务线程数，默认为CPU核数
tachyon.worker.user.timeout.ms：TachyonWorker和用户之间心跳包失效时长，默认为10000ms
tachyon.worker.checkpoint.threads：TachyonWorker的checkpoint线程数，默认为1
tachyon.worker.per.thread.checkpoint.cap.mb.sec：TachyonWorker的checkpoint的速度，默认为1000MB/s
tachyon.worker.network.type：TachyonWorker在传输文件数据时使用的传输方式，默认为NETTY，可选为NIO或NETTY
2.5 用户配置
tachyon.user.failed.space.request.limits：用户向文件系统请求空间失败时的最大重试次数,默认为3
tachyon.user.quota.unit.bytes：客用户一次向TachyonWorker请求的最少字节数，默认为8388608，即8MB
tachyon.user.file.buffer.byte：用户读写文件时的缓存区大小，默认为1048576，即1MB
tachyon.user.default.block.size.byte：用户创建文件时的默认块大小，默认为1073741824，即1GB
tachyon.user.remote.read.buffer.size.byte：用户读远程文件时的缓冲区大小，默认为1048576，即1MB
tachyon.user.heartbeat.interval.ms：用户心跳包时间间隔，默认为1000ms
tachyon.user.file.writetype.default：用户在使用tachyon.hadoop.TFS时的默认写类型，默认为CACHE_THROUGH&lt;/p&gt;
&lt;ol&gt;
  &lt;li&gt;Tachyon的使用
受益于Tachyon良好的设计和兼用性，用户可以很方便地将现有的利用HDFS进行存储的程序移植至Tachyon。同时，Tachyon也提供了自己的命令行工具和一套完整的文件系统API，用户可以灵活地使用Tachyon。&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;3.1 从HDFS到Tachyon
对于现有的运行在Hadoop MapReduce或者Spark上，使用 “hdfs://ip:port/” 为存储路径的程序，能够很方便地移植至Tachyon。&lt;/p&gt;

&lt;p&gt;3.1.1 Hadoop MapReduce
将tachyon-client jar包添加至$HADOOP_CLASSPATH，jar包位于 tachyon/client/target/tachyon-client-0.6.0-SNAPSHOT-jar-with-dependencies.jar（如果是Tachyon-0.5.0，则文件名为tachyon-client-0.5.0-jar-with-dependencies.jar）
添加配置项&amp;lt;”fs.tachyon.impl”, ” tachyon.hadoop.TFS”&amp;gt;，可以在core-site.xml文件中添加，也可以在程序中使用Configuration.set()方法添加
将原有的”hdfs://ip:port/path”路径更改为”tachyon://ip:port/path”
3.1.2 Spark
同样地，添加依赖包，添加配置项，然后更改文件系统路径。&lt;/p&gt;

&lt;p&gt;额外地，添加配置项&amp;lt;”spark.tachyonStore.url”, “tachyon://ip:port/”&amp;gt;后，能够使用”rdd.persist(StorageLevel.OFF_HEAP)”语句将Spark RDD缓存至Tachyon中以减少Java GC的开销。&lt;/p&gt;

&lt;p&gt;3.2 命令行工具
Tachyon提供了命令行工具为用户提供了简单的交互功能，使用方式为&lt;/p&gt;

&lt;p&gt;1
bin/tachyon tfs [COMMAND]
具体的命令有：&lt;/p&gt;

&lt;p&gt;cat：将文件内容输出到控制台
count：输出符合路径前缀的文件总数
ls：输出目录中的文件信息
lsr：递归输出目录中的文件信息
mkdir：创建指定目录包括路径中的父目录，如果目录已经存在则创建失败
rm：删除文件或者目录
tail：将文件的最末1KB输出到控制台
touch：在指定的位置创建空的文件
mv：将文件移动到指定位置
copyFromLocal：将文件从本地文件系统拷贝到Tachyon文件系统指定位置
copyToLocal：将文件从Tachyon文件系统拷贝到本地文件系统指定位置
fileinfo：打印指定文件的块信息
pin：将指定文件常驻内存
unpin：将常驻内存的文件撤销常驻状态
3.3 Java API
Tachyon是用Java开发实现的，因此提供的API也是Java函数。要使用这些API需要依赖tachyon-client jar包，位于 tachyon/client/target/tachyon-client-0.6.0-SNAPSHOT-jar-with-dependencies.jar （如果是Tachyon-0.5.0，则文件名为tachyon-client-0.5.0-jar-with-dependencies.jar）此外，如果是已发布的Tachyon-0.5.0并且目标项目由Maven管理，可以在 pom.xml 文件中添加如下内容以获取依赖包：&lt;/p&gt;
&lt;dependency&gt;
          &lt;groupId&gt;org.tachyonproject&lt;/groupId&gt;
          &lt;artifactId&gt;tachyon-client&lt;/artifactId&gt;
          &lt;version&gt;0.5.0&lt;/version&gt;
 &lt;/dependency&gt;
&lt;p&gt;（Tachyon-0.5.0和Tachyon-0.6.0-SNAPSHOT提供的Java API一大不同之处在于Tachyon-0.6.0-SNAPSHOT中新增了tachyon.TachyonURI类，用来表示Tachyon文件系统中的路径，类似于Hadoop中的org.apache.hadoop.fs.Path。Tachyon-0.5.0中的大部分API在Tachyon-0.6.0-SNAPSHOT中仍然存在，但被标记为@Deprecated）&lt;/p&gt;

&lt;p&gt;Tachyon的Java API功能大部分集中于tachyon.client.TachyonFS和tachyon.client.TachyonFile两个类中&lt;/p&gt;

</description>
        <pubDate>Sat, 10 Feb 2018 00:00:00 +0800</pubDate>
        <link>https://xiazemin.github.io/MyBlog/spark/2018/02/10/Tachyon.html</link>
        <guid isPermaLink="true">https://xiazemin.github.io/MyBlog/spark/2018/02/10/Tachyon.html</guid>
        
        
        <category>spark</category>
        
      </item>
    
      <item>
        <title>crlf 攻击</title>
        <description>&lt;p&gt;CRLF Injection很少遇见，这次被我逮住了。我看zone中（http://zone.wooyun.org/content/13323）还有一些同学对于这个漏洞不甚了解，甚至分不清它与CSRF，我详细说一下吧。&lt;/p&gt;

&lt;p&gt;CRLF是”回车 + 换行”（\r\n）的简称。在HTTP协议中，HTTP Header与HTTP Body是用两个CRLF分隔的，浏览器就是根据这两个CRLF来取出HTTP 内容并显示出来。所以，一旦我们能够控制HTTP 消息头中的字符，注入一些恶意的换行，这样我们就能注入一些会话Cookie或者HTML代码，所以CRLF Injection又叫HTTP Response Splitting，简称HRS。&lt;/p&gt;

&lt;p&gt;HRS是比XSS危害更大的安全问题，具体是为什么，我们往下看。&lt;/p&gt;

&lt;p&gt;对于HRS最简单的利用方式是注入两个\r\n，之后在写入XSS代码，来构造一个xss。&lt;/p&gt;

&lt;p&gt;举个例子，一般网站会在HTTP头中用Location: http://baidu.com这种方式来进行302跳转，所以我们能控制的内容就是Location:后面的XXX某个网址。&lt;/p&gt;

&lt;p&gt;所以一个正常的302跳转包是这样：&lt;/p&gt;

&lt;p&gt;HTTP/1.1 302 Moved Temporarily 
Date: Fri, 27 Jun 2014 17:52:17 GMT 
Content-Type: text/html 
Content-Length: 154 
Connection: close 
Location: http://www.sina.com.cn
但如果我们输入的是&lt;/p&gt;

&lt;p&gt;http://www.sina.com.cn%0aSet-cookie:JSPSESSID%3Dwooyun
注入了一个换行，此时的返回包就会变成这样：&lt;/p&gt;

&lt;p&gt;HTTP/1.1 302 Moved Temporarily 
Date: Fri, 27 Jun 2014 17:52:17 GMT 
Content-Type: text/html 
Content-Length: 154 
Connection: close 
Location: http://www.sina.com.cn 
Set-cookie: JSPSESSID=wooyun
这个时候这样我们就给访问者设置了一个SESSION，造成一个“会话固定漏洞”。&lt;/p&gt;

&lt;p&gt;当然，HRS并不仅限于会话固定，通过注入两个CRLF就能造成一个无视浏览器Filter的反射型XSS。&lt;/p&gt;

&lt;p&gt;比如一个网站接受url参数http://test.sina.com.cn/?url=xxx，xxx放在Location后面作为一个跳转。如果我们输入的是：&lt;/p&gt;

&lt;p&gt;http://test.sina.com.cn/?url=%0d%0a%0d%0a&amp;lt;img src=1 onerror=alert(/xss/)&amp;gt;
我们的返回包就会变成这样：&lt;/p&gt;

&lt;p&gt;HTTP/1.1 302 Moved Temporarily 
Date: Fri, 27 Jun 2014 17:52:17 GMT 
Content-Type: text/html 
Content-Length: 154 
Connection: close 
Location:&lt;/p&gt;

&lt;p&gt;&amp;lt;img src=1 onerror=alert(/xss/)&amp;gt;
之前说了浏览器会根据第一个CRLF把HTTP包分成头和体，然后将体显示出来。于是我们这里&lt;img /&gt;这个标签就会显示出来，造成一个XSS。&lt;/p&gt;

&lt;p&gt;为什么说是无视浏览器filter的，这里涉及到另一个问题。&lt;/p&gt;

&lt;p&gt;浏览器的Filter是浏览器应对一些反射型XSS做的保护策略，当url中含有XSS相关特征的时候就会过滤掉不显示在页面中，所以不能触发XSS。&lt;/p&gt;

&lt;p&gt;怎样才能关掉filter？一般来说用户这边是不行的，只有数据包中http头含有X-XSS-Protection并且值为0的时候，浏览器才不会开启filter。&lt;/p&gt;

&lt;p&gt;说到这里应该就很清楚了，HRS不正是注入HTTP头的一个漏洞吗，我们可以将X-XSS-Protection:0注入到数据包中，再用两个CRLF来注入XSS代码，这样就成功地绕过了浏览器filter，并且执行我们的反射型XSS。&lt;/p&gt;

&lt;p&gt;所以说HRS的危害大于XSS，因为它能绕过一般XSS所绕不过的filter，并能产生会话固定漏洞。&lt;/p&gt;

&lt;p&gt;我们来一个真实案例吧。&lt;/p&gt;

&lt;p&gt;新浪某分站含有一个url跳转漏洞，危害并不大，于是我就想到了CRLF Injection，当我测试&lt;/p&gt;

&lt;p&gt;http://xxx.sina.com.cn/?url=%0a%0d%0a%0d%3Cimg%20src=1%3E
的时候，发现图片已经输出在页面中了，说明CRLF注入成功了：&lt;/p&gt;

&lt;p&gt;那么我们试试XSS看看：&lt;/p&gt;

&lt;p&gt;看控制台，果然被XSS Filter拦截了。&lt;/p&gt;

&lt;p&gt;那么我们就注入一个X-XSS-Protection:0到数据包中，看看什么效果：&lt;/p&gt;

&lt;p&gt;@mramydnei 还想到了一个利用字符编码来绕过XSS Filter的方法，当编码是is-2022-kr时浏览器会忽略%0f，这样我们在onerror后面加个%0f就能绕过filter，前提是注入一个&amp;lt;meta charset=ISO-2022-KR&amp;gt;：
当然，在Location:这里注入只有webkit内核浏览器才能够利用，其他浏览器可能会跳转、出错。不过对于chrome的使用量来说，危害已经足够了。&lt;/p&gt;

&lt;p&gt;如何修复HRS漏洞，当然是过滤\r 、\n之类的换行符，避免输入的数据污染到其他HTTP头。&lt;/p&gt;

</description>
        <pubDate>Tue, 06 Feb 2018 00:00:00 +0800</pubDate>
        <link>https://xiazemin.github.io/MyBlog/web/2018/02/06/crlf.html</link>
        <guid isPermaLink="true">https://xiazemin.github.io/MyBlog/web/2018/02/06/crlf.html</guid>
        
        
        <category>web</category>
        
      </item>
    
      <item>
        <title>iputils</title>
        <description>&lt;!-- more --&gt;
&lt;p&gt;1.1       iputils软件包简介
    iputils软件包是linux环境下一些实用的网络工具的集合。一开始由Alexey Kuznetsov维护。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;iputils包含以下几个工具：

1. ping。使用 ping可以测试计算机名和计算机的ip地址，验证与远程计算机的连接。ping程序由ping.c ping6.cping_common.c ping.h 文件构成

2. tracepath。与traceroute功能相似，使用tracepath测试IP数据报文从源主机传到目的主机经过的路由。tracepath程序由tracepath.c tracepath6.c traceroute6.c 文件构成。

3. arping。使用arping向目的主机发送ARP报文，通过目的主机的IP获得该主机的硬件地址。arping程序由arping.c文件构成。

4. tftpd。tftpd是简单文件传送协议TFTP的服务端程序。tftpd程序由tftp.h tftpd.c tftpsubs.c文件构成。

5. rarpd。rarpd是逆地址解析协议的服务端程序。rarpd程序由rarpd.c文件构成。

6. clockdiff。使用clockdiff可以测算目的主机和本地主机的系统时间差。clockdiff程序由clockdiff.c文件构成。

7. rdisc。rdisc是路由器发现守护程序。rdisc程序由rdisc.c文件构成。
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;1.2       本文简介
   本文是在对源程序的分析的过程中写的总结文档。本文将依次对软件包中的程序进行介绍。介绍主要按照如下几个方面进行：&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;1. 在前言中简要介绍程序的基本用途、基本原理等。这是对于软件包中各软件的基本认识的总结。

2. 在程序使用中介绍程序的使用方法、使用选项等。这是对于使用软件包中程序的使用方法的介绍。

3. 在程序流程图中给出程序的基本流程。流程图的优点是比较能直观地给出程序的功能实现的流程，方便对程序有全局的掌握。然而不可避免地，流程图隐去了诸多的实现细节，所以如果要进一步分析程序，还需要进一步深入细节。

4. 介绍全局变量的含义、用途、变化等。全局变量是在程序中任何地方都可以访问的变量，所以分析全局变量有助于理解程序的数据变化流程。

5. 对于重要函数的介绍。一些重要的函数，不仅在程序的实现上占有重要的作用，而且理解起来有一定的难度，我觉得有必要进行分析。

6. 对于牵涉到的网络协议的介绍。阅读iputils源码的目的和好处之一就是帮助进一步理解网络协议。iputils涉及到IP、UDP、 ARP、RARP、ICMP、TFTP等不同层次的网络协议。本文将给出网络协议的基本介绍，主要是给出了网络报文的格式等内容。

7. 对于程序中重要的实现方法的介绍。而在iputils源码分析中，遇到了很多计算机网络方面的概念、思想、策略和机制。结合iputils的具体实现方法，本文将介绍计算机网络方面的相关知识。
&lt;/code&gt;&lt;/pre&gt;

&lt;ol&gt;
  &lt;li&gt;对其他知识的介绍，例如基于linux的多线程编程或linux下socket编程的知识。在分析源码的过程中，不可回避地遇到了这些知识的使用。
1.3       附件说明&lt;/li&gt;
&lt;/ol&gt;

&lt;pre&gt;&lt;code&gt;本文基于的源码版本为iputils-s20071127。源代码可以在http://www.linux-ipv6.org/gitweb/gitweb.cgi?p=gitroot/iputils.git中下载。

在阅读和分析源代码过程中，对代码进行了大量的注释，附件可以在下载http://download.csdn.net/detail/fsdev/4498604。

为了能够编译通过，定义了rdisc.c需要使用但是源代码中没有定义的宏：

#define OPEN_MAX   10

这个宏的意义是程序所能够打开的最大的文件数目。rdisc程序在退到后台之后，需要关闭除了socket文件之外的所有文件，OPEN_MAX宏就是在这里使用的。为了能够输出测试信息，并尽量不修改原程序代码，定义宏：

#define lixiprintf printf

所有添加输出信息的部分都使用lixiprintf宏。除了加入注释和以上两个更改外，没有修改程序其他地方。
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;2.1       引言
   “ping”这个名字源于声纳定位操作。Ping程序由Mike Muuss编写，目的是为了测试另一台主机是否可达。该程序发送一份ICMP回显请求报文给主机，并等待返回ICMP回显应答。&lt;/p&gt;

&lt;p&gt;2.2       ping程序的使用
    敲入命令：&lt;/p&gt;

&lt;p&gt;[plain] view plain copy
lixi@lixi-desktop:~$ ping -V&lt;br /&gt;
ping utility, iputils-sss20071127&lt;br /&gt;
    说明本机中安装的ping程序和本文研究的ping程序一样，是最新版本。&lt;/p&gt;

&lt;p&gt;[plain] view plain copy
lixi@lixi-desktop:~$ ping -T tsonly www.ustc.edu.cn -c 1&lt;br /&gt;
PING www.ustc.edu.cn (202.38.64.9) 56(124) bytes of data.&lt;br /&gt;
64 bytes from 202.38.64.9: icmp_seq=1 ttl=62 time=0.795 ms&lt;br /&gt;
TS:     6123570 absolute&lt;br /&gt;
    493&lt;br /&gt;
    364&lt;br /&gt;
    -857378&lt;br /&gt;
    0&lt;br /&gt;
    857378&lt;br /&gt;
    -363&lt;br /&gt;
    -493&lt;/p&gt;

&lt;p&gt;— www.ustc.edu.cn ping statistics —&lt;br /&gt;
1 packets transmitted, 1 received, 0% packet loss, time 0ms&lt;br /&gt;
rtt min/avg/max/mdev = 0.795/0.795/0.795/0.000 ms&lt;br /&gt;
    6123570是时间戳的绝对值，而输出的其他时间戳是相对上一个时间戳的差别。在北京时间9：42做的测试，北京时区为UTC+8，故此有9＋42/60-8=1.7&lt;/p&gt;

&lt;p&gt;而6123570/60/60/1000＝1.7。故此出现这个结果是非常有道理的。&lt;/p&gt;

&lt;p&gt;[plain] view plain copy
lixi@lixi-desktop:~$ ping www.ustc.edu.cn -R -c 1&lt;br /&gt;
PING www.ustc.edu.cn (202.38.64.9) 56(124) bytes of data.&lt;br /&gt;
64 bytes from 202.38.64.9: icmp_seq=1 ttl=62 time=0.852 ms&lt;br /&gt;
RR:     lixi-desktop.local (210.45.74.25)&lt;br /&gt;
    202.38.96.36&lt;br /&gt;
    local-gw.ustc.edu.cn (202.38.64.126)&lt;br /&gt;
    202.38.64.9&lt;br /&gt;
    202.38.64.9&lt;br /&gt;
    202.38.96.33&lt;br /&gt;
    210.45.74.1&lt;br /&gt;
    lixi-desktop.local (210.45.74.25)&lt;br /&gt;
    对照上面的路由信息，我们就可以分析出为什么时间戳信息里会有对称的现象，而对称轴的值是0了。&lt;/p&gt;

&lt;p&gt;产生对称性的另一个条件是RTT很小，这里只有0.8ms。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;我们可以还可以分析出202.38.64.9的系统时间和其他路由的系统时间相差很大，大约有-14分钟。
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;[plain] view plain copy
lixi@lixi-desktop:~$ ping -T tsandaddr www.ustc.edu.cn -c 1&lt;br /&gt;
PING www.ustc.edu.cn (202.38.64.9) 56(124) bytes of data.&lt;br /&gt;
64 bytes from 202.38.64.9: icmp_seq=1 ttl=62 time=1.66 ms&lt;br /&gt;
TS:     lixi-desktop.local (210.45.74.25)   7375300 absolute&lt;br /&gt;
    210.45.74.1 828&lt;br /&gt;
    local-gw.ustc.edu.cn (202.38.64.126)    26&lt;br /&gt;
    202.38.64.9 -857405&lt;br /&gt;
Unrecorded hops: 3&lt;/p&gt;

&lt;p&gt;— www.ustc.edu.cn ping statistics —&lt;br /&gt;
1 packets transmitted, 1 received, 0% packet loss, time 0ms&lt;br /&gt;
rtt min/avg/max/mdev = 1.664/1.664/1.664/0.000 ms&lt;br /&gt;
   上面是同时记录路由和时间戳信息。不过这里由于IP选项长度的限制，只能存储4个路由和它对应的时间戳。
[plain] view plain copy
lixi@lixi-desktop:~$ ping -T tsprespec 202.38.64.9 202.38.96.33 210.45.74.1 www.ustc.edu.cn -c 1&lt;br /&gt;
PING www.ustc.edu.cn (202.38.64.9) 56(124) bytes of data.&lt;br /&gt;
64 bytes from 202.38.64.9: icmp_seq=1 ttl=62 time=0.893 ms&lt;br /&gt;
TS:     202.38.64.9 6741320 absolute&lt;br /&gt;
    202.38.96.33    0&lt;br /&gt;
    210.45.74.1 857353&lt;br /&gt;
Unrecorded hops: 1&lt;/p&gt;

&lt;p&gt;— www.ustc.edu.cn ping statistics —&lt;br /&gt;
1 packets transmitted, 1 received, 0% packet loss, time 0ms&lt;br /&gt;
rtt min/avg/max/mdev = 0.893/0.893/0.893/0.000 ms&lt;br /&gt;
    如果我们一定要得到以后的几个路由和时间戳，我们可以采用上述的办法。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;这里在北京时间10：07分的时候进行的测试，202.38.64.9的时间戳是6741320，而我们上面的分析，202.38.64.9的系统时间大约比北京时间晚14分钟。10-8-14/60=1.87。6741320/60/60/1000=1.87。故此出现这个时间戳也是很有道理的。

ping程序的选项解释如下：

-a   

    可听见的ping。

    所谓可听见,不过是在ping.c文件的parse_reply的函数中,输出ASCII码'/a',beep一下。
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;-A&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;    自适应的ping。调整报文间隔时间，使其适应于RTT，这样非常有效率地使得网络中传输的不超过一个（如果-l参数设置了就为多个）。对于非超级用户，最小的时间间隔为200毫秒，在一个RTT比较得下的网络中，这个模式和-f的洪泛模式基本相同。

    为了调整报文时间间隔,使用update_interval()函数来调整时间间隔。

-b

    允许ping广播地址。

    设置broadcast_pings为1，当判断到这个选项设为1之后，且地址是广播地址，那么就设置setsockopt(icmp_sock, SOL_SOCKET, SO_BROADCAST,&amp;amp;broadcast_pings, sizeof(broadcast_pings))。

-B

    不允许ping改变报文的源主机地址，该地址在ping开始运行的时候就已经指定了。

    为了指定源主机地址,ping.c使用函数bind()来把套接字和本地套接字地址绑定，即在已创建的套接字上加上本地套接字地址。

-c &amp;lt;count&amp;gt;

    在发送&amp;lt;count&amp;gt;个ECHO_REQUEST报文。当和-w &amp;lt;deadline&amp;gt;一起设置时，ping等待收到&amp;lt;count&amp;gt;个ECHO_REPLY报文，直到超出时间限制为止。

    设置npackets选项为&amp;lt;count&amp;gt;就可以了。在没有设置deadline的情况下，当nreceived + nerrors &amp;gt;=npackets时就可以退出循环，完成ping的任务了。

-d

    设置socket中的SO_DEBUG选项，使能调试跟踪。实质上Linux内核中没有使用这个套接字选项。

    设置方法：setsockopt(icmp_sock,SOL_SOCKET, SO_DEBUG, (char *)&amp;amp;hold, sizeof(hold));

-F &amp;lt;flow&amp;gt; &amp;lt;label&amp;gt;

   这个选项只有ping6才有。

-f

  洪泛模式。对每一个ECHO_REQUEST报文的发送，打印一个“.”，当接受到ECHO_REPLY报文时，打印一个backspace字符。这样能够快速地表明网络丢失了多少个报文。如果interval没有设置，则设置interval为0，并按照报文接受的速度和一百次每秒的速度来发送报文（看哪个速度快）。只有超级用户能够和-i 0选项一起使用这个选项。

-i &amp;lt;interval&amp;gt;

   在发送每个报文之间等待&amp;lt;interval&amp;gt;秒。默认设置是等待一秒，在洪泛模式下则不等待。只有超级用户才能将&amp;lt;interval&amp;gt;设置为小于0.2秒的数。

   interval为&amp;lt;interval&amp;gt;*1000，程序的实现决定了&amp;lt;interval&amp;gt;输入整型数和浮点数都能被正确接受。

-I &amp;lt;interface/address&amp;gt;

    设置发送的地址或者网络设备。

    程序首先尝试用intinet_pton(int af, const char *src, void *dst)函数由将src代表的字符串转化为dst中的IP地址。如果不能正确转换，则意味着这个选项不是地址，例如210.45.74.25，而是设备名如eth0。如果是后者，则设置device为&amp;lt;interface&amp;gt;，并用bind(icmp_sock, (structsockaddr*)&amp;amp;source, sizeof(source))      setsockopt(probe_fd,SOL_SOCKET, SO_BINDTODEVICE, device, strlen(device)+1)来将套接字和本地套接字地址进行绑定。

-l &amp;lt;preload&amp;gt;

    &amp;lt;preload&amp;gt;是在没有接受到回复报文之前能发送的最多报文。非超级用户最多只能设置为3。

    尽可能快地发送预载的报文，然后再返回到正常发送模式。

    将&amp;lt;preload&amp;gt;值赋到preload变量中。如果不赋值preload默认为1。

-L

    禁止多播数据包的回环，只有在ping的目的主机是广播地址时才管用。

-n

    只有数字形式ip地址值的输出，不通过查询DNS获知IP地址对应的主机名，以节省时间。

    设置F_NUMERIC，不用调用gethostbyaddr来查询DNS主机名了。

    用gethostbyaddr的由查询目的主机的IP地址。

-p &amp;lt;pattern&amp;gt;

    允许为传输的回显报文中包含的内容指定字节模式。这对于诊断与传输数据有关的网络问题可能很有用。数据采用16进制，例如“-p ff”可将传输的报文填充为全1。

-Q &amp;lt;tos&amp;gt;

    用来设置服务质量（Quality of Service ）

    例如最小开销、 可靠性、吞吐量、低延迟。

    IP协议有一个8bit的DS区分服务（以前叫服务类型）。前三位是优先（precedence）字段（在目前，优先字段并未被大家使用），接着4bit是TOS位，最后1bit没有使用，但必须置0。

    4比特TOS位的意义分别为D（最小时延）、T（最大吞吐量）、R（最高可靠性）、C（最小代价）。要设置TOS位为对应意义，可以设置-Q &amp;lt;tos&amp;gt;分别为0x10，0x08，0x04，0x02。TOS的各个位不能同时置1。

-q

    静默模式。这种模式下，出了开始的提示和结束的数据统计，不会输出任何东西。

-R

    记录路由信息。在发送的IP报文首部选项中放入记录路由选项，在接到到报文回复之后，打印出回复报文的路由信息。

    注意：IP报文的选项中最多只能计算9个路由信息，计算方式如下：

    首部长度HLEN。这4bit字段用来定义首部的长度，以4字节为单位。由于首部长度可变，默认长度是20字节，此时4bit字段值为5。4bit的字段最大可以表示的数为15，故此首部长度最大为15*4byte，即60byte。首部的可变字节数为60-20＝40byte，RR选项用去3byte（参见记录路由选项的一般格式），只剩下37byte，最多只能放下9个IP地址。

    注意：很多的主机会略过IP报文的路由选项，因此有可能在回复报文中没有路由信息。

    注意：不能和-T选项一起使用。

-r

    绕过一般的路由表而直接向一个连接着的主机发送报文。如果主机不是通过直接连接的网络相连，则会出现错误。这个选项可以用来ping一个没有通过路由相连而是通过一个接口相连（假设也使用了-I选项）的本地主机。

    使用setsockopt函数设置套接字的SOL_SOCKET级别的SO_DONTROUTE选项即可。

-s &amp;lt;packetsize&amp;gt;

    设置ICMP报文的数据部分的长度。默认值是56，和ICMP首部的8字节一起作为IP报文的数据部分。

    设置datalen变量就可以了，datalen默认为DEFDATALEN（值是56）。长度为datalen的数据和8字节的首部一起作为ICMP报文。

-S &amp;lt;sndbuf&amp;gt;

    设置套接字的发送缓冲区大小。如果没有设置，则被设定为不超过一个报文长度的长度。

-t &amp;lt;ttl&amp;gt;

    设置TTL（time to live）。

    使用setsockopt函数设置套接字的IPPROTO_IP级别的IP_MULTICAST_TTL和IP_TTL选项即可。

-T &amp;lt;timestamp&amp;gt; &amp;lt;option&amp;gt;

    设置IP时间戳选项。时间戳选项可以是以下三种：

    -T tsonly 只记录时间戳。

    -T tsandaddr 收集时间戳和IP地址。

    -T tsprespec [host1 [host2 [host3[host4]]]] 收集来自预定的网络段的时间戳和地址，发送端对选项列表进行初始化，存放了4个IP地址和四个取值为0的时间戳。只有在列表中的下一个地址和当前路由地址相匹配时，才记录它的时间戳。

    与-R选项的分析类似，首部的可变字节数为60-20＝40byte，选项用去4byte（参见时间戳选项的一般格式），只剩下36byte，最多只能放下9个时间戳。

    注意：由于IP首部的空间限制，程序限制-R选项与-T不能同时使用。

-M &amp;lt;hint&amp;gt;

    设定Path MTU查找选下项，可设置成下列三种：

    -M do 不允许分段，甚至不允许在本地分段。

    -M want 找出PMTU，在如果包太大就在本地分段。

    -M dont 不要设置IP首部中的DF位，即允许分段。

    使用setsockopt函数设置套接字的SOL_IP级别的IP_MTU_DISCOVER选项即可。

-U

-v

   冗余输出。输出很多具体信息。

-V

    打印ping的版本，然后退出。

-w &amp;lt;deadline&amp;gt;

    设定时间期限为&amp;lt;deadline&amp;gt;秒，不管已经发送和接到了多少包，只要达到时间期限就结束ping的过程。

-W &amp;lt;timeout&amp;gt;

    等待回复的时间，单位是秒。这个选项只在没有接到任何的回复的情况下有效，只要接到了一个回复，就将等待时间设置为两倍的RTT。如果没有设置，则等待时间设置为一个最大值。
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;2.3       ping程序的流程图
    ping程序的流程图如下所示：&lt;/p&gt;

&lt;p&gt;2.4       IP报文结构
    IP报文结构如下所示：&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;IP数据报文的首部中有选项部分，这个部分可以用来存储IP时间戳或者IP记录路由选项。

存储IP时间戳，如下图所示：

 

IP记录路由选项，如下图所示：
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;2.5       ICMP报文结构
    ICMP的封装方式如下图所示：&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;ICMP报文的结构如下图所示：
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;2.6       ICMP回显请求和回显应答报文格式
    ICMP回显请求和回显应答报文格式如下所示：&lt;/p&gt;

&lt;p&gt;2.7       ICMP报文类型列表
    不同种类的ICMP报文的首部有所不同。如下：&lt;/p&gt;

&lt;p&gt;类型&lt;/p&gt;

&lt;p&gt;代码&lt;/p&gt;

&lt;p&gt;描述&lt;/p&gt;

&lt;p&gt;0&lt;/p&gt;

&lt;p&gt;ICMP_ECHOREPLY&lt;/p&gt;

&lt;p&gt;0&lt;/p&gt;

&lt;p&gt;回显应答&lt;/p&gt;

&lt;p&gt;3&lt;/p&gt;

&lt;p&gt;ICMP_DEST_UNREACH&lt;/p&gt;

&lt;p&gt;目的不可达&lt;/p&gt;

&lt;p&gt;0&lt;/p&gt;

&lt;p&gt;ICMP_NET_UNREACH&lt;/p&gt;

&lt;p&gt;网络不可达&lt;/p&gt;

&lt;p&gt;1&lt;/p&gt;

&lt;p&gt;ICMP_HOST_UNREACH&lt;/p&gt;

&lt;p&gt;主机不可达&lt;/p&gt;

&lt;p&gt;2&lt;/p&gt;

&lt;p&gt;ICMP_PROT_UNREACH&lt;/p&gt;

&lt;p&gt;端口不可达&lt;/p&gt;

&lt;p&gt;3&lt;/p&gt;

&lt;p&gt;ICMP_PORT_UNREACH&lt;/p&gt;

&lt;p&gt;协议不可达&lt;/p&gt;

&lt;p&gt;4&lt;/p&gt;

&lt;p&gt;ICMP_FRAG_NEEDED&lt;/p&gt;

&lt;p&gt;需要进行分片单设置了不分片比特&lt;/p&gt;

&lt;p&gt;5&lt;/p&gt;

&lt;p&gt;ICMP_SR_FAILED&lt;/p&gt;

&lt;p&gt;源站选路失败&lt;/p&gt;

&lt;p&gt;6&lt;/p&gt;

&lt;p&gt;ICMP_NET_UNKNOWN&lt;/p&gt;

&lt;p&gt;目的网络不认识&lt;/p&gt;

&lt;p&gt;7&lt;/p&gt;

&lt;p&gt;ICMP_HOST_UNKNOWN&lt;/p&gt;

&lt;p&gt;目的主机不认识&lt;/p&gt;

&lt;p&gt;8&lt;/p&gt;

&lt;p&gt;ICMP_HOST_ISOLATED&lt;/p&gt;

&lt;p&gt;源主机被隔离（作废不用）&lt;/p&gt;

&lt;p&gt;9&lt;/p&gt;

&lt;p&gt;ICMP_NET_ANO&lt;/p&gt;

&lt;p&gt;目的网络被强制禁止&lt;/p&gt;

&lt;p&gt;10&lt;/p&gt;

&lt;p&gt;ICMP_HOST_ANO&lt;/p&gt;

&lt;p&gt;目的主机被强制禁止&lt;/p&gt;

&lt;p&gt;11&lt;/p&gt;

&lt;p&gt;ICMP_NET_UNR_TOS&lt;/p&gt;

&lt;p&gt;由于服务类型TOS，网络不可达&lt;/p&gt;

&lt;p&gt;12&lt;/p&gt;

&lt;p&gt;ICMP_HOST_UNR_TOS&lt;/p&gt;

&lt;p&gt;由于服务类型TOS，主机不可达&lt;/p&gt;

&lt;p&gt;13&lt;/p&gt;

&lt;p&gt;ICMP_PKT_FILTERED&lt;/p&gt;

&lt;p&gt;由于过滤，通信被强制禁止&lt;/p&gt;

&lt;p&gt;14&lt;/p&gt;

&lt;p&gt;ICMP_PREC_VIOLATION&lt;/p&gt;

&lt;p&gt;主机越权&lt;/p&gt;

&lt;p&gt;15&lt;/p&gt;

&lt;p&gt;ICMP_PREC_CUTOFF&lt;/p&gt;

&lt;p&gt;优先权终止生效&lt;/p&gt;

&lt;p&gt;ICMP_SOURCE_QUENCH&lt;/p&gt;

&lt;p&gt;4&lt;/p&gt;

&lt;p&gt;0&lt;/p&gt;

&lt;p&gt;源端被关闭&lt;/p&gt;

&lt;p&gt;ICMP_REDIRECT&lt;/p&gt;

&lt;p&gt;5&lt;/p&gt;

&lt;p&gt;重定向&lt;/p&gt;

&lt;p&gt;0&lt;/p&gt;

&lt;p&gt;ICMP_REDIR_NET&lt;/p&gt;

&lt;p&gt;对网络重定向&lt;/p&gt;

&lt;p&gt;1&lt;/p&gt;

&lt;p&gt;ICMP_REDIR_HOST&lt;/p&gt;

&lt;p&gt;对主机重定向&lt;/p&gt;

&lt;p&gt;2&lt;/p&gt;

&lt;p&gt;ICMP_REDIR_NETTOS&lt;/p&gt;

&lt;p&gt;对服务类型和网络重定向&lt;/p&gt;

&lt;p&gt;3&lt;/p&gt;

&lt;p&gt;ICMP_REDIR_HOSTTOS&lt;/p&gt;

&lt;p&gt;对服务类型和主机重定向&lt;/p&gt;

&lt;p&gt;ICMP_ECHO&lt;/p&gt;

&lt;p&gt;8&lt;/p&gt;

&lt;p&gt;0&lt;/p&gt;

&lt;p&gt;请求回显&lt;/p&gt;

&lt;p&gt;9&lt;/p&gt;

&lt;p&gt;0&lt;/p&gt;

&lt;p&gt;路由器通告&lt;/p&gt;

&lt;p&gt;10&lt;/p&gt;

&lt;p&gt;0&lt;/p&gt;

&lt;p&gt;路由器请求&lt;/p&gt;

&lt;p&gt;ICMP_TIME_EXCEEDED&lt;/p&gt;

&lt;p&gt;11&lt;/p&gt;

&lt;p&gt;超时&lt;/p&gt;

&lt;p&gt;0&lt;/p&gt;

&lt;p&gt;ICMP_EXC_TTL&lt;/p&gt;

&lt;p&gt;传输请见生存时间为0&lt;/p&gt;

&lt;p&gt;1&lt;/p&gt;

&lt;p&gt;ICMP_EXC_FRAGTIME&lt;/p&gt;

&lt;p&gt;在数据包组装期间生存时间为0&lt;/p&gt;

&lt;p&gt;ICMP_PARAMETERPROB&lt;/p&gt;

&lt;p&gt;12&lt;/p&gt;

&lt;p&gt;参数问题&lt;/p&gt;

&lt;p&gt;0&lt;/p&gt;

&lt;p&gt;坏的IP首部&lt;/p&gt;

&lt;p&gt;1&lt;/p&gt;

&lt;p&gt;缺少必需的选项&lt;/p&gt;

&lt;p&gt;ICMP_TIMESTAMP&lt;/p&gt;

&lt;p&gt;13&lt;/p&gt;

&lt;p&gt;0&lt;/p&gt;

&lt;p&gt;时间戳请求&lt;/p&gt;

&lt;p&gt;ICMP_TIMESTAMPREPLY&lt;/p&gt;

&lt;p&gt;14&lt;/p&gt;

&lt;p&gt;0&lt;/p&gt;

&lt;p&gt;时间戳应答&lt;/p&gt;

&lt;p&gt;ICMP_INFO_REQUEST&lt;/p&gt;

&lt;p&gt;15&lt;/p&gt;

&lt;p&gt;0&lt;/p&gt;

&lt;p&gt;信息请求&lt;/p&gt;

&lt;p&gt;ICMP_INFO_REPLY&lt;/p&gt;

&lt;p&gt;16&lt;/p&gt;

&lt;p&gt;0&lt;/p&gt;

&lt;p&gt;信息应答&lt;/p&gt;

&lt;p&gt;ICMP_ADDRESS&lt;/p&gt;

&lt;p&gt;17&lt;/p&gt;

&lt;p&gt;0&lt;/p&gt;

&lt;p&gt;地址掩码请求&lt;/p&gt;

&lt;p&gt;ICMP_ADDRESSREPLY&lt;/p&gt;

&lt;p&gt;18&lt;/p&gt;

&lt;p&gt;0&lt;/p&gt;

&lt;p&gt;地址掩码应答&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;pr_icmph()函数中分析ICMP报文类型，并针对错误报文打印出出错问题。惨照上表就能比较好地分析各种问题出现的大致原因了。

另外在rdisc.c文件中使用了ICMP的路由器通告报文（类型为9）和ICMP路由器请求报文（类型为10）。

各种ICMP类型和代码的常量定义在linux-2.6.27/include/linux/icmp.h文件中。
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;2.8       socket选项
    程序中使用setsockopt()函数设定了套接字的选项。用到的选项如下：&lt;/p&gt;

&lt;p&gt;level（级别）&lt;/p&gt;

&lt;p&gt;optname（选项名）&lt;/p&gt;

&lt;p&gt;说明&lt;/p&gt;

&lt;p&gt;标志&lt;/p&gt;

&lt;p&gt;SOL_SOCKET&lt;/p&gt;

&lt;p&gt;SO_BROADCAST&lt;/p&gt;

&lt;p&gt;允许或禁止发送广播数据&lt;/p&gt;

&lt;p&gt;Ö&lt;/p&gt;

&lt;p&gt;SO_ATTACH_FILTER&lt;/p&gt;

&lt;p&gt;安装过滤器。&lt;/p&gt;

&lt;p&gt;SO_SNDBUF&lt;/p&gt;

&lt;p&gt;设置发送缓冲区的大小。&lt;/p&gt;

&lt;p&gt;SO_RCVBUF&lt;/p&gt;

&lt;p&gt;设置接收缓冲区的大小。&lt;/p&gt;

&lt;p&gt;SO_DEBUG&lt;/p&gt;

&lt;p&gt;打开或关闭调试信息&lt;/p&gt;

&lt;p&gt;Ö&lt;/p&gt;

&lt;p&gt;SO_DONTROUTE&lt;/p&gt;

&lt;p&gt;打开或关闭路由查找功能。&lt;/p&gt;

&lt;p&gt;Ö&lt;/p&gt;

&lt;p&gt;SO_TIMESTAMP&lt;/p&gt;

&lt;p&gt;打开或关闭数据报中的时间戳接收。&lt;/p&gt;

&lt;p&gt;Ö&lt;/p&gt;

&lt;p&gt;SO_SNDTIMEO&lt;/p&gt;

&lt;p&gt;设置发送超时时间。&lt;/p&gt;

&lt;p&gt;SO_RCVTIMEO&lt;/p&gt;

&lt;p&gt;设置接收超时时间。&lt;/p&gt;

&lt;p&gt;SO_BINDTODEVICE&lt;/p&gt;

&lt;p&gt;将套接字绑定到一个特定的设备上。&lt;/p&gt;

&lt;p&gt;SOL_RAW&lt;/p&gt;

&lt;p&gt;ICMP_FILTER&lt;/p&gt;

&lt;p&gt;设置套接字ICMP过滤选项。&lt;/p&gt;

&lt;p&gt;IPPROTO_IP&lt;/p&gt;

&lt;p&gt;IP_OPTIONS&lt;/p&gt;

&lt;p&gt;设置发出的数据报中的IP选项&lt;/p&gt;

&lt;p&gt;IP_MULTICAST_LOOP&lt;/p&gt;

&lt;p&gt;多播API，禁止组播数据回送&lt;/p&gt;

&lt;p&gt;Ö&lt;/p&gt;

&lt;p&gt;IP_MULTICAST_TTL&lt;/p&gt;

&lt;p&gt;多播API，设置输出组播数据的TTL值&lt;/p&gt;

&lt;p&gt;IP_TOS&lt;/p&gt;

&lt;p&gt;设置发出的数据报中的IP TOS&lt;/p&gt;

&lt;p&gt;SOL_IP&lt;/p&gt;

&lt;p&gt;IP_MTU_DISCOVER&lt;/p&gt;

&lt;p&gt;为套接字设置Path MTU Discovery setting(路径MTU发现设置)&lt;/p&gt;

&lt;p&gt;Ö&lt;/p&gt;

&lt;p&gt;IP_RECVERR&lt;/p&gt;

&lt;p&gt;允许传递扩展的可靠的错误信息&lt;/p&gt;

&lt;p&gt;Ö&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;程序首先取得了一个UDP的套接字probe_fd，并根据用户的输入配置套接字的选项。probe_fd用到的选项主要有：SO_BINDTODEVICE、SO_BINDTODEVICE、SO_BROADCAST、IP_TOS等。

ICMP报文的套接字icmp_sock用到的选项除了SO_BINDTODEVICE选项以外，列表中的所有选项都用到了。
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;2.9       ping.c程序的全局变量的分析
    static int ts_type;&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;    timestamp的类型

    在-T选项中设置，可以设置为IPOPT_TS_TSONLY、IPOPT_TS_TSANDADDR或者IPOPT_TS_PRESPEC。

static int nroute = 0;

     主机输入的总数，最多为9个，因为IP首部选项中最多能存储9个地址

static __u32 route[10];     

    在输入多个主机时，存储地址。

    可能输入多个主机的情况是：-Ttsprespec [host1 [host2 [host3 [host4]]]] 选项，或者ping hostName1 hostName2 ... hostNameN；前者是想获得确定几个路由对应的时间戳，而后者为什么这么设置，我还不大明白  。

struct sockaddr_in whereto;

    存储了目的主机的信息。

int optlen = 0;

    ip选项的长度。

    由IP的协议可知，最大为40，在需要在IP首部选项字段中存储数据时（例如-T、-R选项）就设置为最大值。

int settos = 0;

    服务质量的设置。

    可以用-Q选项用来设置服务质量，例如最小开销、 可靠性、吞吐量、低延迟。

    IP协议有一个8bit的DS区分服务（以前叫服务类型）。前三位是优先（precedence）字段（在目前，优先字段并未被大家使用），接着4bit是TOS位，最后1bit好像没有使用。

    4比特TOS位的意义分别为D（最小时延）、T（最大吞吐量）、R（最高可靠性）、C（最小代价）。

    要设置TOS位为对应意义，可以设置-Q &amp;lt;tos&amp;gt;中的 &amp;lt;tos&amp;gt;分别为0x10，0x08，0x04，0x02     。

int icmp_sock;

    ICMP的soket文件描述符。

u_char outpack[0x10000];

    用来存储ICMP报文首部和数据的数组，为ICMP报文分配的存储空间。

int maxpacket = sizeof(outpack);

    用来存储ICMP报文首部和数据的数组的最大大小。

static int broadcast_pings = 0;

    标识用户是不是想ping广播地址。

    可以通过-b选项设置。

    如果不设置，则默认为0。

struct sockaddr_in source;

    存储了源主机的信息。

    如果-I选项后面带的是源主机地址而不是设备名的话，就将主机的信息存储在source中。在socket试探的连接成功后，程序还用getsockname重新确定了source的值。

char *device;

    如果-I选项后面带的是设备名而不是源主机地址的话，如eth0，就用device指向该设备名。

    该device指向一个设备名之后，会设置socket的对应设备为该设备。

int pmtudisc = -1;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;2.10   ping_common.c程序的全局变量的分析
    int options;&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;    存储各种选项的FLAG设置情况。

    在判断输入选项时设置各个bit位。

int sndbuf;

    发送缓冲区大小。

    可以在-S &amp;lt;sndbuf&amp;gt;中设置，如果没有设置，则估计一个大小。

int ttl;

    报文ttl的值。

    可以在-t选项中设置。

    在设置soket选项时设置IP广播报文TTL和IP报文的TTL都为ttl值。

int rtt;

    用指数加权移动平均算法估计出来的RTT值。

    初始值是0。

    gather_statistics()函数中根据上次的RTT值和原来的rtt值加权得到新rtt的值。

    在update_interva()函数中用来计算新的interval的值。

int rtt_addend;

    配合rtt使用。

    用来计算新的interval的值，似乎是更具上个rtt的值给interval留部分余量。

__u16 acked;

    接到ACK的报文的16bit序列号。

    在gather_statistics()函数里更新，实际的更新方法似的acked不超过0x7FFF，不然就会发生回绕。

int mx_dup_ck = MAX_DUP_CHK;

    ？

long npackets;

    需要传输的最多报文数。

    可以在-c 选项里设置。

    如果没有设置则默认是0，故此每次在查询此值时就判断是否为0，0似乎作为无穷大来考虑。

long nreceived;

    得到回复的报文数。

    初始值是0。

    在gather_statistics函数中递加，进行统计。在程序执行finsh时，使用这个变量，打印出来作为参考。

long nrepeats;

    重复的报文数。

    初始值是0。

    在gather_statistics函数中递加，进行统计。在程序执行finsh时，使用这个变量，打印出来作为参考。

long ntransmitted;

    发送的报文的最大序列号。

    初始值是0。

   在pinger函数中递加，进行统计。在程序执行finsh时，使用这个变量，打印出来作为参考。

long nchecksum;

    checksum错误的恢复报文。

    初始值是0。

    在gather_statistics函数中，若csfailed为1的时候，则递加，进行统计。在程序执行finsh时，使用这个变量，打印出来作为参考。

    不过似乎checksum是不会被改变的，因为gather_statistics的选项csfailed在唯一的一次调用中（parse_reply()函数中）为0。

long nerrors;

    icmp错误数。

    初始值是0。

    在程序接受到出错的报文之后，就会调用receive_error_msg。在这个函数里如果判断确实是一个错误，错误有可能是本地出错，有可能是网络出错，不管是哪个出错，都将这nerrors递加。parse_reply也会改变这个变量。在程序执行finsh时，使用这个变量，打印出来作为参考。

int interval = 1000;           

    发送两个相邻报文之间相距的时间，单位为毫秒。

    可以在-i选项中设置。

    在设置-f的洪泛模式下，会设置interval为0。

    如果没有设置，则默认是1000。

int preload;

    在接受到第一个回复报文之前所发送的报文数。

    可以通过-l &amp;lt;preload&amp;gt;选项设置。

    如果没有设置，默认值是1。

int deadline = 0;

    在deadline秒之后，程序退出。

    可以由-w选项设置。如果设置了，则在setup函数中设置闹钟，当程序执行到deadline秒时产生SIGALRM中断，退出程序。
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;如果没有设置则默认值是0，程序运行没有时间限制。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;int lingertime = MAXWAIT*1000;

    等待回复的最长时间，单位为毫秒。

    可以通过-W选项设置。这个值在完成一次正确发收过程后就由2*tmax代替，而失去作用了。

    默认值是MAXWAIT*1000即10000，MAXWAIT定义在ping_common.h中。

struct timeval start_time;

    程序运行开始时的主机时间。

    在setup函数中使用gettimeofday初始化，在finish函数中和cur_time一起用来计算程序运行的时间。

struct timeval cur_time;

    程序运行时当前的主机时间。

volatile int exiting;

    程序是不是应该退出。

    初始值是0，就是不应该退出。

    在中断处理程序sigexit中会将这个值设为1。这个中断处理程序只在产生SIGALRM和SIGINT中断时(可以用Ctrl+c产生)才会执行。中断处理程序在setup函数中安装。

volatile int status_snapshot;

    程序是不是应该调用status()函数打印出程序的运行状态。

    初始值是0。

    在中断处理程序sigstatus中会将这个值设为1。这个中断处理程序只在产生SIGQUIT中断时(可以用Ctrl+\产生)才会执行。中断处理程序在setup函数中安装。

int confirm = 0;

    表明sendmsg函数的选项的MSG_CONFIRM选项是否设置。

    如果设置MSG_CONFIRM，则会告诉链路层的传送有了进展：已经接受到对方的一个成功的答复。由于MSG_CONFIRM的这个意义，所以在发送第一个数据是MSG_CONFIRM选项不因该设置，即confirm初始值为0。在成功接受到一个回复之后，confirm则应该设置为MSG_CONFIRM了。只有在确定取得一个回复时才将confirm由0改为MSG_CONFIRM，这就是为什么confirm只有在gather_statistics()才会被改变的原因。然而更麻烦的是MSG_CONFIRM选项只有在Linux 2.3及以上内核中才支持，所以就需要confirm_flag变量了。

int confirm_flag = MSG_CONFIRM;

    用来修补老版本linux内核的问题。

    confirm_flag的初始值为MSG_CONFIRM。这样在gather_statistics()里confirm就更新为confirm_flag了。但是，如果由于设置MSG_CONFIRM而产生了发送错误（linux版本较老，不支持MSG_CONFIRM选项）。这样就会在下个循环里调用gather_statistics()，更新confirm变量，保证不会发送出错了。

int working_recverr;

    ？

int timing;

    是否能够在ping过程中测算时间

    如果ICMP报文的数据长度足以存储timeval结构数据，则timing设置为1。如果timing设置为1，则在ICMP报文中插入发送的时间，这样在接受到ICMP回复时，就可以根据该数据计算RRT。否则就无法计算RRT，也就无法进行时间统计了。

    从根本上说timing的值由datalen变量的大小决定。

    可以尝试运行ping -s1 www.ustc.edu.cn -c 1，看看运行结果怎样。

    可以看到没有时间统计输出，因为-s选项设置的datalen值太小。

long tmin = LONG_MAX;             /*minimum round trip time */

    最小RRT

    初始值为LONG_MAX，每次接受到回复报文之后，就在gather_statistics函数中本次RRT是不是比tin大，如果是，就更新tmin。在程序执行完成之后，将打印出这个信息作为参考。

long tmax;                        

    最大RRT

    初始值为0，每次接受到回复报文之后，就在gather_statistics函数中本次RRT是不是比tmax大，如果是，就更新tmax。在程序执行完成之后，将打印出这个信息作为参考。

    此外tmax还作为每次发送报文后等待接受报文的时间长度的参考，见__schedule_exit函数。如果超出这个时间长度还没有完成一次发送和接受，则发生超时中断。

long long tsum;                 /*sum of all times, for doing average */

    每次RRT之和。

    初始值为0，每次接受到回复报文之后，就在gather_statistics函数中加上本次RRT。

    用来计算平均RRT。

long long tsum2;

    每次RRT的平方和。

    初始值为0，每次接受到回复报文之后，就在gather_statistics函数中加上本次RRT的平方。

    用来计算RRT的方差。

int  pipesize =-1;

    初始值为-1。

int datalen = DEFDATALEN;

    数据长度。

    初始值为DEFDATALEN，即56。

    可以通过-s选项设置     。

char *hostname;

    目的主机名字。

    在开始的时候，由用户作为程序的选项输入。随后通过gethostbyname()函数由主机名得到主机，然后将主机名改为函数返回的官方主机名。

    在最后输出的目的主机名就是这个名字。

int uid;

    用户ID。

    在main函数中通过getuid()取得。

    如果uid不是0，即用户不是超级用户，则在设置选项的时候有限制：

    -i&amp;lt;interval&amp;gt;，&amp;lt;interval&amp;gt;不得小于0.2；在ping广播地址时，&amp;lt;interval&amp;gt;不能设置为小于1的数。

    -M&amp;lt;hint&amp;gt;，在ping广播地址时，&amp;lt;hint&amp;gt;不能设置为IP_PMTUDISC_DO之外的IP_PMTUDISC_DONT或IP_PMTUDISC_WANT。

    -s&amp;lt;packetsize&amp;gt;， &amp;lt;packetsize&amp;gt;不能超过sizeof(outpack)-8。

    -v，不会输出比较敏感的冗长信息，例如parse_reply函数中可能输出的额外信息。

    -l&amp;lt;preload&amp;gt;，ping广播地址时，&amp;lt;preload&amp;gt;不能大于3。

    -f，必须要和-i选项配合使用，且&amp;lt;interval&amp;gt;不小于0.2。

int ident;

    本进程的ID。

    在setup函数中通过getpid()取得。

    在ICMP的数据中添加进程ID，并通过判断接受到的ICMP回复的进程ID是不是正确来判断ICMP回复是不是本进程的回复。

static int screen_width = INT_MAX;

   窗口的宽度大小，也就是控制台一行能打印多少字符。

   在setup函数中通过ioctl()取得。
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;2.11   重要函数的分析
    int main(int argc, char **argv);&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;    主函数。

    在这个函数里：取得用户输入的选项，并根据这些选项及其参数设置相应的标识和参数值。根据这些标识和参数值，首先连接（connect）一个探测的UDP报文，以探知目的地址的基本情况。然后设置ICMP报文的套接字选项，然后调用setup()函数来进一步设置与协议无关的套接字选项（与ping6公用）。在套接字设置好后，调用main_loop()函数完成探测。

    定义在ping.c文件中。

void main_loop(int icmp_sock, __u8 *packet, intpacklen);

    完成报文发送、分析的主要函数。

    在这个函数里：一直调用pinger()函数发ICMP报文和调用recvmsg()函数接受报文。如果recvmsg()函数没有正确接受报文，调用receive_error_msg()函数处理接受到的ICMP差错报文。如此反复，直到用户要求终止或者报文发送次数达到要求，或者超出的程序的时间限制，程序才停止发送/接受；程序在停止发送/接受后，调用finish()函数打印出统计数据。

    在main()函数中调用到此函数。

    定义在ping_common.c文件中。在这个文件中的所有函数都能够被ping和ping6共同使用。

void int pinger(void);

    构成并发送报文。

    在这个函数里：调用send_probe()尝试发送报文，并处理send_probe()没有成功发送时出现的错误。在处理某些种类的错误时，用到receive_error_msg()函数。

    在main_loop()函数中调用到此函数。

    定义在ping_common.c文件中。

int send_probe()

    构建报文，并发送报文。

    在这个函数里：根据用户的参数设置，设置ICMP报文的类型、代码、序号、标识符，并往ICMP报文的选项数据部分添加发送时间，然后计算校验和。构建出这个ICMP报文后，调用sendmsg()函数发送ICMP报文。此函数不处理发送出错。

    在pinger()函数中调用到此函数。

    定义在ping.c文件中。

int receive_error_msg()

    处理ICMP差错报文。

    在这个函数里：调用设置了MSG_ERRQUEUE标识的recvmsg()来接收错误队列中的ICMP错误报文。取得错误信息之后，分析出错的原因是由于本地原因还是网络原因，并进行处理（比如设置更严格的ICMP过滤）。

    在main_loop()函数和pinger()函数中调用到此函数。

    定义在ping.c文件中。

void setup(int icmp_sock)

    设置与协议无关的选项。

    在这个函数里：根据用户设置，这些设置包括interval的设置，socket的是否打开调试信息（SO_DEBUG）、是否打开路由查找功能（SO_DONTROUTE）、是否打开数据报中的时间戳接收（SO_TIMESTAMP）、发送时间限制（SO_SNDTIMEO）、接受时间限制（SO_RCVTIMEO）等选项，往报文内填内容的设置，中断处理程序的设置，闹钟的设置等。

    在main()函数和pinger()函数中调用到此函数。

    定义在ping_common.c文件中。
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;2.12   时间间隔和报文预发机制的实现
    程序使用一个分配时间片的概念，来控制发送报文的时间间隔，并实现在没有接到回复报文之前就预先发送preload个请求报文。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;初始时分配interval*preload的时间片用来发送报文（程序中第一次发送设置时间片为interval*(preload-1)，由于设置后没有减去第一次发送用去的interval时间片，所以相当于分配了interval*preload的时间片）。每次发送报文都要用掉interval毫秒的时间片。如果时间片不为负数的话，则一直持续发送报文。如果时间片为负数，则退出循环，开始处理接受到的回复报文。处理接受到的回复报文，会用去比较长的时间。

从上次发送报文，到当前准备发送报文的时间被计时器记录（实际上是通过记录上次发送报文的系统时间到当前系统时间之差来记录的），并作为新的时间片加入原时间片中，作为下次发送报文的时间片。为了确保没有接到回复而发送了的报文数目不会超过preload个，这个新的时间片如果超过interval*preload，则被改为interval*preload。如果新的时间片小于发送一个报文的时间interval，则仍然不发送报文，退出发送报文的循环，接受回复报文和处理可能出现的中断。

通过上述方法，实现了两个功能：

 1. 可以在不等待回复的情况下，预先发送preload个报文。由于初始时分配的时间片为interval*preload，所以刚开始，程序就连续发送interval个请求报文；如果程序等了很长时间没有发送报文，则计时器的引入使得这一段时间也作为发送时间片的新的一部分，这样程序又可以连续发送几个报文。

2. 可以控制报文发送的时间间隔为interval。从初始时开始，在连续发送preload个报文后，时间片被耗尽。只有在计时器中累加的时间片超过interval时才能再连续发送一个或几个报文（不超过preload个）。

相关函数：

int pinger(void);

void main_loop(int icmp_sock, __u8 *packet, int packlen);

相关选项：

-l &amp;lt;preload&amp;gt;

-i &amp;lt;interval&amp;gt;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;2.13   回复等待计时的实现
    当用户使用-c &lt;count&gt;设置了需要传送/接受的报文数，且通过-w &lt;deadline&gt;设置了程序运行的时间，那么则程序只需要在发送&lt;count&gt;个报文，并等待接受报文，直到接受到&lt;count&gt;个回复或者程序运行时间超过限制为止。如果用户只使用-c&lt;count&gt;设置了需要传送/接受的报文数，没有设置程序运行的时间，那么鉴于有些请求报文丢失而永远不会接到报文，程序不能在发送了&lt;count&gt;个报文之后一直等待。程序一直等待一个可能再也不会出现的事情是难以接受的，它应该做的是在发送&lt;count&gt;个请求报文后，等待一段时间，如果实在没有等到回复报文，就退出。&lt;/count&gt;&lt;/count&gt;&lt;/count&gt;&lt;/count&gt;&lt;/count&gt;&lt;/deadline&gt;&lt;/count&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;上面说的等待时间怎么确定呢？如果程序成功地收到了一个或者几个针对请求报文的回复，那么就将两倍的最大RTT作为等待的时间。如果程序没有接到任何的回复，RTT无从得知，就使用lingertime作为等待的最长时间。这个lingertime可以通过-W &amp;lt;timeout&amp;gt;选项由用户设置；如果用户没有设置则为一个常量（程序中，默认等待10秒）。不过值得主注意的是lingertime这个变量在程序成功地收到了回复之后，就没有任何作用了。

最长等待时间由一个闹钟实现。如上所述，设定这个闹钟的条件有下面几个：

1. 需要传送/接受的报文被设置了。

2. 程序运行的时间没有被设置。

3. 已经发送的报文数等于或大于需要传送/接受的报文数。

闹钟的时间被设置为：

1. 如果程序成功地收到了一个或者几个针对请求报文的回复，那么就将两倍的最大RTT作为等待的时间。

2. 否则，设置为lingertime。

当超出闹钟的时间之后，就会产生SIGALRM中断，使得程序退出。

相关函数：

void main_loop(int icmp_sock, __u8 *packet, int packlen);

staticinline int schedule_exit(int next);

schedule_exit(int next)

相关选项：

-c&amp;lt;count&amp;gt;

-w&amp;lt;deadline&amp;gt;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;3.1       引言
    在IP报文的首部和ICMP报文的首部都可以放入时间戳数据。clockdiff程序正是使用时间戳来测算目的主机和本地主机的系统时间差。&lt;/p&gt;

&lt;p&gt;3.2       clockdiff程序的使用
[plain] view plaincopy 
lixi@lixi-desktop:~$ ping -T tsandaddr www.ustc.edu.cn -c 1&lt;br /&gt;
PING www.ustc.edu.cn (202.38.64.9) 56(124) bytes of data.&lt;br /&gt;
64 bytes from 202.38.64.9: icmp_seq=1 ttl=62 time=0.823 ms&lt;br /&gt;
TS:     lixi-desktop.local (210.45.74.25)   12522473 absolute&lt;br /&gt;
    210.45.74.1 -251&lt;br /&gt;
    local-gw.ustc.edu.cn (202.38.64.126)    248&lt;br /&gt;
    202.38.64.9 -857514&lt;br /&gt;
Unrecorded hops: 3&lt;/p&gt;

&lt;p&gt;— www.ustc.edu.cn ping statistics —&lt;br /&gt;
1 packets transmitted, 1 received, 0% packet loss, time 0ms&lt;br /&gt;
rtt min/avg/max/mdev = 0.823/0.823/0.823/0.000 ms&lt;br /&gt;
    首先由上面的得出在RRT不大的时候，几个ICMP时间戳的关系。本地主机和202.38.64.9之间的时间差约为:-857514+248-251=-857517。&lt;/p&gt;

&lt;p&gt;分别用-o（IP选项中时间戳）和不带选项（ICMP路由时间戳）上述路由的系统时间进行测试。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;得到的结果：
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;[plain] view plaincopy 
lixi@lixi-desktop:~# ./clockdiff -o 202.38.64.9  &lt;br /&gt;
…………………………………………..&lt;br /&gt;
host=202.38.64.9 rtt=1(0)ms/1ms delta=-857517ms/-857517ms Wed Dec 17 11:28:30 2008&lt;/p&gt;

&lt;p&gt;[plain] view plaincopy 
lixi@lixi-desktop:~# ./clockdiff 202.38.64.9&lt;br /&gt;
.&lt;br /&gt;
host=202.38.64.9 rtt=750(187)ms/0ms delta=-857517ms/-857517ms Wed Dec 17 11:28:35 2008&lt;/p&gt;

&lt;p&gt;两种方法测试的都比较准确.&lt;/p&gt;

&lt;p&gt;[plain] view plaincopy 
lixi@lixi-desktop:~#./clockdiff gigagate1.Princeton.EDU&lt;br /&gt;
…………………………………………..&lt;br /&gt;
host=gigagate1.Princeton.EDU rtt=307(21)ms/271ms delta=-5ms/-5ms Wed Dec 17 11:50:16 2008&lt;br /&gt;
    上面是测试一个RTT较大的目的主机和本地主机的系统时间差。不过在使用clockdiff的时候，需要一点运气，因为很多路由会忽略ICMP或IP时间戳。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;对clockdiff选项的解释如下：

-o

    使用IP时间戳选项来测量系统时间差。时间戳只用3个。

-o1

    使用IP时间戳选项来测量系统时间差。用4个时间戳。如果-o和-o1都没有设置，那么就是用ICMP时间戳来测试系统时间差。
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;3.3       clockdiff程序的流程图&lt;/p&gt;

&lt;p&gt;3.4       clockdiff程序的主要函数的分析
    int main(int argc, char *argv[]);&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;    主函数。

    在这个函数里：取得用户输入的选项，并根据这些选项及其参数设置相应的标识和参数值。然后取得ICMP报文的套接字。如果设置-o或者-o1选项，设置IP报文的套接字时间戳选项，且调用measure_opt()函数来使用IP时间戳选项来测量本地主机和服务器主机的系统时间差。如果没有设置-o或者-o1选项，并调用measure()函数来使用ICMP时间戳报文来测量本地主机和服务器主机的系统时间差。测量完成后，打印出测试信息或者出错信息。

int measure_opt(struct sockaddr_in * addr);

    使用IP时间戳选项来测量本地主机和服务器主机的系统时间差。

    函数设置ICMP的报文，并发送出去。然后，程序接受ICMP报文，取得IP时间戳选项，并计算本地主机和服务器系统时间差。

int measure(struct sockaddr_in * addr);

    使用ICMP时间戳报文来测量本地主机和服务器主机的系统时间差。

    函数设置ICMP的报文，并发送出去。然后，程序接受ICMP报文，取得ICMP时间戳选项，并计算本地主机和服务器系统时间差。
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;6.5       clockdiff程序的全局变量的分析
    int interactive = 0;&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;    标识标准输入输出是不是和一个终端相连，如果是就输出比较详细的信息，否则只输出必要数据。

    例如clockdiff -o www.ustc.edu.cn &amp;gt;a.txt，就只会输出三个数据，因为标准输出被重定向到了文件的写入里，不与终端相连。

int id;

    当前进程的ID，放在ICMP时间戳请求和应答报文中的标识符中。

    在接受到ICMP回复报文时，用这个标识符来判断ICMP报文是不是本进程发出的ICMP报文的回复报文。

int sock;

    ？

int sock_raw;

    ICMP报文的套接字。

struct sockaddr_in server;

    服务器主机的地址。

    要对比本机和目的主机的系统时间，目的主机就相当于一个服务器。

int ip_opt_len = 0;

    ip_opt_len是ip选项中用来存储时间戳的长度

    可以通过-o和-o1选项来设置。

    如果选择-o选项，则ip_opt_len为4 + 4*8，也就是可以在IP选项中存储4个IP时间戳。时间戳的组织形式为：



    如果选择-o1选项，则ip_opt_len为4 + 3*8，也就是可以在IP选项中存储3个IP时间戳。时间戳的组织形式为：



#define BIASP        43199999

    程序通过计算时间戳中标明的时间来计算本地主机和服务器主机的系统时间差。在系统时间发生回绕的时候，会出现系统时间差的计算问题。这里BIASP就是为了解决这个问题。     

    在假设本地主机和服务器的系统时间差最多不超过12个小时（即43200000毫秒）的情况下：

    对于主机发送报文，如果本地主机在发送报文的时刻，本地主机系统时间已经超过0点。而该报文到达服务器主机的时刻，服务器主机系统时间仍然没有超过0点，则两个时间戳的差值（接受时间减去发送时间）会大于BIASP毫秒。

    同样，对于逆过程（主机接受服务器的报文），如果服务器主机在发送报文的时刻，服务器主机系统时间已经超过0点。而该报文到达本地主机的时刻，本地主机系统时间仍然没有超过0点，则两个时间戳的差值也会大于BIASP毫秒。

#define BIASN         -43200000

    与BIASP类似，BIASN也是为了解决系统时间回绕不一致的问题。

    在假设本地主机和服务器的系统时间差最多不超过12个小时（即43200000毫秒）的情况下：

    对于主机发送报文，如果本地主机在发送报文的时刻，本地主机系统时间没有超过0点。而该报文到达服务器主机的时刻，服务器主机系统时间已经超过0点，则两个时间戳的差值会小于BIASN毫秒。

    同样，对于逆过程（主机接受服务器的报文），如果服务器主机在发送报文的时刻，服务器主机系统时间没有超过0点。而该报文到达本地主机的时刻，本地主机系统时间已经超过0点，则两个时间戳的差值也会小于BIASN毫秒。

    为了解决系统时间回绕不一致的问题，当时间差不处在BIASN和BIASP之间的情况下，则将它们对应到这个去区间内。特别需要强调的是这里有基本假设：本地主机和服务器的系统时间差最多不超过12个小时（即43200000毫秒）。如果不满足这个假设，这种对应关系是错误的。

#define MODULO         86400000

    24个小时就是86400000毫秒，与在BIASN和BIASP一起处理系统时间回绕问题。

#define PROCESSING_TIME      0

    由于记录时间和报文发送的准确时间会有一定的偏差，所以这类处理过程消耗的时间可能会对最终计算出来的系统时间差会产生一个偏移量的影响。这里PROCESSING_TIME就是为了消除这个偏移量的影响的。这里忽略了这个偏移量。而且可以预见的是，想要分析和给出偏移量的影响大小并不容易，因为它与太多的变量有关系。

#define PACKET_IN       1024

    接受报文的存储字节数。

int measure_delta;

    计算的系统时间差。

    计算的系统时间差有两种假设，measure_delta1是另一种假设下的计算结果。

int measure_delta1;

    计算的系统时间差。

    计算的系统时间差有两种假设，measure_delta是另一种假设下的计算结果。

static u_short seqno;

    发送报文的序列号。

    每次发送报文都设置ICMP报文的序列号为seqno，seqno递加。

static u_short seqno0;

    发送报文的最小序列号。

    当接受到报文时要判断ICMP报文的序列号是不是介于seqno0和seqno之间，否则将不认为这个ICMP报文是本程序的恢复报文。

static u_short acked;

    接受到ICMP回复报文的最大序列号。

    当接受到报文时，如果ICMP报文的序列号大于现在的acked，则更新acked。

long rtt = 1000;

    对RTT的预测。

    预测方法是使用指数加权移动平均。

    和rtt_sigma一起用来设置超时时间，用的就是Jacobson/Karels算法。

long min_rtt;

    RTT的最小值。

long rtt_sigma = 0;

    对RTT预测的误差。

    和rtt一起用来设置超时时间，用的就是Jacobson/Karels算法。
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;3.6       clockdiff程序RTT预测的实现
    clockdiff程序使用Jacobson/Karels算法，使用以前的RTT实测值来预测下一次的RTT，并设定传输时间超时值。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;Jacobson/Karels算法在[[1]]文中有介绍。伪代码如下：

Difference = SampleRTT - EstimatedRTT

EstimatedRTT = EstimatedRTT + (δ × Difference)

Deviation = Deviation + δ × (|Difference| - Deviation)

TimeOut = μ × EstimatedRTT + φ × Deviation

其中：

SampleRTT是测量所得的新的RTT数据。

EstimatedRTT是预测的RTT值。

Deviation是预测的偏差值。

TimeOut是超时时间值。

δ为0到1之间的常数。

μ和φ均是一个常数。

在clockdiff程序的实现中：

δ设置为1/4。

μ和φ均设置为1。

相关函数：

int measure_opt(struct sockaddr_in * addr)void main_loop(inticmp_sock, __u8 *packet, int packlen);

int measure(struct sockaddr_in * addr);
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;6.7       clockdiff程序系统时间差测量的实现
    设两台主机的系统时间相差detaT，即源主机的系统时间为T的时刻，目的主机的系统时间为T+detaT。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;通过ICMP时间戳或者IP选项时间戳，可以获得如下信息：

delta1：接受时间戳减去发起时间戳。

delta2：接到回复报文时间减传送时间戳。

时间戳的插入过程如下图所示：

 


由上图可以知道：

delta1 = (T + dataT + RTT/2) – T = RTT/2+detaT

delta2 = (T + RTT) - (T + dataT + RTT/2) =RTT/2-detaT

故此(delta1 - delta2) / 2就是两个主机之间的系统时间差。

由于一次测量的delta1和delta2可能会由于网络拥塞情况的变化而发生较大偏差，故此在实际的实现中多次测量求较优值。引入了如下几个变量：

min1：多次传送中delta1的最小值。

min2：多次传送中delta2的最小值。

min_rtt：多次传送中delta1+delta2的最小值。

PROCESSING_TIME：处理过程中所消耗的时间。

在基于以下的几个基本假设情况下，可以测算系统时间的差值：

1. RTT中发送到目的主机的时间和返回源主机的时间基本相等都为RTT/2。

2. 当min1最小时，min1是对RTT/2+detaT的较优预测。同样，当min2最小时，min2是对RTT/2-detaT的较优预测。故此，(min1 - min2)/2是对deltaT的较优预测。这种预测方法的系统时间差预测值存储为变量measure_delta。

3. 当min_rtt最小时，(delta1 - delta2)/2也是对deltaT的较优预测。这种预测方法的系统时间差预测值存储为变量measure_delta1。

4. 各主机从接受到报文到记录接受到报文时间，这两个时刻的时间间隔为可以忽略；即发送和接受报文的处理过程中所消耗的时间可以忽略。实际上PROCESSING_TIME正是用来消除由处理过程的时间造成的对于计算出来的系统时间差别的影响。不过这里PROCESSING_TIME设置为0，认为处理消耗时间可以忽略。

以上的假设决定了clockdiff测算出来的系统时间差别的不准确性。

相关函数：

int measure_opt(struct sockaddr_in * addr)void main_loop(inticmp_sock, __u8 *packet, int packlen);

int measure(struct sockaddr_in * addr); .1       引言
tracepath和更为强大和更为广泛使用的程序traceroute一样，可以让我们看到IP数据报从一台主机传到另一台主机所经过的路由。

tracepath的作者是Alexey Kuznetsov。
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;4.2       tracepath程序的使用
lixi@lixi-desktop:~$ tracepath 210.45.74.25/8888
 1:  lixi-desktop.local (210.45.74.25)                      0.123ms pmtu 16436
 1:  lixi-desktop.local (210.45.74.25)                      0.054ms reached
 1:  lixi-desktop.local (210.45.74.25)                      0.045ms reached
     Resume: pmtu 16436 hops 1 back 64 
    210.45.74.25是本地主机的IP地址，8888是选择的测试端口。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;可以发现在本机进行了三次测试，为什么有三次测试，在下面的内容中有分析。
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;lixi@lixi-desktop:~$ tracepath 210.45.74.25/8888
 1:  lixi-desktop.local (210.45.74.25)                      0.122ms pmtu 16436
 1?: reply received 8)
 1:  lixi-desktop.local (210.45.74.25)                      0.048ms reached
     Resume: pmtu 16436 hops 1 back 64 
    编写简单的UDP服务程序，对8888端口的UDP请求进行服务（程序见&amp;lt;./test/udpserv.c&amp;gt;）。在运行这个服务程序之后，得到的测试结果如上。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;在第二轮时程序接受到了UDP的程序，所以输出了一个'?'表示疑问。
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;lixi@lixi-desktop:~$ tracepath 210.45.74.25/44444
 1:  lixi-desktop.local (210.45.74.25)                      0.131ms pmtu 16436
 1:  lixi-desktop.local (210.45.74.25)                      0.054ms reached
 1:  lixi-desktop.local (210.45.74.25)                      0.046ms reached
     Resume: pmtu 16436 hops 1 back 64 
     在运行对8888端口进行服务的UDP服务程序时，如果tracepath采用其他端口就不会产生上例中的情况了。&lt;/p&gt;

&lt;p&gt;lixi@lixi-desktop:~$ tracepath www.ustc.edu.cn
 1:  lixi-desktop.local (210.45.74.25)                      0.198ms pmtu 1500
 1:  210.45.74.1 (210.45.74.1)                              0.777ms 
 1:  210.45.74.1 (210.45.74.1)                              0.775ms 
 2:  202.38.96.33 (202.38.96.33)                            1.068ms 
 3:  202.38.64.9 (202.38.64.9)                              1.012ms reached
     Resume: pmtu 1500 hops 3 back 253
    对比此例和上例，可以发现PMTU发生了变化，由16436变成了1500。&lt;/p&gt;

&lt;p&gt;lixi@lixi-desktop:~$ tracepath www.ustc.edu.cn -l 1500
 1:  210.45.74.1 (210.45.74.1)                              0.828ms 
 2:  202.38.96.33 (202.38.96.33)                            0.988ms 
 3:  202.38.64.9 (202.38.64.9)                              1.140ms reached
     Resume: pmtu 1500 hops 3 back 253
    我们将MTU手动设置为1500，程序就不会默认将MTU设置为一个很大的数，然后找出PMTU了。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;tracepath程序的选项解释如下：

-n

    与ping命令的-n选项差不多。

    只有数字形式的输出，不查找DNS主机以节省时间，不查寻主机名，仅仅给出ip地址值。

    只要设置了F_NUMERIC，就不用调用gethostbyaddr来查询DNS主机名了。

    用gethostbyaddr的由查询目的主机的IP地址。

-l

    设置初始的包的大小。如果不设置则，则报文的大小为65535
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;4.3       tracepath程序的流程图
    tracepath程序的流程图如下：&lt;/p&gt;

&lt;p&gt;深入理解iputils网络工具第4篇 tracepath：路由追踪程序&lt;/p&gt;

&lt;p&gt;4.4       tracepath重要函数的分析
    int main(int argc, char argv);&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;    接受用户的选项，设置发送MTU或者设置是否不要验证主机名等标识。取得一个UDP类型的套接字，并设置好这个套接字的选项。，从1开始递增，直至31，设置套接字的IP_TTL选项为不同的值，调用probe_ttl()函数，直到probe_ttl()函数告知找到目的主机或者出现严重的错误为止。

int probe_ttl(int fd, int ttl);

    循环执行十次如下操作，直到正确发送报文跳出循环，或者recverr()返回0：

    调用sendto()函数尝试发送UDP报文到目的地址，如果发送出现错误则调用recverr()函数处理接受到的ICMP差错报文。如果正确发送报文，则跳出循环。

    如果循环过程中：recverr()函数返回0，则本函数返回0；如果recverr()函数返回大于0的数，则重新进行如上循环。

    如果循环超过十次，则表明因为某种原因，无法发送UDP报文，程序返回0。

    如果正确发送了UDP报文，则尝试使用recv()函数接受UDP报文的。正常情况下不会有UDP的，如果果真接受到了，则打印‘?’号表示吃惊，返回0。如果正如所预见到的，没有接到，则调用recverr()函数处理可能接受到的ICMP差错报文，返回recverr()返回的数值。

    总结本函数的返回值意义如下：

    返回0表示找到主机或者有严重的错误。

    返回负数-1，表示没有接受到ICMP差错报文。

    返回正数是当前MTU，表示接受并处理了一些错误，但是还没有找到目的主机。

int recverr(int fd, int ttl);

    函数将progress初始化为-1，然后不断循环执行如下操作，直到循环中函数返回：调用recvmsg()函数接受错误报文，并处理错误，如果没有错误返回progress。在错误队列中查找对应错误（SOL_IP级别IP_RECVERR类型），progress设置为MTU的值，并处理错误。如果错误队列的错误不是对应错误，返回0。

    并处理错误的几种情况如下：

    如果是MTU太大（EMSGSIZE），则修改MTU的变量值，继续循环。

    如果是UDP端口不可达错误（ECONNREFUSED），则UDP报文已经在规定TTL内传送到了目的主机。这种情况返回0。

    如果是EHOSTUNREACH错误且出错原因是接受到了ICMP差错报文，这个ICMP差错报文如果类型为11，代码为0，则表示因为在传输期间TTL等于0所以出错（参看ICMP报文类型）。这就说明UDP还没有到达目的主机TTL就变成了0，需要进一步递加TTL进行试探。

    如果是其他的错误，对于不严重的错误继续循环，否则返回0。

    总结本函数的返回值意义如下：

    返回0表示找到主机或者有严重的错误。

    返回的数如果大于0，其值是当前的MTU，表示接受并处理了一个或几个错误。

    返回负数-1，表示没有发现任何错误，也就是没有进展（progress）。
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;4.5       tracepath全局变量的分析
    struct hhistory his[64];&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;    用来存放历史上发出的UDP报文的ttl设置值和发送时间。

    当发送UDP报文时，将报文的端口号设置为base_port + hisptr，在his[hisptr]元素中，存储该UDP报文的ttl设置值和发送时间。

    当接受到一个UDP的报文（“端口不可达”错误ICMP报文）时，通过ICMP报文的端口号，就可以知道该UDP报文对应的ttl设置值和发送时间存储在his数组的哪个元素里了。

    his数组大小有限，只有64个元素。不过已经能够保证即使hisptr回绕也不会出错了。

int hisptr;

    用来指向his数组的元素。

    当发送UDP报文时，hisptr递加，将发出的UDP报文的ttl设置值和发送时间存储在his[hisptr]元素中。

    由于his数组大小为64，故此hisptr每次加到63，下一次就会回绕到0。

struct sockaddr_in target;

    要查询的目的主机的地址。

    包括地址种类（IPv4）、IP地址、端口号等信息。

    端口号会被设置为基础端口号加上hisptr。

__u16 base_port;

    基础端口号

    可以在设定目的主机时连带设定，否则程序默认是44444端口。

    基础端口号加上hisptr就是UDP报文的发送端口号。

    设置这么大的端口号，是为了使得目的主机的任何一个应用程序都不可能使用该端口，而产生一个“端口不可达”错误。

    这个值很大，目的就是让UDP出现“端口不可达”错误。

const int overhead = 28;

    在UDP数据部分之前的头部大小。

    IP首部为20，UDP首部为8，故此总共为28字节。

    这个数是个常量。

int mtu = 65535;

    可以通过-l选项设置，如果设置的值不大于传输路径的MTU。

    如果不设置默认值是65535，这个默认值肯定会超过传输路径的MTU，当超过了路径的MTU时，程序会受到错误消息，并根据这个错误消息所带的MTU值，更新MTU值。这样就tracepath能找出路径的MTU了。

int hops_to = -1;

    从本地主机到目的主机的跳数。

    如果目的主机不可达，则hops_to一直维持-1，最后就不会输出hops_to。

    当程序接受到目的主机发出的“拒绝服务”ICMP错误报文时，就说明探测到了目的主机。hops_to取为此时的recverr()函数局部变量sndhops的值。

    sndhops有两种方式取得，一种是取得发送时存储在his数组中的ttl值（前面已经谈到如何通过错误报文的IP端口得到存储地址），另一种是取得当前探测阶段发送的UDP报文的ttl的值。

    如果不出意外，第一种方式能比较可靠地取得；但是由于某种原因，前一种方式出问题后，就用后一种方式作为代替。

int hops_from = -1;

    从目的主机到本地主机的剩余TTL值。

    如果目的主机不可达，则hops_from一直维持-1，最后就不会输出。

    hops_from从目的主机发送给本地主机的IP报文头取得TTL字段值即可。

int no_resolve = 0;

    标识是否不要验证主机名。

    可以通过-n选项设置为1。

    如果设置为0，就调用gethostbyaddr的由查询目的主机的IP地址，否则就不用，以节省时间。 5.1       引言
ARP协议是“Address Resolution Protocol”（地址解析协议）的缩写。在同一以太网中，通过地址解析协议，源主机可以通过目的主机的IP地址获得目的主机的MAC地址。arping程序就是完成上述过程的程序。

ARP协议可以参看RFC 826。
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;5.2       arping程序的使用
    敲入命令：&lt;/p&gt;

&lt;p&gt;[plain] view plain copy
lixi@lixi-desktop:~/temp/iputils/iputils-s20071127$ arping 210.45.74.29 -c 1 -D&lt;br /&gt;
ARPING 210.45.74.29 from 0.0.0.0 eth0&lt;br /&gt;
Unicast reply from 210.45.74.29 [00:40:D0:59:CD:D3]  0.684ms&lt;br /&gt;
Sent 1 probes (1 broadcast(s))&lt;br /&gt;
Received 1 response(s)&lt;br /&gt;
    在本地主机的局域网内有一台IP地址为210.45.74.29的主机，所以会接到一个回复。&lt;/p&gt;

&lt;p&gt;[plain] view plain copy
lixi@lixi-desktop:~$ arping 210.45.74.28 -c 1 -D&lt;br /&gt;
ARPING 210.45.74.28 from 0.0.0.0 eth0&lt;br /&gt;
Sent 1 probes (1 broadcast(s))&lt;br /&gt;
Received 0 response(s)&lt;br /&gt;
    向一个不存在的IP发送报文不会接受到回复。&lt;/p&gt;

&lt;p&gt;[plain] view plain copy
root@lixi-desktop:~# arping 210.45.74.25 –U&lt;br /&gt;
root@lixi-desktop:~# tcpdump arp -n | grep 210.45.74.25&lt;br /&gt;
    得到输出结果如下：&lt;/p&gt;

&lt;p&gt;[plain] view plain copy
11:03:13.848653 arp who-has 210.45.74.25 (ff:ff:ff:ff:ff:ff) tell 210.45.74.25&lt;br /&gt;
    这里就是一个免费ARP的例子。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;-A

    与-U选项类似，但是发送的是ARP 回复报文，而不是ARP请求报文。

-b

    只发送MAC级别的广播。一般的arping开始时发送广播，在接受到回复后开始发送单播。

-c &amp;lt;count&amp;gt;

    在发送count个ARP请求后就退出。在和deadline选项一起使用时，arping程序一直等到收到count个ARP回复报文或者时间消耗完毕时才退出。
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;-D&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;    重复地址检测模式（DAD，Duplicate  address detection  mode）。参见RFC2131，4.4.1。如果DAD成功，则返回0，即不会接受到没有任何回复。

-f

    在接受到第一个确定目标主机存在的回复之后，就结束程序，否则一直发送ARP请求。

-I &amp;lt;interface&amp;gt;

    设置网络设备的名字，这个名字就是发送ARP请求报文的设备名字。

-h   

    打印帮助信息，然后退出。

-q

    静默输出，不打印探测结果。

-s &amp;lt;source&amp;gt;

    在ARP报文中使用的IP源地址。如果这个选项没有设置，则源地址设置方法为：

    1. DAD模式下（-D选项），设置为0.0.0.0。

    2. 在主动ARP模式（-U或者-A选项），设置为目的地址。

    3. 其他情况下，通过路由表得到。

-U

    为了更新以太网邻居的ARP快速缓存而主动进行的ARP。也就是免费ARP（gratuitous ARP）。

-V

    打印出版本信息，然后退出。

-w deadline

    设定时间期限为&amp;lt;deadline&amp;gt;秒，不管已经发送和接到了多少包，只要达到时间期限就结束ping的过程。在这种情况下，这样arping程序只有在接受到cout个回复或者deadline的时间消耗完后才退出；而不是像只有-c选项的情况，在发送count个ARP请求的就退出。
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;5.3       arping程序的流程图
    arping程序的流程图如下所示：&lt;/p&gt;

&lt;p&gt;5.4       ARP报文的分组格式
    ARP报文的分组格式如下图所示：&lt;/p&gt;

&lt;p&gt;5.5       arping程序的全局变量的分析
    int quit_on_reply=0;&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;    标识是否在接受到一个回复之后，就马上退出程序。

    可以在-f选项和-D选项中设定为非0值（同时有-f、-D选项或者有多个同种选项）。     

char *device=&quot;eth0&quot;;

    源主机的网络设备号。 

    可以通过-I参数设置。

    默认为eth0。

(setsockopt(probe_fd, SOL_SOCKET,SO_BINDTODEVICE, device, strlen(device)+1)。

    不过好像只有超级用户这个才能执行。

int ifindex;

    Interface number。

char *source;

    存储-s设置的源地址。

    地址的形式可以是IPv4的标准数字和点组成的形式，如210.45.74.25；也可以是主机名字的形式，如www.ustc.edu.cn。

struct in_addr src；

    存储源IP地址，即对ARP的回复报文所要发往的主机的IP地址，有可能是广播地址。

    可以通过-s选项设置。如果这个选项没有设置，则源地址设置方法为：

    1. DAD模式下（-D选项），设置为0.0.0.0。

    2. 在主动ARP模式（-U或者-A选项），设置为目的地址。

    3. 其他情况下，通过路由表得到。

struct in_addr dst;

    存储目的IP地址，即ARP报文所要发往的主机的IP地址。

char *target;

    存储用户设置的目的地址，地址的形式必须是IPv4的标准数字和点组成的形式。

int dad;

    标识是不是DAD模式。

    如果是DAD模式，则原源主机地址一直没有设置，那么就意味着源地址为0.0.0.0。这样当目的主机接到之后，就会向0.0.0.0发送回复，就相当于广播给以太网中所有的主机。因为进行D重复地址检测模式的原因很可能是由于源主机的IP地址没有设置，从而想设置自身的IP地址。在IP地址没有设置的时候，主机只能接受到地址为0.0.0.0的广播信号。

    可以通过-D参数设置。

int unsolicited;

    标识是不是发送免费ARP。

    在-A选项和-U选项中设置unsolicited为1。

int advert;

    标识在免费ARP模式下发送的是ARP回复报文，而不是ARP请求报文。

    在-A选项中设置advert为1。

int quiet;

    标识是否静默输出。

    可以通过-q选项设置。

int count=-1;

    发送ARP的个数。

    可以通过-c选项设置，如果不设置，默认值为-1，即没有个数限制（回绕成0基本不可能）。

int timeout;

    程序运行的时间限制。

    通过-w选项设置。

int unicasting;

    标识是不是应该发送单播报文。

    在程序接受到一个ARP的回复之后，已经能够知道回复者的IP地址了，这时候就可以不广播，而设置传播地址。因此，在接受到ARP回复之后，如果broadcast_only没有被设置，unicasting就应该设置为1，以让下次进行单播。

int s;

    ARP报文的套接字。

int broadcast_only;

    标识是不是一直发送广播报文，而不在接受到一个回复以后就改成单播报文。

    通过-b选项可以设置broadcast_only为1。 

struct sockaddr_ll me;

    存储本地主机的信息，包括本地主机的以太网地址、硬件地址的类型、硬件地址长度和协议地址长度等信息

struct sockaddr_ll he;

    存储本地主机的信息。

struct timeval start;

    程序发送第一个报文的系统时间。

    记录这个时间，可以用来判断程序是否超出时间限制。如果当前的系统时间减去start超过用户设置的时间限制有500毫秒，则程序退出。

struct timeval last;

    程序发送上一个报文的系统时间。

    记录这个时间，可以用来判断是否应当发出下一个ARP请求。如果当前系统时间减去last超过500毫秒，则发出下一个ARP请求。

int sent;

    程序发送的ARP报文数量。

    每次在发送ARP报文之后递加。

int brd_sent;

    程序广播的ARP报文数量。

    每次在发送ARP报文之后，如果ARP报文是广播报文，则递加。

int received;

    程序接受的ARP报文数量。

    每次在接受到正确的ARP报文之后，递加。

int brd_recv;

    程序接受的ARP广播报文数量。

    每次在接受到正确的ARP报文之后，如果报文不是单播报文则递加。

int req_recv;

    程序接受到ARP请求报文数量。

    每次在接受到正确的ARP报文之后，如果报文是ARP请求报文则递加。 7.1       引言
TFTP ( Trivial File Transfer Protocol)即简单文件传送协议，是TCP/IP协议族中的一个用来在客户机与服务器之间进行简单文件传输的协议，提供简单的、低开销的文件传输服务。tftpd程序就是进行tftp服务的服务程序。
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;TFTP协议可以参看RFC 1350。&lt;/p&gt;

&lt;p&gt;7.2       tftpd程序的使用
    由于这个程序需要inetd程序的配合，而环境比较难搭建，所以对程序的测试比较困难。&lt;/p&gt;

&lt;p&gt;7.3       tftpd程序的流程图&lt;/p&gt;

&lt;p&gt;7.4       TFTP报文格式
    TFTP报文格式如下所示：&lt;/p&gt;

&lt;p&gt;7.5       tftpd.c程序的全局变量的分析
    int   peer;&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;    服务连接的套接字。

int   rexmtval =TIMEOUT;

    程序采用停止和等待的自动请求重发（ARQ）算法，当接受ACK报文或者数据报文的时间超过rexmtval，则认为接受超时，重新开始接受报文过程。

    rexmtval一直维持TIMEOUT的值，没有被改变过。

int   maxtimeout =5*TIMEOUT;

    当接受数据报文或者ACK报文的时候，如果出现超时，则会进入中断处理程序。如果中断次数过多，则timeout会累加rexmtval时间。一旦超时中断过多，导致timeout超过maxtimeout，则程序退出，停止服务。

    maxtimeout一直维持5*TIMEOUT的值，没有被改变过。

#define  PKTSIZE     SEGSIZE+4

    如果TFTP报文的操作码是data，表明传输的是0到512字节的数据。

    SEGSIZE是TFTP报文的数据的最大长度，即512字节。

    由于TFTP报文还包括2字节的操作码和2字节的块编号，所以TFTP数据报文的长度为SEGSIZE+4。

char       buf[PKTSIZE];

    缓冲空间，在以下的情况下，作为存储TFTP报文的内存空间：

    1. 清楚初始时接收的报文。

    2. 发送操作码为error类型的TFTP报文。

    3. 在文件传输完毕时（上一次接受到的数据不足512字节），尝试接受操作码为data数据类型的TFTP报文，因为服务器传给用户主机的最后一个ACK有可能丢失。

char       ackbuf[PKTSIZE];

    缓冲空间，在以下的情况下，作为存储TFTP报文的内存空间：

    1. 接受操作码为ACK类型的TFTP报文。

    2. 发送操作码为ACK类型的TFTP报文。

union {

    struct     sockaddr    sa;

    struct     sockaddr_in sin;

    struct     sockaddr_in6 sin6;

} from;

    描述客户连接的地址。

socklen_t      fromlen;

    from所占的内存空间大小。

#define MAXARG    1

    在启动tftpd程序的时候，需要指定ftp文件夹的路径。MAXARG是所能指定文件夹的个数。

char       *dirs[MAXARG+1];

    dirs[0]里保存了ftp文件夹的路径。

int   confirmed;

    表明sendmsg函数的选项的MSG_CONFIRM选项是否设置。

    如果设置MSG_CONFIRM，则会告诉链路层的传送有了进展：已经接受到对方的一个成功的答复。由于MSG_CONFIRM的这个意义，所以在发送第一个数据是MSG_CONFIRM选项不因该设置，即confirm初始值为0。在成功接受到一个回复之后，confirm则应该设置为MSG_CONFIRM了。

int   timeout;

    表示由于等待接受超时的时间总和。

    当接受数据报文或者ACK报文的时候，如果出现超时，则会进入中断处理程序，将timeout递加rexmtval秒，如果。一旦超时中断过多，导致timeout超过maxtimeout，则程序退出，停止服务。

jmp_buf timeoutbuf;

    在发生等待接收超时时，应当将要发送的报文重新发送（报文可能为ACK报文或者data报文）。setjmp()和longjmp()函数就可以用来实现这种跳转的功能。

    由于等待超时时会进入计时器中断处理程序，在中断处理程序中调用longjmp()函数来跳转到最后一次用setjmp()设置timeoutbuf的地方运行，也就是重新进行报文的发送。

    timeoutbuf就记录了调用setjmp()的时候的程序上下文。
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;7.6       tftpsub.c程序的全局变量的分析
    struct bf {&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;    int counter;

    charbuf[PKTSIZE];

} bfs[2];

    缓冲空间，在以下的情况下，作为存储TFTP报文的内存空间：

    1. 接受操作码为data类型的TFTP报文。

    2. 发送操作码为data类型的TFTP报文。

    counter用来标识存储的缓冲空间的数据是一下三种的哪一种：

    1. BF_ALLOC，标识是已经申请的存储空间。

    2. BF_FREE，标识存储空间没有使用。

    3. 大于0的数，标识里面已经存储数据。

static int nextone;

    待使用的下一个缓冲的标号。

static int current;

    正在使用的当前缓冲的标号。

int newline = 0;

    在数据传输是按照8位的ASCII码形式（netascii）组织的情况下，标识是不是有新的行出现。

    在顺次读取或者写入字节流时，如果遇到'\n'或者'\r'字符都会设置newline为1，方便进行特殊处理。

int prevchar = -1;     /* putbuf: previous char (cr check) */

    在数据传输是按照8位的ASCII码形式（netascii）组织的情况下，记录上个处理的字符。

    和newline一样，prevchar是为了处理'\r'或者'\n'的特殊字符。

    处理的效果是：

    1. 如果要发送'\r'字符则传送的实际是\r\0&quot;；如果要发送'\n'字符则传送的实际是&quot;\r\n&quot;。

    2. 如果接受到&quot;\r\n&quot;，则保存的实际是字符'\n'；如果接受到&quot;\r\0&quot;，则保存的实际是字符'\r'。
&lt;/code&gt;&lt;/pre&gt;
</description>
        <pubDate>Mon, 05 Feb 2018 00:00:00 +0800</pubDate>
        <link>https://xiazemin.github.io/MyBlog/linux/2018/02/05/iputils.html</link>
        <guid isPermaLink="true">https://xiazemin.github.io/MyBlog/linux/2018/02/05/iputils.html</guid>
        
        
        <category>linux</category>
        
      </item>
    
      <item>
        <title>cscope</title>
        <description>&lt;!-- more --&gt;
&lt;p&gt;命令的帮助入口：&lt;/p&gt;

&lt;p&gt;:help cscope 
在前面的文章中介绍了利用tag文件，跳转到标签定义的地方。但如果想查找函数在哪里被调用，或者标签在哪些地方出现过，ctags就无能为力了，这时需要使用更为强大的cscope。&lt;/p&gt;

&lt;p&gt;Cscope具有纯正的Unix血统，它最早是由贝尔实验室为PDP-11计算机开发的，后来成为商用的AT&amp;amp;T Unix发行版的组成部分。直到2000年4月，这个工具才由SCO公司以BSD license开源发行。&lt;/p&gt;

&lt;p&gt;Cscope的主页在http://cscope.sourceforge.net/，如果你的计算机上没有cscope，你可以在此处下载它，在写本文时，它的最新版本是15.6。安装它非常简单，你只需要在cscope的源代码目录中执行下面三条命令：&lt;/p&gt;

&lt;p&gt;./configure
make
make install 
在windows上也可以使用cscope，在cscope的主页上可以下载到由DJGPP编译器编译的cscope for windows，不过这个版本不能和vi一起工作。或者你可以下载cygwin工具包(http://www.cygwin.com/)，这个工具包中也包含了cscope。&lt;/p&gt;

&lt;p&gt;在http://iamphet.nm.ru/cscope/有Sergey Khorev预编译的一个Win32版本的cscope，这个版本的cscope可以很好的与windows版本的vim搭配使用。&lt;/p&gt;

&lt;p&gt;cscope的用法很简单，首先需要为你的代码生成一个cscope数据库。在你的项目根目录运行下面的命令：&lt;/p&gt;

&lt;p&gt;cscope -Rbq 
这些选项的含义见后面。这个命令会生成三个文件：cscope.out, cscope.in.out, cscope.po.out。其中cscope.out是基本的符号索引，后两个文件是使用”-q”选项生成的，可以加快cscope的索引速度。在windows上使用cscope时，你可能会遇到-q选项被忽略的提示，解决办法请看这篇文章：Windows下cscope -q选项出错的解决。&lt;/p&gt;

&lt;p&gt;在缺省情况下，cscope在生成数据库后就会进入它自己的查询界面，我们一般不用这个界面，所以使用了”-b”选项。如果你已经进入了这个界面，按CTRL-D退出。&lt;/p&gt;

&lt;p&gt;Cscope在生成数据库中，在你的项目目录中未找到的头文件，会自动到/usr/include目录中查找。如果你想阻止它这样做，使用”-k”选项。&lt;/p&gt;

&lt;p&gt;Cscope缺省只解析C文件(.c和.h)、lex文件(.l)和yacc文件(.y)，虽然它也可以支持C++以及Java，但它在扫描目录时会跳过C++及Java后缀的文件。如果你希望cscope解析C++或Java文件，需要把这些文件的名字和路径保存在一个名为cscope.files的文件。当cscope发现在当前目录中存在cscope.files时，就会为cscope.files中列出的所有文件生成索引数据库。通常我们使用find来生成cscope.files文件，仍以vim 7.0的源代码为例：&lt;/p&gt;

&lt;p&gt;cd ~/src/vim70 
find . –type f &amp;gt; cscope.files
cscope -bq 
这条命令把~src/vim70目录下的所有普通文件都加入了cscope.files，这样，cscope会解析该目录下的每一个文件。上面的cscope命令并没有使用”-R”参数递归查找子目录，因为在cscope.files中已经包含了子目录中的文件。&lt;/p&gt;

&lt;p&gt;注意：find命令输出的文件以相对路径表示，所以cscope.out的索引也相对于当前路径。如果你要在其它路径中使用当前的cscope.out，需要使用下面介绍的-P选项。&lt;/p&gt;

&lt;p&gt;Cscope只在第一次解析时扫描全部文件，以后再调用cscope，它只扫描那些改动过的文件，这大大提高了cscope生成索引的速度。&lt;/p&gt;

&lt;p&gt;下表中列出了cscope的常用选项：&lt;/p&gt;

&lt;p&gt;-R: 在生成索引文件时，搜索子目录树中的代码
-b: 只生成索引文件，不进入cscope的界面
-q: 生成cscope.in.out和cscope.po.out文件，加快cscope的索引速度
-k: 在生成索引文件时，不搜索/usr/include目录
-i: 如果保存文件列表的文件名不是cscope.files时，需要加此选项告诉cscope到哪儿去找源文件列表。可以使用”-“，表示由标准输入获得文件列表。
-Idir: 在-I选项指出的目录中查找头文件
-u: 扫描所有文件，重新生成交叉索引文件
-C: 在搜索时忽略大小写
-Ppath: 在以相对路径表示的文件前加上的path，这样，你不用切换到你数据库文件所在的目录也可以使用它了。
要在vim中使用cscope的功能，需要在编译vim时选择”+cscope”。vim的cscope接口先会调用cscope的命令行接口，然后分析其输出结果找到匹配处显示给用户。&lt;/p&gt;

&lt;p&gt;在vim中使用cscope非常简单，首先调用”cscope add”命令添加一个cscope数据库，然后就可以调用”cscope find”命令进行查找了。vim支持8种cscope的查询功能，如下：&lt;/p&gt;

&lt;p&gt;s: 查找C语言符号，即查找函数名、宏、枚举值等出现的地方
g: 查找函数、宏、枚举等定义的位置，类似ctags所提供的功能
d: 查找本函数调用的函数
c: 查找调用本函数的函数
t: 查找指定的字符串
e: 查找egrep模式，相当于egrep功能，但查找速度快多了
f: 查找并打开文件，类似vim的find功能
i: 查找包含本文件的文件
例如，我们想在vim 7.0的源代码中查找调用do_cscope()函数的函数，我们可以输入：”:cs find c do_cscope”，回车后发现没有找到匹配的功能，可能并没有函数调用do_cscope()。我们再输入”:cs find s do_cscope”，查找这个C符号出现的位置，现在vim列出了这个符号出现的所有位置。&lt;/p&gt;

&lt;p&gt;我们还可以进行字符串查找，它会双引号或单引号括起来的内容中查找。还可以输入一个正则表达式，这类似于egrep程序的功能，但它是在交叉索引数据库中查找，速度要快得多。&lt;/p&gt;

&lt;p&gt;vim提供了一些选项可以调整它的cscope功能：&lt;/p&gt;

&lt;p&gt;cscopecscopeprg选项用于设置cscope程序的位置。
cscopecscopequickfix设定是否使用quickfix窗口来显示cscope的结果，详情请”:help cscopequickfix”；
如果你想vim同时搜索tag文件以及cscope数据库，设置cscopecscopetag选项；
cscopecscopetagorder选项决定是先查找tag文件还是先查找cscope数据库。设置为0则先查找cscope数据库，设置为1先查找tag文件。我通常设置为1，因为在tag文件中查找到的结果，会把最佳匹配列在第一位。
vim的手册中给出了使用cscope的建议方法，使用命令”:help cscope-suggestions”查看。&lt;/p&gt;

&lt;p&gt;下面是我的vimrc中关于cscope接口的设置：&lt;/p&gt;

&lt;p&gt;”””””””””””””””””””””””””””””””””””””””””””””””””””””””””””””””
“ cscope setting
“””””””””””””””””””””””””””””””””””””””””””””””””””””””””””””””
if has(“cscope”)
  set csprg=/usr/bin/cscope
  set csto=1
  set cst
  set nocsverb
  “ add any database in current directory
  if filereadable(“cscope.out”)
      cs add cscope.out
  endif
  set csverb
endif&lt;/p&gt;

&lt;p&gt;nmap &amp;lt;C-@&amp;gt;s :cs find s &lt;C-R&gt;=expand(&quot;&lt;cword&gt;&quot;)&lt;CR&gt;&lt;CR&gt;
nmap &amp;lt;C-@&amp;gt;g :cs find g &lt;C-R&gt;=expand(&quot;&lt;cword&gt;&quot;)&lt;CR&gt;&lt;CR&gt;
nmap &amp;lt;C-@&amp;gt;c :cs find c &lt;C-R&gt;=expand(&quot;&lt;cword&gt;&quot;)&lt;CR&gt;&lt;CR&gt;
nmap &amp;lt;C-@&amp;gt;t :cs find t &lt;C-R&gt;=expand(&quot;&lt;cword&gt;&quot;)&lt;CR&gt;&lt;CR&gt;
nmap &amp;lt;C-@&amp;gt;e :cs find e &lt;C-R&gt;=expand(&quot;&lt;cword&gt;&quot;)&lt;CR&gt;&lt;CR&gt;
nmap &amp;lt;C-@&amp;gt;f :cs find f &lt;C-R&gt;=expand(&quot;&lt;cfile&gt;&quot;)&lt;CR&gt;&lt;CR&gt;
nmap &amp;lt;C-@&amp;gt;i :cs find i ^&lt;C-R&gt;=expand(&quot;&lt;cfile&gt;&quot;)&lt;CR&gt;$&lt;CR&gt;
nmap &amp;lt;C-@&amp;gt;d :cs find d &lt;C-R&gt;=expand(&quot;&lt;cword&gt;&quot;)&lt;CR&gt;&lt;CR&gt;&lt;/CR&gt;&lt;/CR&gt;&lt;/cword&gt;&lt;/C-R&gt;&lt;/CR&gt;&lt;/CR&gt;&lt;/cfile&gt;&lt;/C-R&gt;&lt;/CR&gt;&lt;/CR&gt;&lt;/cfile&gt;&lt;/C-R&gt;&lt;/CR&gt;&lt;/CR&gt;&lt;/cword&gt;&lt;/C-R&gt;&lt;/CR&gt;&lt;/CR&gt;&lt;/cword&gt;&lt;/C-R&gt;&lt;/CR&gt;&lt;/CR&gt;&lt;/cword&gt;&lt;/C-R&gt;&lt;/CR&gt;&lt;/CR&gt;&lt;/cword&gt;&lt;/C-R&gt;&lt;/CR&gt;&lt;/CR&gt;&lt;/cword&gt;&lt;/C-R&gt;&lt;/p&gt;

&lt;p&gt;下面的两个链接是cscope主页提供的cscope使用方法，也可以作为参考：&lt;/p&gt;

&lt;p&gt;vim/cscope指导：http://cscope.sourceforge.net/cscope_vim_tutorial.html&lt;/p&gt;

&lt;p&gt;在大项目中使用cscope：http://cscope.sourceforge.net/large_projects.html&lt;/p&gt;

&lt;p&gt;在vim的网站上有很多与cscope相关的插件，有兴趣可以去看一下。&lt;/p&gt;

&lt;p&gt;首先在目录下建立cscope索引文件
find -name ‘*.c’ &amp;gt; cscope.file
cscope -Rbkq
这个命令会生成三个文件：cscope.out, cscope.in.out, cscope.po.out。
其中cscope.out是基本的符号索引，后两个文件是使用”-q”选项生成的，可以加快cscope的索引速度。
上面所用到的命令参数，含义如下：&lt;/p&gt;

&lt;p&gt;-R: 在生成索引文件时，搜索子目录树中的代码&lt;/p&gt;

&lt;p&gt;-b: 只生成索引文件，不进入cscope的界面&lt;/p&gt;

&lt;p&gt;-k: 在生成索引文件时，不搜索/usr/include目录&lt;/p&gt;

&lt;p&gt;-q: 生成cscope.in.out和cscope.po.out文件，加快cscope的索引速度
接下来，就可以在vim里读代码了。
不
过在使用过程中，发现无法找到C++的类、函数定义、调用关系。仔细阅读了cscope的手册后发现，原来cscope在产生索引文件时，只搜索类型为
C, lex和yacc的文件(后缀名为.c, .h, .l,
.y)，C++的文件根本没有生成索引。不过按照手册上的说明，cscope支持c++和Java语言的文件。于是按照cscope手册上提供的方法，先产生一个文件列表，然后让cscope为这个列表中的每个文件都生成索引。为了方便使用，编写了下面的脚本来更新cscope和ctags的索引文件：&lt;/p&gt;

&lt;p&gt;#!/bin/sh&lt;/p&gt;

&lt;p&gt;find . -name “&lt;em&gt;.h” -o -name “&lt;/em&gt;.c” -o -name “*.cc” &amp;gt; cscope.files&lt;/p&gt;

&lt;p&gt;cscope -bkq -i cscope.files&lt;/p&gt;

&lt;p&gt;ctags -R
这个脚本，首先使用find命令，查找当前目录及子目录中所有后缀名为”.h”, “.c”和”.cc”的文件，并把查找结果重定向到文件cscope.files中。
然后cscope根据cscope.files中的所有文件，生成符号索引文件。
最后一条命令使用ctags命令，生成一个tags文件，在vim中执行”:help tags”命令查询它的用法。它可以和cscope一起使用。
-R: 在生成索引文件时，搜索子目录树中的代码
-b: 只生成索引文件，不进入cscope的界面
-q: 生成cscope.in.out和cscope.po.out文件，加快cscope的索引速度
-k: 在生成索引文件时，不搜索/usr/include目录
-i: 如果保存文件列表的文件名不是cscope.files时，需要加此选项告诉cscope到哪儿去找源文件列表。可以使用“-”，表示由标准输入获得文件列表。
-I dir: 在-I选项指出的目录中查找头文件
-u: 扫描所有文件，重新生成交叉索引文件
-C: 在搜索时忽略大小写
-P path: 在以相对路径表示的文件前加上的path，这样，你不用切换到你数据库文件所在的目录也可以使用它了。
3在vim里读代码
在VIM中使用cscope非常简单，首先调用“cscope add”命令添加一个cscope数据库，然后就可以调用“cscope find”命令进行查找了。VIM支持8种cscope的查询功能，如下：例如，我们想在代码中查找调用work()函数的函数，我们可以输入：“:cs find c work”，回车后发现没有找到匹配的功能，可能并没有函数调用work()。我们再输入“:cs find s work”，查找这个符号出现的位置，现在vim列出了这个符号出现的所有位置。我们还可以进行字符串查找，它会双引号或单引号括起来的内容中查找。还可以输入一个正则表达式，这类似于egrep程序的功能。
s: 查找C语言符号，即查找函数名、宏、枚举值等出现的地方
g: 查找函数、宏、枚举等定义的位置，类似ctags所提供的功能
d: 查找本函数调用的函数
c: 查找调用本函数的函数
t: 查找指定的字符串
e: 查找egrep模式，相当于egrep功能，但查找速度快多了
f: 查找并打开文件，类似vim的find功能
i: 查找包含本文件的文
cs help
find 的选项
0或则S：查找本符号
1或则G：查找本定义
2或则D：查找本函数调用的函数
3或则C：查找调用本函数的函数
4或则T：查找本字符串
6或则E：查找本EGREP模式
7或则F：查找本文件
8或则I：查找包含本文件的文件
热后就可以在vim中使用cscope了，具体使用方法参考&lt;/p&gt;

&lt;p&gt;1、Cscope介绍&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;   Cscope是类似于ctags一样的工具，但可以认为她是ctags的增强版，因为她比ctags能够做更多的事。在Vim中，通过cscope的查询，跳转到指定的地方就像跳转到任何标签；她能够保存标签栈，所以通过合适的键盘映射绑定，你能够在函数向后或向前跳转，就像通常使用的tags一样。

   首次使用Cscope时，他会根据源文件生成符号数据库。然后在以后的使用中，cscope只是在源文件有改动或源文件列表不同时才会重建数据库。当在重建数据库时，未改动过的文件对应的数据库信息会从旧的数据库中拷贝过来，所以会使重建数据库快于一开始的新建数据库。

   当你在命令行下调用cscope时，你会获得一个全屏选择窗口，能够使你查询特定的内容。然而，一旦你查询的有匹配，那么就会用你默认的编辑器来编辑该源文件，但是你不能够简单的使用Ctrl+]或者:tag命令来从一个标签跳转到另一个标签。

   Vim中的cscope接口是通过以命令行形式调用完成的，然后解析查询返回的结果。最终的结果就是cscope查询结果就像通常的tags一样，这样你就可以自由跳转，就像在使用通常的tags（用ctrl+]或者:tag跳转）。
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;2、Cscope相关命令&lt;/p&gt;

&lt;p&gt;所有的cscope命令都是通过向主cscope命令”:cscope”传递参数选项。她最短的缩写是”:cs”。”:scscope”命令也做同样的事情并且同时会横向分隔窗口（简称：”scs”）。&lt;/p&gt;

&lt;p&gt;可用的缩写有：&lt;/p&gt;

&lt;p&gt;add ：增加一个新的cscope数据库/链接库&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;          使用方法：

                 :cs add {file|dir} [pre-path] [flags]

          其中：

                 [pre-path] 就是以-p选项传递给cscope的文件路径，是以相对路径表示的文件
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;前加上的path，这样你不要切换到你数据库文件所在的目录也可以使用它了。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;                 [flags] 你想传递给cscope的额外旗标

          实例：

                 :cscope add /root/code/vimtest/ftpd

                 :cscope add /project/vim/cscope.out /usr/local/vim

                 :cscope add cscope.out /usr/local/vim –C

 

   find ：查询cscope。所有的cscope查询选项都可用除了数字5（“修改这个匹配模式”）。

          使用方法：

                 :cs find {querytype} {name}

          其中：

                 {querytype} 即相对应于实际的cscope行接口数字，同时也相对应于nvi命令：

                        0或者s   —— 查找这个C符号

                        1或者g  —— 查找这个定义

                        2或者d  —— 查找被这个函数调用的函数（们）

                        3或者c  —— 查找调用这个函数的函数（们）

                        4或者t   —— 查找这个字符串

                        6或者e  —— 查找这个egrep匹配模式

                        7或者f   —— 查找这个文件

                        8或者i   —— 查找#include这个文件的文件（们）

          实例：（#号后为注释）

                 :cscope find c ftpd_send_resp                     # 查找所有调用这个函数的函数（们）

                 :cscope find 3 ftpd_send_resp                     # 和上面结果一样

                

                 :cscope find 0 FTPD_CHECK_LOGIN       # 查找FTPD_CHECK_LOGIN这个符号

          执行结果如下：

                 Cscope tag: FTPD_CHECK_LOGIN                   
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;#   line  filename / context / line&lt;/p&gt;

&lt;p&gt;1     19  ftpd.h «GLOBAL»&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;         #define FTPD_CHECK_LOGIN() /
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;2    648  ftpd.c «ftpd_do_pwd»&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;         FTPD_CHECK_LOGIN();
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;3    661  ftpd.c «ftpd_do_cwd»&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;         FTPD_CHECK_LOGIN();
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;4    799  ftpd.c «ftpd_do_list»&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;         FTPD_CHECK_LOGIN();
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;5    856  ftpd.c «ftpd_do_nlst»&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;         FTPD_CHECK_LOGIN();
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;6    931  ftpd.c «ftpd_do_syst»&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;         FTPD_CHECK_LOGIN();
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;7    943  ftpd.c «ftpd_do_size»&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;         FTPD_CHECK_LOGIN();
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;8    960  ftpd.c «ftpd_do_dele»&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;         FTPD_CHECK_LOGIN();
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;9    981  ftpd.c «ftpd_do_pasv»&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;         FTPD_CHECK_LOGIN();
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Enter nr of choice (&lt;CR&gt; to abort):&lt;/CR&gt;&lt;/p&gt;

&lt;p&gt;然后输入最前面的序列号即可。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;   help ：显示一个简短的摘要。

          使用方法：

          :cs help

 

   kill  ：杀掉一个cscope链接（或者杀掉所有的cscope链接）

          使用方法：

          :cs kill {num|partial_name}

          为了杀掉一个cscope链接，那么链接数字或者一个部分名称必须被指定。部分名
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;称可以简单的是cscope数据库文件路径的一部分。要特别小心使用部分路径杀死一个cscope链接。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;          假如指定的链接数字为-1，那么所有的cscope链接都会被杀掉。

 

   reset：重新初始化所有的cscope链接。

          使用方法：

          :cs reset

 

   show：显示cscope的链接

          使用方法：

          :cs show

 

   假如你在使用cscope的同时也使用ctags，|:cstag|可以允许你在跳转之前指定从一个或另一个中查找。例如，你可以选择首先从cscope数据库中查找，然后再查找你的tags文件（由ctags生成）。上述执行的顺序取决于|csto|的值。

   |:cstag|当从cscope数据库中查找标识符时等同于“:cs find g”。

   |:cstag|当从你的tags文件中查找标识符时等同于“|:tjump|”。
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;3、Cscope选项&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;   使用|:set|命令来设置cscope的所有选项。理想情况是，你可以在你的启动文件中做这件事情（例如：.vimrc）。有些cscope相关变量只有在|.vimrc|中才是合法的。在vim已经启动之后再来设置它们没有任何作用！

   ‘cscopeprg’指定了执行cscpoe的命令。默认是”cscope”。例如：

          :set csprg=/usr/local/bin/cscope

 

   ‘cscopequickfix’指定了是否使用quickfix窗口来显示cscope的结果。这是一组用逗号分隔的值。每项都包含于|csope-find|命令（s, g, d, c, t, e, f, 或者i）和旗标（+, -或者0）。

   ‘+’预示着显示结果必须追加到quickfix窗口。

   ‘-’隐含着清空先前的的显示结果，’0’或者不设置表示不使用quickfix窗口。查找会从开始直到第一条命令出现。默认的值是””（不使用quickfix窗口）。下面的值似乎会很有用：”s-,c-,d-,i-,t-,e-”。

 

   假如’cscopetag’被设置，然后诸如”:tag”和ctrl+]和”vim -t”等命令会始终使用|:cstag|而不是默认的:tag行为。通过设置’cst’，你将始终同时查找cscope数据库和tags文件。默认情况是关闭的，例如：

          :set cst

          :set nocst

 

   ‘csto’

   ‘csto’的值决定了|:cstag|执行查找的顺序。假如’csto’被设置为0，那么cscope数据将会被优先查找，假如cscope没有返回匹配项，然后才会查找tag文件。反之，则查找顺序相反。默认值是0，例如：

          :set csto=0

          :set csto=1

 

   假如’cscopeverbose’没有被设置（默认情况是如此），那么当在增加一个cscope数据库时不会显示表示表示执行成功或失败的信息。理想情况是，在增加cscope数据库之前，你应该在你的|.vimrc|中重置此选项，在增加完之后，设置它。此后，当你在vim中增加更多的数据库时，你会得到（希望是有用的）信息展示数据库增加失败。例如：

          :set csverb

          :set nocsverb

 

   ‘cspc’的值决定了一个文件的路径的多少部分被显示。默认值是0，所以整个路径都会被显示。值为1的话，那么就只会显示文件名，不带路径。其他值就会显示不同的部分。例如：

          :set cspc=3

   将会显示文件路径的最后3个部分，包含这个文件名本身。
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;4、在Vim中怎么使用cscope&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;   你需要做的第一步就是为你的源文件建立一个cscope数据库。大多数情况下，可以简单的使用”cscope –b”。

   假设你已经有了一个cscope数据库，你需要将这个数据库“增加”进Vim。那将会建立一个cscope“链接”并且使它能够被Vim所使用。你可以在你的.vimrc文件中做这件事，或者在Vim启动之后手动地做。例如，为了增加数据库”cscope.out”，你可以这样做：

          :cs add cscope.out

   你可以通过执行”:cs show”来再次检查以上执行的结果。这将会产生如下的输出：

   # pid      database name                       prepend path
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;0 11453  cscope.out                             &lt;none&gt;&lt;/none&gt;&lt;/p&gt;

&lt;p&gt;提示：&lt;/p&gt;

&lt;p&gt;由于微软的RTL限制，Win32版本会显示0而不是真正的pid。&lt;/p&gt;

&lt;p&gt;一旦一个cscope链接建立之后，你可以查询cscope并且结果会反馈给你。通过命令”:cs find”来进行查找。例如：&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;   :cs find g FTPD_CHECK_LOGIN
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;执行以上命令可能会变得有点笨重的，因为它要做相当的输入次数。假如有不止一个匹配项，你将会被提供一个选择屏幕来选择你想匹配的项。在你跳转到新位置之后，可以简单的按下ctrl+t就会返回到以前的一个。&lt;/p&gt;

&lt;p&gt;5、建议的用法&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;   将如下内容放置到你的.vimrc中：

   if has(&quot;cscope&quot;)

          set csprg=/usr/local/bin/cscope

          set csto=0

          set cst

          set nocsverb

          &quot; add any database in current directory

          if filereadable(&quot;cscope.out&quot;)

              cs add cscope.out

          &quot; else add database pointed to by environment

          elseif $CSCOPE_DB != &quot;&quot;

              cs add $CSCOPE_DB

          endif

          set csverb

   endif

 

   通过设置’cscopetag’，我们已经有效的将所有:tag的情况都替换为:cstag。这包括:tag、ctrl+]，和”vim -t”。然后，正常的tag命令就会不光在tag文件中查找，也会在cscope数据库中查找。

   有些用户可能想保留常规的tag行为并且有一个不同的快捷方式来使用:cstag。例如，可以使用如下命令来映射ctrl+_（下划线）到:cstag：

          map &amp;lt;C-_&amp;gt; : cstag &amp;lt;C-R&amp;gt;=expand(“&amp;lt;cword&amp;gt;”)&amp;lt;CR&amp;gt;&amp;lt;CR&amp;gt;

 

   一些经常用cscope查找（使用”:cs find”）是查找调用某一特定函数的所有函数，和查找所有出现特定C符号的地方。为了做这些事，你可以使用如下的键盘映射作为例子：

          map g&amp;lt;C-]&amp;gt; :cs find 3 &amp;lt;C-R&amp;gt;=expand(“&amp;lt;cword&amp;gt;”)&amp;lt;CR&amp;gt;&amp;lt;CR&amp;gt;

          map g&amp;lt;C-/&amp;gt; :cs find 0 &amp;lt;C-R&amp;gt;=expand(“&amp;lt;cword&amp;gt;”)&amp;lt;CR&amp;gt;&amp;lt;CR&amp;gt;

 

   这些给ctrl+]（右中括号）和ctrl+/（反斜杠）的映射可以允许你将光标放置到函数名称或者C符号上然后执行快速cscope查找匹配。

 

   或者你可以使用如下方案（很好用，可以将其添加到.vimrc中）：

nmap &amp;lt;C-_&amp;gt;s :cs find s &amp;lt;C-R&amp;gt;=expand(&quot;&amp;lt;cword&amp;gt;&quot;)&amp;lt;CR&amp;gt;&amp;lt;CR&amp;gt;

nmap &amp;lt;C-_&amp;gt;g :cs find g &amp;lt;C-R&amp;gt;=expand(&quot;&amp;lt;cword&amp;gt;&quot;)&amp;lt;CR&amp;gt;&amp;lt;CR&amp;gt;

nmap &amp;lt;C-_&amp;gt;c :cs find c &amp;lt;C-R&amp;gt;=expand(&quot;&amp;lt;cword&amp;gt;&quot;)&amp;lt;CR&amp;gt;&amp;lt;CR&amp;gt;

nmap &amp;lt;C-_&amp;gt;t :cs find t &amp;lt;C-R&amp;gt;=expand(&quot;&amp;lt;cword&amp;gt;&quot;)&amp;lt;CR&amp;gt;&amp;lt;CR&amp;gt;

nmap &amp;lt;C-_&amp;gt;e :cs find e &amp;lt;C-R&amp;gt;=expand(&quot;&amp;lt;cword&amp;gt;&quot;)&amp;lt;CR&amp;gt;&amp;lt;CR&amp;gt;

nmap &amp;lt;C-_&amp;gt;f :cs find f &amp;lt;C-R&amp;gt;=expand(&quot;&amp;lt;cfile&amp;gt;&quot;)&amp;lt;CR&amp;gt;&amp;lt;CR&amp;gt;

nmap &amp;lt;C-_&amp;gt;i :cs find i &amp;lt;C-R&amp;gt;=expand(&quot;&amp;lt;cfile&amp;gt;&quot;)&amp;lt;CR&amp;gt;&amp;lt;CR&amp;gt;

nmap &amp;lt;C-_&amp;gt;d :cs find d &amp;lt;C-R&amp;gt;=expand(&quot;&amp;lt;cword&amp;gt;&quot;)&amp;lt;CR&amp;gt;&amp;lt;CR&amp;gt;

 

   “ 使用’ctrl – 空格’，然后查找时就会使vim水平分隔窗口，结果显示在

   “ 新的窗口中

          nmap &amp;lt;C-Space&amp;gt;s :scs find s &amp;lt;C-R&amp;gt;=expand(&quot;&amp;lt;cword&amp;gt;&quot;)&amp;lt;CR&amp;gt;&amp;lt;CR&amp;gt;

nmap &amp;lt;C-Space&amp;gt;g :scs find g &amp;lt;C-R&amp;gt;=expand(&quot;&amp;lt;cword&amp;gt;&quot;)&amp;lt;CR&amp;gt;&amp;lt;CR&amp;gt;

nmap &amp;lt;C-Space&amp;gt;c :scs find c &amp;lt;C-R&amp;gt;=expand(&quot;&amp;lt;cword&amp;gt;&quot;)&amp;lt;CR&amp;gt;&amp;lt;CR&amp;gt;

nmap &amp;lt;C-Space&amp;gt;t :scs find t &amp;lt;C-R&amp;gt;=expand(&quot;&amp;lt;cword&amp;gt;&quot;)&amp;lt;CR&amp;gt;&amp;lt;CR&amp;gt;

nmap &amp;lt;C-Space&amp;gt;e :scs find e &amp;lt;C-R&amp;gt;=expand(&quot;&amp;lt;cword&amp;gt;&quot;)&amp;lt;CR&amp;gt;&amp;lt;CR&amp;gt;

nmap &amp;lt;C-Space&amp;gt;f :scs find f &amp;lt;C-R&amp;gt;=expand(&quot;&amp;lt;cfile&amp;gt;&quot;)&amp;lt;CR&amp;gt;&amp;lt;CR&amp;gt;

nmap &amp;lt;C-Space&amp;gt;i :scs find i &amp;lt;C-R&amp;gt;=expand(&quot;&amp;lt;cfile&amp;gt;&quot;)&amp;lt;CR&amp;gt;&amp;lt;CR&amp;gt;

nmap &amp;lt;C-Space&amp;gt;d :scs find d &amp;lt;C-R&amp;gt;=expand(&quot;&amp;lt;cword&amp;gt;&quot;)&amp;lt;CR&amp;gt;&amp;lt;CR&amp;gt;

  

   “ 两次按下’ ctrl – 空格’，然后查找时就会竖直分隔窗口而不是水平分隔

          nmap &amp;lt;C-Space&amp;gt;&amp;lt;C-Space&amp;gt;s

                 /:vert scs find s &amp;lt;C-R&amp;gt;=expand(&quot;&amp;lt;cword&amp;gt;&quot;)&amp;lt;CR&amp;gt;&amp;lt;CR&amp;gt;

   nmap &amp;lt;C-Space&amp;gt;&amp;lt;C-Space&amp;gt;g

          /:vert scs find g &amp;lt;C-R&amp;gt;=expand(&quot;&amp;lt;cword&amp;gt;&quot;)&amp;lt;CR&amp;gt;&amp;lt;CR&amp;gt;

   nmap &amp;lt;C-Space&amp;gt;&amp;lt;C-Space&amp;gt;c

          /:vert scs find c &amp;lt;C-R&amp;gt;=expand(&quot;&amp;lt;cword&amp;gt;&quot;)&amp;lt;CR&amp;gt;&amp;lt;CR&amp;gt;

   nmap &amp;lt;C-Space&amp;gt;&amp;lt;C-Space&amp;gt;t

          /:vert scs find t &amp;lt;C-R&amp;gt;=expand(&quot;&amp;lt;cword&amp;gt;&quot;)&amp;lt;CR&amp;gt;&amp;lt;CR&amp;gt;

   nmap &amp;lt;C-Space&amp;gt;&amp;lt;C-Space&amp;gt;e

          /:vert scs find e &amp;lt;C-R&amp;gt;=expand(&quot;&amp;lt;cword&amp;gt;&quot;)&amp;lt;CR&amp;gt;&amp;lt;CR&amp;gt;

   nmap &amp;lt;C-Space&amp;gt;&amp;lt;C-Space&amp;gt;i

          /:vert scs find i &amp;lt;C-R&amp;gt;=expand(&quot;&amp;lt;cfile&amp;gt;&quot;)&amp;lt;CR&amp;gt;&amp;lt;CR&amp;gt;

   nmap &amp;lt;C-Space&amp;gt;&amp;lt;C-Space&amp;gt;d

          /:vert scs find d &amp;lt;C-R&amp;gt;=expand(&quot;&amp;lt;cword&amp;gt;&quot;)&amp;lt;CR&amp;gt;&amp;lt;CR&amp;gt;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;6、结合实际来使用cscope&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;   我这里有一个ftp服务器的工程，主要文件如下（Secure CRT vt100, traditional, 13）：  



   下面就是要cscope命令来建立数据库文件（多了3个和cscope相关的文件）：

 



   说明：
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;a、  cscope的选项分析：&lt;/p&gt;

&lt;p&gt;-R     ：表示包含此目录的子目录，而非仅仅是当前目录；&lt;/p&gt;

&lt;p&gt;-b     ：此参数告诉cscope生成数据库后就自动退出；&lt;/p&gt;

&lt;p&gt;-q     ：生成cscope.in.out和cscope.po.out文件，加快cscope的索引速度&lt;/p&gt;

&lt;p&gt;可能会用到的其他选项：&lt;/p&gt;

&lt;p&gt;-k     ：在生成索引时，不搜索/usr/include目录；&lt;/p&gt;

&lt;p&gt;-i      ：如果保存文件列表的文件名不是cscope.files时，需要加此选项告诉cscope到哪里去找源文件列表；&lt;/p&gt;

&lt;p&gt;-I dir ：在-I选项指出的目录中查找头文件&lt;/p&gt;

&lt;p&gt;-u     ：扫描所有文件，重新生成交叉索引文件；&lt;/p&gt;

&lt;p&gt;-C     ：在搜索时忽略大小写；&lt;/p&gt;

&lt;p&gt;-P path：在以相对路径表示的文件前加上的path，这样你不用切换到你数据库文件的目录也可以使用它了。&lt;/p&gt;

&lt;p&gt;说明：要在VIM中使用cscope的功能，需要在编译Vim时选择”+cscope”。Vim的cscope接口会先调用cscope的命令行接口，然后分析其输出结果找到匹配处显示给用户。&lt;/p&gt;

&lt;p&gt;b、  若是不指定-b选项，则在建立完数据库后进入如下界面：&lt;/p&gt;

&lt;p&gt;这里是想要查找C符号：FTPD_CHECK_LOGIN，你可以通过按Tab键来进行匹配内容和输入项的切换。按下ctrl+d退出。&lt;/p&gt;

&lt;p&gt;注意：在此时，不可以使用ctrl+]进行跳转！&lt;/p&gt;

&lt;p&gt;下面用Vim打开其中的一个文件进行编辑，然后看看使用cscope的具体例子：&lt;/p&gt;

&lt;p&gt;输入：vim ftpd.c&lt;/p&gt;

&lt;p&gt;看到此时光标在ftpd_help这个函数声明上，现在若我们想要看看这个函数是怎么实现的，可以有如下方法：&lt;/p&gt;

&lt;p&gt;1）直接按下ctrl+]                     # 就是按下ctrl键的同时按下’]’键&lt;/p&gt;

&lt;p&gt;2）按下ctrl+_g                          # 按下 ctrl键和下划线（同时按下shift和’-’键）和g&lt;/p&gt;

&lt;p&gt;3）输入“:cs find g ftpd_help”后回车&lt;/p&gt;

&lt;p&gt;4）输入“:tag ftpd_help”         # 假如有安装ctag的话&lt;/p&gt;

&lt;p&gt;然后就会进行跳转：&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;   小结：在非windows系统上很多人都会选择强大的Vim作为编辑器，同时，我们要是能够用好那些同样强大的插件的话，那提高的战斗力可不止一点哦。常常会听到类似的抱怨，linux下没有好用的IDE，殊不知，用Vim结合一些插件，同样可以拥有IDE的强大功能，看代码也不错，可以有类似source insight的功能。这里展示下我的Vim，可能有些简陋，但至少有了些IDE的影子了：

   

 

   对了，还有一点：默认情况下cscope值会在当前目录下针对c、iex和yacc（扩展名分别为.c、.h、.I、.y）程序文件进行解析（如果指定了-R参数则包含其自身的子目录）。这样出现的问题就是，我们对于C++或Java文件怎么办，解决方案是：我们可以生成一个名为cscope.finds的文件列表，并交由cscope去解析。在Linux系统中，生成这个文件列表的方法是：

          find . –name “*.java” &amp;gt; cscope.files

   然后运行cscope –b 命令重新生成数据库就OK了。
&lt;/code&gt;&lt;/pre&gt;

</description>
        <pubDate>Mon, 05 Feb 2018 00:00:00 +0800</pubDate>
        <link>https://xiazemin.github.io/MyBlog/web/2018/02/05/cscope.html</link>
        <guid isPermaLink="true">https://xiazemin.github.io/MyBlog/web/2018/02/05/cscope.html</guid>
        
        
        <category>web</category>
        
      </item>
    
      <item>
        <title>sklearn</title>
        <description>&lt;p&gt;keras是python中比较流行的深度学习库，但是keras本身关注的是深度学习。而python中的scikit-learn库是建立在Scipy上的，有着比较有效的数值计算能力。sklearn是一个具有全特征的通用性的机器学习库，它提供了很多在深度学习中可以用到的工具。&lt;/p&gt;

&lt;p&gt;先安装numpy，再安装scipy
安装sklearn之前，我们需要先安装numpy，scipy函数库。
Numpy下载地址：http://sourceforge.net/projects/numpy/files/NumPy
Scipy下载地址：http://sourceforge.net/projects/scipy/files/Scipy
2、安装sklearn机器学习库
下载地址：https://github.com/scikit-learn/scikit-learn
测试：
import scipy
import sklearn&lt;/p&gt;

&lt;p&gt;LogisticRegression类的各项参数的含义
class sklearn.linear_model.LogisticRegression(penalty=’l2’, 
          dual=False, tol=0.0001, C=1.0, fit_intercept=True, 
          intercept_scaling=1, class_weight=None, 
          random_state=None, solver=’liblinear’, max_iter=100, 
          multi_class=’ovr’, verbose=0, warm_start=False, n_jobs=1)
penalty=’l2’ : 字符串‘l1’或‘l2’,默认‘l2’。
用来指定惩罚的基准（正则化参数）。只有‘l2’支持‘newton-cg’、‘sag’和‘lbfgs’这三种算法。
如果选择‘l2’，solver参数可以选择‘liblinear’、‘newton-cg’、‘sag’和‘lbfgs’这四种算法；如果选择‘l1’的话就只能用‘liblinear’算法。
dual=False : 对偶或者原始方法。Dual只适用于正则化相为l2的‘liblinear’的情况，通常样本数大于特征数的情况下，默认为False。
C=1.0 : C为正则化系数λ的倒数，必须为正数，默认为1。和SVM中的C一样，值越小，代表正则化越强。
fit_intercept=True : 是否存在截距，默认存在。
intercept_scaling=1 : 仅在正则化项为‘liblinear’，且fit_intercept设置为True时有用。
solver=’liblinear’ : solver参数决定了我们对逻辑回归损失函数的优化方法，有四种算法可以选择。
a) liblinear：使用了开源的liblinear库实现，内部使用了坐标轴下降法来迭代优化损失函数。
b) lbfgs：拟牛顿法的一种，利用损失函数二阶导数矩阵即海森矩阵来迭代优化损失函数。
c) newton-cg：也是牛顿法家族的一种，利用损失函数二阶导数矩阵即海森矩阵来迭代优化损失函数。
d) sag：即随机平均梯度下降，是梯度下降法的变种，和普通梯度下降法的区别是每次迭代仅仅用一部分的样本来计算梯度，适合于样本数据多的时候。&lt;/p&gt;

&lt;!-- more --&gt;
&lt;p&gt;参考文档：http://scikit-learn.org/stable/documentation.html&lt;/p&gt;
</description>
        <pubDate>Sat, 03 Feb 2018 00:00:00 +0800</pubDate>
        <link>https://xiazemin.github.io/MyBlog/spark/2018/02/03/sklearn.html</link>
        <guid isPermaLink="true">https://xiazemin.github.io/MyBlog/spark/2018/02/03/sklearn.html</guid>
        
        
        <category>spark</category>
        
      </item>
    
      <item>
        <title>mathlatex</title>
        <description>&lt;!-- more --&gt;
&lt;p&gt;1,LaTeX for WordPress
&amp;lt;对于WordPress博客来说，使用MathJax库的一个简单方法，就是直接使用一个叫LaTeX for WordPress插件。安装插件，简单配置，就可以使用MathJax的js库提供的数学公式在网页上的渲染支持。本博没有使用插件，而是直接在博客主题引用MathJax的js库。&lt;/p&gt;

&lt;p&gt;然后，在网页上编辑公式，只要把LaTeX语法的公式放入MathJax的界定符号之内即可，默认情况下，&lt;script type=&quot;math/tex&quot;&gt;LaTex语法&lt;/script&gt;表示换行居中显示数学公式，而(LaTex语法)表示在行内显示数学公式，即inline的显示方法。
2,Google Chart
Google Chart接受TeX语言，实时返回数学公式的图片
http://www.ruanyifeng.com/blog/2011/07/formula_online_generator.html
https://developers.google.com/chart/?csw=1
3,MathJax.js
https://www.mathjax.org/
第一步先是引入：你可以通过引入CDN，也可以下载js引入，个人推荐CDN引入。
&lt;script type=&quot;text/javascript&quot; src=&quot;https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML&quot;&gt;
&lt;/script&gt;
第二步：有3种使用方法：
①：TeX and LaTeX格式方式
默认运算符是&lt;script type=&quot;math/tex&quot;&gt;...&lt;/script&gt;和[… ]为显示数学，\（…\）用于在线数学。请特别注意，在$…$在线分隔符不使用默认值。这是因为，美元符号出现常常在非数学设置，这可能会导致一些文本被视为意外数学。例如，对于单元分隔符，“…的费用是为第一个$2.50和$2.00每增加一…”将导致短语“2.50的第一个，和”被视为数学因为它属于美元符号之间。注意HTML的标签与TeX语法可能有冲突，“小于号/大于号/ampersands&amp;amp;”需要前后空格，比如：&lt;script type=&quot;math/tex&quot;&gt;% &lt;![CDATA[
a &lt; b %]]&gt;&lt;/script&gt;；
②：第二种方法：添加MathML中等标签的形式
③第三种：AsciiMath输入。以``为符号。
4、MathML
mathml 是数学标记语言，是一种基于XML（标准通用标记语言的子集）的标准，用来在互联网上书写数学符号和公式的置标语言。 
5,KateX
https://khan.github.io/KaTeX/&lt;/p&gt;

</description>
        <pubDate>Fri, 02 Feb 2018 00:00:00 +0800</pubDate>
        <link>https://xiazemin.github.io/MyBlog/web/2018/02/02/mathlatex.html</link>
        <guid isPermaLink="true">https://xiazemin.github.io/MyBlog/web/2018/02/02/mathlatex.html</guid>
        
        
        <category>web</category>
        
      </item>
    
      <item>
        <title>二项逻辑斯蒂回归模型</title>
        <description>&lt;p&gt;Logistic回归与多重线性回归实际上有很多相同之处，最大的区别就在于它们的因变量不同，其他的基本都差不多。正是因为如此，这两种回归可以归于同一个家族，即广义线性模型（generalizedlinear model）。&lt;/p&gt;

&lt;p&gt;这一家族中的模型形式基本上都差不多，不同的就是因变量不同。&lt;/p&gt;

&lt;p&gt;如果是连续的，就是多重线性回归；
如果是二项分布，就是Logistic回归；
如果是Poisson分布，就是Poisson回归；
如果是负二项分布，就是负二项回归。
Logistic回归的因变量可以是二分类的，也可以是多分类的，但是二分类的更为常用，也更加容易解释。所以实际中最常用的就是二分类的Logistic回归。
Logistic回归的主要用途：&lt;/p&gt;

&lt;p&gt;寻找危险因素：寻找某一疾病的危险因素等；
预测：根据模型，预测在不同的自变量情况下，发生某病或某种情况的概率有多大；
判别：实际上跟预测有些类似，也是根据模型，判断某人属于某病或属于某种情况的概率有多大，也就是看一下这个人有多大的可能性是属于某病。
Logistic回归主要在流行病学中应用较多，比较常用的情形是探索某疾病的危险因素，根据危险因素预测某疾病发生的概率，等等。例如，想探讨胃癌发生的危险因素，可以选择两组人群，一组是胃癌组，一组是非胃癌组，两组人群肯定有不同的体征和生活方式等。这里的因变量就是是否胃癌，即“是”或“否”，自变量就可以包括很多了，例如年龄、性别、饮食习惯、幽门螺杆菌感染等。自变量既可以是连续的，也可以是分类的。
常规步骤&lt;/p&gt;

&lt;p&gt;Regression问题的常规步骤为：&lt;/p&gt;

&lt;p&gt;寻找h函数（即hypothesis）；
构造J函数（损失函数）；
想办法使得J函数最小并求得回归参数（θ）
http://blog.csdn.net/wjlucc/article/details/69264144
&lt;!-- more --&gt;&lt;/p&gt;
&lt;ol&gt;
  &lt;li&gt;二项逻辑斯蒂回归模型
二项逻辑斯蒂回归模型是如下的条件概率分布：
$P(Y=1|x)=\frac{\exp{(w \cdot x+b)}}{1+\exp(w\cdot x+b)}$
P(Y=0|x)=11+exp(w⋅x+b)
注意：P(Y=1|x)模型也经常写成hθ(x)=11+exp(−θT⋅x)。 
事件的几率（odds）是指该事件发生的概率与该事件不发生的概率的比值。 
如果事件发生的概率是p，那么该事件的几率是P1−P，该事件的对数几率（log odds）或logit函数是：logit(P)=logp1−p。 
逻辑回归的对数几率是： 
log(P(Y=1|x)1−P(Y=1|x))=w⋅x
意义：在逻辑斯蒂回归模型中，输出Y=1的对数几率是输入x的线性函数。或者说，输出Y=1的对数几率是由属于x的线性函数表示的模型，即逻辑斯蒂回归模型。（这里需要再理解下） 
  感知机只通过决策函数（w⋅x）的符号来判断属于哪一类。逻辑斯蒂回归需要再进一步，它要找到分类概率P(Y=1)与输入向量x的直接关系，再通过比较概率值来判断类别。 
令决策函数（w⋅x）输出值等于概率值比值取对数，即： 
logp1−p=w⋅x⟹p=exp(w⋅x+b)1+exp(w⋅x+b)&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;逻辑斯蒂回归模型的定义式P(Y=1|x)中可以将线性函数w⋅x转换为概率，这时，线性函数的值越接近正无穷，概率值就越接近1；线性函数的值越接近负无穷，概率值就接近0.&lt;/p&gt;
&lt;ol&gt;
  &lt;li&gt;模型参数估计
应用极大似然法进行参数估计，从而获得逻辑斯蒂回归模型。极大似然估计的数学原理参考这里。 
设：P(Y=1|x)=π(x),P(Y=0|x)=1−π(x) 
似然函数为：&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;∏i=1N[π(xi)]yi[1−π(xi)]1−yi&lt;/p&gt;

&lt;p&gt;上式连乘符号内的两项中，每个样本都只会取到两项中的某一项。若该样本的实际标签yi=1，取样本计算为1的概率值π(xi)；若该样本的实际标签yi=0，取样本计算的为0的概率值1−π(xi)。 
对数似然函数为： 
L(w)====∑i=1N[yilogπ(xi)+(1−yi)log(1−π(xi))]∑i=1N[yilogπ(xi)1−π(xi)+log(1−π(xi))]∑i=1N[yi(w⋅xi)+log11+exp(w⋅xi)]∑i=1N[yi(w⋅xi)−log(1+exp(w⋅xi))]&lt;/p&gt;

&lt;p&gt;对上式中的L(w)求极大值，得到w的估计值。 
问题转化成以对数似然函数为目标函数的无约束最优化问题，通常采用梯度下降法以及拟牛顿法求解w。 
假设w的极大估计值是wˆ，那么学到的逻辑斯蒂回归模型为： 
P(Y=1|x)=exp(wˆ⋅x)1+exp(wˆ⋅x)&lt;/p&gt;

&lt;p&gt;P(Y=0|x)=11+exp(wˆ⋅x)&lt;/p&gt;
&lt;ol&gt;
  &lt;li&gt;多项逻辑斯蒂回归
多项逻辑斯蒂回归用于多分类问题，其模型为：&lt;/li&gt;
&lt;/ol&gt;

&lt;table&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td&gt;P(Y=k&lt;/td&gt;
      &lt;td&gt;x)=exp(wk⋅x)1+∑k=1K−1exp(wk⋅x),k=1,2,⋯,K−1&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;table&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td&gt;P(Y=K&lt;/td&gt;
      &lt;td&gt;x)=11+∑k=1K−1exp(wk⋅x)&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;p&gt;上面的公式和二分类的类似，式中k的取值只能取到K−1。&lt;/p&gt;
&lt;ol&gt;
  &lt;li&gt;交叉熵损失函数的求导
逻辑回归的另一种理解是以交叉熵作为损失函数的目标最优化。交叉熵损失函数可以从上文最大似然推导出来。 
交叉熵损失函数为：&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;y(i)log(hθ(x(i)))+(1−y(i))log(1−hθ(x(i)))&lt;/p&gt;

&lt;p&gt;则可以得到目标函数为： 
J(θ)==−1m∑i=1my(i)log(hθ(x(i)))+(1−y(i))log(1−hθ(x(i)))−1m∑i=1m[y(i)θTx(i)−log(1+eθTx(i))]
计算J(θ)对第j个参数分量θj求偏导:&lt;/p&gt;

&lt;p&gt;∂∂θjJ(θ)====∂∂θj(1m∑i=1m[log(1+eθTx(i))−y(i)θTx(i)])1m∑i=1m[∂∂θjlog(1+eθTx(i))−∂∂θj(y(i)θTx(i))]1m∑i=1m⎛⎝x(i)jeθTx(i)1+eθTx(i)−y(i)x(i)j⎞⎠1m∑i=1m(hθ(x(i))−y(i))x(i)j&lt;/p&gt;
</description>
        <pubDate>Fri, 02 Feb 2018 00:00:00 +0800</pubDate>
        <link>https://xiazemin.github.io/MyBlog/spak/2018/02/02/logistic.html</link>
        <guid isPermaLink="true">https://xiazemin.github.io/MyBlog/spak/2018/02/02/logistic.html</guid>
        
        
        <category>spak</category>
        
      </item>
    
      <item>
        <title>Duck typing</title>
        <description>&lt;!-- more --&gt;
&lt;p&gt;还是先看定义 duck typing,
    鸭子类型是多态(polymorphism)的一种形式.在这种形式中,不管对象属于哪个,
    也不管声明的具体接口是什么,只要对象实现了相应的方法,函数就可以在对象上执行操作.
    即忽略对象的真正类型，转而关注对象有没有实现所需的方法、签名和语义.
        duck typing
            A form of polymorphism where functions
            operate on any object that implements the
            appropriate methods, regardless of their
            classes or explicit interface declarations.&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;Wikipedia 是这样描述 duck typing 的,
    在计算机语言中, duk typing 是一个类型测试的一个具体应用.
    是将对类型的检查推迟到代码运行的时候,由动态类型(dynamic typing)
    或者反省(reflection)实现. duck typing 应用在通过应用规则/协议(protocol)
    建立一个适合的对象 object.
    '如果它走起步来像鸭子,并且叫声像鸭子, 那个它一定是一只鸭子.'
    对于一般类型 normal typing, 假定一个对象的 suitability 只有该对象的类型决定.
    然而,对于 duck typing 来说, 一个对象 object 的 suitability 是通过该对象是否
    实现了特定的方法跟属性来决定 certain methods and properties, 而不是由该对象
    的来类型决定.

    注,
        In computer science, reflection is the ability of a computer program to
        examine,introspect, and modify its own structure and behavior at runtime.

    From Wikipedia,
        In computer programming, duck typing is an application of the duck test
        in type safety.It requires that type checking be deferred to runtime,
        and is implemented by means of dynamic typing or reflection.
        Duck typing is concerned with establishing the suitability of an object
        for some purpose, using the principle, &quot;If it walks like a duck and it
        quacks like a duck, then it must be a duck.&quot; With normal typing,
        suitability is assumed to be determined by an object's type only.
        In duck typing, an object's suitability is determined by the presence
        of certain methods and properties (with appropriate meaning),
        rather than the actual type of the object.


鸭子类型的起源 Origins of duck-typing,
    现在谷歌工程师,Python 社区重要贡献者之一: Alex Martelli 说到,
        我相信是 Ruby 社区推动了 duck typing 这个术语的流行.
        但是这个duck typing 这种表达在 Ruby 和 Python 火之前,
        就是在Python 的讨论中使用过.

    根据 Wikipedia, duck typing 这一术语最早被 Alex Martelli 在 2000 所使用.
    Related Link of Wikipedia - https://en.wikipedia.org/wiki/Duck_typing

归功于 python 的 数据类型 data model, 你的用户自定义类型的行为可以像 built-in 类型一样自然。
这并不需要通过继承 inheritance 来获得. 本着 duck typing, 可以在对象中只实现需要的方法, 就能
保证保证对象的行为符合预期. 对 Python 来说，这基本上是指避免使用 isinstance 检查对象的类,
更别提 type(foo) is bar 这种更糟的检查方式了，这样做没有任何好处，甚至禁止最简单的继承方式.
具体使用时,上述建议有一个常见的例外：有些 Python API 接受一个字符串或字符串序列;
如果只有一个字符串,可以把它放到列表中,从而简化处理. 因为字符串是序列类型,
所以为了把它和其他不可变序列区分开,最简单的方式是使用 isinstance(x, str) 检查.
另一方面，如果必须强制执行 API 契约，通常可以使用 isinstance 检查抽象基类。

在看例子之前, 先看简略一下儿 协议 protocol 相关内容,
    在 Python 中创建功能完善的序列类型无需使用继承, 只需实现符合序列协议的方法.
    在面向对象编程中,协议是非正式的接口,只在文档中定义,在代码中不定义.
    例如,Python 的序列协议只需要 __len__ 和 __getitem__ 两个方法.
    任对象/类型(A)只要使用标准的签名和语义实现了这两个方法,就能用在任何期待序列的地方,
    然而A 是不是哪个类的子类无关紧要,只要提供了所需的方法即可.这就是 python 序列协议.
    协议是非正式的,没有强制力,因此如果你知道类的具体使用场景,通常只需要实现一个协议的部分.
    例如,为了支持迭代,只需实现 __getitem__ 方法，没必要提供 __len__方法.

    经典示例, duck typing 处理一个字符串 string 或 可迭代字符串 iterable of strings
        try:                                                      #1
            field_names = field_names.replace(',', ' ').split()   #2
        except AttributeError:                                    #3
            pass                                                  #4
        field_names = tuple(field_names)                          #5

        #1, 假定 field_names 是一个字符串 string. EAFP, it’s easier to ask forgiveness than permission
        #2, 将 field_names 中的 ',' 替换成空格 ' ' 并 split, 将结果放到 list 中
        #3, sorry, field_names 并不像一个 str, field_names 不能 .replace 或者 .replace 后返回的结果不能 .split()
        #4, 这里我men假设 新的 field_names 是一个可迭代对象
        #5, 确保新的 field_names 是一个可迭代对象, 同事保存一个 copy - create 一个 tuple

        field_names = 'abc'                                       #6
        field_names = 'A,B,C'                                     #7
        try:
            field_names = field_names.replace(',', ' ').split()
        except AttributeError:
            pass
        print(field_names)
        field_names = tuple(field_names)
        print(field_names)
        for item in field_names:
            print(item)

        Output,
            ['abc']            #6
            ('abc',)           #6
            abc                #6
            --------------
            ['A', 'B', 'C']    #7
            ('A', 'B', 'C')    #7
            A                  #7
            B                  #7
            C                  #7

    结论,
        Summarize, Outside of frameworks, duck typing is often sim‐pler and more flexible than type checks.
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;对于一门强类型的静态语言来说，要想通过运行时多态来隔离变化，多个实现类就必须属于同一类型体系。也就是说，它们必须通过继承的方式，与同一抽象类型建立is-a关系。&lt;/p&gt;

&lt;p&gt;而Duck Typing则是一种基于特征，而不是基于类型的多态方式。事实上它仍然关心is-a，只不过这种is-a关系是以对方是否具备它所关心的特征来确定的。&lt;/p&gt;

&lt;p&gt;James Whitcomb Riley在描述这种is-a的哲学时，使用了所谓的鸭子测试（Duck Test）:&lt;/p&gt;

&lt;p&gt;当我看到一只鸟走路像鸭子，游泳像鸭子，叫声像鸭子，那我就把它叫做鸭子。（When I see a bird that walks like a duck and swims like a duck and quacks like a duck, I call that bird a duck.）&lt;/p&gt;

&lt;p&gt;鸭子测试
Duck Test基于特征的哲学，给设计提供了强大的灵活性。动态面向对象语言，如Python，Ruby等，都遵从了这种哲学来实现运行时多态。下面给出一个Python的例子：&lt;/p&gt;

&lt;p&gt;class Duck:
    def quack(self):
        print(“Quaaaaaack!”)
    def feathers(self):
        print(“The duck has white and gray feathers.”)&lt;/p&gt;

&lt;p&gt;class Person:
    def quack(self):
        print(“The person imitates a duck.”)
    def feathers(self):
        print(“The person takes a feather from the ground and shows it.”)
    def name(self):
        print(“John Smith”)&lt;/p&gt;

&lt;p&gt;def in_the_forest(duck):
    duck.quack()
    duck.feathers()&lt;/p&gt;

&lt;p&gt;def game():
    donald = Duck()
    john = Person()
    in_the_forest(donald)
    in_the_forest(john)&lt;/p&gt;

&lt;p&gt;game()
但这并不意味着Duck Typing是动态语言的专利。C++作为一门强类型的静态语言，也对此特性有着强有力的支持。只不过，这种支持不是运行时，而是编译时。&lt;/p&gt;

&lt;p&gt;其实现的方式为：一个模板类或模版函数，会要求其实例化的类型必须具备某种特征，如某个函数签名，某个类型定义，某个成员变量等等。如果特征不具备，编译器会报错。&lt;/p&gt;

&lt;p&gt;比如下面一个模板函数:&lt;/p&gt;

&lt;p&gt;template &lt;typename T=&quot;&quot;&gt; 
void f(const T&amp;amp; object) 
{ 
  object.f(0); // 要求类型 T 必须有一个可让此语句编译通过的函数。
} 
对于这样一个函数，下面的四个类均可以用来作为其参数类型。&lt;/typename&gt;&lt;/p&gt;

&lt;p&gt;struct C1 
{
  void f(int); 
};&lt;/p&gt;

&lt;p&gt;struct C2 
{ 
  int f(char); 
};&lt;/p&gt;

&lt;p&gt;struct C3 
{ 
  int f(unsigned short, bool isValid = true); 
};&lt;/p&gt;

&lt;p&gt;struct C4
{
  Foo* f(Object*);
};
一旦上述模板函数实现为下面的样子，则只有C2和C3可以和f配合工作。&lt;/p&gt;

&lt;p&gt;template &lt;typename T=&quot;&quot;&gt; 
void f(const T&amp;amp; object) 
{ 
  int result = object.f(0); 
  // ... 
} 
通过之前的解释我们不难发现，Duck Typing要表达的多态语义如下图所示：&lt;/typename&gt;&lt;/p&gt;

&lt;p&gt;DuckTyping的语义
适配器：类型萃取
Duck Typing需要实例化的类型具备一致的特征，而模板特化的作用正是为了让不同类型具有统一的特征（统一的操作界面），所以模板特化可以作为Duck Typing与实例化类型之间的适配器。这种模板特化手段称为萃取（Traits)，其中类型萃取最为常见，毕竟类型是模板元编程的核心元素。&lt;/p&gt;

&lt;p&gt;所以，类型萃取首先是一种非侵入性的中间层。否则，这些特征就必须被实例化类型提供，而就意味着，当一个实例化类型需要复用多个Duck Typing模板时，就需要迎合多种特征，从而让自己经常被修改，并逐渐变得庞大和难以理解。&lt;/p&gt;

&lt;p&gt;Type Traits的语义
另外，一个Duck Typing模板，比如一个通用算法，需要实例化类型提供一些特征时，如果一个类型是类，则是一件很容易的事情，因为你可以在一个类里定义任何需要的特征。但如果一个基本类型也想复用此通用算法，由于基本类型无法靠自己提供算法所需要的特征，就必须借助于类型萃取。&lt;/p&gt;

&lt;p&gt;结论
这四篇文章所介绍的，就是C++泛型编程的全部关键知识。&lt;/p&gt;

&lt;p&gt;从中可以看出，泛型是一种多态技术。而多态的核心目的是为了消除重复，隔离变化，提高系统的正交性。因而，泛型编程不仅不应该被看做奇技淫巧，而是任何一个追求高效的C++工程师都应该掌握的技术。&lt;/p&gt;

&lt;p&gt;同时，我们也可以看出，相关的思想在其它范式和语言中（FP，动态语言）也都存在。因而，对于其它范式和语言的学习，也会有助于更加深刻的理解泛型，从而正确的使用范型。&lt;/p&gt;

&lt;p&gt;最后给出关于泛型的缺点：&lt;/p&gt;

&lt;p&gt;复杂模板的代码非常难以理解;
编译器关于模板的出错信息十分晦涩，尤其当模板存在嵌套时；
模板实例化会进行代码生成，重复信息会被多次生成，这可能会造成目标代码膨胀;
模板的编译可能非常耗时;
编译器对模板的复杂性往往会有自己限制，比如当使用递归时，当递归层次太深,编译器将无法编译;
不同编译器（包括不同版本）之间对于模板的支持程度不一，当存在移植性需求时，可能出现问题;
模板具有传染性，往往一处选择模板，很多地方也必须跟着使用模板，这会恶化之前的提到的所有问题。
我对此的原则是：在使用其它非泛型技术可以同等解决的前提下，就不会选择泛型。&lt;/p&gt;

&lt;p&gt;python与鸭子类型
调用不同的子类将会产生不同的行为，而无须明确知道这个子类实际上是什么，这是多态的重要应用场景。而在python中，因为鸭子类型(duck typing)使得其多态不是那么酷。 
鸭子类型是动态类型的一种风格。在这种风格中，一个对象有效的语义，不是由继承自特定的类或实现特定的接口，而是由”当前方法和属性的集合”决定。这个概念的名字来源于由James Whitcomb Riley提出的鸭子测试，“鸭子测试”可以这样表述：“当看到一只鸟走起来像鸭子、游泳起来像鸭子、叫起来也像鸭子，那么这只鸟就可以被称为鸭子。” 
在鸭子类型中，关注的不是对象的类型本身，而是它是如何使用的。例如，在不使用鸭子类型的语言中，我们可以编写一个函数，它接受一个类型为”鸭子”的对象，并调用它的”走”和”叫”方法。在使用鸭子类型的语言中，这样的一个函数可以接受一个任意类型的对象，并调用它的”走”和”叫”方法。如果这些需要被调用的方法不存在，那么将引发一个运行时错误。任何拥有这样的正确的”走”和”叫”方法的对象都可被函数接受的这种行为引出了以上表述，这种决定类型的方式因此得名。 
鸭子类型通常得益于不测试方法和函数中参数的类型，而是依赖文档、清晰的代码和测试来确保正确使用。&lt;/p&gt;

&lt;p&gt;静态类型语言和动态类型语言的区别
静态类型语言在编译时便已确定变量的类型，而动态类型语言的变量类型要到程序运行的时候，待变量被赋予某个值之后，才会具有某种类型。 
静态类型语言的优点首先是在编译时就能发现类型不匹配的错误，编辑器可以帮助我们提前避免程序在运行期间有可能发生的一些错误。其次，如果在程序中明确地规定了数据类型，编译器还可以针对这些信息对程序进行一些优化工作，提高程序执行速度。 
静态类型语言的缺点首先是迫使程序员依照强契约来编写程序，为每个变量规定数据类型，归根结底只是辅助我们编写可靠性高程序的一种手段，而不是编写程序的目的，毕竟大部分人编写程序的目的是为了完成需求交付生产。其次，类型的声明也会增加更多的代码，在程序编写过程中，这些细节会让程序员的精力从思考业务逻辑上分散开来。 
动态类型语言的优点是编写的代码数量更少，看起来也更加简洁，程序员可以把精力更多地放在业务逻辑上面。虽然不区分类型在某些情况下会让程序变得难以理解，但整体而言，代码量越少，越专注于逻辑表达，对阅读程序是越有帮助的。 
动态类型语言的缺点是无法保证变量的类型，从而在程序的运行期有可能发生跟类型相关的错误。 
动态类型语言对变量类型的宽容给实际编码带来了很大的灵活性。由于无需进行类型检测，我们可以尝试调用任何对象的任意方法，而无需去考虑它原本是否被设计为拥有该方法。&lt;/p&gt;

&lt;p&gt;面向接口编程
动态类型语言的面向对象设计中，鸭子类型的概念至关重要。利用鸭子类型的思想，我们不必借助超类型的帮助，就能轻松地在动态类型语言中实现一个原则：“面向接口编程，而不是面向实现编程”。例如，一个对象若有push和pop方法，并且这些方法提供了正确的实现，它就可以被当作栈来使用。一个对象如果有length属性，也可以依照下标来存取属性（最好还要拥有slice和splice等方法），这个对象就可以被当作数组来使用。&lt;/p&gt;

&lt;p&gt;在静态类型语言中，要实现“面向接口编程”并不是一件容易的事情，往往要通过抽象类或者接口等将对象进行向上转型。当对象的真正类型被隐藏在它的超类型身后，这些对象才能在类型检查系统的“监视”之下互相被替换使用。只有当对象能够被互相替换使用，才能体现出对象多态性的价值。&lt;/p&gt;

&lt;p&gt;python中的多态
python中的鸭子类型允许我们使用任何提供所需方法的对象，而不需要迫使它成为一个子类。 
由于python属于动态语言，当你定义了一个基类和基类中的方法，并编写几个继承该基类的子类时，由于python在定义变量时不指定变量的类型，而是由解释器根据变量内容推断变量类型的（也就是说变量的类型取决于所关联的对象），这就使得python的多态不像是c++或java中那样，定义一个基类类型变量而隐藏了具体子类的细节&lt;/p&gt;

&lt;p&gt;而scala是静态强类型语言,  调用的方法必须在对象类型层次(本类或者超类）中定义。不过scala通过structural types支持所谓的类型安全的鸭子类型:
     类型安全的鸭子类型 - structural types  - structural types as a type-safe approach to duck typing&lt;/p&gt;
</description>
        <pubDate>Fri, 02 Feb 2018 00:00:00 +0800</pubDate>
        <link>https://xiazemin.github.io/MyBlog/web/2018/02/02/Duck_typing.html</link>
        <guid isPermaLink="true">https://xiazemin.github.io/MyBlog/web/2018/02/02/Duck_typing.html</guid>
        
        
        <category>web</category>
        
      </item>
    
      <item>
        <title>导入第三方依赖到shell</title>
        <description>&lt;!-- more --&gt;
&lt;p&gt;import SparkContext
这是spark下面已经有这个jar包的存在了
spark-shell下面包含所有的spark和java的依赖
但是对于第三代jar包，需要先将第三方依赖（jar包）导入到spark-shell下面才行
spark-shell –jars /home/wangtuntun/下载/nscala-time_2.10-2.12.0.jar
如果需要导入多个依赖，之间用逗号隔开
前提要配置spark-shell到环境变量&lt;/p&gt;
</description>
        <pubDate>Sat, 27 Jan 2018 00:00:00 +0800</pubDate>
        <link>https://xiazemin.github.io/MyBlog/spark/2018/01/27/spark_jar.html</link>
        <guid isPermaLink="true">https://xiazemin.github.io/MyBlog/spark/2018/01/27/spark_jar.html</guid>
        
        
        <category>spark</category>
        
      </item>
    
  </channel>
</rss>
