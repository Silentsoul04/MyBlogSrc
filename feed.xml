<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>泽民博客</title>
    <description>夏泽民的个人主页，学习笔记。</description>
    <link>https://xiazemin.github.io/MyBlog/</link>
    <atom:link href="https://xiazemin.github.io/MyBlog/feed.xml" rel="self" type="application/rss+xml"/>
    <pubDate>Mon, 05 Feb 2018 18:25:18 +0800</pubDate>
    <lastBuildDate>Mon, 05 Feb 2018 18:25:18 +0800</lastBuildDate>
    <generator>Jekyll v3.6.0.pre.beta1</generator>
    
      <item>
        <title>iputils</title>
        <description>&lt;!-- more --&gt;
&lt;p&gt;1.1       iputils软件包简介
    iputils软件包是linux环境下一些实用的网络工具的集合。一开始由Alexey Kuznetsov维护。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;iputils包含以下几个工具：

1. ping。使用 ping可以测试计算机名和计算机的ip地址，验证与远程计算机的连接。ping程序由ping.c ping6.cping_common.c ping.h 文件构成

2. tracepath。与traceroute功能相似，使用tracepath测试IP数据报文从源主机传到目的主机经过的路由。tracepath程序由tracepath.c tracepath6.c traceroute6.c 文件构成。

3. arping。使用arping向目的主机发送ARP报文，通过目的主机的IP获得该主机的硬件地址。arping程序由arping.c文件构成。

4. tftpd。tftpd是简单文件传送协议TFTP的服务端程序。tftpd程序由tftp.h tftpd.c tftpsubs.c文件构成。

5. rarpd。rarpd是逆地址解析协议的服务端程序。rarpd程序由rarpd.c文件构成。

6. clockdiff。使用clockdiff可以测算目的主机和本地主机的系统时间差。clockdiff程序由clockdiff.c文件构成。

7. rdisc。rdisc是路由器发现守护程序。rdisc程序由rdisc.c文件构成。
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;1.2       本文简介
   本文是在对源程序的分析的过程中写的总结文档。本文将依次对软件包中的程序进行介绍。介绍主要按照如下几个方面进行：&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;1. 在前言中简要介绍程序的基本用途、基本原理等。这是对于软件包中各软件的基本认识的总结。

2. 在程序使用中介绍程序的使用方法、使用选项等。这是对于使用软件包中程序的使用方法的介绍。

3. 在程序流程图中给出程序的基本流程。流程图的优点是比较能直观地给出程序的功能实现的流程，方便对程序有全局的掌握。然而不可避免地，流程图隐去了诸多的实现细节，所以如果要进一步分析程序，还需要进一步深入细节。

4. 介绍全局变量的含义、用途、变化等。全局变量是在程序中任何地方都可以访问的变量，所以分析全局变量有助于理解程序的数据变化流程。

5. 对于重要函数的介绍。一些重要的函数，不仅在程序的实现上占有重要的作用，而且理解起来有一定的难度，我觉得有必要进行分析。

6. 对于牵涉到的网络协议的介绍。阅读iputils源码的目的和好处之一就是帮助进一步理解网络协议。iputils涉及到IP、UDP、 ARP、RARP、ICMP、TFTP等不同层次的网络协议。本文将给出网络协议的基本介绍，主要是给出了网络报文的格式等内容。

7. 对于程序中重要的实现方法的介绍。而在iputils源码分析中，遇到了很多计算机网络方面的概念、思想、策略和机制。结合iputils的具体实现方法，本文将介绍计算机网络方面的相关知识。
&lt;/code&gt;&lt;/pre&gt;

&lt;ol&gt;
  &lt;li&gt;对其他知识的介绍，例如基于linux的多线程编程或linux下socket编程的知识。在分析源码的过程中，不可回避地遇到了这些知识的使用。
1.3       附件说明&lt;/li&gt;
&lt;/ol&gt;

&lt;pre&gt;&lt;code&gt;本文基于的源码版本为iputils-s20071127。源代码可以在http://www.linux-ipv6.org/gitweb/gitweb.cgi?p=gitroot/iputils.git中下载。

在阅读和分析源代码过程中，对代码进行了大量的注释，附件可以在下载http://download.csdn.net/detail/fsdev/4498604。

为了能够编译通过，定义了rdisc.c需要使用但是源代码中没有定义的宏：

#define OPEN_MAX   10

这个宏的意义是程序所能够打开的最大的文件数目。rdisc程序在退到后台之后，需要关闭除了socket文件之外的所有文件，OPEN_MAX宏就是在这里使用的。为了能够输出测试信息，并尽量不修改原程序代码，定义宏：

#define lixiprintf printf

所有添加输出信息的部分都使用lixiprintf宏。除了加入注释和以上两个更改外，没有修改程序其他地方。
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;2.1       引言
   “ping”这个名字源于声纳定位操作。Ping程序由Mike Muuss编写，目的是为了测试另一台主机是否可达。该程序发送一份ICMP回显请求报文给主机，并等待返回ICMP回显应答。&lt;/p&gt;

&lt;p&gt;2.2       ping程序的使用
    敲入命令：&lt;/p&gt;

&lt;p&gt;[plain] view plain copy
lixi@lixi-desktop:~$ ping -V&lt;br /&gt;
ping utility, iputils-sss20071127&lt;br /&gt;
    说明本机中安装的ping程序和本文研究的ping程序一样，是最新版本。&lt;/p&gt;

&lt;p&gt;[plain] view plain copy
lixi@lixi-desktop:~$ ping -T tsonly www.ustc.edu.cn -c 1&lt;br /&gt;
PING www.ustc.edu.cn (202.38.64.9) 56(124) bytes of data.&lt;br /&gt;
64 bytes from 202.38.64.9: icmp_seq=1 ttl=62 time=0.795 ms&lt;br /&gt;
TS:     6123570 absolute&lt;br /&gt;
    493&lt;br /&gt;
    364&lt;br /&gt;
    -857378&lt;br /&gt;
    0&lt;br /&gt;
    857378&lt;br /&gt;
    -363&lt;br /&gt;
    -493&lt;/p&gt;

&lt;p&gt;— www.ustc.edu.cn ping statistics —&lt;br /&gt;
1 packets transmitted, 1 received, 0% packet loss, time 0ms&lt;br /&gt;
rtt min/avg/max/mdev = 0.795/0.795/0.795/0.000 ms&lt;br /&gt;
    6123570是时间戳的绝对值，而输出的其他时间戳是相对上一个时间戳的差别。在北京时间9：42做的测试，北京时区为UTC+8，故此有9＋42/60-8=1.7&lt;/p&gt;

&lt;p&gt;而6123570/60/60/1000＝1.7。故此出现这个结果是非常有道理的。&lt;/p&gt;

&lt;p&gt;[plain] view plain copy
lixi@lixi-desktop:~$ ping www.ustc.edu.cn -R -c 1&lt;br /&gt;
PING www.ustc.edu.cn (202.38.64.9) 56(124) bytes of data.&lt;br /&gt;
64 bytes from 202.38.64.9: icmp_seq=1 ttl=62 time=0.852 ms&lt;br /&gt;
RR:     lixi-desktop.local (210.45.74.25)&lt;br /&gt;
    202.38.96.36&lt;br /&gt;
    local-gw.ustc.edu.cn (202.38.64.126)&lt;br /&gt;
    202.38.64.9&lt;br /&gt;
    202.38.64.9&lt;br /&gt;
    202.38.96.33&lt;br /&gt;
    210.45.74.1&lt;br /&gt;
    lixi-desktop.local (210.45.74.25)&lt;br /&gt;
    对照上面的路由信息，我们就可以分析出为什么时间戳信息里会有对称的现象，而对称轴的值是0了。&lt;/p&gt;

&lt;p&gt;产生对称性的另一个条件是RTT很小，这里只有0.8ms。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;我们可以还可以分析出202.38.64.9的系统时间和其他路由的系统时间相差很大，大约有-14分钟。
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;[plain] view plain copy
lixi@lixi-desktop:~$ ping -T tsandaddr www.ustc.edu.cn -c 1&lt;br /&gt;
PING www.ustc.edu.cn (202.38.64.9) 56(124) bytes of data.&lt;br /&gt;
64 bytes from 202.38.64.9: icmp_seq=1 ttl=62 time=1.66 ms&lt;br /&gt;
TS:     lixi-desktop.local (210.45.74.25)   7375300 absolute&lt;br /&gt;
    210.45.74.1 828&lt;br /&gt;
    local-gw.ustc.edu.cn (202.38.64.126)    26&lt;br /&gt;
    202.38.64.9 -857405&lt;br /&gt;
Unrecorded hops: 3&lt;/p&gt;

&lt;p&gt;— www.ustc.edu.cn ping statistics —&lt;br /&gt;
1 packets transmitted, 1 received, 0% packet loss, time 0ms&lt;br /&gt;
rtt min/avg/max/mdev = 1.664/1.664/1.664/0.000 ms&lt;br /&gt;
   上面是同时记录路由和时间戳信息。不过这里由于IP选项长度的限制，只能存储4个路由和它对应的时间戳。
[plain] view plain copy
lixi@lixi-desktop:~$ ping -T tsprespec 202.38.64.9 202.38.96.33 210.45.74.1 www.ustc.edu.cn -c 1&lt;br /&gt;
PING www.ustc.edu.cn (202.38.64.9) 56(124) bytes of data.&lt;br /&gt;
64 bytes from 202.38.64.9: icmp_seq=1 ttl=62 time=0.893 ms&lt;br /&gt;
TS:     202.38.64.9 6741320 absolute&lt;br /&gt;
    202.38.96.33    0&lt;br /&gt;
    210.45.74.1 857353&lt;br /&gt;
Unrecorded hops: 1&lt;/p&gt;

&lt;p&gt;— www.ustc.edu.cn ping statistics —&lt;br /&gt;
1 packets transmitted, 1 received, 0% packet loss, time 0ms&lt;br /&gt;
rtt min/avg/max/mdev = 0.893/0.893/0.893/0.000 ms&lt;br /&gt;
    如果我们一定要得到以后的几个路由和时间戳，我们可以采用上述的办法。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;这里在北京时间10：07分的时候进行的测试，202.38.64.9的时间戳是6741320，而我们上面的分析，202.38.64.9的系统时间大约比北京时间晚14分钟。10-8-14/60=1.87。6741320/60/60/1000=1.87。故此出现这个时间戳也是很有道理的。

ping程序的选项解释如下：

-a   

    可听见的ping。

    所谓可听见,不过是在ping.c文件的parse_reply的函数中,输出ASCII码'/a',beep一下。
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;-A&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;    自适应的ping。调整报文间隔时间，使其适应于RTT，这样非常有效率地使得网络中传输的不超过一个（如果-l参数设置了就为多个）。对于非超级用户，最小的时间间隔为200毫秒，在一个RTT比较得下的网络中，这个模式和-f的洪泛模式基本相同。

    为了调整报文时间间隔,使用update_interval()函数来调整时间间隔。

-b

    允许ping广播地址。

    设置broadcast_pings为1，当判断到这个选项设为1之后，且地址是广播地址，那么就设置setsockopt(icmp_sock, SOL_SOCKET, SO_BROADCAST,&amp;amp;broadcast_pings, sizeof(broadcast_pings))。

-B

    不允许ping改变报文的源主机地址，该地址在ping开始运行的时候就已经指定了。

    为了指定源主机地址,ping.c使用函数bind()来把套接字和本地套接字地址绑定，即在已创建的套接字上加上本地套接字地址。

-c &amp;lt;count&amp;gt;

    在发送&amp;lt;count&amp;gt;个ECHO_REQUEST报文。当和-w &amp;lt;deadline&amp;gt;一起设置时，ping等待收到&amp;lt;count&amp;gt;个ECHO_REPLY报文，直到超出时间限制为止。

    设置npackets选项为&amp;lt;count&amp;gt;就可以了。在没有设置deadline的情况下，当nreceived + nerrors &amp;gt;=npackets时就可以退出循环，完成ping的任务了。

-d

    设置socket中的SO_DEBUG选项，使能调试跟踪。实质上Linux内核中没有使用这个套接字选项。

    设置方法：setsockopt(icmp_sock,SOL_SOCKET, SO_DEBUG, (char *)&amp;amp;hold, sizeof(hold));

-F &amp;lt;flow&amp;gt; &amp;lt;label&amp;gt;

   这个选项只有ping6才有。

-f

  洪泛模式。对每一个ECHO_REQUEST报文的发送，打印一个“.”，当接受到ECHO_REPLY报文时，打印一个backspace字符。这样能够快速地表明网络丢失了多少个报文。如果interval没有设置，则设置interval为0，并按照报文接受的速度和一百次每秒的速度来发送报文（看哪个速度快）。只有超级用户能够和-i 0选项一起使用这个选项。

-i &amp;lt;interval&amp;gt;

   在发送每个报文之间等待&amp;lt;interval&amp;gt;秒。默认设置是等待一秒，在洪泛模式下则不等待。只有超级用户才能将&amp;lt;interval&amp;gt;设置为小于0.2秒的数。

   interval为&amp;lt;interval&amp;gt;*1000，程序的实现决定了&amp;lt;interval&amp;gt;输入整型数和浮点数都能被正确接受。

-I &amp;lt;interface/address&amp;gt;

    设置发送的地址或者网络设备。

    程序首先尝试用intinet_pton(int af, const char *src, void *dst)函数由将src代表的字符串转化为dst中的IP地址。如果不能正确转换，则意味着这个选项不是地址，例如210.45.74.25，而是设备名如eth0。如果是后者，则设置device为&amp;lt;interface&amp;gt;，并用bind(icmp_sock, (structsockaddr*)&amp;amp;source, sizeof(source))      setsockopt(probe_fd,SOL_SOCKET, SO_BINDTODEVICE, device, strlen(device)+1)来将套接字和本地套接字地址进行绑定。

-l &amp;lt;preload&amp;gt;

    &amp;lt;preload&amp;gt;是在没有接受到回复报文之前能发送的最多报文。非超级用户最多只能设置为3。

    尽可能快地发送预载的报文，然后再返回到正常发送模式。

    将&amp;lt;preload&amp;gt;值赋到preload变量中。如果不赋值preload默认为1。

-L

    禁止多播数据包的回环，只有在ping的目的主机是广播地址时才管用。

-n

    只有数字形式ip地址值的输出，不通过查询DNS获知IP地址对应的主机名，以节省时间。

    设置F_NUMERIC，不用调用gethostbyaddr来查询DNS主机名了。

    用gethostbyaddr的由查询目的主机的IP地址。

-p &amp;lt;pattern&amp;gt;

    允许为传输的回显报文中包含的内容指定字节模式。这对于诊断与传输数据有关的网络问题可能很有用。数据采用16进制，例如“-p ff”可将传输的报文填充为全1。

-Q &amp;lt;tos&amp;gt;

    用来设置服务质量（Quality of Service ）

    例如最小开销、 可靠性、吞吐量、低延迟。

    IP协议有一个8bit的DS区分服务（以前叫服务类型）。前三位是优先（precedence）字段（在目前，优先字段并未被大家使用），接着4bit是TOS位，最后1bit没有使用，但必须置0。

    4比特TOS位的意义分别为D（最小时延）、T（最大吞吐量）、R（最高可靠性）、C（最小代价）。要设置TOS位为对应意义，可以设置-Q &amp;lt;tos&amp;gt;分别为0x10，0x08，0x04，0x02。TOS的各个位不能同时置1。

-q

    静默模式。这种模式下，出了开始的提示和结束的数据统计，不会输出任何东西。

-R

    记录路由信息。在发送的IP报文首部选项中放入记录路由选项，在接到到报文回复之后，打印出回复报文的路由信息。

    注意：IP报文的选项中最多只能计算9个路由信息，计算方式如下：

    首部长度HLEN。这4bit字段用来定义首部的长度，以4字节为单位。由于首部长度可变，默认长度是20字节，此时4bit字段值为5。4bit的字段最大可以表示的数为15，故此首部长度最大为15*4byte，即60byte。首部的可变字节数为60-20＝40byte，RR选项用去3byte（参见记录路由选项的一般格式），只剩下37byte，最多只能放下9个IP地址。

    注意：很多的主机会略过IP报文的路由选项，因此有可能在回复报文中没有路由信息。

    注意：不能和-T选项一起使用。

-r

    绕过一般的路由表而直接向一个连接着的主机发送报文。如果主机不是通过直接连接的网络相连，则会出现错误。这个选项可以用来ping一个没有通过路由相连而是通过一个接口相连（假设也使用了-I选项）的本地主机。

    使用setsockopt函数设置套接字的SOL_SOCKET级别的SO_DONTROUTE选项即可。

-s &amp;lt;packetsize&amp;gt;

    设置ICMP报文的数据部分的长度。默认值是56，和ICMP首部的8字节一起作为IP报文的数据部分。

    设置datalen变量就可以了，datalen默认为DEFDATALEN（值是56）。长度为datalen的数据和8字节的首部一起作为ICMP报文。

-S &amp;lt;sndbuf&amp;gt;

    设置套接字的发送缓冲区大小。如果没有设置，则被设定为不超过一个报文长度的长度。

-t &amp;lt;ttl&amp;gt;

    设置TTL（time to live）。

    使用setsockopt函数设置套接字的IPPROTO_IP级别的IP_MULTICAST_TTL和IP_TTL选项即可。

-T &amp;lt;timestamp&amp;gt; &amp;lt;option&amp;gt;

    设置IP时间戳选项。时间戳选项可以是以下三种：

    -T tsonly 只记录时间戳。

    -T tsandaddr 收集时间戳和IP地址。

    -T tsprespec [host1 [host2 [host3[host4]]]] 收集来自预定的网络段的时间戳和地址，发送端对选项列表进行初始化，存放了4个IP地址和四个取值为0的时间戳。只有在列表中的下一个地址和当前路由地址相匹配时，才记录它的时间戳。

    与-R选项的分析类似，首部的可变字节数为60-20＝40byte，选项用去4byte（参见时间戳选项的一般格式），只剩下36byte，最多只能放下9个时间戳。

    注意：由于IP首部的空间限制，程序限制-R选项与-T不能同时使用。

-M &amp;lt;hint&amp;gt;

    设定Path MTU查找选下项，可设置成下列三种：

    -M do 不允许分段，甚至不允许在本地分段。

    -M want 找出PMTU，在如果包太大就在本地分段。

    -M dont 不要设置IP首部中的DF位，即允许分段。

    使用setsockopt函数设置套接字的SOL_IP级别的IP_MTU_DISCOVER选项即可。

-U

-v

   冗余输出。输出很多具体信息。

-V

    打印ping的版本，然后退出。

-w &amp;lt;deadline&amp;gt;

    设定时间期限为&amp;lt;deadline&amp;gt;秒，不管已经发送和接到了多少包，只要达到时间期限就结束ping的过程。

-W &amp;lt;timeout&amp;gt;

    等待回复的时间，单位是秒。这个选项只在没有接到任何的回复的情况下有效，只要接到了一个回复，就将等待时间设置为两倍的RTT。如果没有设置，则等待时间设置为一个最大值。
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;2.3       ping程序的流程图
    ping程序的流程图如下所示：&lt;/p&gt;

&lt;p&gt;2.4       IP报文结构
    IP报文结构如下所示：&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;IP数据报文的首部中有选项部分，这个部分可以用来存储IP时间戳或者IP记录路由选项。

存储IP时间戳，如下图所示：

 

IP记录路由选项，如下图所示：
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;2.5       ICMP报文结构
    ICMP的封装方式如下图所示：&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;ICMP报文的结构如下图所示：
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;2.6       ICMP回显请求和回显应答报文格式
    ICMP回显请求和回显应答报文格式如下所示：&lt;/p&gt;

&lt;p&gt;2.7       ICMP报文类型列表
    不同种类的ICMP报文的首部有所不同。如下：&lt;/p&gt;

&lt;p&gt;类型&lt;/p&gt;

&lt;p&gt;代码&lt;/p&gt;

&lt;p&gt;描述&lt;/p&gt;

&lt;p&gt;0&lt;/p&gt;

&lt;p&gt;ICMP_ECHOREPLY&lt;/p&gt;

&lt;p&gt;0&lt;/p&gt;

&lt;p&gt;回显应答&lt;/p&gt;

&lt;p&gt;3&lt;/p&gt;

&lt;p&gt;ICMP_DEST_UNREACH&lt;/p&gt;

&lt;p&gt;目的不可达&lt;/p&gt;

&lt;p&gt;0&lt;/p&gt;

&lt;p&gt;ICMP_NET_UNREACH&lt;/p&gt;

&lt;p&gt;网络不可达&lt;/p&gt;

&lt;p&gt;1&lt;/p&gt;

&lt;p&gt;ICMP_HOST_UNREACH&lt;/p&gt;

&lt;p&gt;主机不可达&lt;/p&gt;

&lt;p&gt;2&lt;/p&gt;

&lt;p&gt;ICMP_PROT_UNREACH&lt;/p&gt;

&lt;p&gt;端口不可达&lt;/p&gt;

&lt;p&gt;3&lt;/p&gt;

&lt;p&gt;ICMP_PORT_UNREACH&lt;/p&gt;

&lt;p&gt;协议不可达&lt;/p&gt;

&lt;p&gt;4&lt;/p&gt;

&lt;p&gt;ICMP_FRAG_NEEDED&lt;/p&gt;

&lt;p&gt;需要进行分片单设置了不分片比特&lt;/p&gt;

&lt;p&gt;5&lt;/p&gt;

&lt;p&gt;ICMP_SR_FAILED&lt;/p&gt;

&lt;p&gt;源站选路失败&lt;/p&gt;

&lt;p&gt;6&lt;/p&gt;

&lt;p&gt;ICMP_NET_UNKNOWN&lt;/p&gt;

&lt;p&gt;目的网络不认识&lt;/p&gt;

&lt;p&gt;7&lt;/p&gt;

&lt;p&gt;ICMP_HOST_UNKNOWN&lt;/p&gt;

&lt;p&gt;目的主机不认识&lt;/p&gt;

&lt;p&gt;8&lt;/p&gt;

&lt;p&gt;ICMP_HOST_ISOLATED&lt;/p&gt;

&lt;p&gt;源主机被隔离（作废不用）&lt;/p&gt;

&lt;p&gt;9&lt;/p&gt;

&lt;p&gt;ICMP_NET_ANO&lt;/p&gt;

&lt;p&gt;目的网络被强制禁止&lt;/p&gt;

&lt;p&gt;10&lt;/p&gt;

&lt;p&gt;ICMP_HOST_ANO&lt;/p&gt;

&lt;p&gt;目的主机被强制禁止&lt;/p&gt;

&lt;p&gt;11&lt;/p&gt;

&lt;p&gt;ICMP_NET_UNR_TOS&lt;/p&gt;

&lt;p&gt;由于服务类型TOS，网络不可达&lt;/p&gt;

&lt;p&gt;12&lt;/p&gt;

&lt;p&gt;ICMP_HOST_UNR_TOS&lt;/p&gt;

&lt;p&gt;由于服务类型TOS，主机不可达&lt;/p&gt;

&lt;p&gt;13&lt;/p&gt;

&lt;p&gt;ICMP_PKT_FILTERED&lt;/p&gt;

&lt;p&gt;由于过滤，通信被强制禁止&lt;/p&gt;

&lt;p&gt;14&lt;/p&gt;

&lt;p&gt;ICMP_PREC_VIOLATION&lt;/p&gt;

&lt;p&gt;主机越权&lt;/p&gt;

&lt;p&gt;15&lt;/p&gt;

&lt;p&gt;ICMP_PREC_CUTOFF&lt;/p&gt;

&lt;p&gt;优先权终止生效&lt;/p&gt;

&lt;p&gt;ICMP_SOURCE_QUENCH&lt;/p&gt;

&lt;p&gt;4&lt;/p&gt;

&lt;p&gt;0&lt;/p&gt;

&lt;p&gt;源端被关闭&lt;/p&gt;

&lt;p&gt;ICMP_REDIRECT&lt;/p&gt;

&lt;p&gt;5&lt;/p&gt;

&lt;p&gt;重定向&lt;/p&gt;

&lt;p&gt;0&lt;/p&gt;

&lt;p&gt;ICMP_REDIR_NET&lt;/p&gt;

&lt;p&gt;对网络重定向&lt;/p&gt;

&lt;p&gt;1&lt;/p&gt;

&lt;p&gt;ICMP_REDIR_HOST&lt;/p&gt;

&lt;p&gt;对主机重定向&lt;/p&gt;

&lt;p&gt;2&lt;/p&gt;

&lt;p&gt;ICMP_REDIR_NETTOS&lt;/p&gt;

&lt;p&gt;对服务类型和网络重定向&lt;/p&gt;

&lt;p&gt;3&lt;/p&gt;

&lt;p&gt;ICMP_REDIR_HOSTTOS&lt;/p&gt;

&lt;p&gt;对服务类型和主机重定向&lt;/p&gt;

&lt;p&gt;ICMP_ECHO&lt;/p&gt;

&lt;p&gt;8&lt;/p&gt;

&lt;p&gt;0&lt;/p&gt;

&lt;p&gt;请求回显&lt;/p&gt;

&lt;p&gt;9&lt;/p&gt;

&lt;p&gt;0&lt;/p&gt;

&lt;p&gt;路由器通告&lt;/p&gt;

&lt;p&gt;10&lt;/p&gt;

&lt;p&gt;0&lt;/p&gt;

&lt;p&gt;路由器请求&lt;/p&gt;

&lt;p&gt;ICMP_TIME_EXCEEDED&lt;/p&gt;

&lt;p&gt;11&lt;/p&gt;

&lt;p&gt;超时&lt;/p&gt;

&lt;p&gt;0&lt;/p&gt;

&lt;p&gt;ICMP_EXC_TTL&lt;/p&gt;

&lt;p&gt;传输请见生存时间为0&lt;/p&gt;

&lt;p&gt;1&lt;/p&gt;

&lt;p&gt;ICMP_EXC_FRAGTIME&lt;/p&gt;

&lt;p&gt;在数据包组装期间生存时间为0&lt;/p&gt;

&lt;p&gt;ICMP_PARAMETERPROB&lt;/p&gt;

&lt;p&gt;12&lt;/p&gt;

&lt;p&gt;参数问题&lt;/p&gt;

&lt;p&gt;0&lt;/p&gt;

&lt;p&gt;坏的IP首部&lt;/p&gt;

&lt;p&gt;1&lt;/p&gt;

&lt;p&gt;缺少必需的选项&lt;/p&gt;

&lt;p&gt;ICMP_TIMESTAMP&lt;/p&gt;

&lt;p&gt;13&lt;/p&gt;

&lt;p&gt;0&lt;/p&gt;

&lt;p&gt;时间戳请求&lt;/p&gt;

&lt;p&gt;ICMP_TIMESTAMPREPLY&lt;/p&gt;

&lt;p&gt;14&lt;/p&gt;

&lt;p&gt;0&lt;/p&gt;

&lt;p&gt;时间戳应答&lt;/p&gt;

&lt;p&gt;ICMP_INFO_REQUEST&lt;/p&gt;

&lt;p&gt;15&lt;/p&gt;

&lt;p&gt;0&lt;/p&gt;

&lt;p&gt;信息请求&lt;/p&gt;

&lt;p&gt;ICMP_INFO_REPLY&lt;/p&gt;

&lt;p&gt;16&lt;/p&gt;

&lt;p&gt;0&lt;/p&gt;

&lt;p&gt;信息应答&lt;/p&gt;

&lt;p&gt;ICMP_ADDRESS&lt;/p&gt;

&lt;p&gt;17&lt;/p&gt;

&lt;p&gt;0&lt;/p&gt;

&lt;p&gt;地址掩码请求&lt;/p&gt;

&lt;p&gt;ICMP_ADDRESSREPLY&lt;/p&gt;

&lt;p&gt;18&lt;/p&gt;

&lt;p&gt;0&lt;/p&gt;

&lt;p&gt;地址掩码应答&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;pr_icmph()函数中分析ICMP报文类型，并针对错误报文打印出出错问题。惨照上表就能比较好地分析各种问题出现的大致原因了。

另外在rdisc.c文件中使用了ICMP的路由器通告报文（类型为9）和ICMP路由器请求报文（类型为10）。

各种ICMP类型和代码的常量定义在linux-2.6.27/include/linux/icmp.h文件中。
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;2.8       socket选项
    程序中使用setsockopt()函数设定了套接字的选项。用到的选项如下：&lt;/p&gt;

&lt;p&gt;level（级别）&lt;/p&gt;

&lt;p&gt;optname（选项名）&lt;/p&gt;

&lt;p&gt;说明&lt;/p&gt;

&lt;p&gt;标志&lt;/p&gt;

&lt;p&gt;SOL_SOCKET&lt;/p&gt;

&lt;p&gt;SO_BROADCAST&lt;/p&gt;

&lt;p&gt;允许或禁止发送广播数据&lt;/p&gt;

&lt;p&gt;Ö&lt;/p&gt;

&lt;p&gt;SO_ATTACH_FILTER&lt;/p&gt;

&lt;p&gt;安装过滤器。&lt;/p&gt;

&lt;p&gt;SO_SNDBUF&lt;/p&gt;

&lt;p&gt;设置发送缓冲区的大小。&lt;/p&gt;

&lt;p&gt;SO_RCVBUF&lt;/p&gt;

&lt;p&gt;设置接收缓冲区的大小。&lt;/p&gt;

&lt;p&gt;SO_DEBUG&lt;/p&gt;

&lt;p&gt;打开或关闭调试信息&lt;/p&gt;

&lt;p&gt;Ö&lt;/p&gt;

&lt;p&gt;SO_DONTROUTE&lt;/p&gt;

&lt;p&gt;打开或关闭路由查找功能。&lt;/p&gt;

&lt;p&gt;Ö&lt;/p&gt;

&lt;p&gt;SO_TIMESTAMP&lt;/p&gt;

&lt;p&gt;打开或关闭数据报中的时间戳接收。&lt;/p&gt;

&lt;p&gt;Ö&lt;/p&gt;

&lt;p&gt;SO_SNDTIMEO&lt;/p&gt;

&lt;p&gt;设置发送超时时间。&lt;/p&gt;

&lt;p&gt;SO_RCVTIMEO&lt;/p&gt;

&lt;p&gt;设置接收超时时间。&lt;/p&gt;

&lt;p&gt;SO_BINDTODEVICE&lt;/p&gt;

&lt;p&gt;将套接字绑定到一个特定的设备上。&lt;/p&gt;

&lt;p&gt;SOL_RAW&lt;/p&gt;

&lt;p&gt;ICMP_FILTER&lt;/p&gt;

&lt;p&gt;设置套接字ICMP过滤选项。&lt;/p&gt;

&lt;p&gt;IPPROTO_IP&lt;/p&gt;

&lt;p&gt;IP_OPTIONS&lt;/p&gt;

&lt;p&gt;设置发出的数据报中的IP选项&lt;/p&gt;

&lt;p&gt;IP_MULTICAST_LOOP&lt;/p&gt;

&lt;p&gt;多播API，禁止组播数据回送&lt;/p&gt;

&lt;p&gt;Ö&lt;/p&gt;

&lt;p&gt;IP_MULTICAST_TTL&lt;/p&gt;

&lt;p&gt;多播API，设置输出组播数据的TTL值&lt;/p&gt;

&lt;p&gt;IP_TOS&lt;/p&gt;

&lt;p&gt;设置发出的数据报中的IP TOS&lt;/p&gt;

&lt;p&gt;SOL_IP&lt;/p&gt;

&lt;p&gt;IP_MTU_DISCOVER&lt;/p&gt;

&lt;p&gt;为套接字设置Path MTU Discovery setting(路径MTU发现设置)&lt;/p&gt;

&lt;p&gt;Ö&lt;/p&gt;

&lt;p&gt;IP_RECVERR&lt;/p&gt;

&lt;p&gt;允许传递扩展的可靠的错误信息&lt;/p&gt;

&lt;p&gt;Ö&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;程序首先取得了一个UDP的套接字probe_fd，并根据用户的输入配置套接字的选项。probe_fd用到的选项主要有：SO_BINDTODEVICE、SO_BINDTODEVICE、SO_BROADCAST、IP_TOS等。

ICMP报文的套接字icmp_sock用到的选项除了SO_BINDTODEVICE选项以外，列表中的所有选项都用到了。
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;2.9       ping.c程序的全局变量的分析
    static int ts_type;&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;    timestamp的类型

    在-T选项中设置，可以设置为IPOPT_TS_TSONLY、IPOPT_TS_TSANDADDR或者IPOPT_TS_PRESPEC。

static int nroute = 0;

     主机输入的总数，最多为9个，因为IP首部选项中最多能存储9个地址

static __u32 route[10];     

    在输入多个主机时，存储地址。

    可能输入多个主机的情况是：-Ttsprespec [host1 [host2 [host3 [host4]]]] 选项，或者ping hostName1 hostName2 ... hostNameN；前者是想获得确定几个路由对应的时间戳，而后者为什么这么设置，我还不大明白  。

struct sockaddr_in whereto;

    存储了目的主机的信息。

int optlen = 0;

    ip选项的长度。

    由IP的协议可知，最大为40，在需要在IP首部选项字段中存储数据时（例如-T、-R选项）就设置为最大值。

int settos = 0;

    服务质量的设置。

    可以用-Q选项用来设置服务质量，例如最小开销、 可靠性、吞吐量、低延迟。

    IP协议有一个8bit的DS区分服务（以前叫服务类型）。前三位是优先（precedence）字段（在目前，优先字段并未被大家使用），接着4bit是TOS位，最后1bit好像没有使用。

    4比特TOS位的意义分别为D（最小时延）、T（最大吞吐量）、R（最高可靠性）、C（最小代价）。

    要设置TOS位为对应意义，可以设置-Q &amp;lt;tos&amp;gt;中的 &amp;lt;tos&amp;gt;分别为0x10，0x08，0x04，0x02     。

int icmp_sock;

    ICMP的soket文件描述符。

u_char outpack[0x10000];

    用来存储ICMP报文首部和数据的数组，为ICMP报文分配的存储空间。

int maxpacket = sizeof(outpack);

    用来存储ICMP报文首部和数据的数组的最大大小。

static int broadcast_pings = 0;

    标识用户是不是想ping广播地址。

    可以通过-b选项设置。

    如果不设置，则默认为0。

struct sockaddr_in source;

    存储了源主机的信息。

    如果-I选项后面带的是源主机地址而不是设备名的话，就将主机的信息存储在source中。在socket试探的连接成功后，程序还用getsockname重新确定了source的值。

char *device;

    如果-I选项后面带的是设备名而不是源主机地址的话，如eth0，就用device指向该设备名。

    该device指向一个设备名之后，会设置socket的对应设备为该设备。

int pmtudisc = -1;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;2.10   ping_common.c程序的全局变量的分析
    int options;&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;    存储各种选项的FLAG设置情况。

    在判断输入选项时设置各个bit位。

int sndbuf;

    发送缓冲区大小。

    可以在-S &amp;lt;sndbuf&amp;gt;中设置，如果没有设置，则估计一个大小。

int ttl;

    报文ttl的值。

    可以在-t选项中设置。

    在设置soket选项时设置IP广播报文TTL和IP报文的TTL都为ttl值。

int rtt;

    用指数加权移动平均算法估计出来的RTT值。

    初始值是0。

    gather_statistics()函数中根据上次的RTT值和原来的rtt值加权得到新rtt的值。

    在update_interva()函数中用来计算新的interval的值。

int rtt_addend;

    配合rtt使用。

    用来计算新的interval的值，似乎是更具上个rtt的值给interval留部分余量。

__u16 acked;

    接到ACK的报文的16bit序列号。

    在gather_statistics()函数里更新，实际的更新方法似的acked不超过0x7FFF，不然就会发生回绕。

int mx_dup_ck = MAX_DUP_CHK;

    ？

long npackets;

    需要传输的最多报文数。

    可以在-c 选项里设置。

    如果没有设置则默认是0，故此每次在查询此值时就判断是否为0，0似乎作为无穷大来考虑。

long nreceived;

    得到回复的报文数。

    初始值是0。

    在gather_statistics函数中递加，进行统计。在程序执行finsh时，使用这个变量，打印出来作为参考。

long nrepeats;

    重复的报文数。

    初始值是0。

    在gather_statistics函数中递加，进行统计。在程序执行finsh时，使用这个变量，打印出来作为参考。

long ntransmitted;

    发送的报文的最大序列号。

    初始值是0。

   在pinger函数中递加，进行统计。在程序执行finsh时，使用这个变量，打印出来作为参考。

long nchecksum;

    checksum错误的恢复报文。

    初始值是0。

    在gather_statistics函数中，若csfailed为1的时候，则递加，进行统计。在程序执行finsh时，使用这个变量，打印出来作为参考。

    不过似乎checksum是不会被改变的，因为gather_statistics的选项csfailed在唯一的一次调用中（parse_reply()函数中）为0。

long nerrors;

    icmp错误数。

    初始值是0。

    在程序接受到出错的报文之后，就会调用receive_error_msg。在这个函数里如果判断确实是一个错误，错误有可能是本地出错，有可能是网络出错，不管是哪个出错，都将这nerrors递加。parse_reply也会改变这个变量。在程序执行finsh时，使用这个变量，打印出来作为参考。

int interval = 1000;           

    发送两个相邻报文之间相距的时间，单位为毫秒。

    可以在-i选项中设置。

    在设置-f的洪泛模式下，会设置interval为0。

    如果没有设置，则默认是1000。

int preload;

    在接受到第一个回复报文之前所发送的报文数。

    可以通过-l &amp;lt;preload&amp;gt;选项设置。

    如果没有设置，默认值是1。

int deadline = 0;

    在deadline秒之后，程序退出。

    可以由-w选项设置。如果设置了，则在setup函数中设置闹钟，当程序执行到deadline秒时产生SIGALRM中断，退出程序。
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;如果没有设置则默认值是0，程序运行没有时间限制。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;int lingertime = MAXWAIT*1000;

    等待回复的最长时间，单位为毫秒。

    可以通过-W选项设置。这个值在完成一次正确发收过程后就由2*tmax代替，而失去作用了。

    默认值是MAXWAIT*1000即10000，MAXWAIT定义在ping_common.h中。

struct timeval start_time;

    程序运行开始时的主机时间。

    在setup函数中使用gettimeofday初始化，在finish函数中和cur_time一起用来计算程序运行的时间。

struct timeval cur_time;

    程序运行时当前的主机时间。

volatile int exiting;

    程序是不是应该退出。

    初始值是0，就是不应该退出。

    在中断处理程序sigexit中会将这个值设为1。这个中断处理程序只在产生SIGALRM和SIGINT中断时(可以用Ctrl+c产生)才会执行。中断处理程序在setup函数中安装。

volatile int status_snapshot;

    程序是不是应该调用status()函数打印出程序的运行状态。

    初始值是0。

    在中断处理程序sigstatus中会将这个值设为1。这个中断处理程序只在产生SIGQUIT中断时(可以用Ctrl+\产生)才会执行。中断处理程序在setup函数中安装。

int confirm = 0;

    表明sendmsg函数的选项的MSG_CONFIRM选项是否设置。

    如果设置MSG_CONFIRM，则会告诉链路层的传送有了进展：已经接受到对方的一个成功的答复。由于MSG_CONFIRM的这个意义，所以在发送第一个数据是MSG_CONFIRM选项不因该设置，即confirm初始值为0。在成功接受到一个回复之后，confirm则应该设置为MSG_CONFIRM了。只有在确定取得一个回复时才将confirm由0改为MSG_CONFIRM，这就是为什么confirm只有在gather_statistics()才会被改变的原因。然而更麻烦的是MSG_CONFIRM选项只有在Linux 2.3及以上内核中才支持，所以就需要confirm_flag变量了。

int confirm_flag = MSG_CONFIRM;

    用来修补老版本linux内核的问题。

    confirm_flag的初始值为MSG_CONFIRM。这样在gather_statistics()里confirm就更新为confirm_flag了。但是，如果由于设置MSG_CONFIRM而产生了发送错误（linux版本较老，不支持MSG_CONFIRM选项）。这样就会在下个循环里调用gather_statistics()，更新confirm变量，保证不会发送出错了。

int working_recverr;

    ？

int timing;

    是否能够在ping过程中测算时间

    如果ICMP报文的数据长度足以存储timeval结构数据，则timing设置为1。如果timing设置为1，则在ICMP报文中插入发送的时间，这样在接受到ICMP回复时，就可以根据该数据计算RRT。否则就无法计算RRT，也就无法进行时间统计了。

    从根本上说timing的值由datalen变量的大小决定。

    可以尝试运行ping -s1 www.ustc.edu.cn -c 1，看看运行结果怎样。

    可以看到没有时间统计输出，因为-s选项设置的datalen值太小。

long tmin = LONG_MAX;             /*minimum round trip time */

    最小RRT

    初始值为LONG_MAX，每次接受到回复报文之后，就在gather_statistics函数中本次RRT是不是比tin大，如果是，就更新tmin。在程序执行完成之后，将打印出这个信息作为参考。

long tmax;                        

    最大RRT

    初始值为0，每次接受到回复报文之后，就在gather_statistics函数中本次RRT是不是比tmax大，如果是，就更新tmax。在程序执行完成之后，将打印出这个信息作为参考。

    此外tmax还作为每次发送报文后等待接受报文的时间长度的参考，见__schedule_exit函数。如果超出这个时间长度还没有完成一次发送和接受，则发生超时中断。

long long tsum;                 /*sum of all times, for doing average */

    每次RRT之和。

    初始值为0，每次接受到回复报文之后，就在gather_statistics函数中加上本次RRT。

    用来计算平均RRT。

long long tsum2;

    每次RRT的平方和。

    初始值为0，每次接受到回复报文之后，就在gather_statistics函数中加上本次RRT的平方。

    用来计算RRT的方差。

int  pipesize =-1;

    初始值为-1。

int datalen = DEFDATALEN;

    数据长度。

    初始值为DEFDATALEN，即56。

    可以通过-s选项设置     。

char *hostname;

    目的主机名字。

    在开始的时候，由用户作为程序的选项输入。随后通过gethostbyname()函数由主机名得到主机，然后将主机名改为函数返回的官方主机名。

    在最后输出的目的主机名就是这个名字。

int uid;

    用户ID。

    在main函数中通过getuid()取得。

    如果uid不是0，即用户不是超级用户，则在设置选项的时候有限制：

    -i&amp;lt;interval&amp;gt;，&amp;lt;interval&amp;gt;不得小于0.2；在ping广播地址时，&amp;lt;interval&amp;gt;不能设置为小于1的数。

    -M&amp;lt;hint&amp;gt;，在ping广播地址时，&amp;lt;hint&amp;gt;不能设置为IP_PMTUDISC_DO之外的IP_PMTUDISC_DONT或IP_PMTUDISC_WANT。

    -s&amp;lt;packetsize&amp;gt;， &amp;lt;packetsize&amp;gt;不能超过sizeof(outpack)-8。

    -v，不会输出比较敏感的冗长信息，例如parse_reply函数中可能输出的额外信息。

    -l&amp;lt;preload&amp;gt;，ping广播地址时，&amp;lt;preload&amp;gt;不能大于3。

    -f，必须要和-i选项配合使用，且&amp;lt;interval&amp;gt;不小于0.2。

int ident;

    本进程的ID。

    在setup函数中通过getpid()取得。

    在ICMP的数据中添加进程ID，并通过判断接受到的ICMP回复的进程ID是不是正确来判断ICMP回复是不是本进程的回复。

static int screen_width = INT_MAX;

   窗口的宽度大小，也就是控制台一行能打印多少字符。

   在setup函数中通过ioctl()取得。
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;2.11   重要函数的分析
    int main(int argc, char **argv);&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;    主函数。

    在这个函数里：取得用户输入的选项，并根据这些选项及其参数设置相应的标识和参数值。根据这些标识和参数值，首先连接（connect）一个探测的UDP报文，以探知目的地址的基本情况。然后设置ICMP报文的套接字选项，然后调用setup()函数来进一步设置与协议无关的套接字选项（与ping6公用）。在套接字设置好后，调用main_loop()函数完成探测。

    定义在ping.c文件中。

void main_loop(int icmp_sock, __u8 *packet, intpacklen);

    完成报文发送、分析的主要函数。

    在这个函数里：一直调用pinger()函数发ICMP报文和调用recvmsg()函数接受报文。如果recvmsg()函数没有正确接受报文，调用receive_error_msg()函数处理接受到的ICMP差错报文。如此反复，直到用户要求终止或者报文发送次数达到要求，或者超出的程序的时间限制，程序才停止发送/接受；程序在停止发送/接受后，调用finish()函数打印出统计数据。

    在main()函数中调用到此函数。

    定义在ping_common.c文件中。在这个文件中的所有函数都能够被ping和ping6共同使用。

void int pinger(void);

    构成并发送报文。

    在这个函数里：调用send_probe()尝试发送报文，并处理send_probe()没有成功发送时出现的错误。在处理某些种类的错误时，用到receive_error_msg()函数。

    在main_loop()函数中调用到此函数。

    定义在ping_common.c文件中。

int send_probe()

    构建报文，并发送报文。

    在这个函数里：根据用户的参数设置，设置ICMP报文的类型、代码、序号、标识符，并往ICMP报文的选项数据部分添加发送时间，然后计算校验和。构建出这个ICMP报文后，调用sendmsg()函数发送ICMP报文。此函数不处理发送出错。

    在pinger()函数中调用到此函数。

    定义在ping.c文件中。

int receive_error_msg()

    处理ICMP差错报文。

    在这个函数里：调用设置了MSG_ERRQUEUE标识的recvmsg()来接收错误队列中的ICMP错误报文。取得错误信息之后，分析出错的原因是由于本地原因还是网络原因，并进行处理（比如设置更严格的ICMP过滤）。

    在main_loop()函数和pinger()函数中调用到此函数。

    定义在ping.c文件中。

void setup(int icmp_sock)

    设置与协议无关的选项。

    在这个函数里：根据用户设置，这些设置包括interval的设置，socket的是否打开调试信息（SO_DEBUG）、是否打开路由查找功能（SO_DONTROUTE）、是否打开数据报中的时间戳接收（SO_TIMESTAMP）、发送时间限制（SO_SNDTIMEO）、接受时间限制（SO_RCVTIMEO）等选项，往报文内填内容的设置，中断处理程序的设置，闹钟的设置等。

    在main()函数和pinger()函数中调用到此函数。

    定义在ping_common.c文件中。
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;2.12   时间间隔和报文预发机制的实现
    程序使用一个分配时间片的概念，来控制发送报文的时间间隔，并实现在没有接到回复报文之前就预先发送preload个请求报文。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;初始时分配interval*preload的时间片用来发送报文（程序中第一次发送设置时间片为interval*(preload-1)，由于设置后没有减去第一次发送用去的interval时间片，所以相当于分配了interval*preload的时间片）。每次发送报文都要用掉interval毫秒的时间片。如果时间片不为负数的话，则一直持续发送报文。如果时间片为负数，则退出循环，开始处理接受到的回复报文。处理接受到的回复报文，会用去比较长的时间。

从上次发送报文，到当前准备发送报文的时间被计时器记录（实际上是通过记录上次发送报文的系统时间到当前系统时间之差来记录的），并作为新的时间片加入原时间片中，作为下次发送报文的时间片。为了确保没有接到回复而发送了的报文数目不会超过preload个，这个新的时间片如果超过interval*preload，则被改为interval*preload。如果新的时间片小于发送一个报文的时间interval，则仍然不发送报文，退出发送报文的循环，接受回复报文和处理可能出现的中断。

通过上述方法，实现了两个功能：

 1. 可以在不等待回复的情况下，预先发送preload个报文。由于初始时分配的时间片为interval*preload，所以刚开始，程序就连续发送interval个请求报文；如果程序等了很长时间没有发送报文，则计时器的引入使得这一段时间也作为发送时间片的新的一部分，这样程序又可以连续发送几个报文。

2. 可以控制报文发送的时间间隔为interval。从初始时开始，在连续发送preload个报文后，时间片被耗尽。只有在计时器中累加的时间片超过interval时才能再连续发送一个或几个报文（不超过preload个）。

相关函数：

int pinger(void);

void main_loop(int icmp_sock, __u8 *packet, int packlen);

相关选项：

-l &amp;lt;preload&amp;gt;

-i &amp;lt;interval&amp;gt;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;2.13   回复等待计时的实现
    当用户使用-c &lt;count&gt;设置了需要传送/接受的报文数，且通过-w &lt;deadline&gt;设置了程序运行的时间，那么则程序只需要在发送&lt;count&gt;个报文，并等待接受报文，直到接受到&lt;count&gt;个回复或者程序运行时间超过限制为止。如果用户只使用-c&lt;count&gt;设置了需要传送/接受的报文数，没有设置程序运行的时间，那么鉴于有些请求报文丢失而永远不会接到报文，程序不能在发送了&lt;count&gt;个报文之后一直等待。程序一直等待一个可能再也不会出现的事情是难以接受的，它应该做的是在发送&lt;count&gt;个请求报文后，等待一段时间，如果实在没有等到回复报文，就退出。&lt;/count&gt;&lt;/count&gt;&lt;/count&gt;&lt;/count&gt;&lt;/count&gt;&lt;/deadline&gt;&lt;/count&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;上面说的等待时间怎么确定呢？如果程序成功地收到了一个或者几个针对请求报文的回复，那么就将两倍的最大RTT作为等待的时间。如果程序没有接到任何的回复，RTT无从得知，就使用lingertime作为等待的最长时间。这个lingertime可以通过-W &amp;lt;timeout&amp;gt;选项由用户设置；如果用户没有设置则为一个常量（程序中，默认等待10秒）。不过值得主注意的是lingertime这个变量在程序成功地收到了回复之后，就没有任何作用了。

最长等待时间由一个闹钟实现。如上所述，设定这个闹钟的条件有下面几个：

1. 需要传送/接受的报文被设置了。

2. 程序运行的时间没有被设置。

3. 已经发送的报文数等于或大于需要传送/接受的报文数。

闹钟的时间被设置为：

1. 如果程序成功地收到了一个或者几个针对请求报文的回复，那么就将两倍的最大RTT作为等待的时间。

2. 否则，设置为lingertime。

当超出闹钟的时间之后，就会产生SIGALRM中断，使得程序退出。

相关函数：

void main_loop(int icmp_sock, __u8 *packet, int packlen);

staticinline int schedule_exit(int next);

schedule_exit(int next)

相关选项：

-c&amp;lt;count&amp;gt;

-w&amp;lt;deadline&amp;gt;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;3.1       引言
    在IP报文的首部和ICMP报文的首部都可以放入时间戳数据。clockdiff程序正是使用时间戳来测算目的主机和本地主机的系统时间差。&lt;/p&gt;

&lt;p&gt;3.2       clockdiff程序的使用
[plain] view plaincopy 
lixi@lixi-desktop:~$ ping -T tsandaddr www.ustc.edu.cn -c 1&lt;br /&gt;
PING www.ustc.edu.cn (202.38.64.9) 56(124) bytes of data.&lt;br /&gt;
64 bytes from 202.38.64.9: icmp_seq=1 ttl=62 time=0.823 ms&lt;br /&gt;
TS:     lixi-desktop.local (210.45.74.25)   12522473 absolute&lt;br /&gt;
    210.45.74.1 -251&lt;br /&gt;
    local-gw.ustc.edu.cn (202.38.64.126)    248&lt;br /&gt;
    202.38.64.9 -857514&lt;br /&gt;
Unrecorded hops: 3&lt;/p&gt;

&lt;p&gt;— www.ustc.edu.cn ping statistics —&lt;br /&gt;
1 packets transmitted, 1 received, 0% packet loss, time 0ms&lt;br /&gt;
rtt min/avg/max/mdev = 0.823/0.823/0.823/0.000 ms&lt;br /&gt;
    首先由上面的得出在RRT不大的时候，几个ICMP时间戳的关系。本地主机和202.38.64.9之间的时间差约为:-857514+248-251=-857517。&lt;/p&gt;

&lt;p&gt;分别用-o（IP选项中时间戳）和不带选项（ICMP路由时间戳）上述路由的系统时间进行测试。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;得到的结果：
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;[plain] view plaincopy 
lixi@lixi-desktop:~# ./clockdiff -o 202.38.64.9  &lt;br /&gt;
…………………………………………..&lt;br /&gt;
host=202.38.64.9 rtt=1(0)ms/1ms delta=-857517ms/-857517ms Wed Dec 17 11:28:30 2008&lt;/p&gt;

&lt;p&gt;[plain] view plaincopy 
lixi@lixi-desktop:~# ./clockdiff 202.38.64.9&lt;br /&gt;
.&lt;br /&gt;
host=202.38.64.9 rtt=750(187)ms/0ms delta=-857517ms/-857517ms Wed Dec 17 11:28:35 2008&lt;/p&gt;

&lt;p&gt;两种方法测试的都比较准确.&lt;/p&gt;

&lt;p&gt;[plain] view plaincopy 
lixi@lixi-desktop:~#./clockdiff gigagate1.Princeton.EDU&lt;br /&gt;
…………………………………………..&lt;br /&gt;
host=gigagate1.Princeton.EDU rtt=307(21)ms/271ms delta=-5ms/-5ms Wed Dec 17 11:50:16 2008&lt;br /&gt;
    上面是测试一个RTT较大的目的主机和本地主机的系统时间差。不过在使用clockdiff的时候，需要一点运气，因为很多路由会忽略ICMP或IP时间戳。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;对clockdiff选项的解释如下：

-o

    使用IP时间戳选项来测量系统时间差。时间戳只用3个。

-o1

    使用IP时间戳选项来测量系统时间差。用4个时间戳。如果-o和-o1都没有设置，那么就是用ICMP时间戳来测试系统时间差。
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;3.3       clockdiff程序的流程图&lt;/p&gt;

&lt;p&gt;3.4       clockdiff程序的主要函数的分析
    int main(int argc, char *argv[]);&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;    主函数。

    在这个函数里：取得用户输入的选项，并根据这些选项及其参数设置相应的标识和参数值。然后取得ICMP报文的套接字。如果设置-o或者-o1选项，设置IP报文的套接字时间戳选项，且调用measure_opt()函数来使用IP时间戳选项来测量本地主机和服务器主机的系统时间差。如果没有设置-o或者-o1选项，并调用measure()函数来使用ICMP时间戳报文来测量本地主机和服务器主机的系统时间差。测量完成后，打印出测试信息或者出错信息。

int measure_opt(struct sockaddr_in * addr);

    使用IP时间戳选项来测量本地主机和服务器主机的系统时间差。

    函数设置ICMP的报文，并发送出去。然后，程序接受ICMP报文，取得IP时间戳选项，并计算本地主机和服务器系统时间差。

int measure(struct sockaddr_in * addr);

    使用ICMP时间戳报文来测量本地主机和服务器主机的系统时间差。

    函数设置ICMP的报文，并发送出去。然后，程序接受ICMP报文，取得ICMP时间戳选项，并计算本地主机和服务器系统时间差。
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;6.5       clockdiff程序的全局变量的分析
    int interactive = 0;&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;    标识标准输入输出是不是和一个终端相连，如果是就输出比较详细的信息，否则只输出必要数据。

    例如clockdiff -o www.ustc.edu.cn &amp;gt;a.txt，就只会输出三个数据，因为标准输出被重定向到了文件的写入里，不与终端相连。

int id;

    当前进程的ID，放在ICMP时间戳请求和应答报文中的标识符中。

    在接受到ICMP回复报文时，用这个标识符来判断ICMP报文是不是本进程发出的ICMP报文的回复报文。

int sock;

    ？

int sock_raw;

    ICMP报文的套接字。

struct sockaddr_in server;

    服务器主机的地址。

    要对比本机和目的主机的系统时间，目的主机就相当于一个服务器。

int ip_opt_len = 0;

    ip_opt_len是ip选项中用来存储时间戳的长度

    可以通过-o和-o1选项来设置。

    如果选择-o选项，则ip_opt_len为4 + 4*8，也就是可以在IP选项中存储4个IP时间戳。时间戳的组织形式为：



    如果选择-o1选项，则ip_opt_len为4 + 3*8，也就是可以在IP选项中存储3个IP时间戳。时间戳的组织形式为：



#define BIASP        43199999

    程序通过计算时间戳中标明的时间来计算本地主机和服务器主机的系统时间差。在系统时间发生回绕的时候，会出现系统时间差的计算问题。这里BIASP就是为了解决这个问题。     

    在假设本地主机和服务器的系统时间差最多不超过12个小时（即43200000毫秒）的情况下：

    对于主机发送报文，如果本地主机在发送报文的时刻，本地主机系统时间已经超过0点。而该报文到达服务器主机的时刻，服务器主机系统时间仍然没有超过0点，则两个时间戳的差值（接受时间减去发送时间）会大于BIASP毫秒。

    同样，对于逆过程（主机接受服务器的报文），如果服务器主机在发送报文的时刻，服务器主机系统时间已经超过0点。而该报文到达本地主机的时刻，本地主机系统时间仍然没有超过0点，则两个时间戳的差值也会大于BIASP毫秒。

#define BIASN         -43200000

    与BIASP类似，BIASN也是为了解决系统时间回绕不一致的问题。

    在假设本地主机和服务器的系统时间差最多不超过12个小时（即43200000毫秒）的情况下：

    对于主机发送报文，如果本地主机在发送报文的时刻，本地主机系统时间没有超过0点。而该报文到达服务器主机的时刻，服务器主机系统时间已经超过0点，则两个时间戳的差值会小于BIASN毫秒。

    同样，对于逆过程（主机接受服务器的报文），如果服务器主机在发送报文的时刻，服务器主机系统时间没有超过0点。而该报文到达本地主机的时刻，本地主机系统时间已经超过0点，则两个时间戳的差值也会小于BIASN毫秒。

    为了解决系统时间回绕不一致的问题，当时间差不处在BIASN和BIASP之间的情况下，则将它们对应到这个去区间内。特别需要强调的是这里有基本假设：本地主机和服务器的系统时间差最多不超过12个小时（即43200000毫秒）。如果不满足这个假设，这种对应关系是错误的。

#define MODULO         86400000

    24个小时就是86400000毫秒，与在BIASN和BIASP一起处理系统时间回绕问题。

#define PROCESSING_TIME      0

    由于记录时间和报文发送的准确时间会有一定的偏差，所以这类处理过程消耗的时间可能会对最终计算出来的系统时间差会产生一个偏移量的影响。这里PROCESSING_TIME就是为了消除这个偏移量的影响的。这里忽略了这个偏移量。而且可以预见的是，想要分析和给出偏移量的影响大小并不容易，因为它与太多的变量有关系。

#define PACKET_IN       1024

    接受报文的存储字节数。

int measure_delta;

    计算的系统时间差。

    计算的系统时间差有两种假设，measure_delta1是另一种假设下的计算结果。

int measure_delta1;

    计算的系统时间差。

    计算的系统时间差有两种假设，measure_delta是另一种假设下的计算结果。

static u_short seqno;

    发送报文的序列号。

    每次发送报文都设置ICMP报文的序列号为seqno，seqno递加。

static u_short seqno0;

    发送报文的最小序列号。

    当接受到报文时要判断ICMP报文的序列号是不是介于seqno0和seqno之间，否则将不认为这个ICMP报文是本程序的恢复报文。

static u_short acked;

    接受到ICMP回复报文的最大序列号。

    当接受到报文时，如果ICMP报文的序列号大于现在的acked，则更新acked。

long rtt = 1000;

    对RTT的预测。

    预测方法是使用指数加权移动平均。

    和rtt_sigma一起用来设置超时时间，用的就是Jacobson/Karels算法。

long min_rtt;

    RTT的最小值。

long rtt_sigma = 0;

    对RTT预测的误差。

    和rtt一起用来设置超时时间，用的就是Jacobson/Karels算法。
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;3.6       clockdiff程序RTT预测的实现
    clockdiff程序使用Jacobson/Karels算法，使用以前的RTT实测值来预测下一次的RTT，并设定传输时间超时值。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;Jacobson/Karels算法在[[1]]文中有介绍。伪代码如下：

Difference = SampleRTT - EstimatedRTT

EstimatedRTT = EstimatedRTT + (δ × Difference)

Deviation = Deviation + δ × (|Difference| - Deviation)

TimeOut = μ × EstimatedRTT + φ × Deviation

其中：

SampleRTT是测量所得的新的RTT数据。

EstimatedRTT是预测的RTT值。

Deviation是预测的偏差值。

TimeOut是超时时间值。

δ为0到1之间的常数。

μ和φ均是一个常数。

在clockdiff程序的实现中：

δ设置为1/4。

μ和φ均设置为1。

相关函数：

int measure_opt(struct sockaddr_in * addr)void main_loop(inticmp_sock, __u8 *packet, int packlen);

int measure(struct sockaddr_in * addr);
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;6.7       clockdiff程序系统时间差测量的实现
    设两台主机的系统时间相差detaT，即源主机的系统时间为T的时刻，目的主机的系统时间为T+detaT。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;通过ICMP时间戳或者IP选项时间戳，可以获得如下信息：

delta1：接受时间戳减去发起时间戳。

delta2：接到回复报文时间减传送时间戳。

时间戳的插入过程如下图所示：

 


由上图可以知道：

delta1 = (T + dataT + RTT/2) – T = RTT/2+detaT

delta2 = (T + RTT) - (T + dataT + RTT/2) =RTT/2-detaT

故此(delta1 - delta2) / 2就是两个主机之间的系统时间差。

由于一次测量的delta1和delta2可能会由于网络拥塞情况的变化而发生较大偏差，故此在实际的实现中多次测量求较优值。引入了如下几个变量：

min1：多次传送中delta1的最小值。

min2：多次传送中delta2的最小值。

min_rtt：多次传送中delta1+delta2的最小值。

PROCESSING_TIME：处理过程中所消耗的时间。

在基于以下的几个基本假设情况下，可以测算系统时间的差值：

1. RTT中发送到目的主机的时间和返回源主机的时间基本相等都为RTT/2。

2. 当min1最小时，min1是对RTT/2+detaT的较优预测。同样，当min2最小时，min2是对RTT/2-detaT的较优预测。故此，(min1 - min2)/2是对deltaT的较优预测。这种预测方法的系统时间差预测值存储为变量measure_delta。

3. 当min_rtt最小时，(delta1 - delta2)/2也是对deltaT的较优预测。这种预测方法的系统时间差预测值存储为变量measure_delta1。

4. 各主机从接受到报文到记录接受到报文时间，这两个时刻的时间间隔为可以忽略；即发送和接受报文的处理过程中所消耗的时间可以忽略。实际上PROCESSING_TIME正是用来消除由处理过程的时间造成的对于计算出来的系统时间差别的影响。不过这里PROCESSING_TIME设置为0，认为处理消耗时间可以忽略。

以上的假设决定了clockdiff测算出来的系统时间差别的不准确性。

相关函数：

int measure_opt(struct sockaddr_in * addr)void main_loop(inticmp_sock, __u8 *packet, int packlen);

int measure(struct sockaddr_in * addr); .1       引言
tracepath和更为强大和更为广泛使用的程序traceroute一样，可以让我们看到IP数据报从一台主机传到另一台主机所经过的路由。

tracepath的作者是Alexey Kuznetsov。
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;4.2       tracepath程序的使用
lixi@lixi-desktop:~$ tracepath 210.45.74.25/8888
 1:  lixi-desktop.local (210.45.74.25)                      0.123ms pmtu 16436
 1:  lixi-desktop.local (210.45.74.25)                      0.054ms reached
 1:  lixi-desktop.local (210.45.74.25)                      0.045ms reached
     Resume: pmtu 16436 hops 1 back 64 
    210.45.74.25是本地主机的IP地址，8888是选择的测试端口。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;可以发现在本机进行了三次测试，为什么有三次测试，在下面的内容中有分析。
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;lixi@lixi-desktop:~$ tracepath 210.45.74.25/8888
 1:  lixi-desktop.local (210.45.74.25)                      0.122ms pmtu 16436
 1?: reply received 8)
 1:  lixi-desktop.local (210.45.74.25)                      0.048ms reached
     Resume: pmtu 16436 hops 1 back 64 
    编写简单的UDP服务程序，对8888端口的UDP请求进行服务（程序见&amp;lt;./test/udpserv.c&amp;gt;）。在运行这个服务程序之后，得到的测试结果如上。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;在第二轮时程序接受到了UDP的程序，所以输出了一个'?'表示疑问。
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;lixi@lixi-desktop:~$ tracepath 210.45.74.25/44444
 1:  lixi-desktop.local (210.45.74.25)                      0.131ms pmtu 16436
 1:  lixi-desktop.local (210.45.74.25)                      0.054ms reached
 1:  lixi-desktop.local (210.45.74.25)                      0.046ms reached
     Resume: pmtu 16436 hops 1 back 64 
     在运行对8888端口进行服务的UDP服务程序时，如果tracepath采用其他端口就不会产生上例中的情况了。&lt;/p&gt;

&lt;p&gt;lixi@lixi-desktop:~$ tracepath www.ustc.edu.cn
 1:  lixi-desktop.local (210.45.74.25)                      0.198ms pmtu 1500
 1:  210.45.74.1 (210.45.74.1)                              0.777ms 
 1:  210.45.74.1 (210.45.74.1)                              0.775ms 
 2:  202.38.96.33 (202.38.96.33)                            1.068ms 
 3:  202.38.64.9 (202.38.64.9)                              1.012ms reached
     Resume: pmtu 1500 hops 3 back 253
    对比此例和上例，可以发现PMTU发生了变化，由16436变成了1500。&lt;/p&gt;

&lt;p&gt;lixi@lixi-desktop:~$ tracepath www.ustc.edu.cn -l 1500
 1:  210.45.74.1 (210.45.74.1)                              0.828ms 
 2:  202.38.96.33 (202.38.96.33)                            0.988ms 
 3:  202.38.64.9 (202.38.64.9)                              1.140ms reached
     Resume: pmtu 1500 hops 3 back 253
    我们将MTU手动设置为1500，程序就不会默认将MTU设置为一个很大的数，然后找出PMTU了。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;tracepath程序的选项解释如下：

-n

    与ping命令的-n选项差不多。

    只有数字形式的输出，不查找DNS主机以节省时间，不查寻主机名，仅仅给出ip地址值。

    只要设置了F_NUMERIC，就不用调用gethostbyaddr来查询DNS主机名了。

    用gethostbyaddr的由查询目的主机的IP地址。

-l

    设置初始的包的大小。如果不设置则，则报文的大小为65535
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;4.3       tracepath程序的流程图
    tracepath程序的流程图如下：&lt;/p&gt;

&lt;p&gt;深入理解iputils网络工具第4篇 tracepath：路由追踪程序&lt;/p&gt;

&lt;p&gt;4.4       tracepath重要函数的分析
    int main(int argc, char argv);&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;    接受用户的选项，设置发送MTU或者设置是否不要验证主机名等标识。取得一个UDP类型的套接字，并设置好这个套接字的选项。，从1开始递增，直至31，设置套接字的IP_TTL选项为不同的值，调用probe_ttl()函数，直到probe_ttl()函数告知找到目的主机或者出现严重的错误为止。

int probe_ttl(int fd, int ttl);

    循环执行十次如下操作，直到正确发送报文跳出循环，或者recverr()返回0：

    调用sendto()函数尝试发送UDP报文到目的地址，如果发送出现错误则调用recverr()函数处理接受到的ICMP差错报文。如果正确发送报文，则跳出循环。

    如果循环过程中：recverr()函数返回0，则本函数返回0；如果recverr()函数返回大于0的数，则重新进行如上循环。

    如果循环超过十次，则表明因为某种原因，无法发送UDP报文，程序返回0。

    如果正确发送了UDP报文，则尝试使用recv()函数接受UDP报文的。正常情况下不会有UDP的，如果果真接受到了，则打印‘?’号表示吃惊，返回0。如果正如所预见到的，没有接到，则调用recverr()函数处理可能接受到的ICMP差错报文，返回recverr()返回的数值。

    总结本函数的返回值意义如下：

    返回0表示找到主机或者有严重的错误。

    返回负数-1，表示没有接受到ICMP差错报文。

    返回正数是当前MTU，表示接受并处理了一些错误，但是还没有找到目的主机。

int recverr(int fd, int ttl);

    函数将progress初始化为-1，然后不断循环执行如下操作，直到循环中函数返回：调用recvmsg()函数接受错误报文，并处理错误，如果没有错误返回progress。在错误队列中查找对应错误（SOL_IP级别IP_RECVERR类型），progress设置为MTU的值，并处理错误。如果错误队列的错误不是对应错误，返回0。

    并处理错误的几种情况如下：

    如果是MTU太大（EMSGSIZE），则修改MTU的变量值，继续循环。

    如果是UDP端口不可达错误（ECONNREFUSED），则UDP报文已经在规定TTL内传送到了目的主机。这种情况返回0。

    如果是EHOSTUNREACH错误且出错原因是接受到了ICMP差错报文，这个ICMP差错报文如果类型为11，代码为0，则表示因为在传输期间TTL等于0所以出错（参看ICMP报文类型）。这就说明UDP还没有到达目的主机TTL就变成了0，需要进一步递加TTL进行试探。

    如果是其他的错误，对于不严重的错误继续循环，否则返回0。

    总结本函数的返回值意义如下：

    返回0表示找到主机或者有严重的错误。

    返回的数如果大于0，其值是当前的MTU，表示接受并处理了一个或几个错误。

    返回负数-1，表示没有发现任何错误，也就是没有进展（progress）。
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;4.5       tracepath全局变量的分析
    struct hhistory his[64];&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;    用来存放历史上发出的UDP报文的ttl设置值和发送时间。

    当发送UDP报文时，将报文的端口号设置为base_port + hisptr，在his[hisptr]元素中，存储该UDP报文的ttl设置值和发送时间。

    当接受到一个UDP的报文（“端口不可达”错误ICMP报文）时，通过ICMP报文的端口号，就可以知道该UDP报文对应的ttl设置值和发送时间存储在his数组的哪个元素里了。

    his数组大小有限，只有64个元素。不过已经能够保证即使hisptr回绕也不会出错了。

int hisptr;

    用来指向his数组的元素。

    当发送UDP报文时，hisptr递加，将发出的UDP报文的ttl设置值和发送时间存储在his[hisptr]元素中。

    由于his数组大小为64，故此hisptr每次加到63，下一次就会回绕到0。

struct sockaddr_in target;

    要查询的目的主机的地址。

    包括地址种类（IPv4）、IP地址、端口号等信息。

    端口号会被设置为基础端口号加上hisptr。

__u16 base_port;

    基础端口号

    可以在设定目的主机时连带设定，否则程序默认是44444端口。

    基础端口号加上hisptr就是UDP报文的发送端口号。

    设置这么大的端口号，是为了使得目的主机的任何一个应用程序都不可能使用该端口，而产生一个“端口不可达”错误。

    这个值很大，目的就是让UDP出现“端口不可达”错误。

const int overhead = 28;

    在UDP数据部分之前的头部大小。

    IP首部为20，UDP首部为8，故此总共为28字节。

    这个数是个常量。

int mtu = 65535;

    可以通过-l选项设置，如果设置的值不大于传输路径的MTU。

    如果不设置默认值是65535，这个默认值肯定会超过传输路径的MTU，当超过了路径的MTU时，程序会受到错误消息，并根据这个错误消息所带的MTU值，更新MTU值。这样就tracepath能找出路径的MTU了。

int hops_to = -1;

    从本地主机到目的主机的跳数。

    如果目的主机不可达，则hops_to一直维持-1，最后就不会输出hops_to。

    当程序接受到目的主机发出的“拒绝服务”ICMP错误报文时，就说明探测到了目的主机。hops_to取为此时的recverr()函数局部变量sndhops的值。

    sndhops有两种方式取得，一种是取得发送时存储在his数组中的ttl值（前面已经谈到如何通过错误报文的IP端口得到存储地址），另一种是取得当前探测阶段发送的UDP报文的ttl的值。

    如果不出意外，第一种方式能比较可靠地取得；但是由于某种原因，前一种方式出问题后，就用后一种方式作为代替。

int hops_from = -1;

    从目的主机到本地主机的剩余TTL值。

    如果目的主机不可达，则hops_from一直维持-1，最后就不会输出。

    hops_from从目的主机发送给本地主机的IP报文头取得TTL字段值即可。

int no_resolve = 0;

    标识是否不要验证主机名。

    可以通过-n选项设置为1。

    如果设置为0，就调用gethostbyaddr的由查询目的主机的IP地址，否则就不用，以节省时间。 5.1       引言
ARP协议是“Address Resolution Protocol”（地址解析协议）的缩写。在同一以太网中，通过地址解析协议，源主机可以通过目的主机的IP地址获得目的主机的MAC地址。arping程序就是完成上述过程的程序。

ARP协议可以参看RFC 826。
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;5.2       arping程序的使用
    敲入命令：&lt;/p&gt;

&lt;p&gt;[plain] view plain copy
lixi@lixi-desktop:~/temp/iputils/iputils-s20071127$ arping 210.45.74.29 -c 1 -D&lt;br /&gt;
ARPING 210.45.74.29 from 0.0.0.0 eth0&lt;br /&gt;
Unicast reply from 210.45.74.29 [00:40:D0:59:CD:D3]  0.684ms&lt;br /&gt;
Sent 1 probes (1 broadcast(s))&lt;br /&gt;
Received 1 response(s)&lt;br /&gt;
    在本地主机的局域网内有一台IP地址为210.45.74.29的主机，所以会接到一个回复。&lt;/p&gt;

&lt;p&gt;[plain] view plain copy
lixi@lixi-desktop:~$ arping 210.45.74.28 -c 1 -D&lt;br /&gt;
ARPING 210.45.74.28 from 0.0.0.0 eth0&lt;br /&gt;
Sent 1 probes (1 broadcast(s))&lt;br /&gt;
Received 0 response(s)&lt;br /&gt;
    向一个不存在的IP发送报文不会接受到回复。&lt;/p&gt;

&lt;p&gt;[plain] view plain copy
root@lixi-desktop:~# arping 210.45.74.25 –U&lt;br /&gt;
root@lixi-desktop:~# tcpdump arp -n | grep 210.45.74.25&lt;br /&gt;
    得到输出结果如下：&lt;/p&gt;

&lt;p&gt;[plain] view plain copy
11:03:13.848653 arp who-has 210.45.74.25 (ff:ff:ff:ff:ff:ff) tell 210.45.74.25&lt;br /&gt;
    这里就是一个免费ARP的例子。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;-A

    与-U选项类似，但是发送的是ARP 回复报文，而不是ARP请求报文。

-b

    只发送MAC级别的广播。一般的arping开始时发送广播，在接受到回复后开始发送单播。

-c &amp;lt;count&amp;gt;

    在发送count个ARP请求后就退出。在和deadline选项一起使用时，arping程序一直等到收到count个ARP回复报文或者时间消耗完毕时才退出。
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;-D&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;    重复地址检测模式（DAD，Duplicate  address detection  mode）。参见RFC2131，4.4.1。如果DAD成功，则返回0，即不会接受到没有任何回复。

-f

    在接受到第一个确定目标主机存在的回复之后，就结束程序，否则一直发送ARP请求。

-I &amp;lt;interface&amp;gt;

    设置网络设备的名字，这个名字就是发送ARP请求报文的设备名字。

-h   

    打印帮助信息，然后退出。

-q

    静默输出，不打印探测结果。

-s &amp;lt;source&amp;gt;

    在ARP报文中使用的IP源地址。如果这个选项没有设置，则源地址设置方法为：

    1. DAD模式下（-D选项），设置为0.0.0.0。

    2. 在主动ARP模式（-U或者-A选项），设置为目的地址。

    3. 其他情况下，通过路由表得到。

-U

    为了更新以太网邻居的ARP快速缓存而主动进行的ARP。也就是免费ARP（gratuitous ARP）。

-V

    打印出版本信息，然后退出。

-w deadline

    设定时间期限为&amp;lt;deadline&amp;gt;秒，不管已经发送和接到了多少包，只要达到时间期限就结束ping的过程。在这种情况下，这样arping程序只有在接受到cout个回复或者deadline的时间消耗完后才退出；而不是像只有-c选项的情况，在发送count个ARP请求的就退出。
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;5.3       arping程序的流程图
    arping程序的流程图如下所示：&lt;/p&gt;

&lt;p&gt;5.4       ARP报文的分组格式
    ARP报文的分组格式如下图所示：&lt;/p&gt;

&lt;p&gt;5.5       arping程序的全局变量的分析
    int quit_on_reply=0;&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;    标识是否在接受到一个回复之后，就马上退出程序。

    可以在-f选项和-D选项中设定为非0值（同时有-f、-D选项或者有多个同种选项）。     

char *device=&quot;eth0&quot;;

    源主机的网络设备号。 

    可以通过-I参数设置。

    默认为eth0。

(setsockopt(probe_fd, SOL_SOCKET,SO_BINDTODEVICE, device, strlen(device)+1)。

    不过好像只有超级用户这个才能执行。

int ifindex;

    Interface number。

char *source;

    存储-s设置的源地址。

    地址的形式可以是IPv4的标准数字和点组成的形式，如210.45.74.25；也可以是主机名字的形式，如www.ustc.edu.cn。

struct in_addr src；

    存储源IP地址，即对ARP的回复报文所要发往的主机的IP地址，有可能是广播地址。

    可以通过-s选项设置。如果这个选项没有设置，则源地址设置方法为：

    1. DAD模式下（-D选项），设置为0.0.0.0。

    2. 在主动ARP模式（-U或者-A选项），设置为目的地址。

    3. 其他情况下，通过路由表得到。

struct in_addr dst;

    存储目的IP地址，即ARP报文所要发往的主机的IP地址。

char *target;

    存储用户设置的目的地址，地址的形式必须是IPv4的标准数字和点组成的形式。

int dad;

    标识是不是DAD模式。

    如果是DAD模式，则原源主机地址一直没有设置，那么就意味着源地址为0.0.0.0。这样当目的主机接到之后，就会向0.0.0.0发送回复，就相当于广播给以太网中所有的主机。因为进行D重复地址检测模式的原因很可能是由于源主机的IP地址没有设置，从而想设置自身的IP地址。在IP地址没有设置的时候，主机只能接受到地址为0.0.0.0的广播信号。

    可以通过-D参数设置。

int unsolicited;

    标识是不是发送免费ARP。

    在-A选项和-U选项中设置unsolicited为1。

int advert;

    标识在免费ARP模式下发送的是ARP回复报文，而不是ARP请求报文。

    在-A选项中设置advert为1。

int quiet;

    标识是否静默输出。

    可以通过-q选项设置。

int count=-1;

    发送ARP的个数。

    可以通过-c选项设置，如果不设置，默认值为-1，即没有个数限制（回绕成0基本不可能）。

int timeout;

    程序运行的时间限制。

    通过-w选项设置。

int unicasting;

    标识是不是应该发送单播报文。

    在程序接受到一个ARP的回复之后，已经能够知道回复者的IP地址了，这时候就可以不广播，而设置传播地址。因此，在接受到ARP回复之后，如果broadcast_only没有被设置，unicasting就应该设置为1，以让下次进行单播。

int s;

    ARP报文的套接字。

int broadcast_only;

    标识是不是一直发送广播报文，而不在接受到一个回复以后就改成单播报文。

    通过-b选项可以设置broadcast_only为1。 

struct sockaddr_ll me;

    存储本地主机的信息，包括本地主机的以太网地址、硬件地址的类型、硬件地址长度和协议地址长度等信息

struct sockaddr_ll he;

    存储本地主机的信息。

struct timeval start;

    程序发送第一个报文的系统时间。

    记录这个时间，可以用来判断程序是否超出时间限制。如果当前的系统时间减去start超过用户设置的时间限制有500毫秒，则程序退出。

struct timeval last;

    程序发送上一个报文的系统时间。

    记录这个时间，可以用来判断是否应当发出下一个ARP请求。如果当前系统时间减去last超过500毫秒，则发出下一个ARP请求。

int sent;

    程序发送的ARP报文数量。

    每次在发送ARP报文之后递加。

int brd_sent;

    程序广播的ARP报文数量。

    每次在发送ARP报文之后，如果ARP报文是广播报文，则递加。

int received;

    程序接受的ARP报文数量。

    每次在接受到正确的ARP报文之后，递加。

int brd_recv;

    程序接受的ARP广播报文数量。

    每次在接受到正确的ARP报文之后，如果报文不是单播报文则递加。

int req_recv;

    程序接受到ARP请求报文数量。

    每次在接受到正确的ARP报文之后，如果报文是ARP请求报文则递加。 7.1       引言
TFTP ( Trivial File Transfer Protocol)即简单文件传送协议，是TCP/IP协议族中的一个用来在客户机与服务器之间进行简单文件传输的协议，提供简单的、低开销的文件传输服务。tftpd程序就是进行tftp服务的服务程序。
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;TFTP协议可以参看RFC 1350。&lt;/p&gt;

&lt;p&gt;7.2       tftpd程序的使用
    由于这个程序需要inetd程序的配合，而环境比较难搭建，所以对程序的测试比较困难。&lt;/p&gt;

&lt;p&gt;7.3       tftpd程序的流程图&lt;/p&gt;

&lt;p&gt;7.4       TFTP报文格式
    TFTP报文格式如下所示：&lt;/p&gt;

&lt;p&gt;7.5       tftpd.c程序的全局变量的分析
    int   peer;&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;    服务连接的套接字。

int   rexmtval =TIMEOUT;

    程序采用停止和等待的自动请求重发（ARQ）算法，当接受ACK报文或者数据报文的时间超过rexmtval，则认为接受超时，重新开始接受报文过程。

    rexmtval一直维持TIMEOUT的值，没有被改变过。

int   maxtimeout =5*TIMEOUT;

    当接受数据报文或者ACK报文的时候，如果出现超时，则会进入中断处理程序。如果中断次数过多，则timeout会累加rexmtval时间。一旦超时中断过多，导致timeout超过maxtimeout，则程序退出，停止服务。

    maxtimeout一直维持5*TIMEOUT的值，没有被改变过。

#define  PKTSIZE     SEGSIZE+4

    如果TFTP报文的操作码是data，表明传输的是0到512字节的数据。

    SEGSIZE是TFTP报文的数据的最大长度，即512字节。

    由于TFTP报文还包括2字节的操作码和2字节的块编号，所以TFTP数据报文的长度为SEGSIZE+4。

char       buf[PKTSIZE];

    缓冲空间，在以下的情况下，作为存储TFTP报文的内存空间：

    1. 清楚初始时接收的报文。

    2. 发送操作码为error类型的TFTP报文。

    3. 在文件传输完毕时（上一次接受到的数据不足512字节），尝试接受操作码为data数据类型的TFTP报文，因为服务器传给用户主机的最后一个ACK有可能丢失。

char       ackbuf[PKTSIZE];

    缓冲空间，在以下的情况下，作为存储TFTP报文的内存空间：

    1. 接受操作码为ACK类型的TFTP报文。

    2. 发送操作码为ACK类型的TFTP报文。

union {

    struct     sockaddr    sa;

    struct     sockaddr_in sin;

    struct     sockaddr_in6 sin6;

} from;

    描述客户连接的地址。

socklen_t      fromlen;

    from所占的内存空间大小。

#define MAXARG    1

    在启动tftpd程序的时候，需要指定ftp文件夹的路径。MAXARG是所能指定文件夹的个数。

char       *dirs[MAXARG+1];

    dirs[0]里保存了ftp文件夹的路径。

int   confirmed;

    表明sendmsg函数的选项的MSG_CONFIRM选项是否设置。

    如果设置MSG_CONFIRM，则会告诉链路层的传送有了进展：已经接受到对方的一个成功的答复。由于MSG_CONFIRM的这个意义，所以在发送第一个数据是MSG_CONFIRM选项不因该设置，即confirm初始值为0。在成功接受到一个回复之后，confirm则应该设置为MSG_CONFIRM了。

int   timeout;

    表示由于等待接受超时的时间总和。

    当接受数据报文或者ACK报文的时候，如果出现超时，则会进入中断处理程序，将timeout递加rexmtval秒，如果。一旦超时中断过多，导致timeout超过maxtimeout，则程序退出，停止服务。

jmp_buf timeoutbuf;

    在发生等待接收超时时，应当将要发送的报文重新发送（报文可能为ACK报文或者data报文）。setjmp()和longjmp()函数就可以用来实现这种跳转的功能。

    由于等待超时时会进入计时器中断处理程序，在中断处理程序中调用longjmp()函数来跳转到最后一次用setjmp()设置timeoutbuf的地方运行，也就是重新进行报文的发送。

    timeoutbuf就记录了调用setjmp()的时候的程序上下文。
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;7.6       tftpsub.c程序的全局变量的分析
    struct bf {&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;    int counter;

    charbuf[PKTSIZE];

} bfs[2];

    缓冲空间，在以下的情况下，作为存储TFTP报文的内存空间：

    1. 接受操作码为data类型的TFTP报文。

    2. 发送操作码为data类型的TFTP报文。

    counter用来标识存储的缓冲空间的数据是一下三种的哪一种：

    1. BF_ALLOC，标识是已经申请的存储空间。

    2. BF_FREE，标识存储空间没有使用。

    3. 大于0的数，标识里面已经存储数据。

static int nextone;

    待使用的下一个缓冲的标号。

static int current;

    正在使用的当前缓冲的标号。

int newline = 0;

    在数据传输是按照8位的ASCII码形式（netascii）组织的情况下，标识是不是有新的行出现。

    在顺次读取或者写入字节流时，如果遇到'\n'或者'\r'字符都会设置newline为1，方便进行特殊处理。

int prevchar = -1;     /* putbuf: previous char (cr check) */

    在数据传输是按照8位的ASCII码形式（netascii）组织的情况下，记录上个处理的字符。

    和newline一样，prevchar是为了处理'\r'或者'\n'的特殊字符。

    处理的效果是：

    1. 如果要发送'\r'字符则传送的实际是\r\0&quot;；如果要发送'\n'字符则传送的实际是&quot;\r\n&quot;。

    2. 如果接受到&quot;\r\n&quot;，则保存的实际是字符'\n'；如果接受到&quot;\r\0&quot;，则保存的实际是字符'\r'。
&lt;/code&gt;&lt;/pre&gt;
</description>
        <pubDate>Mon, 05 Feb 2018 00:00:00 +0800</pubDate>
        <link>https://xiazemin.github.io/MyBlog/linux/2018/02/05/iputils.html</link>
        <guid isPermaLink="true">https://xiazemin.github.io/MyBlog/linux/2018/02/05/iputils.html</guid>
        
        
        <category>linux</category>
        
      </item>
    
      <item>
        <title>cscope</title>
        <description>&lt;!-- more --&gt;
&lt;p&gt;命令的帮助入口：&lt;/p&gt;

&lt;p&gt;:help cscope 
在前面的文章中介绍了利用tag文件，跳转到标签定义的地方。但如果想查找函数在哪里被调用，或者标签在哪些地方出现过，ctags就无能为力了，这时需要使用更为强大的cscope。&lt;/p&gt;

&lt;p&gt;Cscope具有纯正的Unix血统，它最早是由贝尔实验室为PDP-11计算机开发的，后来成为商用的AT&amp;amp;T Unix发行版的组成部分。直到2000年4月，这个工具才由SCO公司以BSD license开源发行。&lt;/p&gt;

&lt;p&gt;Cscope的主页在http://cscope.sourceforge.net/，如果你的计算机上没有cscope，你可以在此处下载它，在写本文时，它的最新版本是15.6。安装它非常简单，你只需要在cscope的源代码目录中执行下面三条命令：&lt;/p&gt;

&lt;p&gt;./configure
make
make install 
在windows上也可以使用cscope，在cscope的主页上可以下载到由DJGPP编译器编译的cscope for windows，不过这个版本不能和vi一起工作。或者你可以下载cygwin工具包(http://www.cygwin.com/)，这个工具包中也包含了cscope。&lt;/p&gt;

&lt;p&gt;在http://iamphet.nm.ru/cscope/有Sergey Khorev预编译的一个Win32版本的cscope，这个版本的cscope可以很好的与windows版本的vim搭配使用。&lt;/p&gt;

&lt;p&gt;cscope的用法很简单，首先需要为你的代码生成一个cscope数据库。在你的项目根目录运行下面的命令：&lt;/p&gt;

&lt;p&gt;cscope -Rbq 
这些选项的含义见后面。这个命令会生成三个文件：cscope.out, cscope.in.out, cscope.po.out。其中cscope.out是基本的符号索引，后两个文件是使用”-q”选项生成的，可以加快cscope的索引速度。在windows上使用cscope时，你可能会遇到-q选项被忽略的提示，解决办法请看这篇文章：Windows下cscope -q选项出错的解决。&lt;/p&gt;

&lt;p&gt;在缺省情况下，cscope在生成数据库后就会进入它自己的查询界面，我们一般不用这个界面，所以使用了”-b”选项。如果你已经进入了这个界面，按CTRL-D退出。&lt;/p&gt;

&lt;p&gt;Cscope在生成数据库中，在你的项目目录中未找到的头文件，会自动到/usr/include目录中查找。如果你想阻止它这样做，使用”-k”选项。&lt;/p&gt;

&lt;p&gt;Cscope缺省只解析C文件(.c和.h)、lex文件(.l)和yacc文件(.y)，虽然它也可以支持C++以及Java，但它在扫描目录时会跳过C++及Java后缀的文件。如果你希望cscope解析C++或Java文件，需要把这些文件的名字和路径保存在一个名为cscope.files的文件。当cscope发现在当前目录中存在cscope.files时，就会为cscope.files中列出的所有文件生成索引数据库。通常我们使用find来生成cscope.files文件，仍以vim 7.0的源代码为例：&lt;/p&gt;

&lt;p&gt;cd ~/src/vim70 
find . –type f &amp;gt; cscope.files
cscope -bq 
这条命令把~src/vim70目录下的所有普通文件都加入了cscope.files，这样，cscope会解析该目录下的每一个文件。上面的cscope命令并没有使用”-R”参数递归查找子目录，因为在cscope.files中已经包含了子目录中的文件。&lt;/p&gt;

&lt;p&gt;注意：find命令输出的文件以相对路径表示，所以cscope.out的索引也相对于当前路径。如果你要在其它路径中使用当前的cscope.out，需要使用下面介绍的-P选项。&lt;/p&gt;

&lt;p&gt;Cscope只在第一次解析时扫描全部文件，以后再调用cscope，它只扫描那些改动过的文件，这大大提高了cscope生成索引的速度。&lt;/p&gt;

&lt;p&gt;下表中列出了cscope的常用选项：&lt;/p&gt;

&lt;p&gt;-R: 在生成索引文件时，搜索子目录树中的代码
-b: 只生成索引文件，不进入cscope的界面
-q: 生成cscope.in.out和cscope.po.out文件，加快cscope的索引速度
-k: 在生成索引文件时，不搜索/usr/include目录
-i: 如果保存文件列表的文件名不是cscope.files时，需要加此选项告诉cscope到哪儿去找源文件列表。可以使用”-“，表示由标准输入获得文件列表。
-Idir: 在-I选项指出的目录中查找头文件
-u: 扫描所有文件，重新生成交叉索引文件
-C: 在搜索时忽略大小写
-Ppath: 在以相对路径表示的文件前加上的path，这样，你不用切换到你数据库文件所在的目录也可以使用它了。
要在vim中使用cscope的功能，需要在编译vim时选择”+cscope”。vim的cscope接口先会调用cscope的命令行接口，然后分析其输出结果找到匹配处显示给用户。&lt;/p&gt;

&lt;p&gt;在vim中使用cscope非常简单，首先调用”cscope add”命令添加一个cscope数据库，然后就可以调用”cscope find”命令进行查找了。vim支持8种cscope的查询功能，如下：&lt;/p&gt;

&lt;p&gt;s: 查找C语言符号，即查找函数名、宏、枚举值等出现的地方
g: 查找函数、宏、枚举等定义的位置，类似ctags所提供的功能
d: 查找本函数调用的函数
c: 查找调用本函数的函数
t: 查找指定的字符串
e: 查找egrep模式，相当于egrep功能，但查找速度快多了
f: 查找并打开文件，类似vim的find功能
i: 查找包含本文件的文件
例如，我们想在vim 7.0的源代码中查找调用do_cscope()函数的函数，我们可以输入：”:cs find c do_cscope”，回车后发现没有找到匹配的功能，可能并没有函数调用do_cscope()。我们再输入”:cs find s do_cscope”，查找这个C符号出现的位置，现在vim列出了这个符号出现的所有位置。&lt;/p&gt;

&lt;p&gt;我们还可以进行字符串查找，它会双引号或单引号括起来的内容中查找。还可以输入一个正则表达式，这类似于egrep程序的功能，但它是在交叉索引数据库中查找，速度要快得多。&lt;/p&gt;

&lt;p&gt;vim提供了一些选项可以调整它的cscope功能：&lt;/p&gt;

&lt;p&gt;cscopecscopeprg选项用于设置cscope程序的位置。
cscopecscopequickfix设定是否使用quickfix窗口来显示cscope的结果，详情请”:help cscopequickfix”；
如果你想vim同时搜索tag文件以及cscope数据库，设置cscopecscopetag选项；
cscopecscopetagorder选项决定是先查找tag文件还是先查找cscope数据库。设置为0则先查找cscope数据库，设置为1先查找tag文件。我通常设置为1，因为在tag文件中查找到的结果，会把最佳匹配列在第一位。
vim的手册中给出了使用cscope的建议方法，使用命令”:help cscope-suggestions”查看。&lt;/p&gt;

&lt;p&gt;下面是我的vimrc中关于cscope接口的设置：&lt;/p&gt;

&lt;p&gt;”””””””””””””””””””””””””””””””””””””””””””””””””””””””””””””””
“ cscope setting
“””””””””””””””””””””””””””””””””””””””””””””””””””””””””””””””
if has(“cscope”)
  set csprg=/usr/bin/cscope
  set csto=1
  set cst
  set nocsverb
  “ add any database in current directory
  if filereadable(“cscope.out”)
      cs add cscope.out
  endif
  set csverb
endif&lt;/p&gt;

&lt;p&gt;nmap &amp;lt;C-@&amp;gt;s :cs find s &lt;C-R&gt;=expand(&quot;&lt;cword&gt;&quot;)&lt;CR&gt;&lt;CR&gt;
nmap &amp;lt;C-@&amp;gt;g :cs find g &lt;C-R&gt;=expand(&quot;&lt;cword&gt;&quot;)&lt;CR&gt;&lt;CR&gt;
nmap &amp;lt;C-@&amp;gt;c :cs find c &lt;C-R&gt;=expand(&quot;&lt;cword&gt;&quot;)&lt;CR&gt;&lt;CR&gt;
nmap &amp;lt;C-@&amp;gt;t :cs find t &lt;C-R&gt;=expand(&quot;&lt;cword&gt;&quot;)&lt;CR&gt;&lt;CR&gt;
nmap &amp;lt;C-@&amp;gt;e :cs find e &lt;C-R&gt;=expand(&quot;&lt;cword&gt;&quot;)&lt;CR&gt;&lt;CR&gt;
nmap &amp;lt;C-@&amp;gt;f :cs find f &lt;C-R&gt;=expand(&quot;&lt;cfile&gt;&quot;)&lt;CR&gt;&lt;CR&gt;
nmap &amp;lt;C-@&amp;gt;i :cs find i ^&lt;C-R&gt;=expand(&quot;&lt;cfile&gt;&quot;)&lt;CR&gt;$&lt;CR&gt;
nmap &amp;lt;C-@&amp;gt;d :cs find d &lt;C-R&gt;=expand(&quot;&lt;cword&gt;&quot;)&lt;CR&gt;&lt;CR&gt;&lt;/CR&gt;&lt;/CR&gt;&lt;/cword&gt;&lt;/C-R&gt;&lt;/CR&gt;&lt;/CR&gt;&lt;/cfile&gt;&lt;/C-R&gt;&lt;/CR&gt;&lt;/CR&gt;&lt;/cfile&gt;&lt;/C-R&gt;&lt;/CR&gt;&lt;/CR&gt;&lt;/cword&gt;&lt;/C-R&gt;&lt;/CR&gt;&lt;/CR&gt;&lt;/cword&gt;&lt;/C-R&gt;&lt;/CR&gt;&lt;/CR&gt;&lt;/cword&gt;&lt;/C-R&gt;&lt;/CR&gt;&lt;/CR&gt;&lt;/cword&gt;&lt;/C-R&gt;&lt;/CR&gt;&lt;/CR&gt;&lt;/cword&gt;&lt;/C-R&gt;&lt;/p&gt;

&lt;p&gt;下面的两个链接是cscope主页提供的cscope使用方法，也可以作为参考：&lt;/p&gt;

&lt;p&gt;vim/cscope指导：http://cscope.sourceforge.net/cscope_vim_tutorial.html&lt;/p&gt;

&lt;p&gt;在大项目中使用cscope：http://cscope.sourceforge.net/large_projects.html&lt;/p&gt;

&lt;p&gt;在vim的网站上有很多与cscope相关的插件，有兴趣可以去看一下。&lt;/p&gt;

&lt;p&gt;首先在目录下建立cscope索引文件
find -name ‘*.c’ &amp;gt; cscope.file
cscope -Rbkq
这个命令会生成三个文件：cscope.out, cscope.in.out, cscope.po.out。
其中cscope.out是基本的符号索引，后两个文件是使用”-q”选项生成的，可以加快cscope的索引速度。
上面所用到的命令参数，含义如下：&lt;/p&gt;

&lt;p&gt;-R: 在生成索引文件时，搜索子目录树中的代码&lt;/p&gt;

&lt;p&gt;-b: 只生成索引文件，不进入cscope的界面&lt;/p&gt;

&lt;p&gt;-k: 在生成索引文件时，不搜索/usr/include目录&lt;/p&gt;

&lt;p&gt;-q: 生成cscope.in.out和cscope.po.out文件，加快cscope的索引速度
接下来，就可以在vim里读代码了。
不
过在使用过程中，发现无法找到C++的类、函数定义、调用关系。仔细阅读了cscope的手册后发现，原来cscope在产生索引文件时，只搜索类型为
C, lex和yacc的文件(后缀名为.c, .h, .l,
.y)，C++的文件根本没有生成索引。不过按照手册上的说明，cscope支持c++和Java语言的文件。于是按照cscope手册上提供的方法，先产生一个文件列表，然后让cscope为这个列表中的每个文件都生成索引。为了方便使用，编写了下面的脚本来更新cscope和ctags的索引文件：&lt;/p&gt;

&lt;p&gt;#!/bin/sh&lt;/p&gt;

&lt;p&gt;find . -name “&lt;em&gt;.h” -o -name “&lt;/em&gt;.c” -o -name “*.cc” &amp;gt; cscope.files&lt;/p&gt;

&lt;p&gt;cscope -bkq -i cscope.files&lt;/p&gt;

&lt;p&gt;ctags -R
这个脚本，首先使用find命令，查找当前目录及子目录中所有后缀名为”.h”, “.c”和”.cc”的文件，并把查找结果重定向到文件cscope.files中。
然后cscope根据cscope.files中的所有文件，生成符号索引文件。
最后一条命令使用ctags命令，生成一个tags文件，在vim中执行”:help tags”命令查询它的用法。它可以和cscope一起使用。
-R: 在生成索引文件时，搜索子目录树中的代码
-b: 只生成索引文件，不进入cscope的界面
-q: 生成cscope.in.out和cscope.po.out文件，加快cscope的索引速度
-k: 在生成索引文件时，不搜索/usr/include目录
-i: 如果保存文件列表的文件名不是cscope.files时，需要加此选项告诉cscope到哪儿去找源文件列表。可以使用“-”，表示由标准输入获得文件列表。
-I dir: 在-I选项指出的目录中查找头文件
-u: 扫描所有文件，重新生成交叉索引文件
-C: 在搜索时忽略大小写
-P path: 在以相对路径表示的文件前加上的path，这样，你不用切换到你数据库文件所在的目录也可以使用它了。
3在vim里读代码
在VIM中使用cscope非常简单，首先调用“cscope add”命令添加一个cscope数据库，然后就可以调用“cscope find”命令进行查找了。VIM支持8种cscope的查询功能，如下：例如，我们想在代码中查找调用work()函数的函数，我们可以输入：“:cs find c work”，回车后发现没有找到匹配的功能，可能并没有函数调用work()。我们再输入“:cs find s work”，查找这个符号出现的位置，现在vim列出了这个符号出现的所有位置。我们还可以进行字符串查找，它会双引号或单引号括起来的内容中查找。还可以输入一个正则表达式，这类似于egrep程序的功能。
s: 查找C语言符号，即查找函数名、宏、枚举值等出现的地方
g: 查找函数、宏、枚举等定义的位置，类似ctags所提供的功能
d: 查找本函数调用的函数
c: 查找调用本函数的函数
t: 查找指定的字符串
e: 查找egrep模式，相当于egrep功能，但查找速度快多了
f: 查找并打开文件，类似vim的find功能
i: 查找包含本文件的文
cs help
find 的选项
0或则S：查找本符号
1或则G：查找本定义
2或则D：查找本函数调用的函数
3或则C：查找调用本函数的函数
4或则T：查找本字符串
6或则E：查找本EGREP模式
7或则F：查找本文件
8或则I：查找包含本文件的文件
热后就可以在vim中使用cscope了，具体使用方法参考&lt;/p&gt;

&lt;p&gt;1、Cscope介绍&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;   Cscope是类似于ctags一样的工具，但可以认为她是ctags的增强版，因为她比ctags能够做更多的事。在Vim中，通过cscope的查询，跳转到指定的地方就像跳转到任何标签；她能够保存标签栈，所以通过合适的键盘映射绑定，你能够在函数向后或向前跳转，就像通常使用的tags一样。

   首次使用Cscope时，他会根据源文件生成符号数据库。然后在以后的使用中，cscope只是在源文件有改动或源文件列表不同时才会重建数据库。当在重建数据库时，未改动过的文件对应的数据库信息会从旧的数据库中拷贝过来，所以会使重建数据库快于一开始的新建数据库。

   当你在命令行下调用cscope时，你会获得一个全屏选择窗口，能够使你查询特定的内容。然而，一旦你查询的有匹配，那么就会用你默认的编辑器来编辑该源文件，但是你不能够简单的使用Ctrl+]或者:tag命令来从一个标签跳转到另一个标签。

   Vim中的cscope接口是通过以命令行形式调用完成的，然后解析查询返回的结果。最终的结果就是cscope查询结果就像通常的tags一样，这样你就可以自由跳转，就像在使用通常的tags（用ctrl+]或者:tag跳转）。
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;2、Cscope相关命令&lt;/p&gt;

&lt;p&gt;所有的cscope命令都是通过向主cscope命令”:cscope”传递参数选项。她最短的缩写是”:cs”。”:scscope”命令也做同样的事情并且同时会横向分隔窗口（简称：”scs”）。&lt;/p&gt;

&lt;p&gt;可用的缩写有：&lt;/p&gt;

&lt;p&gt;add ：增加一个新的cscope数据库/链接库&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;          使用方法：

                 :cs add {file|dir} [pre-path] [flags]

          其中：

                 [pre-path] 就是以-p选项传递给cscope的文件路径，是以相对路径表示的文件
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;前加上的path，这样你不要切换到你数据库文件所在的目录也可以使用它了。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;                 [flags] 你想传递给cscope的额外旗标

          实例：

                 :cscope add /root/code/vimtest/ftpd

                 :cscope add /project/vim/cscope.out /usr/local/vim

                 :cscope add cscope.out /usr/local/vim –C

 

   find ：查询cscope。所有的cscope查询选项都可用除了数字5（“修改这个匹配模式”）。

          使用方法：

                 :cs find {querytype} {name}

          其中：

                 {querytype} 即相对应于实际的cscope行接口数字，同时也相对应于nvi命令：

                        0或者s   —— 查找这个C符号

                        1或者g  —— 查找这个定义

                        2或者d  —— 查找被这个函数调用的函数（们）

                        3或者c  —— 查找调用这个函数的函数（们）

                        4或者t   —— 查找这个字符串

                        6或者e  —— 查找这个egrep匹配模式

                        7或者f   —— 查找这个文件

                        8或者i   —— 查找#include这个文件的文件（们）

          实例：（#号后为注释）

                 :cscope find c ftpd_send_resp                     # 查找所有调用这个函数的函数（们）

                 :cscope find 3 ftpd_send_resp                     # 和上面结果一样

                

                 :cscope find 0 FTPD_CHECK_LOGIN       # 查找FTPD_CHECK_LOGIN这个符号

          执行结果如下：

                 Cscope tag: FTPD_CHECK_LOGIN                   
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;#   line  filename / context / line&lt;/p&gt;

&lt;p&gt;1     19  ftpd.h «GLOBAL»&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;         #define FTPD_CHECK_LOGIN() /
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;2    648  ftpd.c «ftpd_do_pwd»&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;         FTPD_CHECK_LOGIN();
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;3    661  ftpd.c «ftpd_do_cwd»&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;         FTPD_CHECK_LOGIN();
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;4    799  ftpd.c «ftpd_do_list»&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;         FTPD_CHECK_LOGIN();
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;5    856  ftpd.c «ftpd_do_nlst»&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;         FTPD_CHECK_LOGIN();
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;6    931  ftpd.c «ftpd_do_syst»&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;         FTPD_CHECK_LOGIN();
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;7    943  ftpd.c «ftpd_do_size»&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;         FTPD_CHECK_LOGIN();
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;8    960  ftpd.c «ftpd_do_dele»&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;         FTPD_CHECK_LOGIN();
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;9    981  ftpd.c «ftpd_do_pasv»&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;         FTPD_CHECK_LOGIN();
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Enter nr of choice (&lt;CR&gt; to abort):&lt;/CR&gt;&lt;/p&gt;

&lt;p&gt;然后输入最前面的序列号即可。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;   help ：显示一个简短的摘要。

          使用方法：

          :cs help

 

   kill  ：杀掉一个cscope链接（或者杀掉所有的cscope链接）

          使用方法：

          :cs kill {num|partial_name}

          为了杀掉一个cscope链接，那么链接数字或者一个部分名称必须被指定。部分名
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;称可以简单的是cscope数据库文件路径的一部分。要特别小心使用部分路径杀死一个cscope链接。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;          假如指定的链接数字为-1，那么所有的cscope链接都会被杀掉。

 

   reset：重新初始化所有的cscope链接。

          使用方法：

          :cs reset

 

   show：显示cscope的链接

          使用方法：

          :cs show

 

   假如你在使用cscope的同时也使用ctags，|:cstag|可以允许你在跳转之前指定从一个或另一个中查找。例如，你可以选择首先从cscope数据库中查找，然后再查找你的tags文件（由ctags生成）。上述执行的顺序取决于|csto|的值。

   |:cstag|当从cscope数据库中查找标识符时等同于“:cs find g”。

   |:cstag|当从你的tags文件中查找标识符时等同于“|:tjump|”。
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;3、Cscope选项&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;   使用|:set|命令来设置cscope的所有选项。理想情况是，你可以在你的启动文件中做这件事情（例如：.vimrc）。有些cscope相关变量只有在|.vimrc|中才是合法的。在vim已经启动之后再来设置它们没有任何作用！

   ‘cscopeprg’指定了执行cscpoe的命令。默认是”cscope”。例如：

          :set csprg=/usr/local/bin/cscope

 

   ‘cscopequickfix’指定了是否使用quickfix窗口来显示cscope的结果。这是一组用逗号分隔的值。每项都包含于|csope-find|命令（s, g, d, c, t, e, f, 或者i）和旗标（+, -或者0）。

   ‘+’预示着显示结果必须追加到quickfix窗口。

   ‘-’隐含着清空先前的的显示结果，’0’或者不设置表示不使用quickfix窗口。查找会从开始直到第一条命令出现。默认的值是””（不使用quickfix窗口）。下面的值似乎会很有用：”s-,c-,d-,i-,t-,e-”。

 

   假如’cscopetag’被设置，然后诸如”:tag”和ctrl+]和”vim -t”等命令会始终使用|:cstag|而不是默认的:tag行为。通过设置’cst’，你将始终同时查找cscope数据库和tags文件。默认情况是关闭的，例如：

          :set cst

          :set nocst

 

   ‘csto’

   ‘csto’的值决定了|:cstag|执行查找的顺序。假如’csto’被设置为0，那么cscope数据将会被优先查找，假如cscope没有返回匹配项，然后才会查找tag文件。反之，则查找顺序相反。默认值是0，例如：

          :set csto=0

          :set csto=1

 

   假如’cscopeverbose’没有被设置（默认情况是如此），那么当在增加一个cscope数据库时不会显示表示表示执行成功或失败的信息。理想情况是，在增加cscope数据库之前，你应该在你的|.vimrc|中重置此选项，在增加完之后，设置它。此后，当你在vim中增加更多的数据库时，你会得到（希望是有用的）信息展示数据库增加失败。例如：

          :set csverb

          :set nocsverb

 

   ‘cspc’的值决定了一个文件的路径的多少部分被显示。默认值是0，所以整个路径都会被显示。值为1的话，那么就只会显示文件名，不带路径。其他值就会显示不同的部分。例如：

          :set cspc=3

   将会显示文件路径的最后3个部分，包含这个文件名本身。
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;4、在Vim中怎么使用cscope&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;   你需要做的第一步就是为你的源文件建立一个cscope数据库。大多数情况下，可以简单的使用”cscope –b”。

   假设你已经有了一个cscope数据库，你需要将这个数据库“增加”进Vim。那将会建立一个cscope“链接”并且使它能够被Vim所使用。你可以在你的.vimrc文件中做这件事，或者在Vim启动之后手动地做。例如，为了增加数据库”cscope.out”，你可以这样做：

          :cs add cscope.out

   你可以通过执行”:cs show”来再次检查以上执行的结果。这将会产生如下的输出：

   # pid      database name                       prepend path
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;0 11453  cscope.out                             &lt;none&gt;&lt;/none&gt;&lt;/p&gt;

&lt;p&gt;提示：&lt;/p&gt;

&lt;p&gt;由于微软的RTL限制，Win32版本会显示0而不是真正的pid。&lt;/p&gt;

&lt;p&gt;一旦一个cscope链接建立之后，你可以查询cscope并且结果会反馈给你。通过命令”:cs find”来进行查找。例如：&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;   :cs find g FTPD_CHECK_LOGIN
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;执行以上命令可能会变得有点笨重的，因为它要做相当的输入次数。假如有不止一个匹配项，你将会被提供一个选择屏幕来选择你想匹配的项。在你跳转到新位置之后，可以简单的按下ctrl+t就会返回到以前的一个。&lt;/p&gt;

&lt;p&gt;5、建议的用法&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;   将如下内容放置到你的.vimrc中：

   if has(&quot;cscope&quot;)

          set csprg=/usr/local/bin/cscope

          set csto=0

          set cst

          set nocsverb

          &quot; add any database in current directory

          if filereadable(&quot;cscope.out&quot;)

              cs add cscope.out

          &quot; else add database pointed to by environment

          elseif $CSCOPE_DB != &quot;&quot;

              cs add $CSCOPE_DB

          endif

          set csverb

   endif

 

   通过设置’cscopetag’，我们已经有效的将所有:tag的情况都替换为:cstag。这包括:tag、ctrl+]，和”vim -t”。然后，正常的tag命令就会不光在tag文件中查找，也会在cscope数据库中查找。

   有些用户可能想保留常规的tag行为并且有一个不同的快捷方式来使用:cstag。例如，可以使用如下命令来映射ctrl+_（下划线）到:cstag：

          map &amp;lt;C-_&amp;gt; : cstag &amp;lt;C-R&amp;gt;=expand(“&amp;lt;cword&amp;gt;”)&amp;lt;CR&amp;gt;&amp;lt;CR&amp;gt;

 

   一些经常用cscope查找（使用”:cs find”）是查找调用某一特定函数的所有函数，和查找所有出现特定C符号的地方。为了做这些事，你可以使用如下的键盘映射作为例子：

          map g&amp;lt;C-]&amp;gt; :cs find 3 &amp;lt;C-R&amp;gt;=expand(“&amp;lt;cword&amp;gt;”)&amp;lt;CR&amp;gt;&amp;lt;CR&amp;gt;

          map g&amp;lt;C-/&amp;gt; :cs find 0 &amp;lt;C-R&amp;gt;=expand(“&amp;lt;cword&amp;gt;”)&amp;lt;CR&amp;gt;&amp;lt;CR&amp;gt;

 

   这些给ctrl+]（右中括号）和ctrl+/（反斜杠）的映射可以允许你将光标放置到函数名称或者C符号上然后执行快速cscope查找匹配。

 

   或者你可以使用如下方案（很好用，可以将其添加到.vimrc中）：

nmap &amp;lt;C-_&amp;gt;s :cs find s &amp;lt;C-R&amp;gt;=expand(&quot;&amp;lt;cword&amp;gt;&quot;)&amp;lt;CR&amp;gt;&amp;lt;CR&amp;gt;

nmap &amp;lt;C-_&amp;gt;g :cs find g &amp;lt;C-R&amp;gt;=expand(&quot;&amp;lt;cword&amp;gt;&quot;)&amp;lt;CR&amp;gt;&amp;lt;CR&amp;gt;

nmap &amp;lt;C-_&amp;gt;c :cs find c &amp;lt;C-R&amp;gt;=expand(&quot;&amp;lt;cword&amp;gt;&quot;)&amp;lt;CR&amp;gt;&amp;lt;CR&amp;gt;

nmap &amp;lt;C-_&amp;gt;t :cs find t &amp;lt;C-R&amp;gt;=expand(&quot;&amp;lt;cword&amp;gt;&quot;)&amp;lt;CR&amp;gt;&amp;lt;CR&amp;gt;

nmap &amp;lt;C-_&amp;gt;e :cs find e &amp;lt;C-R&amp;gt;=expand(&quot;&amp;lt;cword&amp;gt;&quot;)&amp;lt;CR&amp;gt;&amp;lt;CR&amp;gt;

nmap &amp;lt;C-_&amp;gt;f :cs find f &amp;lt;C-R&amp;gt;=expand(&quot;&amp;lt;cfile&amp;gt;&quot;)&amp;lt;CR&amp;gt;&amp;lt;CR&amp;gt;

nmap &amp;lt;C-_&amp;gt;i :cs find i &amp;lt;C-R&amp;gt;=expand(&quot;&amp;lt;cfile&amp;gt;&quot;)&amp;lt;CR&amp;gt;&amp;lt;CR&amp;gt;

nmap &amp;lt;C-_&amp;gt;d :cs find d &amp;lt;C-R&amp;gt;=expand(&quot;&amp;lt;cword&amp;gt;&quot;)&amp;lt;CR&amp;gt;&amp;lt;CR&amp;gt;

 

   “ 使用’ctrl – 空格’，然后查找时就会使vim水平分隔窗口，结果显示在

   “ 新的窗口中

          nmap &amp;lt;C-Space&amp;gt;s :scs find s &amp;lt;C-R&amp;gt;=expand(&quot;&amp;lt;cword&amp;gt;&quot;)&amp;lt;CR&amp;gt;&amp;lt;CR&amp;gt;

nmap &amp;lt;C-Space&amp;gt;g :scs find g &amp;lt;C-R&amp;gt;=expand(&quot;&amp;lt;cword&amp;gt;&quot;)&amp;lt;CR&amp;gt;&amp;lt;CR&amp;gt;

nmap &amp;lt;C-Space&amp;gt;c :scs find c &amp;lt;C-R&amp;gt;=expand(&quot;&amp;lt;cword&amp;gt;&quot;)&amp;lt;CR&amp;gt;&amp;lt;CR&amp;gt;

nmap &amp;lt;C-Space&amp;gt;t :scs find t &amp;lt;C-R&amp;gt;=expand(&quot;&amp;lt;cword&amp;gt;&quot;)&amp;lt;CR&amp;gt;&amp;lt;CR&amp;gt;

nmap &amp;lt;C-Space&amp;gt;e :scs find e &amp;lt;C-R&amp;gt;=expand(&quot;&amp;lt;cword&amp;gt;&quot;)&amp;lt;CR&amp;gt;&amp;lt;CR&amp;gt;

nmap &amp;lt;C-Space&amp;gt;f :scs find f &amp;lt;C-R&amp;gt;=expand(&quot;&amp;lt;cfile&amp;gt;&quot;)&amp;lt;CR&amp;gt;&amp;lt;CR&amp;gt;

nmap &amp;lt;C-Space&amp;gt;i :scs find i &amp;lt;C-R&amp;gt;=expand(&quot;&amp;lt;cfile&amp;gt;&quot;)&amp;lt;CR&amp;gt;&amp;lt;CR&amp;gt;

nmap &amp;lt;C-Space&amp;gt;d :scs find d &amp;lt;C-R&amp;gt;=expand(&quot;&amp;lt;cword&amp;gt;&quot;)&amp;lt;CR&amp;gt;&amp;lt;CR&amp;gt;

  

   “ 两次按下’ ctrl – 空格’，然后查找时就会竖直分隔窗口而不是水平分隔

          nmap &amp;lt;C-Space&amp;gt;&amp;lt;C-Space&amp;gt;s

                 /:vert scs find s &amp;lt;C-R&amp;gt;=expand(&quot;&amp;lt;cword&amp;gt;&quot;)&amp;lt;CR&amp;gt;&amp;lt;CR&amp;gt;

   nmap &amp;lt;C-Space&amp;gt;&amp;lt;C-Space&amp;gt;g

          /:vert scs find g &amp;lt;C-R&amp;gt;=expand(&quot;&amp;lt;cword&amp;gt;&quot;)&amp;lt;CR&amp;gt;&amp;lt;CR&amp;gt;

   nmap &amp;lt;C-Space&amp;gt;&amp;lt;C-Space&amp;gt;c

          /:vert scs find c &amp;lt;C-R&amp;gt;=expand(&quot;&amp;lt;cword&amp;gt;&quot;)&amp;lt;CR&amp;gt;&amp;lt;CR&amp;gt;

   nmap &amp;lt;C-Space&amp;gt;&amp;lt;C-Space&amp;gt;t

          /:vert scs find t &amp;lt;C-R&amp;gt;=expand(&quot;&amp;lt;cword&amp;gt;&quot;)&amp;lt;CR&amp;gt;&amp;lt;CR&amp;gt;

   nmap &amp;lt;C-Space&amp;gt;&amp;lt;C-Space&amp;gt;e

          /:vert scs find e &amp;lt;C-R&amp;gt;=expand(&quot;&amp;lt;cword&amp;gt;&quot;)&amp;lt;CR&amp;gt;&amp;lt;CR&amp;gt;

   nmap &amp;lt;C-Space&amp;gt;&amp;lt;C-Space&amp;gt;i

          /:vert scs find i &amp;lt;C-R&amp;gt;=expand(&quot;&amp;lt;cfile&amp;gt;&quot;)&amp;lt;CR&amp;gt;&amp;lt;CR&amp;gt;

   nmap &amp;lt;C-Space&amp;gt;&amp;lt;C-Space&amp;gt;d

          /:vert scs find d &amp;lt;C-R&amp;gt;=expand(&quot;&amp;lt;cword&amp;gt;&quot;)&amp;lt;CR&amp;gt;&amp;lt;CR&amp;gt;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;6、结合实际来使用cscope&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;   我这里有一个ftp服务器的工程，主要文件如下（Secure CRT vt100, traditional, 13）：  



   下面就是要cscope命令来建立数据库文件（多了3个和cscope相关的文件）：

 



   说明：
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;a、  cscope的选项分析：&lt;/p&gt;

&lt;p&gt;-R     ：表示包含此目录的子目录，而非仅仅是当前目录；&lt;/p&gt;

&lt;p&gt;-b     ：此参数告诉cscope生成数据库后就自动退出；&lt;/p&gt;

&lt;p&gt;-q     ：生成cscope.in.out和cscope.po.out文件，加快cscope的索引速度&lt;/p&gt;

&lt;p&gt;可能会用到的其他选项：&lt;/p&gt;

&lt;p&gt;-k     ：在生成索引时，不搜索/usr/include目录；&lt;/p&gt;

&lt;p&gt;-i      ：如果保存文件列表的文件名不是cscope.files时，需要加此选项告诉cscope到哪里去找源文件列表；&lt;/p&gt;

&lt;p&gt;-I dir ：在-I选项指出的目录中查找头文件&lt;/p&gt;

&lt;p&gt;-u     ：扫描所有文件，重新生成交叉索引文件；&lt;/p&gt;

&lt;p&gt;-C     ：在搜索时忽略大小写；&lt;/p&gt;

&lt;p&gt;-P path：在以相对路径表示的文件前加上的path，这样你不用切换到你数据库文件的目录也可以使用它了。&lt;/p&gt;

&lt;p&gt;说明：要在VIM中使用cscope的功能，需要在编译Vim时选择”+cscope”。Vim的cscope接口会先调用cscope的命令行接口，然后分析其输出结果找到匹配处显示给用户。&lt;/p&gt;

&lt;p&gt;b、  若是不指定-b选项，则在建立完数据库后进入如下界面：&lt;/p&gt;

&lt;p&gt;这里是想要查找C符号：FTPD_CHECK_LOGIN，你可以通过按Tab键来进行匹配内容和输入项的切换。按下ctrl+d退出。&lt;/p&gt;

&lt;p&gt;注意：在此时，不可以使用ctrl+]进行跳转！&lt;/p&gt;

&lt;p&gt;下面用Vim打开其中的一个文件进行编辑，然后看看使用cscope的具体例子：&lt;/p&gt;

&lt;p&gt;输入：vim ftpd.c&lt;/p&gt;

&lt;p&gt;看到此时光标在ftpd_help这个函数声明上，现在若我们想要看看这个函数是怎么实现的，可以有如下方法：&lt;/p&gt;

&lt;p&gt;1）直接按下ctrl+]                     # 就是按下ctrl键的同时按下’]’键&lt;/p&gt;

&lt;p&gt;2）按下ctrl+_g                          # 按下 ctrl键和下划线（同时按下shift和’-’键）和g&lt;/p&gt;

&lt;p&gt;3）输入“:cs find g ftpd_help”后回车&lt;/p&gt;

&lt;p&gt;4）输入“:tag ftpd_help”         # 假如有安装ctag的话&lt;/p&gt;

&lt;p&gt;然后就会进行跳转：&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;   小结：在非windows系统上很多人都会选择强大的Vim作为编辑器，同时，我们要是能够用好那些同样强大的插件的话，那提高的战斗力可不止一点哦。常常会听到类似的抱怨，linux下没有好用的IDE，殊不知，用Vim结合一些插件，同样可以拥有IDE的强大功能，看代码也不错，可以有类似source insight的功能。这里展示下我的Vim，可能有些简陋，但至少有了些IDE的影子了：

   

 

   对了，还有一点：默认情况下cscope值会在当前目录下针对c、iex和yacc（扩展名分别为.c、.h、.I、.y）程序文件进行解析（如果指定了-R参数则包含其自身的子目录）。这样出现的问题就是，我们对于C++或Java文件怎么办，解决方案是：我们可以生成一个名为cscope.finds的文件列表，并交由cscope去解析。在Linux系统中，生成这个文件列表的方法是：

          find . –name “*.java” &amp;gt; cscope.files

   然后运行cscope –b 命令重新生成数据库就OK了。
&lt;/code&gt;&lt;/pre&gt;

</description>
        <pubDate>Mon, 05 Feb 2018 00:00:00 +0800</pubDate>
        <link>https://xiazemin.github.io/MyBlog/web/2018/02/05/cscope.html</link>
        <guid isPermaLink="true">https://xiazemin.github.io/MyBlog/web/2018/02/05/cscope.html</guid>
        
        
        <category>web</category>
        
      </item>
    
      <item>
        <title>sklearn</title>
        <description>&lt;p&gt;keras是python中比较流行的深度学习库，但是keras本身关注的是深度学习。而python中的scikit-learn库是建立在Scipy上的，有着比较有效的数值计算能力。sklearn是一个具有全特征的通用性的机器学习库，它提供了很多在深度学习中可以用到的工具。&lt;/p&gt;

&lt;p&gt;先安装numpy，再安装scipy
安装sklearn之前，我们需要先安装numpy，scipy函数库。
Numpy下载地址：http://sourceforge.net/projects/numpy/files/NumPy
Scipy下载地址：http://sourceforge.net/projects/scipy/files/Scipy
2、安装sklearn机器学习库
下载地址：https://github.com/scikit-learn/scikit-learn
测试：
import scipy
import sklearn&lt;/p&gt;

&lt;p&gt;LogisticRegression类的各项参数的含义
class sklearn.linear_model.LogisticRegression(penalty=’l2’, 
          dual=False, tol=0.0001, C=1.0, fit_intercept=True, 
          intercept_scaling=1, class_weight=None, 
          random_state=None, solver=’liblinear’, max_iter=100, 
          multi_class=’ovr’, verbose=0, warm_start=False, n_jobs=1)
penalty=’l2’ : 字符串‘l1’或‘l2’,默认‘l2’。
用来指定惩罚的基准（正则化参数）。只有‘l2’支持‘newton-cg’、‘sag’和‘lbfgs’这三种算法。
如果选择‘l2’，solver参数可以选择‘liblinear’、‘newton-cg’、‘sag’和‘lbfgs’这四种算法；如果选择‘l1’的话就只能用‘liblinear’算法。
dual=False : 对偶或者原始方法。Dual只适用于正则化相为l2的‘liblinear’的情况，通常样本数大于特征数的情况下，默认为False。
C=1.0 : C为正则化系数λ的倒数，必须为正数，默认为1。和SVM中的C一样，值越小，代表正则化越强。
fit_intercept=True : 是否存在截距，默认存在。
intercept_scaling=1 : 仅在正则化项为‘liblinear’，且fit_intercept设置为True时有用。
solver=’liblinear’ : solver参数决定了我们对逻辑回归损失函数的优化方法，有四种算法可以选择。
a) liblinear：使用了开源的liblinear库实现，内部使用了坐标轴下降法来迭代优化损失函数。
b) lbfgs：拟牛顿法的一种，利用损失函数二阶导数矩阵即海森矩阵来迭代优化损失函数。
c) newton-cg：也是牛顿法家族的一种，利用损失函数二阶导数矩阵即海森矩阵来迭代优化损失函数。
d) sag：即随机平均梯度下降，是梯度下降法的变种，和普通梯度下降法的区别是每次迭代仅仅用一部分的样本来计算梯度，适合于样本数据多的时候。&lt;/p&gt;

&lt;!-- more --&gt;
&lt;p&gt;参考文档：http://scikit-learn.org/stable/documentation.html&lt;/p&gt;
</description>
        <pubDate>Sat, 03 Feb 2018 00:00:00 +0800</pubDate>
        <link>https://xiazemin.github.io/MyBlog/spark/2018/02/03/sklearn.html</link>
        <guid isPermaLink="true">https://xiazemin.github.io/MyBlog/spark/2018/02/03/sklearn.html</guid>
        
        
        <category>spark</category>
        
      </item>
    
      <item>
        <title>mathlatex</title>
        <description>&lt;!-- more --&gt;
&lt;p&gt;1,LaTeX for WordPress
&amp;lt;对于WordPress博客来说，使用MathJax库的一个简单方法，就是直接使用一个叫LaTeX for WordPress插件。安装插件，简单配置，就可以使用MathJax的js库提供的数学公式在网页上的渲染支持。本博没有使用插件，而是直接在博客主题引用MathJax的js库。&lt;/p&gt;

&lt;p&gt;然后，在网页上编辑公式，只要把LaTeX语法的公式放入MathJax的界定符号之内即可，默认情况下，&lt;script type=&quot;math/tex&quot;&gt;LaTex语法&lt;/script&gt;表示换行居中显示数学公式，而(LaTex语法)表示在行内显示数学公式，即inline的显示方法。
2,Google Chart
Google Chart接受TeX语言，实时返回数学公式的图片
http://www.ruanyifeng.com/blog/2011/07/formula_online_generator.html
https://developers.google.com/chart/?csw=1
3,MathJax.js
https://www.mathjax.org/
第一步先是引入：你可以通过引入CDN，也可以下载js引入，个人推荐CDN引入。
&lt;script type=&quot;text/javascript&quot; src=&quot;https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML&quot;&gt;
&lt;/script&gt;
第二步：有3种使用方法：
①：TeX and LaTeX格式方式
默认运算符是&lt;script type=&quot;math/tex&quot;&gt;...&lt;/script&gt;和[… ]为显示数学，\（…\）用于在线数学。请特别注意，在$…$在线分隔符不使用默认值。这是因为，美元符号出现常常在非数学设置，这可能会导致一些文本被视为意外数学。例如，对于单元分隔符，“…的费用是为第一个$2.50和$2.00每增加一…”将导致短语“2.50的第一个，和”被视为数学因为它属于美元符号之间。注意HTML的标签与TeX语法可能有冲突，“小于号/大于号/ampersands&amp;amp;”需要前后空格，比如：&lt;script type=&quot;math/tex&quot;&gt;% &lt;![CDATA[
a &lt; b %]]&gt;&lt;/script&gt;；
②：第二种方法：添加MathML中等标签的形式
③第三种：AsciiMath输入。以``为符号。
4、MathML
mathml 是数学标记语言，是一种基于XML（标准通用标记语言的子集）的标准，用来在互联网上书写数学符号和公式的置标语言。 
5,KateX
https://khan.github.io/KaTeX/&lt;/p&gt;

</description>
        <pubDate>Fri, 02 Feb 2018 00:00:00 +0800</pubDate>
        <link>https://xiazemin.github.io/MyBlog/web/2018/02/02/mathlatex.html</link>
        <guid isPermaLink="true">https://xiazemin.github.io/MyBlog/web/2018/02/02/mathlatex.html</guid>
        
        
        <category>web</category>
        
      </item>
    
      <item>
        <title>二项逻辑斯蒂回归模型</title>
        <description>&lt;p&gt;Logistic回归与多重线性回归实际上有很多相同之处，最大的区别就在于它们的因变量不同，其他的基本都差不多。正是因为如此，这两种回归可以归于同一个家族，即广义线性模型（generalizedlinear model）。&lt;/p&gt;

&lt;p&gt;这一家族中的模型形式基本上都差不多，不同的就是因变量不同。&lt;/p&gt;

&lt;p&gt;如果是连续的，就是多重线性回归；
如果是二项分布，就是Logistic回归；
如果是Poisson分布，就是Poisson回归；
如果是负二项分布，就是负二项回归。
Logistic回归的因变量可以是二分类的，也可以是多分类的，但是二分类的更为常用，也更加容易解释。所以实际中最常用的就是二分类的Logistic回归。
Logistic回归的主要用途：&lt;/p&gt;

&lt;p&gt;寻找危险因素：寻找某一疾病的危险因素等；
预测：根据模型，预测在不同的自变量情况下，发生某病或某种情况的概率有多大；
判别：实际上跟预测有些类似，也是根据模型，判断某人属于某病或属于某种情况的概率有多大，也就是看一下这个人有多大的可能性是属于某病。
Logistic回归主要在流行病学中应用较多，比较常用的情形是探索某疾病的危险因素，根据危险因素预测某疾病发生的概率，等等。例如，想探讨胃癌发生的危险因素，可以选择两组人群，一组是胃癌组，一组是非胃癌组，两组人群肯定有不同的体征和生活方式等。这里的因变量就是是否胃癌，即“是”或“否”，自变量就可以包括很多了，例如年龄、性别、饮食习惯、幽门螺杆菌感染等。自变量既可以是连续的，也可以是分类的。
常规步骤&lt;/p&gt;

&lt;p&gt;Regression问题的常规步骤为：&lt;/p&gt;

&lt;p&gt;寻找h函数（即hypothesis）；
构造J函数（损失函数）；
想办法使得J函数最小并求得回归参数（θ）
http://blog.csdn.net/wjlucc/article/details/69264144
&lt;!-- more --&gt;&lt;/p&gt;
&lt;ol&gt;
  &lt;li&gt;二项逻辑斯蒂回归模型
二项逻辑斯蒂回归模型是如下的条件概率分布：
$P(Y=1|x)=\frac{\exp{(w \cdot x+b)}}{1+\exp(w\cdot x+b)}$
P(Y=0|x)=11+exp(w⋅x+b)
注意：P(Y=1|x)模型也经常写成hθ(x)=11+exp(−θT⋅x)。 
事件的几率（odds）是指该事件发生的概率与该事件不发生的概率的比值。 
如果事件发生的概率是p，那么该事件的几率是P1−P，该事件的对数几率（log odds）或logit函数是：logit(P)=logp1−p。 
逻辑回归的对数几率是： 
log(P(Y=1|x)1−P(Y=1|x))=w⋅x
意义：在逻辑斯蒂回归模型中，输出Y=1的对数几率是输入x的线性函数。或者说，输出Y=1的对数几率是由属于x的线性函数表示的模型，即逻辑斯蒂回归模型。（这里需要再理解下） 
  感知机只通过决策函数（w⋅x）的符号来判断属于哪一类。逻辑斯蒂回归需要再进一步，它要找到分类概率P(Y=1)与输入向量x的直接关系，再通过比较概率值来判断类别。 
令决策函数（w⋅x）输出值等于概率值比值取对数，即： 
logp1−p=w⋅x⟹p=exp(w⋅x+b)1+exp(w⋅x+b)&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;逻辑斯蒂回归模型的定义式P(Y=1|x)中可以将线性函数w⋅x转换为概率，这时，线性函数的值越接近正无穷，概率值就越接近1；线性函数的值越接近负无穷，概率值就接近0.&lt;/p&gt;
&lt;ol&gt;
  &lt;li&gt;模型参数估计
应用极大似然法进行参数估计，从而获得逻辑斯蒂回归模型。极大似然估计的数学原理参考这里。 
设：P(Y=1|x)=π(x),P(Y=0|x)=1−π(x) 
似然函数为：&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;∏i=1N[π(xi)]yi[1−π(xi)]1−yi&lt;/p&gt;

&lt;p&gt;上式连乘符号内的两项中，每个样本都只会取到两项中的某一项。若该样本的实际标签yi=1，取样本计算为1的概率值π(xi)；若该样本的实际标签yi=0，取样本计算的为0的概率值1−π(xi)。 
对数似然函数为： 
L(w)====∑i=1N[yilogπ(xi)+(1−yi)log(1−π(xi))]∑i=1N[yilogπ(xi)1−π(xi)+log(1−π(xi))]∑i=1N[yi(w⋅xi)+log11+exp(w⋅xi)]∑i=1N[yi(w⋅xi)−log(1+exp(w⋅xi))]&lt;/p&gt;

&lt;p&gt;对上式中的L(w)求极大值，得到w的估计值。 
问题转化成以对数似然函数为目标函数的无约束最优化问题，通常采用梯度下降法以及拟牛顿法求解w。 
假设w的极大估计值是wˆ，那么学到的逻辑斯蒂回归模型为： 
P(Y=1|x)=exp(wˆ⋅x)1+exp(wˆ⋅x)&lt;/p&gt;

&lt;p&gt;P(Y=0|x)=11+exp(wˆ⋅x)&lt;/p&gt;
&lt;ol&gt;
  &lt;li&gt;多项逻辑斯蒂回归
多项逻辑斯蒂回归用于多分类问题，其模型为：&lt;/li&gt;
&lt;/ol&gt;

&lt;table&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td&gt;P(Y=k&lt;/td&gt;
      &lt;td&gt;x)=exp(wk⋅x)1+∑k=1K−1exp(wk⋅x),k=1,2,⋯,K−1&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;table&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td&gt;P(Y=K&lt;/td&gt;
      &lt;td&gt;x)=11+∑k=1K−1exp(wk⋅x)&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;p&gt;上面的公式和二分类的类似，式中k的取值只能取到K−1。&lt;/p&gt;
&lt;ol&gt;
  &lt;li&gt;交叉熵损失函数的求导
逻辑回归的另一种理解是以交叉熵作为损失函数的目标最优化。交叉熵损失函数可以从上文最大似然推导出来。 
交叉熵损失函数为：&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;y(i)log(hθ(x(i)))+(1−y(i))log(1−hθ(x(i)))&lt;/p&gt;

&lt;p&gt;则可以得到目标函数为： 
J(θ)==−1m∑i=1my(i)log(hθ(x(i)))+(1−y(i))log(1−hθ(x(i)))−1m∑i=1m[y(i)θTx(i)−log(1+eθTx(i))]
计算J(θ)对第j个参数分量θj求偏导:&lt;/p&gt;

&lt;p&gt;∂∂θjJ(θ)====∂∂θj(1m∑i=1m[log(1+eθTx(i))−y(i)θTx(i)])1m∑i=1m[∂∂θjlog(1+eθTx(i))−∂∂θj(y(i)θTx(i))]1m∑i=1m⎛⎝x(i)jeθTx(i)1+eθTx(i)−y(i)x(i)j⎞⎠1m∑i=1m(hθ(x(i))−y(i))x(i)j&lt;/p&gt;
</description>
        <pubDate>Fri, 02 Feb 2018 00:00:00 +0800</pubDate>
        <link>https://xiazemin.github.io/MyBlog/spak/2018/02/02/logistic.html</link>
        <guid isPermaLink="true">https://xiazemin.github.io/MyBlog/spak/2018/02/02/logistic.html</guid>
        
        
        <category>spak</category>
        
      </item>
    
      <item>
        <title>Duck typing</title>
        <description>&lt;!-- more --&gt;
&lt;p&gt;还是先看定义 duck typing,
    鸭子类型是多态(polymorphism)的一种形式.在这种形式中,不管对象属于哪个,
    也不管声明的具体接口是什么,只要对象实现了相应的方法,函数就可以在对象上执行操作.
    即忽略对象的真正类型，转而关注对象有没有实现所需的方法、签名和语义.
        duck typing
            A form of polymorphism where functions
            operate on any object that implements the
            appropriate methods, regardless of their
            classes or explicit interface declarations.&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;Wikipedia 是这样描述 duck typing 的,
    在计算机语言中, duk typing 是一个类型测试的一个具体应用.
    是将对类型的检查推迟到代码运行的时候,由动态类型(dynamic typing)
    或者反省(reflection)实现. duck typing 应用在通过应用规则/协议(protocol)
    建立一个适合的对象 object.
    '如果它走起步来像鸭子,并且叫声像鸭子, 那个它一定是一只鸭子.'
    对于一般类型 normal typing, 假定一个对象的 suitability 只有该对象的类型决定.
    然而,对于 duck typing 来说, 一个对象 object 的 suitability 是通过该对象是否
    实现了特定的方法跟属性来决定 certain methods and properties, 而不是由该对象
    的来类型决定.

    注,
        In computer science, reflection is the ability of a computer program to
        examine,introspect, and modify its own structure and behavior at runtime.

    From Wikipedia,
        In computer programming, duck typing is an application of the duck test
        in type safety.It requires that type checking be deferred to runtime,
        and is implemented by means of dynamic typing or reflection.
        Duck typing is concerned with establishing the suitability of an object
        for some purpose, using the principle, &quot;If it walks like a duck and it
        quacks like a duck, then it must be a duck.&quot; With normal typing,
        suitability is assumed to be determined by an object's type only.
        In duck typing, an object's suitability is determined by the presence
        of certain methods and properties (with appropriate meaning),
        rather than the actual type of the object.


鸭子类型的起源 Origins of duck-typing,
    现在谷歌工程师,Python 社区重要贡献者之一: Alex Martelli 说到,
        我相信是 Ruby 社区推动了 duck typing 这个术语的流行.
        但是这个duck typing 这种表达在 Ruby 和 Python 火之前,
        就是在Python 的讨论中使用过.

    根据 Wikipedia, duck typing 这一术语最早被 Alex Martelli 在 2000 所使用.
    Related Link of Wikipedia - https://en.wikipedia.org/wiki/Duck_typing

归功于 python 的 数据类型 data model, 你的用户自定义类型的行为可以像 built-in 类型一样自然。
这并不需要通过继承 inheritance 来获得. 本着 duck typing, 可以在对象中只实现需要的方法, 就能
保证保证对象的行为符合预期. 对 Python 来说，这基本上是指避免使用 isinstance 检查对象的类,
更别提 type(foo) is bar 这种更糟的检查方式了，这样做没有任何好处，甚至禁止最简单的继承方式.
具体使用时,上述建议有一个常见的例外：有些 Python API 接受一个字符串或字符串序列;
如果只有一个字符串,可以把它放到列表中,从而简化处理. 因为字符串是序列类型,
所以为了把它和其他不可变序列区分开,最简单的方式是使用 isinstance(x, str) 检查.
另一方面，如果必须强制执行 API 契约，通常可以使用 isinstance 检查抽象基类。

在看例子之前, 先看简略一下儿 协议 protocol 相关内容,
    在 Python 中创建功能完善的序列类型无需使用继承, 只需实现符合序列协议的方法.
    在面向对象编程中,协议是非正式的接口,只在文档中定义,在代码中不定义.
    例如,Python 的序列协议只需要 __len__ 和 __getitem__ 两个方法.
    任对象/类型(A)只要使用标准的签名和语义实现了这两个方法,就能用在任何期待序列的地方,
    然而A 是不是哪个类的子类无关紧要,只要提供了所需的方法即可.这就是 python 序列协议.
    协议是非正式的,没有强制力,因此如果你知道类的具体使用场景,通常只需要实现一个协议的部分.
    例如,为了支持迭代,只需实现 __getitem__ 方法，没必要提供 __len__方法.

    经典示例, duck typing 处理一个字符串 string 或 可迭代字符串 iterable of strings
        try:                                                      #1
            field_names = field_names.replace(',', ' ').split()   #2
        except AttributeError:                                    #3
            pass                                                  #4
        field_names = tuple(field_names)                          #5

        #1, 假定 field_names 是一个字符串 string. EAFP, it’s easier to ask forgiveness than permission
        #2, 将 field_names 中的 ',' 替换成空格 ' ' 并 split, 将结果放到 list 中
        #3, sorry, field_names 并不像一个 str, field_names 不能 .replace 或者 .replace 后返回的结果不能 .split()
        #4, 这里我men假设 新的 field_names 是一个可迭代对象
        #5, 确保新的 field_names 是一个可迭代对象, 同事保存一个 copy - create 一个 tuple

        field_names = 'abc'                                       #6
        field_names = 'A,B,C'                                     #7
        try:
            field_names = field_names.replace(',', ' ').split()
        except AttributeError:
            pass
        print(field_names)
        field_names = tuple(field_names)
        print(field_names)
        for item in field_names:
            print(item)

        Output,
            ['abc']            #6
            ('abc',)           #6
            abc                #6
            --------------
            ['A', 'B', 'C']    #7
            ('A', 'B', 'C')    #7
            A                  #7
            B                  #7
            C                  #7

    结论,
        Summarize, Outside of frameworks, duck typing is often sim‐pler and more flexible than type checks.
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;对于一门强类型的静态语言来说，要想通过运行时多态来隔离变化，多个实现类就必须属于同一类型体系。也就是说，它们必须通过继承的方式，与同一抽象类型建立is-a关系。&lt;/p&gt;

&lt;p&gt;而Duck Typing则是一种基于特征，而不是基于类型的多态方式。事实上它仍然关心is-a，只不过这种is-a关系是以对方是否具备它所关心的特征来确定的。&lt;/p&gt;

&lt;p&gt;James Whitcomb Riley在描述这种is-a的哲学时，使用了所谓的鸭子测试（Duck Test）:&lt;/p&gt;

&lt;p&gt;当我看到一只鸟走路像鸭子，游泳像鸭子，叫声像鸭子，那我就把它叫做鸭子。（When I see a bird that walks like a duck and swims like a duck and quacks like a duck, I call that bird a duck.）&lt;/p&gt;

&lt;p&gt;鸭子测试
Duck Test基于特征的哲学，给设计提供了强大的灵活性。动态面向对象语言，如Python，Ruby等，都遵从了这种哲学来实现运行时多态。下面给出一个Python的例子：&lt;/p&gt;

&lt;p&gt;class Duck:
    def quack(self):
        print(“Quaaaaaack!”)
    def feathers(self):
        print(“The duck has white and gray feathers.”)&lt;/p&gt;

&lt;p&gt;class Person:
    def quack(self):
        print(“The person imitates a duck.”)
    def feathers(self):
        print(“The person takes a feather from the ground and shows it.”)
    def name(self):
        print(“John Smith”)&lt;/p&gt;

&lt;p&gt;def in_the_forest(duck):
    duck.quack()
    duck.feathers()&lt;/p&gt;

&lt;p&gt;def game():
    donald = Duck()
    john = Person()
    in_the_forest(donald)
    in_the_forest(john)&lt;/p&gt;

&lt;p&gt;game()
但这并不意味着Duck Typing是动态语言的专利。C++作为一门强类型的静态语言，也对此特性有着强有力的支持。只不过，这种支持不是运行时，而是编译时。&lt;/p&gt;

&lt;p&gt;其实现的方式为：一个模板类或模版函数，会要求其实例化的类型必须具备某种特征，如某个函数签名，某个类型定义，某个成员变量等等。如果特征不具备，编译器会报错。&lt;/p&gt;

&lt;p&gt;比如下面一个模板函数:&lt;/p&gt;

&lt;p&gt;template &lt;typename T=&quot;&quot;&gt; 
void f(const T&amp;amp; object) 
{ 
  object.f(0); // 要求类型 T 必须有一个可让此语句编译通过的函数。
} 
对于这样一个函数，下面的四个类均可以用来作为其参数类型。&lt;/typename&gt;&lt;/p&gt;

&lt;p&gt;struct C1 
{
  void f(int); 
};&lt;/p&gt;

&lt;p&gt;struct C2 
{ 
  int f(char); 
};&lt;/p&gt;

&lt;p&gt;struct C3 
{ 
  int f(unsigned short, bool isValid = true); 
};&lt;/p&gt;

&lt;p&gt;struct C4
{
  Foo* f(Object*);
};
一旦上述模板函数实现为下面的样子，则只有C2和C3可以和f配合工作。&lt;/p&gt;

&lt;p&gt;template &lt;typename T=&quot;&quot;&gt; 
void f(const T&amp;amp; object) 
{ 
  int result = object.f(0); 
  // ... 
} 
通过之前的解释我们不难发现，Duck Typing要表达的多态语义如下图所示：&lt;/typename&gt;&lt;/p&gt;

&lt;p&gt;DuckTyping的语义
适配器：类型萃取
Duck Typing需要实例化的类型具备一致的特征，而模板特化的作用正是为了让不同类型具有统一的特征（统一的操作界面），所以模板特化可以作为Duck Typing与实例化类型之间的适配器。这种模板特化手段称为萃取（Traits)，其中类型萃取最为常见，毕竟类型是模板元编程的核心元素。&lt;/p&gt;

&lt;p&gt;所以，类型萃取首先是一种非侵入性的中间层。否则，这些特征就必须被实例化类型提供，而就意味着，当一个实例化类型需要复用多个Duck Typing模板时，就需要迎合多种特征，从而让自己经常被修改，并逐渐变得庞大和难以理解。&lt;/p&gt;

&lt;p&gt;Type Traits的语义
另外，一个Duck Typing模板，比如一个通用算法，需要实例化类型提供一些特征时，如果一个类型是类，则是一件很容易的事情，因为你可以在一个类里定义任何需要的特征。但如果一个基本类型也想复用此通用算法，由于基本类型无法靠自己提供算法所需要的特征，就必须借助于类型萃取。&lt;/p&gt;

&lt;p&gt;结论
这四篇文章所介绍的，就是C++泛型编程的全部关键知识。&lt;/p&gt;

&lt;p&gt;从中可以看出，泛型是一种多态技术。而多态的核心目的是为了消除重复，隔离变化，提高系统的正交性。因而，泛型编程不仅不应该被看做奇技淫巧，而是任何一个追求高效的C++工程师都应该掌握的技术。&lt;/p&gt;

&lt;p&gt;同时，我们也可以看出，相关的思想在其它范式和语言中（FP，动态语言）也都存在。因而，对于其它范式和语言的学习，也会有助于更加深刻的理解泛型，从而正确的使用范型。&lt;/p&gt;

&lt;p&gt;最后给出关于泛型的缺点：&lt;/p&gt;

&lt;p&gt;复杂模板的代码非常难以理解;
编译器关于模板的出错信息十分晦涩，尤其当模板存在嵌套时；
模板实例化会进行代码生成，重复信息会被多次生成，这可能会造成目标代码膨胀;
模板的编译可能非常耗时;
编译器对模板的复杂性往往会有自己限制，比如当使用递归时，当递归层次太深,编译器将无法编译;
不同编译器（包括不同版本）之间对于模板的支持程度不一，当存在移植性需求时，可能出现问题;
模板具有传染性，往往一处选择模板，很多地方也必须跟着使用模板，这会恶化之前的提到的所有问题。
我对此的原则是：在使用其它非泛型技术可以同等解决的前提下，就不会选择泛型。&lt;/p&gt;

&lt;p&gt;python与鸭子类型
调用不同的子类将会产生不同的行为，而无须明确知道这个子类实际上是什么，这是多态的重要应用场景。而在python中，因为鸭子类型(duck typing)使得其多态不是那么酷。 
鸭子类型是动态类型的一种风格。在这种风格中，一个对象有效的语义，不是由继承自特定的类或实现特定的接口，而是由”当前方法和属性的集合”决定。这个概念的名字来源于由James Whitcomb Riley提出的鸭子测试，“鸭子测试”可以这样表述：“当看到一只鸟走起来像鸭子、游泳起来像鸭子、叫起来也像鸭子，那么这只鸟就可以被称为鸭子。” 
在鸭子类型中，关注的不是对象的类型本身，而是它是如何使用的。例如，在不使用鸭子类型的语言中，我们可以编写一个函数，它接受一个类型为”鸭子”的对象，并调用它的”走”和”叫”方法。在使用鸭子类型的语言中，这样的一个函数可以接受一个任意类型的对象，并调用它的”走”和”叫”方法。如果这些需要被调用的方法不存在，那么将引发一个运行时错误。任何拥有这样的正确的”走”和”叫”方法的对象都可被函数接受的这种行为引出了以上表述，这种决定类型的方式因此得名。 
鸭子类型通常得益于不测试方法和函数中参数的类型，而是依赖文档、清晰的代码和测试来确保正确使用。&lt;/p&gt;

&lt;p&gt;静态类型语言和动态类型语言的区别
静态类型语言在编译时便已确定变量的类型，而动态类型语言的变量类型要到程序运行的时候，待变量被赋予某个值之后，才会具有某种类型。 
静态类型语言的优点首先是在编译时就能发现类型不匹配的错误，编辑器可以帮助我们提前避免程序在运行期间有可能发生的一些错误。其次，如果在程序中明确地规定了数据类型，编译器还可以针对这些信息对程序进行一些优化工作，提高程序执行速度。 
静态类型语言的缺点首先是迫使程序员依照强契约来编写程序，为每个变量规定数据类型，归根结底只是辅助我们编写可靠性高程序的一种手段，而不是编写程序的目的，毕竟大部分人编写程序的目的是为了完成需求交付生产。其次，类型的声明也会增加更多的代码，在程序编写过程中，这些细节会让程序员的精力从思考业务逻辑上分散开来。 
动态类型语言的优点是编写的代码数量更少，看起来也更加简洁，程序员可以把精力更多地放在业务逻辑上面。虽然不区分类型在某些情况下会让程序变得难以理解，但整体而言，代码量越少，越专注于逻辑表达，对阅读程序是越有帮助的。 
动态类型语言的缺点是无法保证变量的类型，从而在程序的运行期有可能发生跟类型相关的错误。 
动态类型语言对变量类型的宽容给实际编码带来了很大的灵活性。由于无需进行类型检测，我们可以尝试调用任何对象的任意方法，而无需去考虑它原本是否被设计为拥有该方法。&lt;/p&gt;

&lt;p&gt;面向接口编程
动态类型语言的面向对象设计中，鸭子类型的概念至关重要。利用鸭子类型的思想，我们不必借助超类型的帮助，就能轻松地在动态类型语言中实现一个原则：“面向接口编程，而不是面向实现编程”。例如，一个对象若有push和pop方法，并且这些方法提供了正确的实现，它就可以被当作栈来使用。一个对象如果有length属性，也可以依照下标来存取属性（最好还要拥有slice和splice等方法），这个对象就可以被当作数组来使用。&lt;/p&gt;

&lt;p&gt;在静态类型语言中，要实现“面向接口编程”并不是一件容易的事情，往往要通过抽象类或者接口等将对象进行向上转型。当对象的真正类型被隐藏在它的超类型身后，这些对象才能在类型检查系统的“监视”之下互相被替换使用。只有当对象能够被互相替换使用，才能体现出对象多态性的价值。&lt;/p&gt;

&lt;p&gt;python中的多态
python中的鸭子类型允许我们使用任何提供所需方法的对象，而不需要迫使它成为一个子类。 
由于python属于动态语言，当你定义了一个基类和基类中的方法，并编写几个继承该基类的子类时，由于python在定义变量时不指定变量的类型，而是由解释器根据变量内容推断变量类型的（也就是说变量的类型取决于所关联的对象），这就使得python的多态不像是c++或java中那样，定义一个基类类型变量而隐藏了具体子类的细节&lt;/p&gt;

&lt;p&gt;而scala是静态强类型语言,  调用的方法必须在对象类型层次(本类或者超类）中定义。不过scala通过structural types支持所谓的类型安全的鸭子类型:
     类型安全的鸭子类型 - structural types  - structural types as a type-safe approach to duck typing&lt;/p&gt;
</description>
        <pubDate>Fri, 02 Feb 2018 00:00:00 +0800</pubDate>
        <link>https://xiazemin.github.io/MyBlog/web/2018/02/02/Duck_typing.html</link>
        <guid isPermaLink="true">https://xiazemin.github.io/MyBlog/web/2018/02/02/Duck_typing.html</guid>
        
        
        <category>web</category>
        
      </item>
    
      <item>
        <title>导入第三方依赖到shell</title>
        <description>&lt;!-- more --&gt;
&lt;p&gt;import SparkContext
这是spark下面已经有这个jar包的存在了
spark-shell下面包含所有的spark和java的依赖
但是对于第三代jar包，需要先将第三方依赖（jar包）导入到spark-shell下面才行
spark-shell –jars /home/wangtuntun/下载/nscala-time_2.10-2.12.0.jar
如果需要导入多个依赖，之间用逗号隔开
前提要配置spark-shell到环境变量&lt;/p&gt;
</description>
        <pubDate>Sat, 27 Jan 2018 00:00:00 +0800</pubDate>
        <link>https://xiazemin.github.io/MyBlog/spark/2018/01/27/spark_jar.html</link>
        <guid isPermaLink="true">https://xiazemin.github.io/MyBlog/spark/2018/01/27/spark_jar.html</guid>
        
        
        <category>spark</category>
        
      </item>
    
      <item>
        <title>zero copy</title>
        <description>&lt;!-- more --&gt;
&lt;p&gt;许多web应用都会向用户提供大量的静态内容，这意味着有很多data从硬盘读出之后，会原封不动的通过socket传输给用户。这种操作看起来可能不会怎么消耗CPU，但是实际上它是低效的：kernal把数据从disk读出来，然后把它传输给user级的application，然后application再次把同样的内容再传回给处于kernal级的socket。这种场景下，application实际上只是作为一种低效的中间介质，用来把disk file的data传给socket。&lt;/p&gt;

&lt;p&gt;data每次穿过user-kernel boundary，都会被copy，这会消耗cpu，并且占用RAM的带宽。幸运的是，你可以用一种叫做Zero-Copy的技术来去掉这些无谓的copy。应用程序用zero copy来请求kernel直接把disk的data传输给socket，而不是通过应用程序传输。Zero copy大大提高了应用程序的性能，并且减少了kernel和user模式的上下文切换。&lt;/p&gt;

&lt;p&gt;Java的libaries在linux和unix中支持zero copy，一个关键的api是java.nio.channel.FileChannel的transferTo()方法。我们可以用transferTo()来把bytes直接从调用它的channel传输到另一个writable byte channel，中间不会使data经过应用程序。本文首先描述传统的copy是怎样坑爹的，然后再展示zero-copy技术在性能上是多么的给力以及为什么给力。&lt;/p&gt;

&lt;p&gt;Date transfer: The traditional approach&lt;/p&gt;

&lt;p&gt;考虑一下这个场景，通过网络把一个文件传输给另一个程序。这个操作的核心代码就是下面的两个函数：&lt;/p&gt;

&lt;p&gt;Listing 1. Copying bytes from a file to a socket&lt;/p&gt;

&lt;p&gt;File.read(fileDesc, buf, len);
Socket.send(socket, buf, len);
尽管看起来很简单，但是在OS的内部，这个copy操作要经历四次user mode和kernel mode之间的上下文切换，甚至连数据都被拷贝了四次&lt;/p&gt;

&lt;p&gt;read() 引入了一次从user mode到kernel mode的上下文切换。实际上调用了sys_read() 来从文件中读取data。第一次copy由DMA完成，将文件内容从disk读出，存储在kernel的buffer中。
然后data被copy到user buffer中，此时read()成功返回。这是触发了第二次context switch: 从kernel到user。至此，数据存储在user的buffer中。
send() socket call 带来了第三次context switch，这次是从user mode到kernel mode。同时，也发生了第三次copy：把data放到了kernel adress space中。当然，这次的kernel buffer和第一步的buffer是不同的两个buffer。
最终 send() system call 返回了，同时也造成了第四次context switch。同时第四次copy发生，DMA将data从kernel buffer拷贝到protocol engine中。第四次copy是独立而且异步的。
使用kernel buffer做中介(而不是直接把data传到user buffer中)看起来比较低效(多了一次copy)。然而实际上kernel buffer是用来提高性能的。在进行读操作的时候，kernel buffer起到了预读cache的作用。当写请求的data size比kernel buffer的size小的时候，这能够显著的提升性能。在进行写操作时，kernel buffer的存在可以使得写请求完全异步。&lt;/p&gt;

&lt;p&gt;悲剧的是，当请求的data size远大于kernel buffer size的时候，这个方法本身变成了性能的瓶颈。因为data需要在disk，kernel buffer，user buffer之间拷贝很多次(每次写满整个buffer)。&lt;/p&gt;

&lt;p&gt;而Zero copy正是通过消除这些多余的data copy来提升性能。&lt;/p&gt;

&lt;p&gt;Data Transfer：The Zero Copy Approach&lt;/p&gt;

&lt;p&gt;如果重新检查一遍traditional approach，你会注意到实际上第二次和第三次copy是毫无意义的。应用程序仅仅缓存了一下data就原封不动的把它发回给socket buffer。实际上，data应该直接在read buffer和socket buffer之间传输。transferTo()方法正是做了这样的操作。Listing 2是transferTo()的函数原型：&lt;/p&gt;

&lt;p&gt;public void transferTo(long position, long count, WritableByteChannel target);
transferTo()方法把data从file channel传输到指定的writable byte channel。它需要底层的操作系统支持zero copy。在UNIX和各种Linux中，会执行List 3中的系统调用sendfile()，该命令把data从一个文件描述符传输到另一个文件描述符(Linux中万物皆文件)：&lt;/p&gt;

&lt;p&gt;#include &amp;lt;sys/socket.h&amp;gt;
ssize_t sendfile(int out_fd, int in_fd, off_t *offset, size_t count);
在List 1中的file.read()和socket.send()可以用一句transferTo()替代，如List 4：&lt;/p&gt;

&lt;p&gt;transferTo(position, count, writableChannel);&lt;/p&gt;

&lt;p&gt;在像Listing 4那样使用transferTo()之后，整个过程如下：&lt;/p&gt;

&lt;p&gt;transferTo()方法使得文件内容被DMA engine直接copy到一个read buffer中。然后数据被kernel再次拷贝到和output socket相关联的那个kernel buffer中去。
第三次拷贝由DMA engine完成，它把kernel buffer中的data拷贝到protocol engine中。
这是一个很明显的进步：我们把context switch的次数从4次减少到了2次，同时也把data copy的次数从4次降低到了3次(而且其中只有一次占用了CPU，另外两次由DMA完成)。但是，要做到zero copy，这还差得远。如果网卡支持 gather operation，我们可以通过kernel进一步减少数据的拷贝操作。在2.4及以上版本的linux内核中，开发者修改了socket buffer descriptor来适应这一需求。这个方法不仅减少了context switch，还消除了和CPU有关的数据拷贝。user层面的使用方法没有变，但是内部原理却发生了变化：&lt;/p&gt;

&lt;p&gt;transferTo()方法使得文件内容被copy到了kernel buffer，这一动作由DMA engine完成。
没有data被copy到socket buffer。取而代之的是socket buffer被追加了一些descriptor的信息，包括data的位置和长度。然后DMA engine直接把data从kernel buffer传输到protocol engine，这样就消除了唯一的一次需要占用CPU的拷贝操作。
Figure 5描述了新的transferTo()方法中的data copy:&lt;/p&gt;

&lt;p&gt;Kafka在提高效率方面做了很大努力。Kafka的一个主要使用场景是处理网站活动日志，吞吐量是非常大的，每个页面都会产生好多次写操作。读方面，假设每个消息只被消费一次，读的量的也是很大的，Kafka也尽量使读的操作更轻量化。&lt;/p&gt;

&lt;p&gt;我们之前讨论了磁盘的性能问题，线性读写的情况下影响磁盘性能问题大约有两个方面：太多的琐碎的I/O操作和太多的字节拷贝。I/O问题发生在客户端和服务端之间，也发生在服务端内部的持久化的操作中。
消息集（message set）
为了避免这些问题，Kafka建立了“消息集（message set）”的概念，将消息组织到一起，作为处理的单位。以消息集为单位处理消息，比以单个的消息为单位处理，会提升不少性能。Producer把消息集一块发送给服务端，而不是一条条的发送；服务端把消息集一次性的追加到日志文件中，这样减少了琐碎的I/O操作。consumer也可以一次性的请求一个消息集。
另外一个性能优化是在字节拷贝方面。在低负载的情况下这不是问题，但是在高负载的情况下它的影响还是很大的。为了避免这个问题，Kafka使用了标准的二进制消息格式，这个格式可以在producer,broker和producer之间共享而无需做任何改动。
zero copy
Broker维护的消息日志仅仅是一些目录文件，消息集以固定队的格式写入到日志文件中，这个格式producer和consumer是共享的，这使得Kafka可以一个很重要的点进行优化：消息在网络上的传递。现代的unix操作系统提供了高性能的将数据从页面缓存发送到socket的系统函数，在linux中，这个函数是sendfile.
为了更好的理解sendfile的好处，我们先来看下一般将数据从文件发送到socket的数据流向：&lt;/p&gt;

&lt;p&gt;操作系统把数据从文件拷贝内核中的页缓存中
应用程序从页缓存从把数据拷贝自己的内存缓存中
应用程序将数据写入到内核中socket缓存中
操作系统把数据从socket缓存中拷贝到网卡接口缓存，从这里发送到网络上。&lt;/p&gt;

&lt;p&gt;这显然是低效率的，有4次拷贝和2次系统调用。Sendfile通过直接将数据从页面缓存发送网卡接口缓存，避免了重复拷贝，大大的优化了性能。
在一个多consumers的场景里，数据仅仅被拷贝到页面缓存一次而不是每次消费消息的时候都重复的进行拷贝。这使得消息以近乎网络带宽的速率发送出去。这样在磁盘层面你几乎看不到任何的读操作，因为数据都是从页面缓存中直接发送到网络上去了。&lt;/p&gt;

</description>
        <pubDate>Fri, 26 Jan 2018 00:00:00 +0800</pubDate>
        <link>https://xiazemin.github.io/MyBlog/linux/2018/01/26/zero_copy.html</link>
        <guid isPermaLink="true">https://xiazemin.github.io/MyBlog/linux/2018/01/26/zero_copy.html</guid>
        
        
        <category>linux</category>
        
      </item>
    
      <item>
        <title>进程在后台运行原理</title>
        <description>&lt;!-- more --&gt;
&lt;p&gt;nohup/setsid/&amp;amp;
场景：
如果只是临时有一个命令需要长时间运行，什么方法能最简便的保证它在后台稳定运行呢？&lt;/p&gt;

&lt;p&gt;hangup 名称的来由
在 Unix 的早期版本中，每个终端都会通过 modem 和系统通讯。当用户 logout 时，modem 就会挂断（hang up）电话。 同理，当 modem 断开连接时，就会给终端发送 hangup 信号来通知其关闭所有子进程。&lt;/p&gt;

&lt;p&gt;解决方法：
我们知道，当用户注销（logout）或者网络断开时，终端会收到 HUP（hangup）信号从而关闭其所有子进程。因此，我们的解决办法就有两种途径：要么让进程忽略 HUP 信号，要么让进程运行在新的会话里从而成为不属于此终端的子进程。&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;nohup&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;nohup 无疑是我们首先想到的办法。顾名思义，nohup 的用途就是让提交的命令忽略 hangup 信号。让我们先来看一下 nohup 的帮助信息：
NOHUP(1)                        User Commands                        NOHUP(1)&lt;/p&gt;

&lt;p&gt;NAME
       nohup - run a command immune to hangups, with output to a non-tty&lt;/p&gt;

&lt;p&gt;SYNOPSIS
       nohup COMMAND [ARG]…
       nohup OPTION&lt;/p&gt;

&lt;p&gt;DESCRIPTION
       Run COMMAND, ignoring hangup signals.&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;   --help display this help and exit
 
   --version
          output version information and exit 可见，nohup 的使用是十分方便的，只需在要处理的命令前加上 nohup 即可，标准输出和标准错误缺省会被重定向到 nohup.out 文件中。一般我们可在结尾加上&quot;&amp;amp;&quot;来将命令同时放入后台运行，也可用&quot;&amp;gt;filename 2&amp;gt;&amp;amp;1&quot;来更改缺省的重定向文件名。
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;nohup 示例
[root@pvcent107 ~]# nohup ping www.ibm.com &amp;amp;
[1] 3059
nohup: appending output to `nohup.out’
[root@pvcent107 ~]# ps -ef |grep 3059
root      3059   984  0 21:06 pts/3    00:00:00 ping www.ibm.com
root      3067   984  0 21:06 pts/3    00:00:00 grep 3059
[root@pvcent107 ~]#
2。setsid&lt;/p&gt;

&lt;p&gt;nohup 无疑能通过忽略 HUP 信号来使我们的进程避免中途被中断，但如果我们换个角度思考，如果我们的进程不属于接受 HUP 信号的终端的子进程，那么自然也就不会受到 HUP 信号的影响了。setsid 就能帮助我们做到这一点。让我们先来看一下 setsid 的帮助信息：
SETSID(8)                 Linux Programmer’s Manual                 SETSID(8)&lt;/p&gt;

&lt;p&gt;NAME
       setsid - run a program in a new session&lt;/p&gt;

&lt;p&gt;SYNOPSIS
       setsid program [ arg … ]&lt;/p&gt;

&lt;p&gt;DESCRIPTION
       setsid runs a program in a new session.
可见 setsid 的使用也是非常方便的，也只需在要处理的命令前加上 setsid 即可。&lt;/p&gt;

&lt;p&gt;setsid 示例
[root@pvcent107 ~]# setsid ping www.ibm.com
[root@pvcent107 ~]# ps -ef |grep www.ibm.com
root     31094     1  0 07:28 ?        00:00:00 ping www.ibm.com
root     31102 29217  0 07:29 pts/4    00:00:00 grep www.ibm.com
[root@pvcent107 ~]#
值得注意的是，上例中我们的进程 ID(PID)为31094，而它的父 ID（PPID）为1（即为 init 进程 ID），并不是当前终端的进程 ID。请将此例与nohup 例中的父 ID 做比较。&lt;/p&gt;

&lt;p&gt;3。&amp;amp;&lt;/p&gt;

&lt;p&gt;这里还有一个关于 subshell 的小技巧。我们知道，将一个或多个命名包含在“()”中就能让这些命令在子 shell 中运行中，从而扩展出很多有趣的功能，我们现在要讨论的就是其中之一。&lt;/p&gt;

&lt;p&gt;当我们将”&amp;amp;”也放入“()”内之后，我们就会发现所提交的作业并不在作业列表中，也就是说，是无法通过jobs来查看的。让我们来看看为什么这样就能躲过 HUP 信号的影响吧。&lt;/p&gt;

&lt;p&gt;subshell 示例
[root@pvcent107 ~]# (ping www.ibm.com &amp;amp;)
[root@pvcent107 ~]# ps -ef |grep www.ibm.com
root     16270     1  0 14:13 pts/4    00:00:00 ping www.ibm.com
root     16278 15362  0 14:13 pts/4    00:00:00 grep www.ibm.com
[root@pvcent107 ~]#
从上例中可以看出，新提交的进程的父 ID（PPID）为1（init 进程的 PID），并不是当前终端的进程 ID。因此并不属于当前终端的子进程，从而也就不会受到当前终端的 HUP 信号的影响了。&lt;/p&gt;

&lt;p&gt;disown
场景：
我们已经知道，如果事先在命令前加上 nohup 或者 setsid 就可以避免 HUP 信号的影响。但是如果我们未加任何处理就已经提交了命令，该如何补救才能让它避免 HUP 信号的影响呢？&lt;/p&gt;

&lt;p&gt;解决方法：
这时想加 nohup 或者 setsid 已经为时已晚，只能通过作业调度和 disown 来解决这个问题了。让我们来看一下 disown 的帮助信息：
disown [-ar] [-h] [jobspec …]
    Without options, each jobspec is  removed  from  the  table  of
    active  jobs.   If  the -h option is given, each jobspec is not
    removed from the table, but is marked so  that  SIGHUP  is  not
    sent  to the job if the shell receives a SIGHUP.  If no jobspec
    is present, and neither the -a nor the -r option  is  supplied,
    the  current  job  is  used.  If no jobspec is supplied, the -a
    option means to remove or mark all jobs; the -r option  without
    a  jobspec  argument  restricts operation to running jobs.  The
    return value is 0 unless a jobspec does  not  specify  a  valid
    job.
可以看出，我们可以用如下方式来达成我们的目的。&lt;/p&gt;

&lt;p&gt;灵活运用 CTRL-z
在我们的日常工作中，我们可以用 CTRL-z 来将当前进程挂起到后台暂停运行，执行一些别的操作，然后再用 fg 来将挂起的进程重新放回前台（也可用 bg 来将挂起的进程放在后台）继续运行。这样我们就可以在一个终端内灵活切换运行多个任务，这一点在调试代码时尤为有用。因为将代码编辑器挂起到后台再重新放回时，光标定位仍然停留在上次挂起时的位置，避免了重新定位的麻烦。&lt;/p&gt;

&lt;p&gt;用disown -h jobspec来使某个作业忽略HUP信号。
用disown -ah 来使所有的作业都忽略HUP信号。
用disown -rh 来使正在运行的作业忽略HUP信号。
需要注意的是，当使用过 disown 之后，会将把目标作业从作业列表中移除，我们将不能再使用jobs来查看它，但是依然能够用ps -ef查找到它。&lt;/p&gt;

&lt;p&gt;但是还有一个问题，这种方法的操作对象是作业，如果我们在运行命令时在结尾加了”&amp;amp;”来使它成为一个作业并在后台运行，那么就万事大吉了，我们可以通过jobs命令来得到所有作业的列表。但是如果并没有把当前命令作为作业来运行，如何才能得到它的作业号呢？答案就是用 CTRL-z（按住Ctrl键的同时按住z键）了！&lt;/p&gt;

&lt;p&gt;CTRL-z 的用途就是将当前进程挂起（Suspend），然后我们就可以用jobs命令来查询它的作业号，再用bg jobspec来将它放入后台并继续运行。需要注意的是，如果挂起会影响当前进程的运行结果，请慎用此方法。&lt;/p&gt;

&lt;p&gt;disown 示例1（如果提交命令时已经用“&amp;amp;”将命令放入后台运行，则可以直接使用“disown”）
[root@pvcent107 build]# cp -r testLargeFile largeFile &amp;amp;
[1] 4825
[root@pvcent107 build]# jobs
[1]+  Running                 cp -i -r testLargeFile largeFile &amp;amp;
[root@pvcent107 build]# disown -h %1
[root@pvcent107 build]# ps -ef |grep largeFile
root      4825   968  1 09:46 pts/4    00:00:00 cp -i -r testLargeFile largeFile
root      4853   968  0 09:46 pts/4    00:00:00 grep largeFile
[root@pvcent107 build]# logout
disown 示例2（如果提交命令时未使用“&amp;amp;”将命令放入后台运行，可使用 CTRL-z 和“bg”将其放入后台，再使用“disown”）
[root@pvcent107 build]# cp -r testLargeFile largeFile2&lt;/p&gt;

&lt;p&gt;[1]+  Stopped                 cp -i -r testLargeFile largeFile2
[root@pvcent107 build]# bg %1
[1]+ cp -i -r testLargeFile largeFile2 &amp;amp;
[root@pvcent107 build]# jobs
[1]+  Running                 cp -i -r testLargeFile largeFile2 &amp;amp;
[root@pvcent107 build]# disown -h %1
[root@pvcent107 build]# ps -ef |grep largeFile2
root      5790  5577  1 10:04 pts/3    00:00:00 cp -i -r testLargeFile largeFile2
root      5824  5577  0 10:05 pts/3    00:00:00 grep largeFile2
[root@pvcent107 build]#
screen
场景：
我们已经知道了如何让进程免受 HUP 信号的影响，但是如果有大量这种命令需要在稳定的后台里运行，如何避免对每条命令都做这样的操作呢？&lt;/p&gt;

&lt;p&gt;解决方法：
此时最方便的方法就是 screen 了。简单的说，screen 提供了 ANSI/VT100 的终端模拟器，使它能够在一个真实终端下运行多个全屏的伪终端。screen 的参数很多，具有很强大的功能，我们在此仅介绍其常用功能以及简要分析一下为什么使用 screen 能够避免 HUP 信号的影响。我们先看一下 screen 的帮助信息：
SCREEN(1)                                                           SCREEN(1)&lt;/p&gt;

&lt;p&gt;NAME
       screen - screen manager with VT100/ANSI terminal emulation&lt;/p&gt;

&lt;p&gt;SYNOPSIS
       screen [ -options ] [ cmd [ args ] ]
       screen -r [[pid.]tty[.host]]
       screen -r sessionowner/[[pid.]tty[.host]]&lt;/p&gt;

&lt;p&gt;DESCRIPTION
       Screen  is  a  full-screen  window manager that multiplexes a physical
       terminal between several  processes  (typically  interactive  shells).
       Each  virtual  terminal provides the functions of a DEC VT100 terminal
       and, in addition, several control functions from the  ISO  6429  (ECMA
       48,  ANSI  X3.64)  and ISO 2022 standards (e.g. insert/delete line and
       support for multiple character sets).  There is a  scrollback  history
       buffer  for  each virtual terminal and a copy-and-paste mechanism that
       allows moving text regions between windows.
使用 screen 很方便，有以下几个常用选项：&lt;/p&gt;

&lt;p&gt;用screen -dmS session name来建立一个处于断开模式下的会话（并指定其会话名）。
用screen -list 来列出所有会话。
用screen -r session name来重新连接指定会话。
用快捷键CTRL-a d 来暂时断开当前会话。
screen 示例
[root@pvcent107 ~]# screen -dmS Urumchi
[root@pvcent107 ~]# screen -list
There is a screen on:
        12842.Urumchi   (Detached)
1 Socket in /tmp/screens/S-root.&lt;/p&gt;

&lt;p&gt;[root@pvcent107 ~]# screen -r Urumchi
当我们用“-r”连接到 screen 会话后，我们就可以在这个伪终端里面为所欲为，再也不用担心 HUP 信号会对我们的进程造成影响，也不用给每个命令前都加上“nohup”或者“setsid”了。这是为什么呢？让我来看一下下面两个例子吧。&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;
    &lt;p&gt;未使用 screen 时新进程的进程树
[root@pvcent107 ~]# ping www.google.com &amp;amp;
[1] 9499
[root@pvcent107 ~]# pstree -H 9499
init─┬─Xvnc
  ├─acpid
  ├─atd
  ├─2*[sendmail] 
  ├─sshd─┬─sshd───bash───pstree
  │       └─sshd───bash───ping
我们可以看出，未使用 screen 时我们所处的 bash 是 sshd 的子进程，当 ssh 断开连接时，HUP 信号自然会影响到它下面的所有子进程（包括我们新建立的 ping 进程）。&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;使用了 screen 后新进程的进程树
[root@pvcent107 ~]# screen -r Urumchi
[root@pvcent107 ~]# ping www.ibm.com &amp;amp;
[1] 9488
[root@pvcent107 ~]# pstree -H 9488
init─┬─Xvnc
  ├─acpid
  ├─atd
  ├─screen───bash───ping
  ├─2*[sendmail]
而使用了 screen 后就不同了，此时 bash 是 screen 的子进程，而 screen 是 init（PID为1）的子进程。那么当 ssh 断开连接时，HUP 信号自然不会影响到 screen 下面的子进程了。&lt;/p&gt;
  &lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;生产环境下，除了我们ssh登录上去，然后手动跑的那部分以外，其他都是自动运行的，这些大部分都应该是后台执行的。如何才能后台执行呢？&lt;/p&gt;

&lt;p&gt;nohup ./XXX &amp;amp;
由系统的其他daemon进程启动。这样的话，你的程序是它的子进程，跟终端没关系。退出终端也不会导致进程退出。如写在crontab里。
写成daemon程序，可以手动执行，退出终端时程序不退出。
如何选择呢？ 
（1）首先，清理过期日志这一类需求，可以写一个死循环一直运行，也可以写在crontab里，每次执行完就退出（如果每分钟一次可以满足的话）； 
（2）crontab的需要接受最多1分钟的时延，如果实时性要求更高一些，那么就需要考虑写个死循环了，这个程序可以由crontab来start和restart，只有在挂了重启时才会出现1分钟时延； 
（3）服务不能中断的（nginx、redis、apache，所有在线服务），一般都是daemon程序。但理论上用（2）似乎也可以；当然这两者细节上有很多区别。&lt;/p&gt;

&lt;p&gt;是nohup的关键代码了，首先向系统注册一个SIGHUP信号，处理方式是忽略，系统默认的方式kill进程，接着execvp函数执行参数后面的进程。&lt;/p&gt;

&lt;p&gt;为什么这样可以做到把代码放到后台运行呢，不让进程不因SIGHUP信号而终止呢，得弄清楚什么时候系统会向进程发送SINHUP信号呢，其实在posix标准里，linux也遵守这个标准，当用户在连接上linux终端后，当当前会话终端中断时，系统会向当前会话的前台进程组发送一个SIGHUP信号，系统默认对这个信号的处理方式是KILL该进程，如果进程忽视这个信号，没有被kill的话，接着系统会再次向该进程发送一个SIGCONT信号，nohup的作用就是让程序忽视SIGHUP信号，避免终端连接中断时，进程被kill，同时改变进程标准输入输出。&lt;/p&gt;

&lt;p&gt;其实有没有必要一定用nohup方式去启动后台进程呢，我觉得没有必要，当一个会话的终端中断后，系统只会给当前会话的前台进程组发送SIGHUP信号，如果启动进程时，让进程在后台去执行，也是执行的时候后面加一个&amp;amp;，也可以自己去重定向输入输出，会话的终端中断时，后台的进程组是不会收到SIGHUP信号，也就不会被系统kill掉，当然也可以在代码里注册SIGHUP该信号，防止进程被kill。
你可能会遇到nohup命令问题，这里将介绍nohup命令问题的解决方法,Linux本身是这个操作系统的核心部分，也就是操作系统的内核。内核 是完成那些最基本操作的程序，它负责其他程序（如文本编辑器程序）的启动与终止、内存申请处理硬盘访问、网络连接管理等方面的工作。Unix/Linux 下一般想让某个程序在后台运行，很多都是使用 &amp;amp; 在程序结尾来让程序自动运行。&lt;/p&gt;

&lt;p&gt;比如我们要运行mysql在后台：/usr/local/mysql/bin/mysqld_safe –user=mysql &amp;amp;但是我们很多程序并不象mysqld一样可以做成守护进程，可能我们的程序只是普通程序而已，一般这种程序即使使用 &amp;amp; 结尾，如果终端关闭，那么程序也会被关闭。为了能够后台运行，我们需要使用nohup命令，比如我们有个start.sh需要在后台运行，并且希望在后台 能够一直运行，那么就使用nohup：&lt;/p&gt;

&lt;p&gt;nohup /root/start.sh &amp;amp;&lt;/p&gt;

&lt;p&gt;在shell中回车后提示：
[~]$ appending output to nohup.out原程序的的标准输出被自动改向到当前目录下的nohup.out文件，起到了log的作用。但是有时候在这一步会有问题，当把终端关闭 后，进程会自动被关闭，察看nohup.out可以看到在关闭终端瞬间服务自动关闭。咨询红旗Linux工程师后，他也不得其解，在我的终端上执行后，他 启动的进程竟然在关闭终端后依然运行。&lt;/p&gt;

&lt;p&gt;在第二遍给我演示时，我才发现我和他操作终端时的一个细节不同：他是在当shell中提示了nohup成功后还需要按终端上键盘任意键退回到 shell输入命令窗口，然后通过在shell中输入exit来退出终端；而我是每次在nohup执行成功后直接点关闭程序按钮关闭终端.。所以这时候会 断掉该命令所对应的session，导致nohup对应的进程被通知需要一起shutdown。这个细节有人和我一样没注意到，所以在这儿记录一下了。&lt;/p&gt;

&lt;p&gt;附：nohup命令参考nohup命令
用途：不挂断地运行命令。
语法：nohup Command [ Arg … ] [　&amp;amp; ]
描 述：nohup命令运行由 Command 参数和任何相关的 Arg 参数指定的命令，忽略所有挂断（SIGHUP）信号。在注销后使用 nohup 命令运行后台中的程序。要运行后台中的 nohup命令，添加 &amp;amp; （ 表示”and”的符号）到命令的尾部。&lt;/p&gt;

&lt;p&gt;无论是否将 nohup命令的输出重定向到终端，输出都将附加到当前目录的 nohup.out 文件中。如果当前目录的 nohup.out 文件不可写，输出重定向到 $HOME/nohup.out 文件中。如果没有文件能创建或打开以用于追加，那么 Command 参数指定的命令不可调用。如果标准错误是一个终端，那么把指定的命令写给标准错误的所有输出作为标准输出重定向到相同的文件描述符。&lt;/p&gt;

&lt;p&gt;退出状态：该命令返回下列出口值：126 可以查找但不能调用 Command 参数指定的命令。127 nohup 命令发生错误或不能查找由 Command 参数指定的命令。否则，nohup命令的退出状态是 Command 参数指定nohup命令的退出状态。&lt;/p&gt;

&lt;p&gt;nohup命令及其输出文件&lt;/p&gt;

&lt;p&gt;nohup命令：如果你正在运行一个进程，而且你觉得在退出帐户时该进程还不会结束，那么可以使用nohup命令。该命令可以在你退出帐户/关闭终端之后继续运行相应的进程。nohup就是不挂起的意思( n ohang up)。&lt;/p&gt;

&lt;p&gt;该命令的一般形式为：nohup command &amp;amp;使用nohup命令提交作业
如果使用nohup命令提交作业，那么在缺省情况下该作业的所有输出都被重定向到一个名为nohup.out的文件中，除非另外指定了输出文件：
nohup command &amp;gt; myout.file 2&amp;gt;&amp;amp;1 &amp;amp;在上面的例子中，输出被重定向到myout.file文件中。使用 jobs 查看任务。使用 fg %n　关闭。&lt;/p&gt;

&lt;p&gt;另外有两个常用的ftp工具ncftpget和ncftpput，可以实现后台的ftp上传和下载，这样就可以利用这些命令在后台上传和下载文件了。&lt;/p&gt;

&lt;p&gt;unix中进程组织结构为session包含一个前台进程组及一个或多个后台进程组，一个进程组包含多个进程。&lt;/p&gt;

&lt;p&gt;一个session可能会有一个session首进程，而一个session首进程可能会有一个控制终端。&lt;/p&gt;

&lt;p&gt;一个进程组可能会有一个进程组首进程。&lt;/p&gt;

&lt;p&gt;进程组首进程的进程与该进程组ID相等。&lt;/p&gt;

&lt;p&gt;这儿是可能会有，在一定情况之下是没有的。&lt;/p&gt;

&lt;p&gt;与终端交互的进程是前台进程，否则便是后台进程。&lt;/p&gt;

&lt;p&gt;SIGHUP会在以下3种情况下被发送给相应的进程：&lt;/p&gt;

&lt;p&gt;1、终端关闭时，该信号被发送到首进程以及作为job提交的进程（即用 &amp;amp; 符号提交的进程）&lt;/p&gt;

&lt;p&gt;2、session首进程退出时，该信号被发送到该session中的前台进程组中的每一个进程&lt;/p&gt;

&lt;p&gt;3、若父进程退出导致进程组成为孤儿进程组，且该进程组中有进程处于停止状态（收到SIGSTOP或SIGTSTP信号），该信号会被发送到该进程组中的每一个进程。&lt;/p&gt;

&lt;p&gt;系统对信号的默认处理是终止收到该信号的进程。&lt;/p&gt;

&lt;p&gt;所以若程序中没有捕捉该信号，当收到该信号时，进程就会退出。&lt;/p&gt;

&lt;p&gt;下面观察几种因终端关闭导致进程退出的情况，在这儿进程退出是因为收到了SIGHUP信号。&lt;/p&gt;

&lt;p&gt;login shell是session首进程。&lt;/p&gt;

&lt;p&gt;编译后的执行文件为sigtest&lt;/p&gt;

&lt;p&gt;1、命令： sigtest front &amp;gt; tt.txt&lt;/p&gt;

&lt;p&gt;操作： 关闭终端&lt;/p&gt;

&lt;p&gt;结果： tt文件的内容为front: sighup received&lt;/p&gt;

&lt;p&gt;原因：&lt;/p&gt;

&lt;p&gt;sigtest是前台进程，终端关闭后，根据上面提到的第1种情况， loginshell作为session首进程，会收到SIGHUP信号然后退出，&lt;/p&gt;

&lt;p&gt;根据第2种情况，sigtest作为前台进程，会收到login shell发出的SIGHUP信号。&lt;/p&gt;

&lt;p&gt;2、命令：&lt;/p&gt;

&lt;p&gt;sigtest back &amp;gt; tt.txt &amp;amp;&lt;/p&gt;

&lt;p&gt;操作：&lt;/p&gt;

&lt;p&gt;关闭终端&lt;/p&gt;

&lt;p&gt;结果：&lt;/p&gt;

&lt;p&gt;tt文件的内容为back: sighup received&lt;/p&gt;

&lt;p&gt;原因：&lt;/p&gt;

&lt;p&gt;sigtest是提交的job，根据上面提到的第1种情况，sigtest会收到SIGHUP信号&lt;/p&gt;

&lt;p&gt;3、写一个shell，内容为&lt;/p&gt;

&lt;p&gt;[cpp] view plain copy
sigtest &amp;amp;&lt;br /&gt;
执行该shell&lt;/p&gt;

&lt;p&gt;操作： 关闭终端&lt;/p&gt;

&lt;table&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td&gt;结果： ps -ef&lt;/td&gt;
      &lt;td&gt;grep sigtest会看到该进程还在，tt文件为空&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;p&gt;原因：&lt;/p&gt;

&lt;p&gt;执行该shell时，sigtest作为job提交，然后该shell退出，致使sigtest变成了孤儿进程，不再是当前session的job了，&lt;/p&gt;

&lt;p&gt;因此sigtest即不是session首进程也不是job，不会收到SIGHUP&lt;/p&gt;

&lt;p&gt;同时孤儿进程属于后台进程，因此loginshell退出后不会发送SIGHUP给sigtest，因为它只将该信号发送给前台进程。&lt;/p&gt;

&lt;p&gt;第3条说过若进程组变成孤儿进程组的时候，若有进程处于停止状态，也会收到SIGHUP信号，但sigtest没有处于停止状态，所以不会收到SIGHUP信号&lt;/p&gt;

&lt;p&gt;4、nohup sigtest &amp;gt; tt&lt;/p&gt;

&lt;p&gt;操作：&lt;/p&gt;

&lt;p&gt;关闭终端&lt;/p&gt;

&lt;p&gt;结果： tt文件为空&lt;/p&gt;

&lt;p&gt;原因：nohup可以防止进程收到SIGHUP信号&lt;/p&gt;

&lt;p&gt;至此，我们就清楚了何种情况下终端关闭后进程会退出，何种情况下不会退出。&lt;/p&gt;

&lt;p&gt;要想终端关闭后进程不退出有以下几种方法，均为通过shell的方式：&lt;/p&gt;

&lt;p&gt;1、 编写shell，内容如下&lt;/p&gt;

&lt;p&gt;[cpp] view plain copy
trap “” SIGHUP  #该句的作用是屏蔽SIGHUP信号，trap可以屏蔽很多信号&lt;/p&gt;

&lt;p&gt;sigtest&lt;/p&gt;

&lt;p&gt;2、nohup sigtest可以直接在命令行执行，&lt;/p&gt;

&lt;p&gt;若想做完该操作后继续别的操作， 可以执行&lt;/p&gt;

&lt;p&gt;[cpp] view plain copy
nohup sigtest &amp;amp;&lt;/p&gt;

&lt;p&gt;3、 编写shell，内容如下&lt;/p&gt;

&lt;p&gt;[cpp] view plain copy
sigtest &amp;amp;&lt;/p&gt;

&lt;p&gt;其实任何将进程变为孤儿进程的方式都可以，包括fork后父进程马上退出&lt;/p&gt;

</description>
        <pubDate>Wed, 24 Jan 2018 00:00:00 +0800</pubDate>
        <link>https://xiazemin.github.io/MyBlog/linux/2018/01/24/nohup.html</link>
        <guid isPermaLink="true">https://xiazemin.github.io/MyBlog/linux/2018/01/24/nohup.html</guid>
        
        
        <category>linux</category>
        
      </item>
    
      <item>
        <title>mongodb</title>
        <description>&lt;!-- more --&gt;
&lt;p&gt;一、概念：&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;  分片（sharding）是指将数据库拆分，将其分散在不同的机器上的过程。将数据分散到不同的机器上，不需要功能强大的服务器就可以存储更多的数据和处理更大的负载。基本思想就是将集合切成小块，这些块分散到若干片里，每个片只负责总数据的一部分，最后通过一个均衡器来对各个分片进行均衡（数据迁移）。通过一个名为mongos的路由进程进行操作，mongos知道数据和片的对应关系（通过配置服务器）。大部分使用场景都是解决磁盘空间的问题，对于写入有可能会变差（+++里面的说明+++），查询则尽量避免跨分片查询。使用分片的时机：
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;1，机器的磁盘不够用了。使用分片解决磁盘空间的问题。
2，单个mongod已经不能满足写数据的性能要求。通过分片让写压力分散到各个分片上面，使用分片服务器自身的资源。
3，想把大量数据放到内存里提高性能。和上面一样，通过分片使用分片服务器自身的资源。
二、部署安装： 前提是安装了mongodb（本文用3.0测试）&lt;/p&gt;

&lt;p&gt;在搭建分片之前，先了解下分片中各个角色的作用。&lt;/p&gt;

&lt;p&gt;① 配置服务器。是一个独立的mongod进程，保存集群和分片的元数据，即各分片包含了哪些数据的信息。最先开始建立，启用日志功能。像启动普通的mongod一样启动配置服务器，指定configsvr选项。不需要太多的空间和资源，配置服务器的1KB空间相当于真是数据的200MB。保存的只是数据的分布表。当服务不可用，则变成只读，无法分块、迁移数据。
② 路由服务器。即mongos，起到一个路由的功能，供程序连接。本身不保存数据，在启动时从配置服务器加载集群信息，开启mongos进程需要知道配置服务器的地址，指定configdb选项。
③ 分片服务器。是一个独立普通的mongod进程，保存数据信息。可以是一个副本集也可以是单独的一台服务器。
部署环境：3台机子&lt;/p&gt;

&lt;p&gt;A：配置(3)、路由1、分片1；&lt;/p&gt;

&lt;p&gt;B：分片2，路由2；&lt;/p&gt;

&lt;p&gt;C：分片3&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;  在部署之前先明白片键的意义，一个好的片键对分片至关重要。片键必须是一个索引，数据根据这个片键进行拆分分散。通过sh.shardCollection加会自动创建索引。一个自增的片键对写入和数据均匀分布就不是很好，因为自增的片键总会在一个分片上写入，后续达到某个阀值可能会写到别的分片。但是按照片键查询会非常高效。随机片键对数据的均匀分布效果很好。注意尽量避免在多个分片上进行查询。在所有分片上查询，mongos会对结果进行归并排序。
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;启动上面这些服务，因为在后台运行，所以用配置文件启动，配置文件说明。&lt;/p&gt;

&lt;p&gt;1）配置服务器的启动。(A上开启3个，Port：20000、21000、22000)&lt;/p&gt;

&lt;p&gt;配置服务器是一个普通的mongod进程，所以只需要新开一个实例即可。配置服务器必须开启1个或则3个，开启2个则会报错：&lt;/p&gt;

&lt;p&gt;BadValue need either 1 or 3 configdbs
因为要放到后台用用配置文件启动，需要修改配置文件：&lt;/p&gt;

&lt;p&gt;/etc/mongod_20000.conf&lt;/p&gt;

&lt;p&gt;复制代码
#数据目录
dbpath=/usr/local/config/
#日志文件
logpath=/var/log/mongodb/mongodb_config.log
#日志追加
logappend=true
#端口
port = 20000
#最大连接数
maxConns = 50
pidfilepath = /var/run/mongo_20000.pid
#日志,redo log
journal = true
#刷写提交机制
journalCommitInterval = 200
#守护进程模式
fork = true
#刷写数据到日志的频率
syncdelay = 60
#storageEngine = wiredTiger
#操作日志,单位M
oplogSize = 1000
#命名空间的文件大小,默认16M，最大2G。
nssize = 16
noauth = true
unixSocketPrefix = /tmp
configsvr = true
复制代码
/etc/mongod_21000.conf&lt;/p&gt;

&lt;p&gt;复制代码
数据目录
dbpath=/usr/local/config1/
#日志文件
logpath=/var/log/mongodb/mongodb_config1.log
#日志追加
logappend=true
#端口
port = 21000
#最大连接数
maxConns = 50
pidfilepath = /var/run/mongo_21000.pid
#日志,redo log
journal = true
#刷写提交机制
journalCommitInterval = 200
#守护进程模式
fork = true
#刷写数据到日志的频率
syncdelay = 60
#storageEngine = wiredTiger
#操作日志,单位M
oplogSize = 1000
#命名空间的文件大小,默认16M，最大2G。
nssize = 16
noauth = true
unixSocketPrefix = /tmp
configsvr = true
复制代码
开启配置服务器：&lt;/p&gt;

&lt;p&gt;复制代码
root@mongo1:~# mongod -f /etc/mongod_20000.conf 
about to fork child process, waiting until server is ready for connections.
forked process: 8545
child process started successfully, parent exiting&lt;/p&gt;

&lt;p&gt;root@mongo1:~# mongod -f /etc/mongod_21000.conf 
about to fork child process, waiting until server is ready for connections.
forked process: 8595
child process started successfully, parent exiting
复制代码
同理再起一个22000端口的配置服务器。&lt;/p&gt;

&lt;p&gt;View Code
2）路由服务器的启动。(A、B上各开启1个，Port：30000)&lt;/p&gt;

&lt;p&gt;路由服务器不保存数据，把日志记录一下即可。&lt;/p&gt;

&lt;p&gt;复制代码&lt;/p&gt;
&lt;h1 id=&quot;mongos&quot;&gt;mongos&lt;/h1&gt;

&lt;p&gt;#日志文件
logpath=/var/log/mongodb/mongodb_route.log
#日志追加
logappend=true
#端口
port = 30000
#最大连接数
maxConns = 100
#绑定地址
#bind_ip=192.168.200.*,…,&lt;/p&gt;

&lt;p&gt;pidfilepath = /var/run/mongo_30000.pid&lt;/p&gt;

&lt;p&gt;configdb=192.168.200.A:20000,192.168.200.A:21000,192.168.200.A:22000  #必须是1个或则3个配置 。
#configdb=127.0.0.1:20000  #报错
#守护进程模式 fork = true
复制代码
其中最重要的参数是configdb，不能在其后面带的配置服务器的地址写成localhost或则127.0.0.1，需要设置成其他分片也能访问的地址，即192.168.200.A:20000/21000/22000。否则在addshard的时候会报错：&lt;/p&gt;

&lt;p&gt;{
“ok” : 0,
“errmsg” : “can’t use localhost as a shard since all shards need to communicate. either use all shards and configdbs in localhost or all in actual IPs  host: 172.16.5.104:20000 isLocalHost:0”
}
开启mongos：&lt;/p&gt;

&lt;p&gt;root@mongo1:~# mongos -f /etc/mongod_30000.conf 
2015-07-10T14:42:58.741+0800 W SHARDING running with 1 config server should be done only for testing purposes and is not recommended for production
about to fork child process, waiting until server is ready for connections.
forked process: 8965
child process started successfully, parent exiting
3）分片服务器的启动：&lt;/p&gt;

&lt;p&gt;就是一个普通的mongod进程：&lt;/p&gt;

&lt;p&gt;root@mongo1:~# mongod -f /etc/mongod_40000.conf 
note: noprealloc may hurt performance in many applications
about to fork child process, waiting until server is ready for connections.
forked process: 9020
child process started successfully, parent exiting
A服务器上面的服务开启完毕&lt;/p&gt;

&lt;p&gt;root@mongo1:~# ps -ef | grep mongo
root      9020     1  0 14:47 ?        00:00:06 mongod -f /etc/mongod_40000.conf
root      9990     1  0 15:14 ?        00:00:02 mongod -f /etc/mongod_20000.conf
root     10004     1  0 15:14 ?        00:00:01 mongod -f /etc/mongod_21000.conf
root     10076     1  0 15:20 ?        00:00:00 mongod -f /etc/mongod_22000.conf
root     10096     1  0 15:20 ?        00:00:00 mongos -f /etc/mongod_30000.conf
按照上面的方法再到B上开启分片服务和路由服务(配置文件一样)，以及在C上开启分片服务。到此分片的配置服务器、路由服务器、分片服务器都已经部署完成。&lt;/p&gt;

&lt;p&gt;三、配置分片：下面的操作都是在mongodb的命令行里执行&lt;/p&gt;

&lt;p&gt;1）添加分片：sh.addShard(“IP:Port”)&lt;/p&gt;

&lt;p&gt;登陆路由服务器mongos 操作：&lt;/p&gt;

&lt;p&gt;root@mongo1:~# mongo –port=30000
MongoDB shell version: 3.0.4
connecting to: 127.0.0.1:30000/test
mongos&amp;gt; 
添加分片：&lt;/p&gt;

&lt;p&gt;复制代码
mongos&amp;gt; sh.status()    #查看集群的信息
— Sharding Status — 
  sharding version: {
    “_id” : 1,
    “minCompatibleVersion” : 5,
    “currentVersion” : 6,
    “clusterId” : ObjectId(“559f72470f93270ba60b26c6”)
}
  shards:
  balancer:
    Currently enabled:  yes
    Currently running:  no
    Failed balancer rounds in last 5 attempts:  0
    Migration Results for the last 24 hours: 
        No recent migrations
  databases:
    {  “_id” : “admin”,  “partitioned” : false,  “primary” : “config” }&lt;/p&gt;

&lt;p&gt;mongos&amp;gt; sh.addShard(“192.168.200.A:40000”) #添加分片
{ “shardAdded” : “shard0000”, “ok” : 1 }
mongos&amp;gt; sh.addShard(“192.168.200.B:40000”) #添加分片
{ “shardAdded” : “shard0001”, “ok” : 1 }
mongos&amp;gt; sh.addShard(“192.168.200.C:40000”) #添加分片
{ “shardAdded” : “shard0002”, “ok” : 1 }&lt;/p&gt;

&lt;p&gt;mongos&amp;gt; sh.status()    #查看集群信息
— Sharding Status — 
  sharding version: {
    “_id” : 1,
    “minCompatibleVersion” : 5,
    “currentVersion” : 6,
    “clusterId” : ObjectId(“559f72470f93270ba60b26c6”)
}
  shards:  #分片信息
    {  “_id” : “shard0000”,  “host” : “192.168.200.A:40000” }
    {  “_id” : “shard0001”,  “host” : “192.168.200.B:40000” }
    {  “_id” : “shard0002”,  “host” : “192.168.200.C:40000” }
  balancer:
    Currently enabled:  yes
    Currently running:  no
    Failed balancer rounds in last 5 attempts:  0
    Migration Results for the last 24 hours: 
        No recent migrations
  databases:
    {  “_id” : “admin”,  “partitioned” : false,  “primary” : “config” }
复制代码
2）开启分片功能：sh.enableSharding(“库名”)、sh.shardCollection(“库名.集合名”,{“key”:1})&lt;/p&gt;

&lt;p&gt;复制代码
mongos&amp;gt; sh.enableSharding(“dba”)  #首先对数据库启用分片
{ “ok” : 1 }
mongos&amp;gt; sh.status()               #查看分片信息
— Sharding Status —…
…
  databases:
    {  “_id” : “admin”,  “partitioned” : false,  “primary” : “config” }
    {  “_id” : “test”,  “partitioned” : false,  “primary” : “shard0000” }
    {  “_id” : “dba”,  “partitioned” : true,  “primary” : “shard0000” }&lt;/p&gt;

&lt;p&gt;mongos&amp;gt; sh.shardCollection(“dba.account”,{“name”:1})    #再对集合进行分片，name字段是片键。片键的选择：利于分块、分散写请求、查询数据。
{ “collectionsharded” : “dba.account”, “ok” : 1 }
mongos&amp;gt; sh.status()
— Sharding Status —…
  shards:
    {  “_id” : “shard0000”,  “host” : “192.168.200.51:40000” }
    {  “_id” : “shard0001”,  “host” : “192.168.200.52:40000” }
    {  “_id” : “shard0002”,  “host” : “192.168.200.53:40000” }
…
  databases:
    {  “_id” : “admin”,  “partitioned” : false,  “primary” : “config” }
    {  “_id” : “test”,  “partitioned” : false,  “primary” : “shard0000” }
    {  “_id” : “dba”,  “partitioned” : true,  “primary” : “shard0000” }  #库
        dba.account
            shard key: { “name” : 1 }                                    #集合
            chunks:
                shard0000    1
            { “name” : { “$minKey” : 1 } } –» { “name” : { “$maxKey” : 1 } } on : shard0000 Timestamp(1, 0) 
复制代码
上面加粗部分表示分片信息已经配置完成。要是出现：&lt;/p&gt;

&lt;p&gt;too many chunks to print, use verbose if you want to force print
想要看到详细的信息则需要执行：&lt;/p&gt;

&lt;p&gt;mongos&amp;gt; sh.status({“verbose”:1})
或则
mongos&amp;gt; db.printShardingStatus(“vvvv”)
或则
mongos&amp;gt; printShardingStatus(db.getSisterDB(“config”),1)
四、测试 ：对dba库的account集合进行测试，随机写入，查看是否分散到3个分片中。&lt;/p&gt;

&lt;p&gt;判断是否为shard：db.runCommand({isdbgrid:1})&lt;/p&gt;

&lt;p&gt;mongos&amp;gt; db.runCommand({isdbgrid:1})
{ “isdbgrid” : 1, “hostname” : “mongo3c”, “ok” : 1 }
通过一个python脚本进行随机写入：分别向A、B 2个mongos各写入10万条记录。&lt;/p&gt;

&lt;p&gt;View Code
查看是否分片：db.collection.stats()&lt;/p&gt;

&lt;p&gt;复制代码
mongos&amp;gt; db.account.stats() #查看集合的分布情况
…
…
    “shards” : {
        “shard0000” : {
            “ns” : “dba.account”,
            “count” : 89710,
            “size” : 10047520,
…
…
        “shard0001” : {
            “ns” : “dba.account”,
            “count” : 19273,
            “size” : 2158576,
…
…
        “shard0002” : {
            “ns” : “dba.account”,
            “count” : 91017,
            “size” : 10193904,
…
…
复制代码
上面加粗部分为集合的基本信息，可以看到分片成功，各个分片都有数据(count)。到此MongoDB分片集群搭建成功。&lt;/p&gt;

&lt;p&gt;++++++++++++++++++++++++++++++++++++++++++++++++&lt;/p&gt;

&lt;p&gt;感兴趣的同学可以看下面这个比较有趣的现象：&lt;/p&gt;

&lt;p&gt;复制代码
#在写之前分片的基本信息：
mongos&amp;gt; sh.status()
— Sharding Status — 
…
…
  databases:
    {  “_id” : “admin”,  “partitioned” : false,  “primary” : “config” }
    {  “_id” : “test”,  “partitioned” : false,  “primary” : “shard0000” }
    {  “_id” : “dba”,  “partitioned” : true,  “primary” : “shard0000” }
        dba.account
            shard key: { “name” : 1 }
            chunks:
                shard0000    1
            { “name” : { “$minKey” : 1 } } –» { “name” : { “$maxKey” : 1 } } on : shard0000 Timestamp(1, 0)   #可以看到这里片键的写入，都是写在shard0000里面的。&lt;/p&gt;

&lt;p&gt;#在写期间的分片基本信息：
mongos&amp;gt; sh.status()
— Sharding Status — 
…
…
  databases:
    {  “_id” : “admin”,  “partitioned” : false,  “primary” : “config” }
    {  “_id” : “test”,  “partitioned” : false,  “primary” : “shard0000” }
    {  “_id” : “dba”,  “partitioned” : true,  “primary” : “shard0000” }
        dba.account
            shard key: { “name” : 1 }
            chunks:          #数据块分布
                shard0000    1
                shard0001    1
                shard0002    1
            { “name” : { “$minKey” : 1 } } –» { “name” : “5yyfY8mmR5HyhGJ” } on : shard0001 Timestamp(2, 0) 
            { “name” : “5yyfY8mmR5HyhGJ” } –» { “name” : “woQAv99Pq1FVoMX” } on : shard0002 Timestamp(3, 0) 
            { “name” : “woQAv99Pq1FVoMX” } –» { “name” : { “$maxKey” : 1 } } on : shard0000 Timestamp(3, 1)   #可以看到片键写入的基本分布&lt;/p&gt;

&lt;p&gt;#在写完成后的基本信息：
mongos&amp;gt; sh.status()
— Sharding Status — 
…
…
  databases:
    {  “_id” : “admin”,  “partitioned” : false,  “primary” : “config” }
    {  “_id” : “test”,  “partitioned” : false,  “primary” : “shard0000” }
    {  “_id” : “dba”,  “partitioned” : true,  “primary” : “shard0000” }
        dba.account
            shard key: { “name” : 1 }
            chunks:          #数据块分布
                shard0000    2
                shard0001    1
                shard0002    2
            { “name” : { “$minKey” : 1 } } –» { “name” : “5yyfY8mmR5HyhGJ” } on : shard0001 Timestamp(2, 0) 
            { “name” : “5yyfY8mmR5HyhGJ” } –» { “name” : “UavMbMlfszZOFrz” } on : shard0000 Timestamp(4, 0) 
            { “name” : “UavMbMlfszZOFrz” } –» { “name” : “t9LyVSNXDmf6esP” } on : shard0002 Timestamp(4, 1) 
            { “name” : “t9LyVSNXDmf6esP” } –» { “name” : “woQAv99Pq1FVoMX” } on : shard0002 Timestamp(3, 4) 
            { “name” : “woQAv99Pq1FVoMX” } –» { “name” : { “$maxKey” : 1 } } on : shard0000 Timestamp(3, 1)  #最后片键写入的分布
复制代码
上面加粗的信息对比上看到，本来在每个分片上都只有一个块，最后在shard0000、shard0002上有2个块，被拆分了。shard0001不变。这是因为mongos在收到写请求的时候，会检查当前块的拆分阀值点。到达该阀值的时候，会向分片发起一个拆分的请求。例子中shard0000和shard0002里的块被拆分了。分片内的数据进行了迁移（有一定的消耗），最后通过一个均衡器来对数据进行转移分配。所以在写入途中要是看到一个分片中集合的数量变小也是正常的。&lt;/p&gt;

&lt;p&gt;balancer:  #均衡器
    Currently enabled:  yes
    Currently running:  yes   #正在转移
        Balancer lock taken at Fri Jul 10 2015 22:57:27 GMT+0800 (CST) by mongo2:30000:1436540125:1804289383:Balancer:846930886
均衡器：均衡器负责数据迁移，周期性的检查分片是否存在不均衡，如果不存在则会开始块的迁移，config.locks集合里的state表示均衡器是否找正在运行，0表示非活动状态，2表示正在均衡。均衡迁移数据的过程会增加系统的负载：目标分片必须查询源分片的所有文档，将文档插入目标分片中，再清除源分片的数据。可以关闭均衡器（不建议）：关闭会导致各分片数据分布不均衡，磁盘空间得不到有效的利用。&lt;/p&gt;

&lt;p&gt;mongos&amp;gt; sh.setBalancerState(false)  #关闭自动均衡器，手动均衡，打开：sh.setBalancerState(true)
mongos&amp;gt; db.settings.find()          #查看均衡器状态
{ “_id” : “balancer”, “stopped” : true }
可以为均衡器设置一个均衡时间窗口：activeWindow&lt;/p&gt;

&lt;p&gt;mongos&amp;gt; db.settings.update({“_id”:”balancer”},{“$set”:{“activeWindow”:{“start”:”08:00”,”stop”:”02:00”}}},true)
WriteResult({ “nMatched” : 1, “nUpserted” : 0, “nModified” : 1 })
mongos&amp;gt; db.settings.find({“_id”:”balancer”})
{ “_id” : “balancer”, “stopped” : false, “activeWindow” : { “start” : “08:00”, “stop” : “02:00” } }
上面说明：均衡只会在早上8点到凌晨2点进行均衡操作。均衡器是以块的数量作为迁移指标，而非数据大小，块的大小默认是64M，可以修改:(config.settings)&lt;/p&gt;

&lt;p&gt;mongos&amp;gt; db.settings.find()
{ “_id” : “chunksize”, “value” : 64 }
mongos&amp;gt; db.settings.save({“_id”:”chunksize”,”value”:32})
WriteResult({ “nMatched” : 1, “nUpserted” : 0, “nModified” : 1 })
mongos&amp;gt; db.settings.find()
{ “_id” : “chunksize”, “value” : 32 }
上面把块的默认大小改成了32M，除了通过均衡器自动迁移外，还可以手动迁移数据：sh.moveChunk(“db.collection”,{块地址},”新片名称”)&lt;/p&gt;

&lt;p&gt;复制代码
mongos&amp;gt; db.chunks.find({“&lt;em&gt;id” : “abc.account-name&lt;/em&gt;&quot;wPeFnJEvendSTbH&quot;”}).pretty() #先到config.chunks上任意找一个块
{
    “&lt;em&gt;id” : “abc.account-name&lt;/em&gt;&quot;wPeFnJEvendSTbH&quot;”,
    “lastmod” : Timestamp(3, 1),
    “lastmodEpoch” : ObjectId(“55a52ff1fdd9a605a0371327”),
    “ns” : “abc.account”,
    “min” : {
        “name” : “wPeFnJEvendSTbH”              #被移动的块
    },
    “max” : {
        “name” : { “$maxKey” : 1 }
    },
    “shard” : “shard0000”                       #原先所在的分片
}
mongos&amp;gt; sh.moveChunk(“abc.account”,{“name” : “wPeFnJEvendSTbH”},”mablevi”)  #把abc.account集合中包含name(片键)为”“的快迁移到mablevi分片中
{ “millis” : 6800, “ok” : 1 }
mongos&amp;gt; db.chunks.find({“&lt;em&gt;id” : “abc.account-name&lt;/em&gt;&quot;wPeFnJEvendSTbH&quot;”}).pretty()&lt;br /&gt;
{
    “&lt;em&gt;id” : “abc.account-name&lt;/em&gt;&quot;wPeFnJEvendSTbH&quot;”,
    “lastmod” : Timestamp(5, 0),
    “lastmodEpoch” : ObjectId(“55a52ff1fdd9a605a0371327”),
    “ns” : “abc.account”,
    “min” : {
        “name” : “wPeFnJEvendSTbH”
    },
    “max” : {
        “name” : { “$maxKey” : 1 }
    },
    “shard” : “mablevi”                        #已被迁移到新片
}
复制代码
上面是手动移动数据的操作，数据被移动。 要是块超出了64M限制【原因是片键没选好(日期、状态值等)，导致一个块无限增大】，则无法进行自动均衡，无法分块。有2个办法：1是加大块的大小(setting)，2是拆分sh.splitAt()（推荐）。&lt;/p&gt;

&lt;p&gt;所以要是遇到分片写入比单点写入慢就是因为分片路由服务（mongos）需要维护元数据、数据迁移、路由开销等。&lt;/p&gt;

&lt;p&gt;++++++++++++++++++++++++++++++++++++++++++++++++&lt;/p&gt;

&lt;p&gt;五、高可用：Sharding+Replset&lt;/p&gt;

&lt;p&gt;上面的分片都是单点的，要是一个分片坏了，则数据会丢失，利用之前减少的副本集，能否把副本集加入到分片中？下面就来说明下。&lt;/p&gt;

&lt;p&gt;1）添加副本集分片服务器（mmm副本集名称）：这里测试就只对一个分片加副本集，要实现完全的高可用就需要对所有分片加副本集，避免单点故障&lt;/p&gt;

&lt;p&gt;一个普通的副本集：&lt;/p&gt;

&lt;p&gt;View Code
现在需要把这个副本集加入到分片中：&lt;/p&gt;

&lt;p&gt;复制代码
mongos&amp;gt; sh.addShard(“mmm/192.168.200.25:27017,192.168.200.245:27017,192.168.200.245:37017”) #加入副本集分片
{ “shardAdded” : “mmm”, “ok” : 1 }&lt;/p&gt;

&lt;p&gt;mongos&amp;gt; sh.status()
— Sharding Status — 
…
…
shards:
    {  “_id” : “mmm”,  “host” : “mmm/192.168.200.245:27017,192.168.200.245:37017,192.168.200.25:27017” }
    {  “_id” : “shard0000”,  “host” : “192.168.200.51:40000” }
    {  “_id” : “shard0001”,  “host” : “192.168.200.52:40000” }
    {  “_id” : “shard0002”,  “host” : “192.168.200.53:40000” }
  balancer:
    Currently enabled:  yes
    Currently running:  no
    Failed balancer rounds in last 5 attempts:  0
    Migration Results for the last 24 hours: 
        4 : Success
  databases:
    {  “_id” : “admin”,  “partitioned” : false,  “primary” : “config” }
    {  “_id” : “test”,  “partitioned” : false,  “primary” : “shard0000” }
    {  “_id” : “dba”,  “partitioned” : true,  “primary” : “shard0000” }
        dba.account
            shard key: { “name” : 1 }
            chunks:
                mmm    1
                shard0000    1
                shard0001    1
                shard0002    2
            { “name” : { “$minKey” : 1 } } –» { “name” : “5yyfY8mmR5HyhGJ” } on : shard0001 Timestamp(2, 0) 
            { “name” : “5yyfY8mmR5HyhGJ” } –» { “name” : “UavMbMlfszZOFrz” } on : mmm Timestamp(5, 0) 
            { “name” : “UavMbMlfszZOFrz” } –» { “name” : “t9LyVSNXDmf6esP” } on : shard0002 Timestamp(4, 1) 
            { “name” : “t9LyVSNXDmf6esP” } –» { “name” : “woQAv99Pq1FVoMX” } on : shard0002 Timestamp(3, 4) 
            { “name” : “woQAv99Pq1FVoMX” } –» { “name” : { “$maxKey” : 1 } } on : shard0000 Timestamp(5, 1) 
    {  “_id” : “abc”,  “partitioned” : false,  “primary” : “shard0000” }   #未设置分片
复制代码
上面加粗部分表示副本集分片已经成功加入，并且新加入的分片会分到已有的分片数据。&lt;/p&gt;

&lt;p&gt;复制代码
mongos&amp;gt; db.account.stats()
…
…
    “shards” : {
        “mmm” : {
            “ns” : “dba.account”,
            “count” : 7723,        #后加入的分片得到了数据
            “size” : 741408,
            “avgObjSize” : 96,
            “storageSize” : 2793472,
            “numExtents” : 5,
            “nindexes” : 2,
            “lastExtentSize” : 2097152,
            “paddingFactor” : 1,
            “systemFlags” : 1,
            “userFlags” : 0,
            “totalIndexSize” : 719488,
            “indexSizes” : {
                “&lt;em&gt;id&lt;/em&gt;” : 343392,
                “name_1” : 376096
            },
            “ok” : 1
        },
…
…
复制代码
2）继续用python脚本写数据，填充到副本集中&lt;/p&gt;

&lt;p&gt;由于之前的副本集是比较老的版本（2.4），所以在写入副本集分片的时候报错：&lt;/p&gt;

&lt;p&gt;复制代码
mongos&amp;gt; db.account.insert({“name”:”UavMbMlfsz1OFrz”})
WriteResult({
    “nInserted” : 0,
    “writeError” : {
        “code” : 83,
        “errmsg” : “write results unavailable from 192.168.200.25:27017 :: caused by :: Location28563 cannot send batch write operation to server 192.168.200.25:27017 (192.168.200.25)”
    }
})
复制代码
太混蛋了，错误提示不太人性化，搞了半天。所以说版本一致性还是很重要的。现在重新开了一个副本集：&lt;/p&gt;

&lt;p&gt;View Code
把之前的副本集分片删除了，如何删除见下面3）。&lt;/p&gt;

&lt;p&gt;新的副本集加入分片中：&lt;/p&gt;

&lt;p&gt;复制代码
mongos&amp;gt; sh.addShard(“mablevi/192.168.200.53:50000,192.168.200.53:50001,192.168.200.53:50002”)
{ “shardAdded” : “mablevi”, “ok” : 1 }&lt;/p&gt;

&lt;p&gt;mongos&amp;gt; sh.status()
— Sharding Status — 
…
…
  shards:
    {  “_id” : “mablevi”,  “host” : “mablevi/192.168.200.53:50000,192.168.200.53:50001,192.168.200.53:50002” }
    {  “_id” : “shard0000”,  “host” : “192.168.200.51:40000” }
    {  “_id” : “shard0001”,  “host” : “192.168.200.52:40000” }
    {  “_id” : “shard0002”,  “host” : “192.168.200.53:40000” }
…
…
        dba.account
            shard key: { “name” : 1 }
            chunks:
                mablevi    1
                shard0000    1
                shard0001    1
                shard0002    2
            { “name” : { “$minKey” : 1 } } –» { “name” : “5yyfY8mmR5HyhGJ” } on : shard0001 Timestamp(2, 0) 
            { “name” : “5yyfY8mmR5HyhGJ” } –» { “name” : “UavMbMlfszZOFrz” } on : mablevi Timestamp(9, 0) #新加入的分片得到数据
            { “name” : “UavMbMlfszZOFrz” } –» { “name” : “t9LyVSNXDmf6esP” } on : shard0002 Timestamp(4, 1) 
            { “name” : “t9LyVSNXDmf6esP” } –» { “name” : “woQAv99Pq1FVoMX” } on : shard0002 Timestamp(3, 4) 
            { “name” : “woQAv99Pq1FVoMX” } –» { “name” : { “$maxKey” : 1 } } on : shard0000 Timestamp(9, 1) 
    {  “_id” : “abc”,  “partitioned” : false,  “primary” : “shard0000” }
    {  “_id” : “mablevi”,  “partitioned” : false,  “primary” : “shard0001” }
复制代码
继续用python写入操作：&lt;/p&gt;

&lt;p&gt;复制代码
mongos&amp;gt; db.account.stats()
{
…
…
    “shards” : {
        “mablevi” : {
            “ns” : “dba.account”,
            “count” : 47240,
            “size” : 5290880,
…
…
复制代码
副本集的分片被写入了47240条记录。此时把副本集分片的Primary shutdown掉，再查看：&lt;/p&gt;

&lt;p&gt;复制代码
mongos&amp;gt; db.account.stats()
{
    “sharded” : true,
    “code” : 13639,
    “ok” : 0,
    “errmsg” : “exception: can’t connect to new replica set master [192.168.200.53:50000], err: couldn’t connect to server 192.168.200.53:50000 (192.168.200.53), connection attempt failed”  #由于副本集的Primary被shutdown之后，选举新主还是要几秒的时间，期间数据不能访问，导致分片数据也不能访问
}
mongos&amp;gt; db.account.stats()
…
…
    “shards” : {
        “mablevi” : {
            “ns” : “dba.account”,
            “count” : 47240,       #副本集新主选举完毕之后，分片数据访问正常。数据没有丢失，高可用得到了实现。
            “size” : 5290880,
…
…
复制代码
要是让副本集分片只剩下一台（Secondary），则分片会报错：&lt;/p&gt;

&lt;p&gt;复制代码
mongos&amp;gt; db.account.stats()
{
    “sharded” : true,
    “code” : 10009,
    “ok” : 0,
    “errmsg” : “exception: ReplicaSetMonitor no master found for set: mablevi” #数据不能访问
}
复制代码
3）删除分片： db.runCommand({“removeshard”:”mmm”})&lt;/p&gt;

&lt;p&gt;要是觉得分片太多了，想删除，则：&lt;/p&gt;

&lt;p&gt;复制代码
mongos&amp;gt; use admin   #需要到admin下面删除
switched to db admin
mongos&amp;gt; db.runCommand({“removeshard”:”mmm”})
{
    “msg” : “draining started successfully”,
    “state” : “started”,   #开始删除，数据正在转移
    “shard” : “mmm”,
    “ok” : 1
}
mongos&amp;gt; sh.status()
— Sharding Status —…
…
  shards:
    {  “_id” : “mmm”,  “host” : “mmm/192.168.200.245:27017,192.168.200.245:37017,192.168.200.25:27017”,  “draining” : true }  #删除的分片数据移动到其他分片
    {  “_id” : “shard0000”,  “host” : “192.168.200.51:40000” }
    {  “_id” : “shard0001”,  “host” : “192.168.200.52:40000” }
    {  “_id” : “shard0002”,  “host” : “192.168.200.53:40000” }
…
…
  databases:
    {  “_id” : “admin”,  “partitioned” : false,  “primary” : “config” }
    {  “_id” : “test”,  “partitioned” : false,  “primary” : “shard0000” }
    {  “_id” : “dba”,  “partitioned” : true,  “primary” : “shard0000” }
        dba.account
            shard key: { “name” : 1 }
            chunks:
                shard0000    2
                shard0001    1
                shard0002    2
            { “name” : { “$minKey” : 1 } } –» { “name” : “5yyfY8mmR5HyhGJ” } on : shard0001 Timestamp(2, 0) 
            { “name” : “5yyfY8mmR5HyhGJ” } –» { “name” : “UavMbMlfszZOFrz” } on : shard0000 Timestamp(8, 0) 
            { “name” : “UavMbMlfszZOFrz” } –» { “name” : “t9LyVSNXDmf6esP” } on : shard0002 Timestamp(4, 1) #这里已经没有了被删除分片信息
            { “name” : “t9LyVSNXDmf6esP” } –» { “name” : “woQAv99Pq1FVoMX” } on : shard0002 Timestamp(3, 4) 
            { “name” : “woQAv99Pq1FVoMX” } –» { “name” : { “$maxKey” : 1 } } on : shard0000 Timestamp(7, 1) 
    {  “_id” : “abc”,  “partitioned” : false,  “primary” : “shard0000” }
    {  “_id” : “mablevi”,  “partitioned” : false,  “primary” : “shard0001” }&lt;/p&gt;

&lt;p&gt;mongos&amp;gt; db.runCommand({“removeshard”:”mmm”})   #再次执行，直到执行成功，要是原来分片的数据比较大，这里比较费时，要是一个主分片则需要执行movePrimary
{
    “msg” : “removeshard completed successfully”,
    “state” : “completed”,  #完成删除
    “shard” : “mmm”,
    “ok” : 1
}
mongos&amp;gt; sh.status()
— Sharding Status —…
  shards:   #分片消失
    {  “_id” : “shard0000”,  “host” : “192.168.200.51:40000” }
    {  “_id” : “shard0001”,  “host” : “192.168.200.52:40000” }
    {  “_id” : “shard0002”,  “host” : “192.168.200.53:40000” }
…
…
            { “name” : { “$minKey” : 1 } } –» { “name” : “5yyfY8mmR5HyhGJ” } on : shard0001 Timestamp(2, 0) 
            { “name” : “5yyfY8mmR5HyhGJ” } –» { “name” : “UavMbMlfszZOFrz” } on : shard0000 Timestamp(8, 0) 
            { “name” : “UavMbMlfszZOFrz” } –» { “name” : “t9LyVSNXDmf6esP” } on : shard0002 Timestamp(4, 1) #已经没有了被删除分片的信息
            { “name” : “t9LyVSNXDmf6esP” } –» { “name” : “woQAv99Pq1FVoMX” } on : shard0002 Timestamp(3, 4) 
            { “name” : “woQAv99Pq1FVoMX” } –» { “name” : { “$maxKey” : 1 } } on : shard0000 Timestamp(7, 1) 
    {  “_id” : “abc”,  “partitioned” : false,  “primary” : “shard0000” }
    {  “_id” : “mablevi”,  “partitioned” : false,  “primary” : “shard0001” }
复制代码
分片被删除之后，数据被移到其他分片中，不会丢失。要是想让主分片进行转移则(movePrimary):&lt;/p&gt;

&lt;p&gt;mongos&amp;gt; db.adminCommand({“movePrimary”:”test”,”to”:”shard0001”}) #把test的主分片从shard0000迁移到shard0001 
刷新下配置服务器：db.adminCommand({“flushRouterConfig”:1})&lt;/p&gt;

&lt;p&gt;db.adminCommand({“flushRouterConfig”:1})
最后来查看下分片成员：db.runCommand({ listshards : 1 })&lt;/p&gt;

&lt;p&gt;复制代码
mongos&amp;gt; use admin  #需要进入admin才能执行
switched to db admin
mongos&amp;gt; db.runCommand({ listshards : 1 })
{
    “shards” : [
        {
            “_id” : “shard0000”,
            “host” : “192.168.200.51:40000”
        },
        {
            “_id” : “shard0001”,
            “host” : “192.168.200.52:40000”
        },
        {
            “_id” : “shard0002”,
            “host” : “192.168.200.53:40000”
        },
        {
            “_id” : “mablevi”,
            “host” : “mablevi/192.168.200.53:50000,192.168.200.53:50001,192.168.200.53:50002”
        }
    ],
    “ok” : 1
}
复制代码
到此已经把MongoDB分片原理、搭建、应用大致已经介绍完。&lt;/p&gt;

&lt;p&gt;六、认证分配&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;  上面的所有操作都是在无账号密码下进行的，这样是不安全的，那如何使用账号密码呢？和副本级一样，需要添加KeyFile参数，但是针对上面的三个角色（config、mongos、mongod）账号密码怎么添加呢？官网上已经做了说明：http://docs.mongodb.org/manual/tutorial/enable-authentication-in-sharded-cluster/。下面就对有账号密码认证分片进行相关设置说明。
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;首先要创建账号(Root角色)和生成一个KeyFile文件，其中mongos 不需要创建账号。&lt;/p&gt;

&lt;p&gt;openssl rand -base64 741 &amp;gt; mongodb-keyfile
chmod 600 mongodb-keyfile
其实这个文件也可以直接用明文，只要保证各个地方指定的文件是同一个就可以了。&lt;/p&gt;

&lt;p&gt;1）mongd： 首先在mongod角色的分片成员上生成key file文件，特别注意的是有副本级的分片，再把这个文件分别复制到其他角色的服务器上。再添加参数：&lt;/p&gt;

&lt;p&gt;auth = true
keyFile = /usr/local/mongodb-keyfile
2）Config上添加参数：&lt;/p&gt;

&lt;p&gt;auth = true
keyFile = /usr/local/mongodb-keyfile
3）mongos上添加参数，因为mongos本来就是从config里加载数据的，所以只需要添加keyfile文件即可，不需要找上面createUser。&lt;/p&gt;

&lt;p&gt;keyFile = /usr/local/mongodb-keyfile
最后重启各个服务，再进入mongos里查看：&lt;/p&gt;

&lt;p&gt;复制代码
root@mongo1:/usr/local# mongo –port=30000
MongoDB shell version: 3.0.4
connecting to: 127.0.0.1:30000/test
mongos&amp;gt; sh.status()      #没有认证，没有权限报错。
2015-07-14T23:42:11.800+0800 E QUERY    Error: error: { “$err” : “not authorized for query on config.version”, “code” : 13 }
    at Error (&lt;anonymous&gt;)
    at DBQuery.next (src/mongo/shell/query.js:259:15)
    at DBCollection.findOne (src/mongo/shell/collection.js:189:22)
    at printShardingStatus (src/mongo/shell/shardingtest.js:659:55)
    at Function.sh.status (src/mongo/shell/utils_sh.js:60:5)
    at (shell):1:4 at src/mongo/shell/query.js:259
mongos&amp;gt; use admin
switched to db admin
mongos&amp;gt; db.auth('dba','dba')   #认证
1
mongos&amp;gt; sh.status()            #有权限
--- Sharding Status --- 
  sharding version: {
    &quot;_id&quot; : 1,
    &quot;minCompatibleVersion&quot; : 5,
    &quot;currentVersion&quot; : 6,
    &quot;clusterId&quot; : ObjectId(&quot;55a51ef18bd517d4acec5ef9&quot;)
}
  shards:
    {  &quot;_id&quot; : &quot;mablevi&quot;,  &quot;host&quot; : &quot;mablevi/192.168.200.53:50000,192.168.200.53:50001,192.168.200.53:50002&quot; }
    {  &quot;_id&quot; : &quot;shard0000&quot;,  &quot;host&quot; : &quot;192.168.200.51:40000&quot; }
    {  &quot;_id&quot; : &quot;shard0001&quot;,  &quot;host&quot; : &quot;192.168.200.52:40000&quot; }
    {  &quot;_id&quot; : &quot;shard0002&quot;,  &quot;host&quot; : &quot;192.168.200.53:40000&quot; }
  balancer:
  ...
  ...
  databases:
    {  &quot;_id&quot; : &quot;admin&quot;,  &quot;partitioned&quot; : false,  &quot;primary&quot; : &quot;config&quot; }
    {  &quot;_id&quot; : &quot;test&quot;,  &quot;partitioned&quot; : false,  &quot;primary&quot; : &quot;shard0000&quot; }
    {  &quot;_id&quot; : &quot;dba&quot;,  &quot;partitioned&quot; : true,  &quot;primary&quot; : &quot;shard0000&quot; }
        dba.account
            shard key: { &quot;name&quot; : 1 }
            chunks:
                mablevi    1
                shard0000    1
                shard0001    2
                shard0002    1
            { &quot;name&quot; : { &quot;$minKey&quot; : 1 } } --&amp;gt;&amp;gt; { &quot;name&quot; : &quot;9XXqCaBhfhPIXLq&quot; } on : mablevi Timestamp(2, 0) 
            { &quot;name&quot; : &quot;9XXqCaBhfhPIXLq&quot; } --&amp;gt;&amp;gt; { &quot;name&quot; : &quot;RWINvgjYYQmbZds&quot; } on : shard0002 Timestamp(4, 0) 
            { &quot;name&quot; : &quot;RWINvgjYYQmbZds&quot; } --&amp;gt;&amp;gt; { &quot;name&quot; : &quot;jSPRBNH8rvnzblG&quot; } on : shard0001 Timestamp(4, 1) 
            { &quot;name&quot; : &quot;jSPRBNH8rvnzblG&quot; } --&amp;gt;&amp;gt; { &quot;name&quot; : &quot;okmjUUZuuKgftDC&quot; } on : shard0001 Timestamp(3, 4) 
            { &quot;name&quot; : &quot;okmjUUZuuKgftDC&quot; } --&amp;gt;&amp;gt; { &quot;name&quot; : { &quot;$maxKey&quot; : 1 } } on : shard0000 Timestamp(3, 1) 
复制代码
七、分片备份、还原&lt;/anonymous&gt;&lt;/p&gt;

&lt;p&gt;因为分片机制里面会有平衡器来迁移数据，所以各个分片里的数据很可能会移动，所以在备份分片时需要做：&lt;/p&gt;

&lt;p&gt;①：先停止平衡器的工作，并检查没有chunk move动作，保证dump的时候没有进行数据迁移。&lt;/p&gt;

&lt;p&gt;mongos&amp;gt; sh.stopBalancer()
②：锁定数据库，保证数据没有写入：在各个分片上和配置服务器上执行。&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;db.fsyncLock()
{
    “info” : “now locked against writes, use db.fsyncUnlock() to unlock”,
    “seeAlso” : “http://dochub.mongodb.org/core/fsynccommand”,
    “ok” : 1
}
③：执行备份操作，备份各个分片服务器和配置服务器。&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;mongodump -udba -p12345 -d dba_test –authenticationDatabase admin -o backup/
④：解锁数据库，备份完成之后在分片和配置服务器上解锁数据库，允许修改。&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;db.fsyncUnlock()
{ “ok” : 1, “info” : “unlock completed” }
当数据库出现问题，需要还原的时候，需要还原各个分片和配置服务器，并且重启MongoDB实例。还原数据库需要做：&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;①：还原各个分片和配置服务器。&lt;/p&gt;

&lt;p&gt;mongorestore –host=127.0.0.1 –port=27017 -udba -p12345 -d dba_test –authenticationDatabase admin –drop backup/dba_test
②：重启各个实例&lt;/p&gt;

&lt;p&gt;为什么需要索引？
当你抱怨MongoDB集合查询效率低的时候，可能你就需要考虑使用索引了，为了方便后续介绍，先科普下MongoDB里的索引机制（同样适用于其他的数据库比如mysql）。&lt;/p&gt;

&lt;p&gt;mongo-9552:PRIMARY&amp;gt; db.person.find()
{ “_id” : ObjectId(“571b5da31b0d530a03b3ce82”), “name” : “jack”, “age” : 19 }
{ “_id” : ObjectId(“571b5dae1b0d530a03b3ce83”), “name” : “rose”, “age” : 20 }
{ “_id” : ObjectId(“571b5db81b0d530a03b3ce84”), “name” : “jack”, “age” : 18 }
{ “_id” : ObjectId(“571b5dc21b0d530a03b3ce85”), “name” : “tony”, “age” : 21 }
{ “_id” : ObjectId(“571b5dc21b0d530a03b3ce86”), “name” : “adam”, “age” : 18 }
当你往某各个集合插入多个文档后，每个文档在经过底层的存储引擎持久化后，会有一个位置信息，通过这个位置信息，就能从存储引擎里读出该文档。比如mmapv1引擎里，位置信息是『文件id + 文件内offset 』， 在wiredtiger存储引擎（一个KV存储引擎）里，位置信息是wiredtiger在存储文档时生成的一个key，通过这个key能访问到对应的文档；为方便介绍，统一用pos(position的缩写)来代表位置信息。&lt;/p&gt;

&lt;p&gt;比如上面的例子里，person集合里包含插入了4个文档，假设其存储后位置信息如下(为方便描述，文档省去_id字段)&lt;/p&gt;

&lt;p&gt;位置信息	文档
pos1	{“name” : “jack”, “age” : 19 }
pos2	{“name” : “rose”, “age” : 20 }
pos3	{“name” : “jack”, “age” : 18 }
pos4	{“name” : “tony”, “age” : 21}
pos5	{“name” : “adam”, “age” : 18}
假设现在有个查询 db.person.find( {age: 18} ), 查询所有年龄为18岁的人，这时需要遍历所有的文档（『全表扫描』），根据位置信息读出文档，对比age字段是否为18。当然如果只有4个文档，全表扫描的开销并不大，但如果集合文档数量到百万、甚至千万上亿的时候，对集合进行全表扫描开销是非常大的，一个查询耗费数十秒甚至几分钟都有可能。&lt;/p&gt;

&lt;p&gt;如果想加速 db.person.find( {age: 18} ），就可以考虑对person表的age字段建立索引。&lt;/p&gt;

&lt;p&gt;db.person.createIndex( {age: 1} )  // 按age字段创建升序索引
建立索引后，MongoDB会额外存储一份按age字段升序排序的索引数据，索引结构类似如下，索引通常采用类似btree的结构持久化存储，以保证从索引里快速（O(logN)的时间复杂度）找出某个age值对应的位置信息，然后根据位置信息就能读取出对应的文档。&lt;/p&gt;

&lt;p&gt;AGE	位置信息
18	pos3
18	pos5
19	pos1
20	pos2
21	pos4
简单的说，索引就是将文档按照某个（或某些）字段顺序组织起来，以便能根据该字段高效的查询。有了索引，至少能优化如下场景的效率：&lt;/p&gt;

&lt;p&gt;查询，比如查询年龄为18的所有人
更新/删除，将年龄为18的所有人的信息更新或删除，因为更新或删除时，需要根据条件先查询出所有符合条件的文档，所以本质上还是在优化查询
排序，将所有人的信息按年龄排序，如果没有索引，需要全表扫描文档，然后再对扫描的结果进行排序
众所周知，MongoDB默认会为插入的文档生成_id字段（如果应用本身没有指定该字段），_id是文档唯一的标识，为了保证能根据文档id快递查询文档，MongoDB默认会为集合创建_id字段的索引。&lt;/p&gt;

&lt;p&gt;mongo-9552:PRIMARY&amp;gt; db.person.getIndexes() // 查询集合的索引信息
[
    {
        “ns” : “test.person”,  // 集合名
        “v” : 1,               // 索引版本
        “key” : {              // 索引的字段及排序方向
            “&lt;em&gt;id” : 1           // 根据_id字段升序索引
        },
        “name” : “_id&lt;/em&gt;”        // 索引的名称
    }
]
MongoDB索引类型
MongoDB支持多种类型的索引，包括单字段索引、复合索引、多key索引、文本索引等，每种类型的索引有不同的使用场合。&lt;/p&gt;

&lt;p&gt;单字段索引 （Single Field Index）
    db.person.createIndex( {age: 1} ) 
上述语句针对age创建了单字段索引，其能加速对age字段的各种查询请求，是最常见的索引形式，MongoDB默认创建的id索引也是这种类型。&lt;/p&gt;

&lt;p&gt;{age: 1} 代表升序索引，也可以通过{age: -1}来指定降序索引，对于单字段索引，升序/降序效果是一样的。&lt;/p&gt;

&lt;p&gt;复合索引 (Compound Index)
复合索引是Single Field Index的升级版本，它针对多个字段联合创建索引，先按第一个字段排序，第一个字段相同的文档按第二个字段排序，依次类推，如下针对age, name这2个字段创建一个复合索引。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;db.person.createIndex( {age: 1, name: 1} )  上述索引对应的数据组织类似下表，与{age: 1}索引不同的时，当age字段相同时，在根据name字段进行排序，所以pos5对应的文档排在pos3之前。
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;AGE,NAME	位置信息
18,adam	pos5
18,jack	pos3
19,jack	pos1
20,rose	pos2
21,tony	pos4
复合索引能满足的查询场景比单字段索引更丰富，不光能满足多个字段组合起来的查询，比如db.person.find( {age： 18， name: “jack”} )，也能满足所以能匹配符合索引前缀的查询，这里{age: 1}即为{age: 1, name: 1}的前缀，所以类似db.person.find( {age： 18} )的查询也能通过该索引来加速；但db.person.find( {name: “jack”} )则无法使用该复合索引。如果经常需要根据『name字段』以及『name和age字段组合』来查询，则应该创建如下的复合索引&lt;/p&gt;

&lt;p&gt;db.person.createIndex( {name: 1, age: 1} ) 
除了查询的需求能够影响索引的顺序，字段的值分布也是一个重要的考量因素，即使person集合所有的查询都是『name和age字段组合』（指定特定的name和age），字段的顺序也是有影响的。&lt;/p&gt;

&lt;p&gt;age字段的取值很有限，即拥有相同age字段的文档会有很多；而name字段的取值则丰富很多，拥有相同name字段的文档很少；显然先按name字段查找，再在相同name的文档里查找age字段更为高效。&lt;/p&gt;

&lt;p&gt;多key索引 （Multikey Index）
当索引的字段为数组时，创建出的索引称为多key索引，多key索引会为数组的每个元素建立一条索引，比如person表加入一个habbit字段（数组）用于描述兴趣爱好，需要查询有相同兴趣爱好的人就可以利用habbit字段的多key索引。&lt;/p&gt;

&lt;p&gt;{“name” : “jack”, “age” : 19, habbit: [“football, runnning”]}
db.person.createIndex( {habbit: 1} )  // 自动创建多key索引
db.person.find( {habbit: “football”} )
其他类型索引
哈希索引（Hashed Index）是指按照某个字段的hash值来建立索引，目前主要用于MongoDB Sharded Cluster的Hash分片，hash索引只能满足字段完全匹配的查询，不能满足范围查询等。&lt;/p&gt;

&lt;p&gt;地理位置索引（Geospatial Index）能很好的解决O2O的应用场景，比如『查找附近的美食』、『查找某个区域内的车站』等。&lt;/p&gt;

&lt;p&gt;文本索引（Text Index）能解决快速文本查找的需求，比如有一个博客文章集合，需要根据博客的内容来快速查找，则可以针对博客内容建立文本索引。&lt;/p&gt;

&lt;p&gt;索引额外属性
MongoDB除了支持多种不同类型的索引，还能对索引定制一些特殊的属性。&lt;/p&gt;

&lt;p&gt;唯一索引 (unique index)：保证索引对应的字段不会出现相同的值，比如_id索引就是唯一索引
TTL索引：可以针对某个时间字段，指定文档的过期时间（经过指定时间后过期 或 在某个时间点过期）
部分索引 (partial index): 只针对符合某个特定条件的文档建立索引，3.2版本才支持该特性
稀疏索引(sparse index): 只针对存在索引字段的文档建立索引，可看做是部分索引的一种特殊情况
索引优化
db profiling
MongoDB支持对DB的请求进行profiling，目前支持3种级别的profiling。&lt;/p&gt;

&lt;p&gt;0： 不开启profiling
1： 将处理时间超过某个阈值(默认100ms)的请求都记录到DB下的system.profile集合 （类似于mysql、redis的slowlog）
2： 将所有的请求都记录到DB下的system.profile集合（生产环境慎用）
通常，生产环境建议使用1级别的profiling，并根据自身需求配置合理的阈值，用于监测慢请求的情况，并及时的做索引优化。&lt;/p&gt;

&lt;p&gt;如果能在集合创建的时候就能『根据业务查询需求决定应该创建哪些索引』，当然是最佳的选择；但由于业务需求多变，要根据实际情况不断的进行优化。索引并不是越多越好，集合的索引太多，会影响写入、更新的性能，每次写入都需要更新所有索引的数据；所以你system.profile里的慢请求可能是索引建立的不够导致，也可能是索引过多导致。&lt;/p&gt;

&lt;p&gt;查询计划
索引已经建立了，但查询还是很慢怎么破？这时就得深入的分析下索引的使用情况了，可通过查看下详细的查询计划来决定如何优化。通过执行计划可以看出如下问题&lt;/p&gt;

&lt;p&gt;根据某个/些字段查询，但没有建立索引
根据某个/些字段查询，但建立了多个索引，执行查询时没有使用预期的索引。
建立索引前，db.person.find( {age： 18} )必须执行COLLSCAN，即全表扫描。&lt;/p&gt;

&lt;p&gt;mongo-9552:PRIMARY&amp;gt; db.person.find({age: 18}).explain()
{
    “queryPlanner” : {
        “plannerVersion” : 1,
        “namespace” : “test.person”,
        “indexFilterSet” : false,
        “parsedQuery” : {
            “age” : {
                “$eq” : 18
            }
        },
        “winningPlan” : {
            “stage” : “COLLSCAN”,
            “filter” : {
                “age” : {
                    “$eq” : 18
                }
            },
            “direction” : “forward”
        },
        “rejectedPlans” : [ ]
    },
    “serverInfo” : {
        “host” : “localhost”,
        “port” : 9552,
        “version” : “3.2.3”,
        “gitVersion” : “b326ba837cf6f49d65c2f85e1b70f6f31ece7937”
    },
    “ok” : 1
}
建立索引后，通过查询计划可以看出，先进行[IXSCAN]((https://docs.mongodb.org/manual/reference/explain-results/#queryplanner)(从索引中查找)，然后FETCH，读取出满足条件的文档。&lt;/p&gt;

&lt;p&gt;mongo-9552:PRIMARY&amp;gt; db.person.find({age: 18}).explain()
{
    “queryPlanner” : {
        “plannerVersion” : 1,
        “namespace” : “test.person”,
        “indexFilterSet” : false,
        “parsedQuery” : {
            “age” : {
                “$eq” : 18
            }
        },
        “winningPlan” : {
            “stage” : “FETCH”,
            “inputStage” : {
                “stage” : “IXSCAN”,
                “keyPattern” : {
                    “age” : 1
                },
                “indexName” : “age_1”,
                “isMultiKey” : false,
                “isUnique” : false,
                “isSparse” : false,
                “isPartial” : false,
                “indexVersion” : 1,
                “direction” : “forward”,
                “indexBounds” : {
                    “age” : [
                        “[18.0, 18.0]”
                    ]
                }
            }
        },
        “rejectedPlans” : [ ]
    },
    “serverInfo” : {
        “host” : “localhost”,
        “port” : 9552,
        “version” : “3.2.3”,
        “gitVersion” : “b326ba837cf6f49d65c2f85e1b70f6f31ece7937”
    },
    “ok” : 1
}&lt;/p&gt;

&lt;p&gt;一、存储引擎（Storage）&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;mongodb 3.0默认存储引擎为MMAPV1，还有一个新引擎wiredTiger可选，或许可以提高一定的性能。

mongodb中有多个databases，每个database可以创建多个collections，collection是底层数据分区（partition）的单位，每个collection都有多个底层的数据文件组成。（参见下文data files存储原理）

 

wiredTiger引擎：3.0新增引擎，官方宣称在read、insert和复杂的update下具有更高的性能。所以后续版本，我们建议使用wiredTiger。所有的write请求都基于“文档级别”的lock，因此多个客户端可以同时更新一个colleciton中的不同文档，这种更细颗粒度的lock，可以支撑更高的读写负载和并发量。因为对于production环境，更多的CPU可以有效提升wireTiger的性能，因为它是的IO是多线程的。wiredTiger不像MMAPV1引擎那样尽可能的耗尽内存，它可以通过在配置文件中指定“cacheSizeGB”参数设定引擎使用的内存量，此内存用于缓存工作集数据（索引、namespace，未提交的write，query缓冲等）。

journal就是一个预写事务日志，来确保数据的持久性，wiredTiger每隔60秒（默认）或者待写入的数据达到2G时，mongodb将对journal文件提交一个checkpoint（检测点，将内存中的数据变更flush到磁盘中的数据文件中，并做一个标记点，表示此前的数据表示已经持久存储在了数据文件中，此后的数据变更存在于内存和journal日志）。对于write操作，首先被持久写入journal，然后在内存中保存变更数据，条件满足后提交一个新的检测点，即检测点之前的数据只是在journal中持久存储，但并没有在mongodb的数据文件中持久化，延迟持久化可以提升磁盘效率，如果在提交checkpoint之前，mongodb异常退出，此后再次启动可以根据journal日志恢复数据。journal日志默认每个100毫秒同步磁盘一次，每100M数据生成一个新的journal文件，journal默认使用了snappy压缩，检测点创建后，此前的journal日志即可清除。mongod可以禁用journal，这在一定程度上可以降低它带来的开支；对于单点mongod，关闭journal可能会在异常关闭时丢失checkpoint之间的数据（那些尚未提交到磁盘数据文件的数据）；对于replica set架构，持久性的保证稍高，但仍然不能保证绝对的安全（比如replica set中所有节点几乎同时退出时）。



 

MMAPv1引擎：mongodb原生的存储引擎，比较简单，直接使用系统级的内存映射文件机制（memory mapped files），一直是mongodb的默认存储引擎，对于insert、read和in-place update（update不导致文档的size变大）性能较高；不过MMAPV1在lock的并发级别上，支持到collection级别，所以对于同一个collection同时只能有一个write操作执行，这一点相对于wiredTiger而言，在write并发性上就稍弱一些。对于production环境而言，较大的内存可以使此引擎更加高效，有效减少“page fault”频率，但是因为其并发级别的限制，多核CPU并不能使其受益。此引擎将不会使用到swap空间，但是对于wiredTiger而言需要一定的swap空间。（核心：对于大文件MAP操作，比较忌讳的就是在文件的中间修改数据，而且导致文件长度增长，这会涉及到索引引用的大面积调整）

 

为了确保数据的安全性，mongodb将所有的变更操作写入journal并间歇性的持久到磁盘上，对于实际数据文件将延迟写入，和wiredTiger一样journal也是用于数据恢复。所有的记录在磁盘上连续存储，当一个document尺寸变大时，mongodb需要重新分配一个新的记录（旧的record标记删除，新的记record在文件尾部重新分配空间），这意味着mongodb同时还需要更新此文档的索引（指向新的record的offset），与in-place update相比，将消耗更多的时间和存储开支。由此可见，如果你的mongodb的使用场景中有大量的这种update，那么或许MMAPv1引擎并不太适合，同时也反映出如果document没有索引，是无法保证document在read中的顺序（即自然顺序）。3.0之后，mongodb默认采用“Power of 2 Sized Allocations”，所以每个document对应的record将有实际数据和一些padding组成，这padding可以允许document的尺寸在update时适度的增长，以最小化重新分配record的可能性。此外重新分配空间，也会导致磁盘碎片（旧的record空间）。

 

Power of 2 Sized Allocations：默认情况下，MMAPv1中空间分配使用此策略，每个document的size是2的次幂，比如32、64、128、256...2MB，如果文档尺寸大于2MB，则空间为2MB的倍数（2M,4M,6M等）。这种策略有2种优势，首先那些删除或者update变大而产生的磁盘碎片空间（尺寸变大，意味着开辟新空间存储此document，旧的空间被mark为deleted）可以被其他insert重用，再者padding可以允许文档尺寸有限度的增长，而无需每次update变大都重新分配空间。此外，mongodb还提供了一个可选的“No padding Allocation”策略（即按照实际数据尺寸分配空间），如果你确信数据绝大多数情况下都是insert、in-place update，极少的delete，此策略将可以有效的节约磁盘空间，看起来数据更加紧凑，磁盘利用率也更高。

 

备注：mongodb 3.2+之后，默认的存储引擎为“wiredTiger”，大量优化了存储性能，建议升级到3.2+版本。
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;二、Capped Collections：一种特殊的collection，其尺寸大小是固定值，类似于一个可循环使用的buffer，如果空间被填满之后，新的插入将会覆盖最旧的文档，我们通常不会对Capped进行删除或者update操作，所以这种类型的collection能够支撑较高的write和read，通常情况下我们不需要对这种collection构建索引，因为insert是append（insert的数据保存是严格有序的）、read是iterator方式，几乎没有随机读；在replica set模式下，其oplog就是使用这种colleciton实现的。    Capped Collection的设计目的就是用来保存“最近的”一定尺寸的document。&lt;/p&gt;

&lt;p&gt;Java代码  收藏代码
db.createCollection(“capped_collections”,new CreateCollectionOptions()&lt;br /&gt;
                .capped(true)&lt;br /&gt;
                .maxDocuments(6552350)&lt;br /&gt;
                .usePowerOf2Sizes(false).autoIndex(true));//不会涉及到更新，所以可以不用power of 2&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;Capped Collection在语义上，类似于“FIFO”队列，而且是有界队列。适用于数据缓存，消息类型的存储。Capped支持update，但是我们通常不建议，如果更新导致document的尺寸变大，操作将会失败，只能使用in-place update，而且还需要建立合适的索引。在capped中使用remove操作是允许的。autoIndex属性表示默认对_id字段建立索引，我们推荐这么做。在上文中我们提到了Tailable Cursor，就是为Capped而设计的，效果类似于“tail -f ”。
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;三、数据模型（Data Model）&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;上文已经描述过，mongodb是一个模式自由的NOSQL，不像其他RDBMS一样需要预先定义Schema而且所有的数据都“整齐划一”，mongodb的document是BSON格式，松散的，原则上说任何一个Colleciton都可以保存任意结构的document，甚至它们的格式千差万别，不过从应用角度考虑，包括业务数据分类和查询优化机制等，我们仍然建议每个colleciton中的document数据结构应该比较接近。

对于有些update，比如对array新增元素等，会导致document尺寸的增加，无论任何存储系统包括MYSQL、Hbase等，对于这种情况都需要额外的考虑，这归结于磁盘空间的分配是连续的（连续意味着读取性能将更高，存储文件空间通常是预分配固定尺寸，我们需要尽可能的利用磁盘IO的这种优势）。对于MMAPV1引擎，如果文档尺寸超过了原分配的空间（上文提到Power of 2 Allocate），mongodb将会重新分配新的空间来保存整个文档（旧文档空间回收，可以被后续的insert重用）。

 

document模型的设计与存储，需要兼顾应用的实际需要，否则可能会影响性能。mongodb支持内嵌document，即document中一个字段的值也是一个document，可以形成类似于RDBMS中的“one-to-one”、“one-to-many”，只需要对reference作为一个内嵌文档保存即可。这种情况就需要考虑mongodb存储引擎的机制了，如果你的内嵌文档（即reference文档）尺寸是动态的，比如一个user可以有多个card，因为card数量无法预估，这就会导致document的尺寸可能不断增加以至于超过“Power of 2 Allocate”，从而触发空间重新分配，带来性能开销，这种情况下，我们需要将内嵌文档单独保存到一个额外的collection中，作为一个或者多个document存储，比如把card列表保存在card collection中。“one-to-one”的情况也需要个别考虑，如果reference文档尺寸较小，可以内嵌，如果尺寸较大，建议单独存储。此外内嵌文档还有个优点就是write的原子性，如果使用reference的话，就无法保证了。

 

索引：提高查询性能，默认情况下_id字段会被创建唯一索引；因为索引不仅需要占用大量内存而且也会占用磁盘，所以我们需要建立有限个索引，而且最好不要建立重复索引；每个索引需要8KB的空间，同时update、insert操作会导致索引的调整，会稍微影响write的性能，索引只能使read操作收益，所以读写比高的应用可以考虑建立索引。

 

大集合拆分：比如一个用于存储log的collection，log分为有两种“dev”、“debug”，结果大致为{&quot;log&quot;:&quot;dev&quot;,&quot;content&quot;:&quot;....&quot;},{&quot;log&quot;:&quot;debug&quot;,&quot;content&quot;:&quot;.....&quot;}。这两种日志的document个数比较接近，对于查询时，即使给log字段建立索引，这个索引也不是高效的，所以可以考虑将它们分别放在2个Collection中，比如：log_dev和log_debug。

 

数据生命周期管理：mongodb提供了expire机制，即可以指定文档保存的时长，过期后自动删除，即TTL特性，这个特性在很多场合将是非常有用的，比如“验证码保留15分钟有效期”、“消息保存7天”等等，mongodb会启动一个后台线程来删除那些过期的document。需要对一个日期字段创建“TTL索引”，比如插入一个文档：{&quot;check_code&quot;:&quot;101010&quot;,$currentDate:{&quot;created&quot;:true}}}，其中created字段默认值为系统时间Date；然后我们对created字段建立TTL索引：
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Java代码  收藏代码
collection.createIndex(new Document(“created”,1),new IndexOptions().expireAfter(15L,TimeUnit.MILLISECONDS));//15分钟&lt;br /&gt;
    我们向collection中insert文档时，created的时间为系统当前时间，其中在creatd字段上建立了“TTL”索引，索引TTL为15分钟，mongodb后台线程将会扫描并检测每条document的（created时间 + 15分钟）与当前时间比较，如果发现过期，则删除索引条目（连带删除document）。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;某些情况下，我们可能需要实现“在某个指定的时刻过期”，我们只需要将上述文档和索引变通改造即可，即created指定为“目标时间”，expiredAfter指定为0。 
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;四、架构模式&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;Replica set：复制集，mongodb的架构方式之一 ，通常是三个对等的节点构成一个“复制集”集群，有“primary”和secondary等多中角色（稍后详细介绍），其中primary负责读写请求，secondary可以负责读请求，这有配置决定，其中secondary紧跟primary并应用write操作；如果primay失效，则集群进行“多数派”选举，选举出新的primary，即failover机制，即HA架构。复制集解决了单点故障问题，也是mongodb垂直扩展的最小部署单位，当然sharding cluster中每个shard节点也可以使用Replica set提高数据可用性。

 

Sharding cluster：分片集群，数据水平扩展的手段之一；replica set这种架构的缺点就是“集群数据容量”受限于单个节点的磁盘大小，如果数据量不断增加，对它进行扩容将时非常苦难的事情，所以我们需要采用Sharding模式来解决这个问题。将整个collection的数据将根据sharding key被sharding到多个mongod节点上，即每个节点持有collection的一部分数据，这个集群持有全部数据，原则上sharding可以支撑数TB的数据。

 

系统配置：1）建议mongodb部署在linux系统上，较高版本，选择合适的底层文件系统（ext4），开启合适的swap空间  2）无论是MMAPV1或者wiredTiger引擎，较大的内存总能带来直接收益。3）对数据存储文件关闭“atime”（文件每次access都会更改这个时间值，表示文件最近被访问的时间），可以提升文件访问效率。 4）ulimit参数调整，这个在基于网络IO或者磁盘IO操作的应用中，通常都会调整，上调系统允许打开的文件个数（ulimit -n 65535）。
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;五、数据文件存储原理（Data Files storage，MMAPV1引擎）&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;1、Data Files

mongodb的数据将会保存在底层文件系统中，比如我们dbpath设定为“/data/db”目录，我们创建一个database为“test”，collection为“sample”，然后在此collection中插入数条documents。我们查看dbpath下生成的文件列表：
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Java代码  收藏代码&lt;/p&gt;
&lt;blockquote&gt;
  &lt;p&gt;ls -lh&lt;br /&gt;
-rw——-  1 mongo  mongo    16M 11  6 17:24 test.0&lt;br /&gt;
-rw——-  1 mongo  mongo    32M 11  6 17:24 test.1&lt;br /&gt;
-rw——-  1 mongo  mongo    64M 11  6 17:24 test.2&lt;br /&gt;
-rw——-  1 mongo  mongo   128M 11  6 17:24 test.3&lt;br /&gt;
-rw——-  1 mongo  mongo   256M 11  6 17:24 test.4&lt;br /&gt;
-rw——-  1 mongo  mongo   512M 11  6 17:24 test.5&lt;br /&gt;
-rw——-  1 mongo  mongo   512M 11  6 17:24 test.6&lt;br /&gt;
-rw——-  1 mongo  mongo    16M 11  6 17:24 test.ns&lt;/p&gt;
&lt;/blockquote&gt;

&lt;pre&gt;&lt;code&gt;可以看到test这个数据库目前已经有6个数据文件（data files），每个文件以“database”的名字 + 序列数字组成，序列号从0开始，逐个递增，数据文件从16M开始，每次扩张一倍（16M、32M、64M、128M...），在默认情况下单个data file的最大尺寸为2G，如果设置了smallFiles属性（配置文件中）则最大限定为512M；mongodb中每个database最多支持16000个数据文件，即约32T，如果设置了smallFiles则单个database的最大数据量为8T。如果你的database中的数据文件很多，可以使用directoryPerDB配置项将每个db的数据文件放置在各自的目录中。当最后一个data file有数据写入后，mongodb将会立即预分配下一个data file，可以通过“--nopreallocate”启动命令参数来关闭此选项。

 

一个database中所有的collections以及索引信息会分散存储在多个数据文件中，即mongodb并没有像SQL数据库那样，每个表的数据、索引分别存储；数据分块的单位为extent（范围，区域），即一个data file中有多个extents组成，extent中可以保存collection数据或者indexes数据，一个extent只能保存同一个collection数据，不同的collections数据分布在不同的extents中，indexes数据也保存在各自的extents中；最终，一个collection有一个或者多个extents构成，最小size为8K，最大可以为2G，依次增大；它们分散在多个data files中。对于一个data file而言，可能包含多个collection的数据，即有多个不同collections的extents、index extents混合构成。每个extent包含多条documents（或者index entries），每个extent的大小可能不相等，但一个extent不会跨越2个data files。

 



 

有人肯定疑问：一个collection中有哪些extents，这种信息mongodb存在哪里？在每个database的namespace文件中，比如test.ns文件中，每个collection只保存了第一个extent的位置信息，并不保存所有的extents列表，但每个extent都维护者一个链表关系，即每个extent都在其header信息中记录了此extent的上一个、下一个extent的位置信息，这样当对此collection进行scan操作时（比如全表扫描），可以提供很大的便利性。

 

我们可以通过db.stats()指令查看当前database中extents的信息：
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Java代码  收藏代码&lt;/p&gt;
&lt;blockquote&gt;
  &lt;p&gt;use test&lt;br /&gt;
switched to db test&lt;br /&gt;
db.stats();&lt;br /&gt;
{&lt;br /&gt;
    “db” : “test”,&lt;br /&gt;
    “collections” : 3,  ##collection的个数&lt;br /&gt;
    “objects” : 1000006, ##documents总条数&lt;br /&gt;
    “avgObjSize” : 495.9974400153599, ##record的平均大小，单位byte&lt;br /&gt;
    “dataSize” : 496000416, ##document所占空间的总量&lt;br /&gt;
    “storageSize” : 629649408, ##&lt;br /&gt;
    “numExtents” : 18,  ##extents个数&lt;br /&gt;
    “indexes” : 2,&lt;br /&gt;
    “indexSize” : 108282944,&lt;br /&gt;
    “fileSize” : 1006632960,&lt;br /&gt;
    “nsSizeMB” : 16, ##namespace文件大小&lt;br /&gt;
    “extentFreeList” : {   ##尚未使用（已分配尚未使用、已删除但尚未被重用）的extent列表&lt;br /&gt;
        “num” : 0,&lt;br /&gt;
        “totalSize” : 0&lt;br /&gt;
    },&lt;br /&gt;
    “dataFileVersion” : {&lt;br /&gt;
        “major” : 4,&lt;br /&gt;
        “minor” : 22&lt;br /&gt;
    },&lt;br /&gt;
    “ok” : 1&lt;br /&gt;
}&lt;br /&gt;
    列表信息中有几个字段简单介绍一下：&lt;/p&gt;
&lt;/blockquote&gt;

&lt;pre&gt;&lt;code&gt;1） dataSize：documents所占的空间总量，mongodb将会为每个document分配一定空间用于保存数据，每个document所占空间包括“文档实际大小” + “padding”，对于MMAPV1引擎，mongodb默认采用了“Power of 2 Sized Allocations”策略，这也意味着通常会有padding，不过如果你的document不会被update（或者update为in-place方式，不会导致文档尺寸变大），可以在在createCollection是指定noPadding属性为true，这样dataSize的大小就是documents实际大小；当documents被删除后，将导致dataSize减小；不过如果在原有document的空间内（包括其padding空间）update（或者replace），则不会导致dataSize的变大，因为mongodb并没有分配任何新的document空间。

2）storageSize：所有collection的documents占用总空间，包括那些已经删除的documents所占的空间，为存储documents的extents所占空间总和。文档的删除或者收缩不会导致storageSize变小。

3）indexSize：所用collection的索引数据的大小，为存储indexes的extents所占空间的总和。

4）fileSize：为底层所有data files的大小总和，但不包括namespace文件。为storageSize、indexSize、以及一些尚未使用的空间等等。当删除database、collections时会导致此值变小。

 

此外，如果你想查看一个collection中extents的分配情况，可以使用db.&amp;lt;collection名称&amp;gt;.stats()，结构与上述类似；如果你希望更细致的了解collection中extents的全部信息，则可以使用db.&amp;lt;collection名称&amp;gt;.validate()，此方法接收一个boolean值，表示是否查看明细，这个指令会scan全部的data files，因此比较耗时：
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Java代码  收藏代码&lt;/p&gt;
&lt;blockquote&gt;
  &lt;p&gt;db.sample.validate(true);&lt;br /&gt;
{&lt;br /&gt;
    “ns” : “test.sample”,&lt;br /&gt;
    “datasize” : 496000000,&lt;br /&gt;
    “nrecords” : 1000000,&lt;br /&gt;
    “lastExtentSize” : 168742912,&lt;br /&gt;
    “firstExtent” : “0:5000 ns:test.sample”,&lt;br /&gt;
    “lastExtent” : “3:a05f000 ns:test.sample”,&lt;br /&gt;
    “extentCount” : 16,&lt;br /&gt;
    “extents” : [&lt;br /&gt;
        {&lt;br /&gt;
            “loc” : “0:5000”,&lt;br /&gt;
            “xnext” : “0:49000”,&lt;br /&gt;
            “xprev” : “null”,&lt;br /&gt;
            “nsdiag” : “test.sample”,&lt;br /&gt;
            “size” : 8192,&lt;br /&gt;
            “firstRecord” : “0:50b0”,&lt;br /&gt;
            “lastRecord” : “0:6cb0”&lt;br /&gt;
        },&lt;br /&gt;
        …&lt;br /&gt;
        ]&lt;br /&gt;
        …&lt;br /&gt;
}&lt;br /&gt;
    可以看到extents在逻辑上是链表形式，以及每个extent的数据量、以及所在data file的offset位置。具体参见【validate方法】&lt;/p&gt;
&lt;/blockquote&gt;

&lt;pre&gt;&lt;code&gt;从上文中我们已经得知，删除document会导致磁盘碎片，有些update也会导致磁盘碎片，比如update导致文档尺寸变大，进而超过原来分配的空间；当有新的insert操作时，mongodb会检测现有的extents中是否合适的碎片空间可以被重用，如果有，则重用这些fragment，否则分配新的存储空间。磁盘碎片，对write操作有一定的性能影响，而且会导致磁盘空间浪费；如果你需要删除某个collection中大部分数据，则可以考虑将有效数据先转存到新的collection，然后直接drop()原有的collection。或者使用db.runCommand({compact: '&amp;lt;collection&amp;gt;'})。

如果你的database已经运行一段时间，数据已经有很大的磁盘碎片（storageSize与dataSize比较），可以通过mongodump将指定database的所有数据导出，然后将原有的db删除，再通过mongorestore指令将数据重新导入。（同compact，这种操作需要停机维护）

 

mongod中还有2个默认的database，系统级的，“admin”和“local”；它们的存储原理同上，其中“admin”用于存储“用户授权信息”，比如每个database中用户的role、权限等；“local”即为本地数据库，我们常说的oplog（replication架构中使用，类似与binlog）即保存在此数据库中。

 

2、Namespace文件

对于namespace文件，比如“test.ns”文件，默认大小为16M，此文件中主要用于保存“collection”、index的命名信息，比如collection的“属性”信息、每个索引的属性类型等，如果你的database中需要存储大量的collection（比如每一小时生成一个collection，在数据分析应用中），那么我们可以通过配置文件“nsSize”选项来指定。参见【mongodb配置文件】

 

3、journal文件

journal日志为mongodb提供了数据保障能力，它本质上与mysql binlog没有太大区别，用于当mongodb异常crash后，重启时进行数据恢复；这归结于mongodb的数据持久写入磁盘是滞后的。默认情况下，“journal”特性是开启的，特别在production环境中，我们没有理由来关闭它。（除非，数据丢失对应用而言，是无关紧要的）

 

一个mongodb实例中所有的databases共享journal文件。

 

对于write操作而言，首先写入journal日志，然后将数据在内存中修改（mmap），此后后台线程间歇性的将内存中变更的数据flush到底层的data files中，时间间隔为60秒（参见配置项“syncPeriodSecs”）；write操作在journal文件中是有序的，为了提升性能，write将会首先写入journal日志的内存buffer中，当buffer数据达到100M或者每隔100毫秒，buffer中的数据将会flush到磁盘中的journal文件中；如果mongodb异常退出，将可能导致最多100M数据或者最近100ms内的数据丢失，flush磁盘的时间间隔有配置项“commitIntervalMs”决定，默认为100毫秒。mongodb之所以不能对每个write都将journal同步磁盘，这也是对性能的考虑，mysql的binlog也采用了类似的权衡方式。开启journal日志功能，将会导致write性能有所降低，可能降低5~30%，因为它直接加剧了磁盘的写入负载，我们可以将journal日志单独放置在其他磁盘驱动器中来提高写入并发能力（与data files分别使用不同的磁盘驱动器）。

 

如果你希望数据尽可能的不丢失，可以考虑：1）减小commitIntervalMs的值 2）每个write指定“write concern”中指定“j”参数为true  3）最佳手段就是采用“replica set”架构模式，通过数据备份方式解决，同时还需要在“write concern”中指定“w”选项，且保障级别不低于“majority”。【参见mongodb复制集】最终我们需要在“写入性能”和“数据一致性”两个方面权衡，即CAP理论。

 

根据write并发量，journal日志文件为1G，如果指定了smallFiles配置项，则最大为128M，和data files一样journal文件也采用了“preallocated”方式，journal日志保存在dbpath下“journal”子目录中，一般会有三个journal文件，每个journal文件格式类似于“j._&amp;lt;序列数字&amp;gt;”。并不是每次buffer flush都生成一个新的journal日志，而是当前journal文件即将满时会预创建一个新的文件，journal文件中保存了write操作的记录，每条记录中包含write操作内容之外，还包含一个“lsn”（last sequence number），表示此记录的ID；此外我们会发现在journal目录下，还有一个“lsn”文件，这个文件非常小，只保存了一个数字，当write变更的数据被flush到磁盘中的data files后，也意味着这些数据已经持久化了，那么它们在“异常恢复”时也不需要了，那么其对应的journal日志将可以删除，“lsn”文件中记录的就是write持久化的最后一个journal记录的ID，此ID之前的write操作已经被持久写入data files，此ID之前的journal在“异常恢复”时则不需要关注；如果某个journal文件中最大 ID小于“lsn”，则此journal可以被删除或者重用。
&lt;/code&gt;&lt;/pre&gt;

</description>
        <pubDate>Wed, 24 Jan 2018 00:00:00 +0800</pubDate>
        <link>https://xiazemin.github.io/MyBlog/web/2018/01/24/mongodb.html</link>
        <guid isPermaLink="true">https://xiazemin.github.io/MyBlog/web/2018/01/24/mongodb.html</guid>
        
        
        <category>web</category>
        
      </item>
    
  </channel>
</rss>
