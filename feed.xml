<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>泽民博客</title>
    <description>夏泽民的个人主页，学习笔记。</description>
    <link>https://xiazemin.github.io/MyBlog/</link>
    <atom:link href="https://xiazemin.github.io/MyBlog/feed.xml" rel="self" type="application/rss+xml"/>
    <pubDate>Tue, 13 Feb 2018 13:03:35 +0800</pubDate>
    <lastBuildDate>Tue, 13 Feb 2018 13:03:35 +0800</lastBuildDate>
    <generator>Jekyll v3.6.0.pre.beta1</generator>
    
      <item>
        <title>lex</title>
        <description>&lt;!-- more --&gt;
&lt;p&gt;ex
Lex 是一种生成扫描器的工具。扫描器是一种识别文本中的词汇模式的程序。 这些词汇模式（或者常规表达式）在一种特殊的句子结构中定义，这个我们一会儿就要讨论。&lt;/p&gt;

&lt;p&gt;一种匹配的常规表达式可能会包含相关的动作。这一动作可能还包括返回一个标记。 当 Lex 接收到文件或文本形式的输入时，它试图将文本与常规表达式进行匹配。 它一次读入一个输入字符，直到找到一个匹配的模式。 如果能够找到一个匹配的模式，Lex 就执行相关的动作（可能包括返回一个标记）。 另一方面，如果没有可以匹配的常规表达式，将会停止进一步的处理，Lex 将显示一个错误消息。&lt;/p&gt;

&lt;p&gt;Lex 和 C 是强耦合的。一个 .lex 文件（Lex 文件具有 .lex 的扩展名）通过 lex 公用程序来传递，并生成 C 的输出文件。这些文件被编译为词法分析器的可执行版本。&lt;/p&gt;

&lt;p&gt;Lex 的常规表达式
常规表达式是一种使用元语言的模式描述。表达式由符号组成。符号一般是字符和数字，但是 Lex 中还有一些具有特殊含义的其他标记。 下面两个表格定义了 Lex 中使用的一些标记并给出了几个典型的例子。&lt;/p&gt;

&lt;p&gt;用 Lex 定义常规表达式
字符	含义
A-Z, 0-9, a-z	构成了部分模式的字符和数字。
.	匹配任意字符，除了 \n。&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;用来指定范围。例如：A-Z 指从 A 到 Z 之间的所有字符。
[ ]	一个字符集合。匹配括号内的 任意 字符。如果第一个字符是 ^ 那么它表示否定模式。例如: [abC] 匹配 a, b, 和 C中的任何一个。&lt;/li&gt;
  &lt;li&gt;匹配 0个或者多个上述的模式。&lt;/li&gt;
  &lt;li&gt;匹配 1个或者多个上述模式。
?	匹配 0个或1个上述模式。
$	作为模式的最后一个字符匹配一行的结尾。
{ }	指出一个模式可能出现的次数。 例如: A{1,3} 表示 A 可能出现1次或3次。
\	用来转义元字符。同样用来覆盖字符在此表中定义的特殊意义，只取字符的本意。
^	否定。
|	表达式间的逻辑或。
“&lt;一些符号&gt;&quot;	字符的字面含义。元字符具有。
/	向前匹配。如果在匹配的模版中的“/”后跟有后续表达式，只匹配模版中“/”前 面的部分。如：如果输入 A01，那么在模版 A0/1 中的 A0 是匹配的。
( )	将一系列常规表达式分组。
常规表达式举例
常规表达式	含义
joke[rs]	匹配 jokes 或 joker。
A{1,2}shis+	匹配 AAshis, Ashis, AAshi, Ashi。
(A[b-e])+	匹配在 A 出现位置后跟随的从 b 到 e 的所有字符中的 0 个或 1个。
Lex 中的标记声明类似 C 中的变量名。每个标记都有一个相关的表达式。 （下表中给出了标记和表达式的例子。） 使用这个表中的例子，我们就可以编一个字数统计的程序了。 我们的第一个任务就是说明如何声明标记。&lt;/一些符号&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;标记声明举例
标记	相关表达式	含义
数字(number)	([0-9])+	1个或多个数字
字符(chars)	[A-Za-z]	任意字符
空格(blank)	“ “	一个空格
字(word)	(chars)+	1个或多个 chars
变量(variable)	(字符)+(数字)&lt;em&gt;(字符)&lt;/em&gt;(数字)*	
Lex 编程
Lex 编程可以分为三步：&lt;/p&gt;

&lt;p&gt;以 Lex 可以理解的格式指定模式相关的动作。
在这一文件上运行 Lex，生成扫描器的 C 代码。
编译和链接 C 代码，生成可执行的扫描器。
注意: 如果扫描器是用 Yacc 开发的解析器的一部分，只需要进行第一步和第二步。 关于这一特殊问题的帮助请阅读 Yacc和 将 Lex 和 Yacc 结合起来部分。&lt;/p&gt;

&lt;p&gt;现在让我们来看一看 Lex 可以理解的程序格式。一个 Lex 程序分为三个段：第一段是 C 和 Lex 的全局声明，第二段包括模式（C 代码），第三段是补充的 C 函数。 例如, 第三段中一般都有 main() 函数。这些段以%%来分界。 那么，回到字数统计的 Lex 程序，让我们看一下程序不同段的构成。&lt;/p&gt;

&lt;p&gt;C 和 Lex 的全局声明
这一段中我们可以增加 C 变量声明。这里我们将为字数统计程序声明一个整型变量，来保存程序统计出来的字数。 我们还将进行 Lex 的标记声明。&lt;/p&gt;

&lt;p&gt;字数统计程序的声明
%{
 int wordCount = 0;
 %}
 chars [A-za-z_'.&quot;]
 numbers ([0-9])+
 delim [” “\n\t]
 whitespace {delim}+
 words {chars}+
 %%
两个百分号标记指出了 Lex 程序中这一段的结束和三段中第二段的开始。&lt;/p&gt;

&lt;p&gt;Lex 的模式匹配规则
让我们看一下 Lex 描述我们所要匹配的标记的规则。（我们将使用 C 来定义标记匹配后的动作。） 继续看我们的字数统计程序，下面是标记匹配的规则。&lt;/p&gt;

&lt;p&gt;字数统计程序中的 Lex 规则
{words} { wordCount++; /*
 increase the word count by one&lt;em&gt;/ }
 {whitespace} { /&lt;/em&gt; do
 nothing&lt;em&gt;/ }
 {numbers} { /&lt;/em&gt; one may
 want to add some processing here*/ }
 %%
C 代码
Lex 编程的第三段，也就是最后一段覆盖了 C 的函数声明（有时是主函数）。注意这一段必须包括 yywrap() 函数。 Lex 有一套可供使用的函数和变量。 其中之一就是 yywrap。 一般来说，yywrap() 的定义如下例。我们将在 高级 Lex 中探讨这一问题。&lt;/p&gt;

&lt;p&gt;字数统计程序的 C 代码段
void main()
 {
 yylex(); /* start the
 analysis*/
 printf(“ No of words:
 %d\n”, wordCount);
 }
 int yywrap()
 {
 return 1;
 }
上一节我们讨论了 Lex 编程的基本元素，它将帮助你编写简单的词法分析程序。 在 高级 Lex 这一节中我们将讨论 Lex 提供的函数，这样你就能编写更加复杂的程序了。&lt;/p&gt;

&lt;p&gt;将它们全部结合起来
.lex文件是 Lex 的扫描器。它在 Lex 程序中如下表示：&lt;/p&gt;

&lt;p&gt;1
$ lex &lt;file name.lex=&quot;&quot;&gt;
这生成了 lex.yy.c 文件，它可以用 C 编译器来进行编译。它还可以用解析器来生成可执行程序，或者在链接步骤中通过选项 �ll 包含 Lex 库。&lt;/file&gt;&lt;/p&gt;

&lt;p&gt;这里是一些 Lex 的标志：&lt;/p&gt;

&lt;p&gt;-c表示 C 动作，它是缺省的。
-t写入 lex.yy.c 程序来代替标准输出。
-v提供一个两行的统计汇总。
-n不打印 -v 的汇总。
高级 Lex
Lex 有几个函数和变量提供了不同的信息，可以用来编译实现复杂函数的程序。 下表中列出了一些变量和函数，以及它们的使用。 详尽的列表请参考 Lex 或 Flex 手册（见后文的 资源）。&lt;/p&gt;

&lt;p&gt;Lex 变量
yyin	FILE* 类型。 它指向 lexer 正在解析的当前文件。
yyout	FILE* 类型。 它指向记录 lexer 输出的位置。 缺省情况下，yyin 和 yyout 都指向标准输入和输出。
yytext	匹配模式的文本存储在这一变量中（char*）。
yyleng	给出匹配模式的长度。
yylineno	提供当前的行数信息。 （lexer不一定支持。）
Lex 函数
yylex()	这一函数开始分析。 它由 Lex 自动生成。
yywrap()	这一函数在文件（或输入）的末尾调用。 如果函数的返回值是1，就停止解析。 因此它可以用来解析多个文件。 代码可以写在第三段，这就能够解析多个文件。 方法是使用 yyin 文件指针（见上表）指向不同的文件，直到所有的文件都被解析。 最后，yywrap() 可以返回 1 来表示解析的结束。
yyless(int n)	这一函数可以用来送回除了前�n? 个字符外的所有读出标记。
yymore()	这一函数告诉 Lexer 将下一个标记附加到当前标记后。
对 Lex 的讨论就到这里。下面我们来讨论 Yacc…&lt;/p&gt;

&lt;p&gt;Yacc
Yacc 代表 Yet Another Compiler Compiler。 Yacc 的 GNU 版叫做 Bison。它是一种工具，将任何一种编程语言的所有语法翻译成针对此种语言的 Yacc 语 法解析器。它用巴科斯范式(BNF, Backus Naur Form)来书写。按照惯例，Yacc 文件有 .y 后缀。编译行如下调用 Yacc 编译器：
$ yacc &lt;options&gt;
 &amp;lt;filename ending with .y&amp;gt;
在进一步阐述以前，让我们复习一下什么是语法。在上一节中，我们看到 Lex 从输入序列中识别标记。 如果你在查看标记序列，你可能想在这一序列出现时执行某一动作。 这种情况下有效序列的规范称为语法。Yacc 语法文件包括这一语法规范。 它还包含了序列匹配时你想要做的事。&lt;/options&gt;&lt;/p&gt;

&lt;p&gt;为了更加说清这一概念，让我们以英语为例。 这一套标记可能是：名词, 动词, 形容词等等。为了使用这些标记造一个语法正确的句子，你的结构必须符合一定的规则。 一个简单的句子可能是名词+动词或者名词+动词+名词。(如 I care. See spot run.)&lt;/p&gt;

&lt;p&gt;所以在我们这里，标记本身来自语言（Lex），并且标记序列允许用 Yacc 来指定这些标记(标记序列也叫语法)。&lt;/p&gt;

&lt;p&gt;终端和非终端符号
终端符号 : 代表一类在语法结构上等效的标记。 终端符号有三种类型：&lt;/p&gt;

&lt;p&gt;命名标记: 这些由 %token 标识符来定义。 按照惯例，它们都是大写。&lt;/p&gt;

&lt;p&gt;字符标记 : 字符常量的写法与 C 相同。例如, – 就是一个字符标记。&lt;/p&gt;

&lt;p&gt;字符串标记 : 写法与 C 的字符串常量相同。例如，”«” 就是一个字符串标记。&lt;/p&gt;

&lt;p&gt;lexer 返回命名标记。&lt;/p&gt;

&lt;p&gt;非终端符号 : 是一组非终端符号和终端符号组成的符号。 按照惯例，它们都是小写。 在例子中，file 是一个非终端标记而 NAME 是一个终端标记。&lt;/p&gt;

&lt;p&gt;用 Yacc 来创建一个编译器包括四个步骤：&lt;/p&gt;

&lt;p&gt;通过在语法文件上运行 Yacc 生成一个解析器。
说明语法：
编写一个 .y 的语法文件（同时说明 C 在这里要进行的动作）。
编写一个词法分析器来处理输入并将标记传递给解析器。 这可以使用 Lex 来完成。
编写一个函数，通过调用 yyparse() 来开始解析。
编写错误处理例程（如 yyerror()）。
编译 Yacc 生成的代码以及其他相关的源文件。
将目标文件链接到适当的可执行解析器库。
用 Yacc 编写语法
如同 Lex 一样, 一个 Yacc 程序也用双百分号分为三段。 它们是：声明、语法规则和 C 代码。 我们将解析一个格式为 姓名 = 年龄 的文件作为例子，来说明语法规则。 我们假设文件有多个姓名和年龄，它们以空格分隔。 在看 Yacc 程序的每一段时，我们将为我们的例子编写一个语法文件。&lt;/p&gt;

&lt;p&gt;C 与 Yacc 的声明
C 声明可能会定义动作中使用的类型和变量，以及宏。 还可以包含头文件。每个 Yacc 声明段声明了终端符号和非终端符号（标记）的名称，还可能描述操作符优先级和针对不同符号的数据类型。 lexer (Lex) 一般返回这些标记。所有这些标记都必须在 Yacc 声明中进行说明。&lt;/p&gt;

&lt;p&gt;在文件解析的例子中我们感兴趣的是这些标记：name, equal sign, 和 age。Name 是一个完全由字符组成的值。 Age 是数字。于是声明段就会像这样：&lt;/p&gt;

&lt;p&gt;文件解析例子的声明
%
 #typedef char* string; /*
 to specify token types as char* &lt;em&gt;/
 #define YYSTYPE string /&lt;/em&gt;
 a Yacc variable which has the value of returned token &lt;em&gt;/
 %}
 %token NAME EQ AGE
 %%
你可能会觉得 YYSTYPE 有点奇怪。但是类似 Lex, Yacc 也有一套变量和函数可供用户来进行功能扩展。 YYSTYPE 定义了用来将值从 lexer 拷贝到解析器或者 Yacc 的 yylval （另一个 Yacc 变量）的类型。 默认的类型是 int。 由于字符串可以从 lexer 拷贝，类型被重定义为 char&lt;/em&gt;。 关于 Yacc 变量的详细讨论，请参考 Yacc 手册（见 资源）。&lt;/p&gt;

&lt;p&gt;Yacc 语法规则
Yacc 语法规则具有以下一般格式：
result: components { /*
 action to be taken in C */ }
 ;
在这个例子中，result 是规则描述的非终端符号。Components 是根据规则放在一起的不同的终端和非终端符号。 如果匹配特定序列的话 Components 后面可以跟随要执行的动作。 考虑如下的例子：
param : NAME EQ NAME {
 printf(“\tName:%s\tValue(name):%s\n”, $1,$3);}
     | NAME EQ VALUE{
     printf(“\tName:%s\tValue(value):%s\n”,$1,$3);}
 ;
如果上例中序列 NAME EQ NAME 被匹配，将执行相应的 { } 括号中的动作。 这里另一个有用的就是 $1 和 $3 的使用, 它们引用了标记 NAME 和 NAME（或者第二行的 VALUE）的值。 lexer 通过 Yacc 的变量 yylval 返回这些值。标记 NAME 的 Lex 代码是这样的：
char [A-Za-z]
 name {char}+
 %%
 {name} { yylval = strdup(yytext);
 return NAME; }
文件解析例子的规则段是这样的：&lt;/p&gt;

&lt;p&gt;文件解析的语法
file : record file
 | record
 ;
 record: NAME EQ AGE {
 printf(“%s is now %s years old!!!”, $1, $3);}
 ;
 %%
附加 C 代码
现在让我们看一下语法文件的最后一段，附加 C 代码。 （这一段是可选的，如果有人想要略过它的话：）一个函数如 main() 调用 yyparse() 函数（Yacc 中 Lex 的 yylex() 等效函数）。 一般来说，Yacc 最好提供 yyerror(char msg) 函数的代码。 当解析器遇到错误时调用 yyerror(char msg)。错误消息作为参数来传递。 一个简单的 yyerror( char* ) 可能是这样的：
int yyerror(char* msg)
 {
 printf(“Error: %s
 encountered at line number:%d\n”, msg, yylineno);
 }
yylineno 提供了行数信息。&lt;/p&gt;

&lt;p&gt;这一段还包括文件解析例子的主函数：&lt;/p&gt;

&lt;p&gt;附加 C 代码
void main()
 {
     yyparse();
 }
 int yyerror(char* msg)
 {
 printf(“Error: %s
 encountered \n”, msg);
要生成代码，可能用到以下命令：
$ yacc _d &lt;filename.y&gt;
这生成了输出文件 y.tab.h 和 y.tab.c，它们可以用 UNIX 上的任何标准 C 编译器来编译（如 gcc）。&lt;/filename.y&gt;&lt;/p&gt;

&lt;p&gt;命令行的其他常用选项
‘-d’ ,’–defines’ : 编写额外的输出文件，它们包含这些宏定义：语法中定义的标记类型名称，语义的取值类型 YYSTYPE, 以及一些外部变量声明。如果解析器输出文件名叫 ‘name.c’, 那么 ‘-d’ 文件就叫做 ‘name.h’。 如果你想将 yylex 定义放到独立的源文件中，你需要 ‘name.h’, 因为 yylex 必须能够引用标记类型代码和 yylval变量。
‘-b file-prefix’ ,’–file-prefix=prefix’ : 指定一个所有Yacc输出文件名都可以使用的前缀。选择一个名字，就如输入文件名叫 ‘prefix.c’.
‘-o outfile’ ,’–output-file=outfile’ : 指定解析器文件的输出文件名。其他输出文件根据 ‘-d’ 选项描述的输出文件来命名。
Yacc 库通常在编译步骤中自动被包括。但是它也能被显式的包括，以便在编译步骤中指定 �ly选项。这种情况下的编译命令行是：
$ cc &lt;source file=&quot;&quot; names=&quot;&quot; /&gt; -ly
将 Lex 与 Yacc 结合起来
到目前为止我们已经分别讨论了 Lex 和 Yacc。现在让我们来看一下他们是怎样结合使用的。&lt;/p&gt;

&lt;p&gt;一个程序通常在每次返回一个标记时都要调用 yylex() 函数。只有在文件结束或者出现错误标记时才会终止。&lt;/p&gt;

&lt;p&gt;一个由 Yacc 生成的解析器调用 yylex() 函数来获得标记。 yylex() 可以由 Lex 来生成或完全由自己来编写。 对于由 Lex 生成的 lexer 来说，要和 Yacc 结合使用，每当 Lex 中匹配一个模式时都必须返回一个标记。 因此 Lex 中匹配模式时的动作一般格式为：
{pattern} { /* do smthg*/
 return TOKEN_NAME; }
于是 Yacc 就会获得返回的标记。当 Yacc 编译一个带有 _d 标记的 .y文件时，会生成一个头文件，它对每个标记都有 #define 的定义。 如果 Lex 和 Yacc 一起使用的话，头文件必须在相应的 Lex 文件 .lex中的 C 声明段中包括。&lt;/p&gt;

&lt;p&gt;让我们回到名字和年龄的文件解析例子中，看一看 Lex 和 Yacc 文件的代码。&lt;/p&gt;

&lt;p&gt;Name.y - 语法文件
%
 typedef char* string;
 #define YYSTYPE string
 %}
 %token NAME EQ AGE
 %%
 file : record file
 | record
 ;
 record : NAME EQ AGE {
 printf(“%s is %s years old!!!\n”, $1, $3); }
 ;
 %%
 int main()
 {
 yyparse();
 return 0;
 }
 int yyerror(char *msg)
 {
 printf(“Error
 encountered: %s \n”, msg);
 }
Name.lex - Lex 的解析器文件
%{
 #include “y.tab.h”&lt;/p&gt;

&lt;p&gt;#include &lt;stdio.h&gt;
 #include &lt;string.h&gt;
 extern char* yylval;
 %}
 char [A-Za-z]
 num [0-9]
 eq [=]
 name {char}+
 age {num}+
 %%
 {name} { yylval = strdup(yytext);
 return NAME; }
 {eq} { return EQ; }
 {age} { yylval = strdup(yytext);
 return AGE; }
 %%
 int yywrap()
 {
 return 1;
 }
作为一个参考，我们列出了 y.tab.h, Yacc 生成的头文件。&lt;/string.h&gt;&lt;/stdio.h&gt;&lt;/p&gt;

&lt;p&gt;y.tab.h - Yacc 生成的头文件&lt;/p&gt;
&lt;h1 id=&quot;define-name-257&quot;&gt;define NAME 257&lt;/h1&gt;
&lt;p&gt;# define EQ 258
 # define AGE 259&lt;/p&gt;

&lt;p&gt;无论是词法分析，还是语法分析，给我的第一感觉就是逻辑要严谨。由于项目有自己一套完整的语言和语法，设计好其对应的词法分析器和语法分析器显得尤为重要。
        我们采用flex进行词法分析。flex是一个用来生成扫描器（scanners）的工具，其中扫描器就是可以识别文本中词法模式的程序。具体流程为：flex读取给定的输入文件，或标准输入（当没有给定文件名时）读取信息来生成一个扫描器。信息以正则表达式和C代码组成，这种形式称为规则（rule）。flex生成C源代码文件lex.yy.c，其中定义了一个函数yylex()。这个文件通过编译，并用-lfl 链接生成可执行文件。当可执行文件被执行时，它分析输入中可能存在的符合正则表达的内容。当找到任何一个与正则表达式相匹配内容时，相应的C 代码将被执行。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;    flex输入文件由三段组成：定义（definitions），规则（rules），用户代码（user code）
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;一、定义段（definitions）&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;    定义段包含了简单名称的声明（这些声明可以简化扫描器的说明）和开始条件。在本项目中，定义段中还包含了选项options。现将介绍一些比较常用的options。

    flex 提供一个机制用来在扫描器的说明中，而不是在flex 命令中控制选项。在扫描器的说明文件（flex 的输入文件）的第一段中使用%option 指令就可以实现。你可以用单个%option 指令指定多个选项，也可以使用多个%option指令。

    %option 7bit，%option 8bit——指示flex生成一个7bit或8bit的扫描器与-7，-8 选项等价。

    %option backup——生成一个备份信息到lex.backup，与-b选项等价。

    %option caseful，%option case-sensitive——区分大小写，与-i相反。

    %option case-insensitive，%option caseless——忽略大小写，与-i选项等价。

    %option debug——让生成的扫描器运行在debug模式，与-d选项等价。

    %option default，%option nodefault——%default与-s选项相反，后者与其等价。-s选项作用：使不匹配的输入回显到输出设备的rule失去作用。在此种情况下，如果扫描器不能匹配到任何规则rule的输入，它会终止并返回错误。在查找扫描器的规则漏洞时，-s和%option nodefault都非常有用。

    %option interactive——指示flex生成一个交互式的扫描器。交互式扫描器就是向前查看下一个匹配的token是什么。结果就是总向前多看了一个字符，即使是在扫描器已经看够了文本已经排除了token 的歧义。但向前查看给了扫描器强大的交互能力。与-I等价。

    %option warn——与-w选项相反。%option nowarn与-w选项等价。

    %option array——与%array等价。

    %option pointer——与%point等价。

    以下为%option中定义，但在命令行里没有的特性。

    %option always-interactive——指示flex 生成的扫描器总是把它的输入认为是&quot;interactive&quot;。

    %option main——指示flex 为扫描器提供一个缺省的main()函数，它只是简单的调用了yylex()。这个选项暗示noyywrap。

    %option never-interactive——flex 生成的扫描器从不认为输入是交互的（不会调用isatty()）。这和总是interactive 正好相反。

    %option yylineno——flex 生成的扫描器用全局变量yylineno 维护着输入文件的当前行编号。option lex-compat隐含有这个选项。

    %option yywrap——如果没有设置（就如%option noyywrap），当扫描器遇到end-of-file 时，不会调用yywrap()，但简单的假定没有更多的文件可以扫描（直到用户把yyin 指向新的文件并再一次调用yylex（））。

    flex 通过扫描rule 中的action 来判断你是否使用了REJECT 或是yymore 属性。你可用%option reject 表示要使用这个特性而用%option noyymore 表示不使用这个特性。

    三个选项使用了字符串值，从'='开始：%option outfile=&quot;ABC&quot;等同于-oABC ；%option prefix=&quot;XYZ&quot; 等同于-PXYZ；最后，%option yyclass=&quot;foo&quot; 只有当生成C++扫描器（-+选项）时才有效。

   有些选项可以限制一个例程不出现在生成的扫描器中。下面这些例程如果不被设置（如%option nounput）将不会出现在生成的扫描器中。

   input unput yy_push_state yy_pop_sate yy_top_state yy_scan_buffer yy_scan_bytes yy_scan_string

   可重入c扫描器（Reentrant C Scanners）

   flex能够生成一个可重入的扫描器。通过定义%option reentrant（与-R选项等价）来实现可重入。所生成的扫描器在一个或多个控制线程中不仅可移植，而且安全性好。可重入扫描器通常应用于多线程应用程序。任何一个线程都可以在不考虑与其他线程同步的情况下创建并执行一个可重入的flex扫描器。

   默认情况下，flex生成一个不可重入的扫描器。本项目为了实现多线程，因而在定义段指定%option reentrant。

   性能考虑（performance consideration）

   flex的设计目标就是生成一个高性能的扫描器。它已经对处理大量rule 做了优化。除了用-C 选项进行表格压缩之外，还有一些option/action 会影响到扫描器的速度。从最大影响到最弱，有这一些：

   REJECT          %option yylineno           arbitrary trailing context

   pattern sets that require backing up        %array          %option interactive             %option always-interactive

   '^'beginning-of-line operator      yymore()

   头三个的开销最大，后两个的开销最小。注意unput()有可能被用例程实现而造成更多操作，而yyless()是一个开销相当低的宏；所以如果只是回放一些你多扫了的文本，可以用yyless()。

   本项目中也用到了名字定义和开始条件。其中名字定义包括数字、字符、空白符，多行注释，单行注释，引号间的字符串，整数、浮点数、实数，标示符，变量，日期。

   数字—digit [0-9]，字符—character [a-zA-Z]，空白符—space [ \t\r](在制表符前面留有空格表示空格符)

   多行注释（以/#开头，中间可以为任意非#非\n字符，也可以为一串#后面紧跟非/非\n字符，最后结尾为1个或多个#后跟/）

   comstart   \/\#

   comstop \#+\/

   cominside ([^#\n]*|#+[^#/\n])

   单行注释 line_comment  ^#[^\n]*

   引号间的字符串（以双引号开头以双引号结尾。内容为非转义字符和双引号，当遇到转义字符时，进行特殊处理；当遇到双引号时，停止匹配）

   dquotes \&quot;

   stringstart {dquotes}

   stringstop {dquotes}

   stringinside [^\\\&quot;]+

   注意：在多行注释和引号间的字符串的匹配中，采用了排斥条件（开始条件分为排斥和共享条件）

   排斥条件的定义为 %xc（针对多行注释）

                                     %xs（针对引号间的字符串）

   整数 integer {digit}+

   浮点数 decimal (({digit}+\.{digit}*)|({digit}*\.{digit}+))

                 decimalfail {digit}+\.\.

   实数 real ({integer}|{decimal})[eE][+-]?{digit}+

             realfail1 ({integer}|decimal)[eE]

             realfail2 ({integer}|decimal)[eE][+-]

   标示符 identstart [a-zA-Z\200-\377_]

   identcont [a-zA-Z\200-\377_0-9\$]

   identifier {identstart}{identcont}*

   变量（$后跟一个或多个字符） variable \${character}+

   日期 date {digit}+\-{digit}+(\-{digit}+)?

             datefail1 {digit}+\-{digit}+\-

             datefail2 {digit}+\- 
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;二、规则段（rules）&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;   规则段包含模式（pattern）和动作（action），其中模式不能有缩进，而且动作必须在同一行上跟在动作后面。

   在规则段可以使用开始条件（start conditions）。flex 提供了一种按条件激活规则rule 的机制。所有模式以&quot;&amp;lt;sc&amp;gt;&quot;为前缀的rule 只有在扫描器是在一个名为&quot;sc&quot;的启动条件时才会被激活。使用BEGIN action 可以激活一个开始条件。直到下一个BEGIN action 被执行，在给出开始条件的rule将被激活并且其他给出其他开始条件的rule 并不会被激活。如果使用的是排他的开始条件，那么只有以开始条件修饰的rule 才会被激活。跟在同一个排他开始条件后的rule 说明在扫描器中，这些rule 是独立于flex 输入中的其他rule。

    本项目中涉及到排斥条件的有多行注释、引号间的字符串。

    其中MOVELOC,SAVETOKEN为定义段中定义的宏

    #define MOVELOC  {yylloc-&amp;gt;first_column = yylloc-&amp;gt;last_column;\

                                         yylloc-&amp;gt;last_column = yylloc-&amp;gt;first_column + yyleng;}

    #define RESETLOC {yylloc-&amp;gt;first_column = yylloc-&amp;gt;last_column = 1;\

                                        yylloc-&amp;gt;first_line++;\

                                        yylloc-&amp;gt;last_line++;}

   #define SAVETOKEN yylval-&amp;gt;str = new std::string(yytext, yyleng)

    多行注释(语句输出省略)

    {comstart}       {         MOVELOC;

                                        BEGIN(xc);

                              }

    &amp;lt;xc&amp;gt;{cominside} {     MOVELOC;      }

    &amp;lt;xc&amp;gt;\n              {         RESETLOC;     }

    &amp;lt;xc&amp;gt;{comstop} {       MOVELOC;

                                        BEGIN(INITIAL);

                              }

    &amp;lt;xc&amp;gt;&amp;lt;&amp;lt;EOF&amp;gt;&amp;gt; {       BEGIN(INITIAL);

                                       std::cerr &amp;lt;&amp;lt; &quot;unterminated /# comment&quot; &amp;lt;&amp;lt; endl;

                                       yyterminate();

                               }

   引号间的字符串(输出语句省略)

   {stringstart}         {   MOVELOC;

                                     BEGIN(xs);

                                     SAVETOKEN;

                              }

   &amp;lt;xs&amp;gt;{stringstop} {  MOVELOC;

                                     BEGIN(INITIAL);

                                     *(yylval-&amp;gt;str) += yytext;

                                     return QUOTES_STRING;

                              }

   &amp;lt;xs&amp;gt;\n               {       RESETLOC;

                                      *(yylval-&amp;gt;str) += yytext;

                              }

   &amp;lt;xs&amp;gt;\\n               {     MOVELOC;

                                      *(yylval-&amp;gt;str) += &quot;\n&quot;;

                              }

    &amp;lt;xs&amp;gt;\\t               {      MOVELOC;

                                      *(yylval-&amp;gt;str) += &quot;\t&quot;;

                              }

    &amp;lt;xs&amp;gt;\\r               {      MOVLOC;

                                      *(yylval-&amp;gt;str) += &quot;\r&quot;;

                              }

    &amp;lt;xs&amp;gt;\\b             {      MOVELOC;

                                      *(yylval-&amp;gt;str) += &quot;\b&quot;;

                              }

    &amp;lt;xs&amp;gt;\\f               {      MOVELOC;

                                      *(yylval-&amp;gt;str) += &quot;\f&quot;;

                              }

     &amp;lt;xs&amp;gt;\\.             {       MOVELOC;

                                      *(yylval-&amp;gt;str) += yytext[1];

                              }

    &amp;lt;xs&amp;gt;\\\n             {     RESETLOC;

                                      *(yylval-&amp;gt;str) += &quot;\n&quot;;

                              }

   &amp;lt;xs&amp;gt;{stringinside} {        MOVELOC;

                                    *(yylval-&amp;gt;str) += yytext;

                              }

   &amp;lt;xs&amp;gt;&amp;lt;&amp;lt;EOF&amp;gt;&amp;gt; {     BEGIN(INITIAL);

                                    std::cerr &amp;lt;&amp;lt; &quot;unterminated \&quot;&quot; &amp;lt;&amp;lt; endl;

                                     delete yylval-&amp;gt;str;

                                    yyterminate();

                             }
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;三、用户代码段&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;  用户代码段只会简单的拷贝到lex.yy.c中。这个和扫描器一起，调用扫描器或者被扫描器调用。如果被省略，则第二个%%可以省略。

  使用了%option reentrant后

  1所有的函数都会带一个额外的参数yyscanner。

  2所有的全局变量都被它们的宏等价替换。

  这些变量包括yytext,yyleng, yylineno, yyin, yyout,yyextra, yylval, and yylloc，你可以在action部分安全地使用这些宏（如同使用普通变量一样），但不能够在外部直接使用。以yytext为例，在一个可重入的扫描器中，yytext以及其他类似变量都不是全局变量，因而不能通过action外部或是其他函数来直接访问yytext，而应该使用yyget_text访问器函数来实现对yytext的访问。

  3在使用yylex之前调用yylex_init，在使用之后调用yylex_destroy。

  init以及destroy函数

  int yylex_init ( yyscan_t * ptr_yy_globals ) ;

  int yylex_init_extra ( YY_EXTRA_TYPE user_defined, yyscan_t * ptr_yy_globals ) ;

  int yylex ( yyscan_t yyscanner ) ;

  int yylex_destroy ( yyscan_t yyscanner ) ;

  函数yylex_init必须在调用任意其他函数之前调用，其参数是一个未初始化的指针地址，并由该函数初始化，这样会覆盖以前的内容。ptr_yy_global中存储的值会传递给yylex和yylex_destroy。flex不会保存传递给yylex_init的变量，因而传递一个局部指针的地址值给yylex_init是很安全的，只要其在调用扫描器到调用yylex_destroy期间一直存在就行。

  yylex的可重入版本带一个参数，该参数即为yylex_init通过变量返回的值。

  yylex_destroy函数用来释放扫描器使用过的资源。当要重复使用时，就不必destroy。

  4获取函数（get或set）提供了访问普通flex变量的途径。

  5用户自定义数据可以再yyextra中存储。

  在一个可重入的扫描器中，使用全局变量让程序的不同部分通信或是保持状态是不明智的。然而，你需要在action中使用额外的数据或是调用额外的函数。同样，你需要传递信息给你的扫描器。在一个不可重入的扫描器中，实现这的唯一方式就是使用全局变量。flex允许你存储任意的、额外的数据到扫描器中。定义如下：

  #define YY_EXTRA_TYPE void*

  YY_EXTRA_TYPE yyget_extra ( yyscan_t scanner );

  void yyset_extra ( YY_EXTRA_TYPE arbitrary_data , yyscan_t scanner);

  项目中最后的代码如下，其中scanner_init初始化yylex，yy_scan_buffer函数（作用是建立输入缓存）从yyext-&amp;gt;scanbuf指定的开始位置扫描slen+2个字节，最后两个字节必须是YY_END_OF_BUFFER_CHAR。
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;[html] view plain copy
yyscan_t&lt;br /&gt;
scanner_init(const char *str, inl_yylex_extra *yyext)&lt;br /&gt;
{&lt;br /&gt;
         int             slen = strlen(str);&lt;br /&gt;
         yyscan_t        scanner;&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;     if(yylex_init(&amp;amp;scanner) != 0)  
     {  
             std::cerr &amp;lt;&amp;lt; &quot;yylex_init() failed&quot; &amp;lt;&amp;lt; std::endl;  
             exit(1);  
     }  
   
     inl_yyset_extra(yyext, scanner);  
   
     yyext-&amp;gt;scanbuf = (char *)malloc(slen + 2);  
     yyext-&amp;gt;scanbuflen = slen;  
   
     memcpy(yyext-&amp;gt;scanbuf, str, slen);  
     yyext-&amp;gt;scanbuf[slen] = yyext-&amp;gt;scanbuf[slen + 1] = YY_END_OF_BUFFER_CHAR;  
     yy_scan_buffer(yyext-&amp;gt;scanbuf, slen + 2, scanner);  
   
     return scanner;   }  
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;void scanner_finish(yyscan_t yyscanner)&lt;br /&gt;
{&lt;br /&gt;
         free((*((inl_yylex_extra**)(yyscanner)))-&amp;gt;scanbuf);&lt;br /&gt;
         inl_yylex_destroy(yyscanner);&lt;br /&gt;
}&lt;/p&gt;
</description>
        <pubDate>Tue, 13 Feb 2018 00:00:00 +0800</pubDate>
        <link>https://xiazemin.github.io/MyBlog/lang/2018/02/13/lex.html</link>
        <guid isPermaLink="true">https://xiazemin.github.io/MyBlog/lang/2018/02/13/lex.html</guid>
        
        
        <category>lang</category>
        
      </item>
    
      <item>
        <title>vld_dot_graphviz</title>
        <description>&lt;!-- more --&gt;
&lt;p&gt;PHP7.1下 vld扩展的安装使用
PHP7.1下 vld扩展的安装使用
原创 2017年03月29日 08:03:05 595
1）git clone https://github.com/derickr/vld.git&lt;/p&gt;

&lt;p&gt;2）cd vld&lt;/p&gt;

&lt;p&gt;3）phpize&lt;/p&gt;

&lt;p&gt;4）./configure&lt;/p&gt;

&lt;p&gt;5）make &amp;amp;&amp;amp; make install&lt;/p&gt;

&lt;p&gt;6）添加ext-vld.ini配置文件&lt;/p&gt;

&lt;p&gt;7）重启fpm&lt;/p&gt;

&lt;table&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td&gt;8）php -m&lt;/td&gt;
      &lt;td&gt;grep vld 查看扩展&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;p&gt;9）php -dvld.active test.php 测试vld扩展&lt;/p&gt;

&lt;p&gt;PHP7.1下 vld扩展的安装使用
原创 2017年03月29日 08:03:05 595
1）git clone https://github.com/derickr/vld.git&lt;/p&gt;

&lt;p&gt;2）cd vld&lt;/p&gt;

&lt;p&gt;3）phpize&lt;/p&gt;

&lt;p&gt;4）./configure&lt;/p&gt;

&lt;p&gt;5）make &amp;amp;&amp;amp; make install&lt;/p&gt;

&lt;p&gt;6）添加ext-vld.ini配置文件&lt;/p&gt;

&lt;p&gt;7）重启fpm&lt;/p&gt;

&lt;table&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td&gt;8）php -m&lt;/td&gt;
      &lt;td&gt;grep vld 查看扩展&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;p&gt;9）php -dvld.active test.php 测试vld扩展&lt;/p&gt;

&lt;p&gt;关于VLD扩展显示信息的一点点解释&lt;/p&gt;

&lt;p&gt;其中：&lt;/p&gt;

&lt;p&gt;branch analysis from position 在分析数组时使用&lt;/p&gt;

&lt;p&gt;return found是否返还&lt;/p&gt;

&lt;p&gt;filename 分析的文件名&lt;/p&gt;

&lt;p&gt;function name函数名&lt;/p&gt;

&lt;p&gt;number of ops生成的操作数&lt;/p&gt;

&lt;p&gt;compiled vars编译期间的变量，PHP5后添加，是一个缓存优化，在PHP源码中以IS_CV标记&lt;/p&gt;

&lt;p&gt;op list生成的中间代码的变量列表&lt;/p&gt;

&lt;p&gt;-dvld.active输出的是VLD的默认设置，使用-dvld.verbosity可以查看更加详细的内容&lt;/p&gt;

&lt;p&gt;包含各个中间代码的操作数等&lt;/p&gt;

&lt;p&gt;若只想看到输出的中间代码，并不想实际执行这段代码，可以使用-dvld.execute = 0来禁用代码的执行&lt;/p&gt;

&lt;p&gt;php -dvld.active=1 -dvld.execute=0 test.php&lt;/p&gt;

&lt;p&gt;它还可以支持输出.dot文件&lt;/p&gt;

&lt;p&gt;php -dvld.active=1 -dvld.save_dir=’D:\tmp’ -dvld.save_paths=1 -dvld.dump_paths=1 t.php 会将生成的中间代码的信息输出再D:/tmp/path.dot中&lt;/p&gt;

&lt;p&gt;-dvld.format是否以自定义的格式输出，默认为否，是指以-dvld.col_sep指定的参数间隔&lt;/p&gt;

&lt;p&gt;-dvld.col_sep在-dvld.format参数启用时才会有效，默认为 \t&lt;/p&gt;

&lt;p&gt;-dvld.verbosity是否显示更加详细的信息，默认为1，其值可以是0，1，2，3 或者小于0只是比1小的效果会喝0一样，负数的效果和3的效果一样&lt;/p&gt;

&lt;p&gt;-dvld.save_dir指定文件的输出路径，默认/tmp&lt;/p&gt;

&lt;p&gt;-dvld.save_path指定文件输出的路径，默认0表示不输出文件&lt;/p&gt;

&lt;p&gt;-dvld.dump_paths控制输出的内容，0或1 默认1，即输出内容&lt;/p&gt;

&lt;p&gt;2、linux下咋安装graphviz
http://www.cnblogs.com/sld666666/archive/2010/06/25/1765510.html
2.1）CentOS 下安装 graphviz&lt;/p&gt;

&lt;p&gt;$ sudo yum install graphviz&lt;/p&gt;

&lt;p&gt;Install 39 Package(s)&lt;/p&gt;

&lt;p&gt;总下载量：13 M
Installed size: 35 M
确定吗？[y/N]：y&lt;/p&gt;

&lt;p&gt;已安装:
graphviz.i686 0:2.26.0-10.el6&lt;/p&gt;

&lt;p&gt;完毕！&lt;/p&gt;

&lt;p&gt;3、在Linux下如何使用&lt;/p&gt;

&lt;p&gt;　　假设我们把上面的代码写到了一个叫做aa.gv的文本文件里面，那么我们执行如下命令就可以了：&lt;/p&gt;

&lt;p&gt;　　$ dot -Tpng -ohehe.png aa.gv&lt;/p&gt;

&lt;p&gt;　　这样就会在当前目录下生成一个叫做hehe.png的图片文件
　　&lt;/p&gt;

&lt;p&gt;mac&lt;/p&gt;

&lt;p&gt;wget http://pecl.php.net/get/vld-0.14.0.tgz
tar zxvf vld-0.14.0.tgz
cd vld-0.14.0
phpize
locate php-config
./configure –with-php-config=/usr/local/Cellar/php70/7.0.25_17/bin/php-config
 make &amp;amp;&amp;amp; make install
 php -r ‘phpinfo();’ |grep vld
 ls /usr/local/Cellar/php70/7.0.25_17/lib/php/extensions/no-debug-non-zts-20151012/vld.so
 vi  /usr/local/etc/php/7.0/php.ini
 php -r ‘phpinfo();’ |grep vld
 php -dvld.active=1 -dvld.execute=0 test.php
 php -dvld.active=1 -dvld.save_paths=1 test.php
 ls /tmp
 brew install graphviz
 dot -Tpng /tmp/paths.dot -o paths.png
&lt;img src=&quot;https://xiazemin.github.io/MyBlog/img/paths.png&quot; /&gt;&lt;/p&gt;
</description>
        <pubDate>Mon, 12 Feb 2018 00:00:00 +0800</pubDate>
        <link>https://xiazemin.github.io/MyBlog/web/2018/02/12/vld_dot_graphviz.html</link>
        <guid isPermaLink="true">https://xiazemin.github.io/MyBlog/web/2018/02/12/vld_dot_graphviz.html</guid>
        
        
        <category>web</category>
        
      </item>
    
      <item>
        <title>phpvld</title>
        <description>&lt;!-- more --&gt;
&lt;p&gt;vld介绍&lt;/p&gt;

&lt;p&gt;　　vld是PECL（PHP 扩展和应用仓库）的一个PHP扩展，现在最新版本是 0.14.0（2016-12-18），它的作用是：显示转储PHP脚本（opcode）的内部表示（来自PECL的vld简介）。简单来说，可以查看PHP程序的opcode。
vld扩展的安装&lt;/p&gt;

&lt;p&gt;　　1、下载官方插件安装压缩包&lt;/p&gt;

&lt;p&gt;　　　　官方网址：http://pecl.php.net/package/vld
　　　　下载命令：# wget http://pecl.php.net/get/vld-0.14.0.tgz&lt;/p&gt;

&lt;p&gt;　　　　注：下载的URL是在相对的版本链接上，点击右键，复制链接即可&lt;/p&gt;

&lt;p&gt;　　2、解包&lt;/p&gt;

&lt;p&gt;　　　　解包命令：# tar zxvf vld-0.14.0.tgz&lt;/p&gt;

&lt;p&gt;　　3、编译和安装&lt;/p&gt;

&lt;p&gt;　　　　进入解压后的vld目录：# cd vld-0.14.0/&lt;/p&gt;

&lt;p&gt;　　　　扩展php扩展模块:# phpize&lt;/p&gt;

&lt;p&gt;　　　　使用locate找php-config路径：# locate php-config&lt;/p&gt;

&lt;p&gt;　　　　　　注：locate命令没有的话可以使用命令：【# yum -y install mlocate 】 安装后使用 【#  updatedb】 更新数据后可以直接使用&lt;/p&gt;

&lt;p&gt;　　　　　　找到的php-config如下：&lt;/p&gt;

&lt;p&gt;　　　　　　&lt;/p&gt;

&lt;p&gt;　　　　配置编译vld的php-config路径：#  ./configure –with-php-config=/usr/bin/php-config –enable-vld&lt;/p&gt;

&lt;p&gt;　　　　编译安装：# make &amp;amp;&amp;amp; make install&lt;/p&gt;

&lt;p&gt;　　4、重启服务器&lt;/p&gt;

&lt;p&gt;　　　　重启Apache：# systemctl restart httpd.service&lt;/p&gt;

&lt;p&gt;　　　　重启Nginx和PHP-fpm（如果有Nginx的话重启）：&lt;/p&gt;

&lt;p&gt;　　　　　　# systemctl restart nginx.service&lt;/p&gt;

&lt;p&gt;　　　　　　# systemctl restart php-fpm.service&lt;/p&gt;

&lt;p&gt;　　　　注：systemctl是新版本的centos系统有的，没有该命令的可以使用下面三个命令代替&lt;/p&gt;

&lt;p&gt;　　　　　　# service apachectl restart&lt;/p&gt;

&lt;p&gt;　　　　　　# service nginx restart&lt;/p&gt;

&lt;p&gt;　　　　　　# service php-fpm restart&lt;/p&gt;

&lt;p&gt;vld扩展的测试&lt;/p&gt;

&lt;p&gt;　　使用phpinfo()函数测试是否已成功安装，测试代码：&lt;/p&gt;

&lt;?php 
    phpinfo();
?&gt;
&lt;p&gt;　　　　1、使用网络访问结果如下（显示enabled）：
　　　　2、使用命令测试（显示enabled）：&lt;/p&gt;

&lt;p&gt;　　　　　　命令是:# php test.php | grep “vld”
那么，vld怎么用捏？&lt;/p&gt;

&lt;p&gt;　　vld不能单独使用，它需要和PHP命令一起。它主要有两个参数分别是 -dvld.active （等于1证明是使用vld扩展）和 -dvld.execute （等于1证明是需要执该PHP文件，默认是1）。&lt;/p&gt;

&lt;p&gt;　　测试命令：# php -dvld.active=1 -dvld.execute=0 test.php&lt;/p&gt;

&lt;p&gt;　　（就是指运行test.php的时候，使用vld插件，不执行，只显示opcode）&lt;/p&gt;

&lt;p&gt;VLD(Vulcan Logic Dumper)是一个在Zend引擎中，以挂钩的方式实现的用于输出PHP脚本生成的中间代码（执行单元）的扩展。 它可以在一定程序上查看Zend引擎内部的一些实现原理，是我们学习PHP源码的必备良器。它的作者是Derick Rethans, 除了VLD扩展，我们常用的XDebug扩展的也有该牛人的身影。&lt;/p&gt;

&lt;p&gt;VLD扩展是一个开源的项目，在这里可以下载到最新的版本，虽然最新版本的更新也是一年前的事了。 作者没有提供编译好的扩展，Win下使用VC6.0编译生成dll文件，可以看我之前写过的一篇文章(使用VC6.0生成VLD扩展)。 *nix系统下直接configue,make,make install生成。如果遇到问题，请自行Google之。&lt;/p&gt;

&lt;p&gt;看一个简单的例子,假如存在t.php文件，其内容如下：&lt;/p&gt;

&lt;p&gt;$a = 10;
echo $a;
在命令行下使用VLD扩展显示信息。&lt;/p&gt;

&lt;p&gt;php -dvld.active=1 t.php
-dvld.active=1表示激活VLD扩展，使用VLD扩展输出中间代码，此命令在CMD中输出信息为：&lt;/p&gt;

&lt;p&gt;Branch analysis from position: 0
Return found
filename:       D:\work\xampp\xampp\php\t.php
function name:  (null)
number of ops:  5
compiled vars:  !0 = $a
line     # *  op                           fetch          ext  return  operands
———————————————————————————
   2     0  &amp;gt;   EXT_STMT
         1      ASSIGN                                                   !0, 10
   3     2      EXT_STMT
         3      ECHO                                                     !0
   4     4    &amp;gt; RETURN                                                   1&lt;/p&gt;

&lt;p&gt;branch: #  0; line:     2-    4; sop:     0; eop:     4
path #1: 0,
10
如上为VLD输出的PHP代码生成的中间代码的信息，说明如下：&lt;/p&gt;

&lt;p&gt;Branch analysis from position 这条信息多在分析数组时使用。
Return found 是否返回，这个基本上有都有。
filename 分析的文件名
function name 函数名，针对每个函数VLD都会生成一段如上的独立的信息，这里显示当前函数的名称
number of ops 生成的操作数
compiled vars 编译期间的变量，这些变量是在PHP5后添加的，它是一个缓存优化。这样的变量在PHP源码中以IS_CV标记。
op list 生成的中间代码的变量列表
使用-dvld.active参数输出的是VLD默认设置，如果想看更加详细的内容。可以使用-dvld.verbosity参数。&lt;/p&gt;

&lt;p&gt;php -dvld.active=1 -dvld.verbosity=3 t.php
-dvld.verbosity=3或更大的值的效果都是一样的，它们是VLD在当前版本可以显示的最详细的信息了，包括各个中间代码的操作数等。显示结果如下：&lt;/p&gt;

&lt;p&gt;Finding entry points
Branch analysis from position: 0
Add 0
Add 1
Add 2
Add 3
Add 4
Return found
filename:       D:\work\xampp\xampp\php\t.php
function name:  (null)
number of ops:  5
compiled vars:  !0 = $a
line     # *  op                           fetch          ext  return  operands
——————————————————————————–
-
   2     0  &amp;gt;   EXT_STMT                                          RES[  IS_UNUSED  ]         OP1[  IS_UNUSED  ] OP2[  IS_UNUSED  ]
         1      ASSIGN                                                    OP1[IS_CV !0 ] OP2[ ,  IS_CONST (0) 10 ]
   3     2      EXT_STMT                                          RES[  IS_UNUSED  ]         OP1[  IS_UNUSED  ] OP2[  IS_UNUSED  ]
         3      ECHO                                                      OP1[IS_CV !0 ]
         4    &amp;gt; RETURN                                                    OP1[IS_CONST (0) 1 ]&lt;/p&gt;

&lt;p&gt;branch: #  0; line:     2-    3; sop:     0; eop:     4
path #1: 0,
10
以上的信息与没有加-dvld.verbosity=3的输出相比，多了Add 字段，还有中间代码的操作数的类型，如IS_CV,IS_CONST等。 PHP代码中的$a = 10; 其中10的类型为IS_CONST, $a作为一个编译期间的一个缓存变量存在，其类型为IS_CV。&lt;/p&gt;

&lt;p&gt;如果我们只是想要看输出的中间代码，并不想执行这段PHP代码，可以使用-dvld.execute=0来禁用代码的执行。&lt;/p&gt;

&lt;p&gt;php -dvld.active=1 -dvld.execute=0 t.php
运行这个命令，你会发现这与最开始的输出有一点点不同，它没有输出10。 除了直接在屏幕上输出以外，VLD扩展还支持输出.dot文件，如下的命令：&lt;/p&gt;

&lt;p&gt;php -dvld.active=1 -dvld.save_dir=’D:\tmp’ -dvld.save_paths=1 -dvld.dump_paths=1 t.php
以上的命令的意思是将生成的中间代码的一些信息输出在D:/tmp/paths.dot文件中。 -dvld.save_dir指定文件输出的路径，-dvld.save_paths控制是否输出文件，-dvld.dump_paths控制输出的内容，现在只有0和1两种情况。 输出的文件名已经在程序中硬编码为paths.dot。这三个参数是相互依赖的关系，一般都会同时出现。&lt;/p&gt;

&lt;p&gt;总结一下，VLD扩展的参数列表：&lt;/p&gt;

&lt;p&gt;-dvld.active 是否在执行PHP时激活VLD挂钩，默认为0，表示禁用。可以使用-dvld.active=1启用。
-dvld.skip_prepend 是否跳过php.ini配置文件中auto_prepend_file指定的文件， 默认为0，即不跳过包含的文件，显示这些包含的文件中的代码所生成的中间代码。此参数生效有一个前提条件：-dvld.execute=0
-dvld.skip_append 是否跳过php.ini配置文件中auto_append_file指定的文件， 默认为0，即不跳过包含的文件，显示这些包含的文件中的代码所生成的中间代码。此参数生效有一个前提条件：-dvld.execute=0
-dvld.execute 是否执行这段PHP脚本，默认值为1，表示执行。可以使用-dvld.execute=0，表示只显示中间代码，不执行生成的中间代码。
-dvld.format 是否以自定义的格式显示，默认为0，表示否。可以使用-dvld.format=1，表示以自己定义的格式显示。这里自定义的格式输出是以-dvld.col_sep指定的参数间隔
-dvld.col_sep 在-dvld.format参数启用时此函数才会有效，默认为 “\t”。
-dvld.verbosity 是否显示更详细的信息，默认为1，其值可以为0,1,2,3 其实比0小的也可以，只是效果和0一样，比如0.1之类，但是负数除外，负数和效果和3的效果一样 比3大的值也是可以的，只是效果和3一样。
-dvld.save_dir 指定文件输出的路径，默认路径为/tmp。
-dvld.save_paths 控制是否输出文件，默认为0，表示不输出文件
-dvld.dump_paths 控制输出的内容，现在只有0和1两种情况，默认为1,输出内容&lt;/p&gt;

&lt;p&gt;VLD(Vulcan Logic Dumper)的简介如下：&lt;/p&gt;

&lt;p&gt;The Vulcan Logic Dumper hooks into the Zend Engine and dumps all the opcodes (execution units) of a script. It can be used to see what is going on in the Zend Engine.&lt;/p&gt;

&lt;pre&gt;&lt;code&gt; 之前的文章 PHP解释器引擎执行流程 结尾处提到了VLD的原理，此扩展利用PHP对扩展模块提供的请求初始化钩子函数（PHP_RINIT_FUNCTION），在每此请求到来的时候将默认的编译函数指针zend_compile_file和执行函数指针zend_execute指向自己定义的vld_compile_file函数和vld_execute函数，这两个函数中，对原函数进行了封装，原编译函数能返回一个op_array的指针，所以在新的编译函数中可以截获这个op_array的指针，然后输出相关opcode信息。  

关于PHP扩展模块的安装这里就不介绍了，网络上很多相关资料。

那么让我们看看这个扩展安装后的实际效果，以下为一个非常简单的PHP脚本，test.php:
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;[php] view plain copy
&lt;?php  
$a = &quot;Hello world&quot;;  
echo $a;  
?&gt;&lt;/p&gt;

&lt;p&gt;在命令行下执行该脚本：&lt;/p&gt;

&lt;p&gt;php -dvld.active=1 test.php&lt;/p&gt;

&lt;p&gt;于是可以看到vld输出的内容:&lt;/p&gt;

&lt;p&gt;希望看到跟详细的内容可以用以下方式：&lt;/p&gt;

&lt;p&gt;php -dvld.active=1 -dvld.verbosity=3 test.php&lt;/p&gt;

&lt;p&gt;这里简单的说说输出内容的含义：&lt;/p&gt;

&lt;p&gt;这段代码一共有3个op分别是：&lt;/p&gt;

&lt;p&gt;1：ASSIGN          // #define ZEND_ASSIGN                           38&lt;/p&gt;

&lt;p&gt;2：ECHO             // #define ZEND_ECHO                             40&lt;/p&gt;

&lt;p&gt;3：RETURN         //  #define ZEND_RETURN                          62&lt;/p&gt;

&lt;p&gt;第1个op ASSIGN的操作句柄是将OP2的值赋值给OP1，对应的就是$a = “Hello world”这句代码，那么OP2就是”Hello world”的，OP1应该就是$a,但是实际上输出的内容中显示的是!0,实际上$a属于编译后的变量，!0就代表了$a,可以在输出op list的上一行看到&lt;/p&gt;

&lt;p&gt;compiled vars:  !0 = $a&lt;/p&gt;

&lt;p&gt;这样的优化可以避免每次查找变量$a都在变量符号表中去检索，起到一定的缓存的作用。在这条op执行结束之后，!0的值就等于”Hello world”了。&lt;/p&gt;

&lt;p&gt;第2个op ECHO的操作句柄是将 OP1的内容送到标准输出，对应的就是echo $a这句代码，这样就把”Hello world”输出到终端了&lt;/p&gt;

&lt;p&gt;第3个op RETURN 是在每个PHP文件结尾都会自动加上的，它的操作句柄是将OP1的常量值返回&lt;/p&gt;

&lt;p&gt;这样我们就能很清晰的知道一段PHP代码会得到什么样的OP code,vld真的是一个不错的分析工具。&lt;/p&gt;

&lt;p&gt;也许有人会问，你怎么知道每个op对应的执行句柄是什么呢，vld能输出这些信息吗？非常可惜，vld不能帮助我们输出OP对应的执行句柄信息。在默认以CALL方式执行op的模式下，每个op对应的handler都是一个函数，vld中截获的op中有这些handler的指针，但是无法通过这些指针知道相应的函数名，c语言没有一些更高级的语言那样的反射特性。所以如果想知道每个op对应的handler，就需要另外想办法了，目前为止，我只发现了两种方法可以得到这些信息。下面简单的介绍这两种方法。&lt;/p&gt;

&lt;p&gt;方法一：&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;在之前的文章 PHP代码如何执行？中介绍过，op的handler都定义在{PHPSRC}/Zend/zend_vm_execute.h中，这是一个由PHP生成的极大的c源文件，其中有每个handler的函数定义以及op映射到handler的算法,在zend_init_opcodes_handlers函数中，初始化一个 static const opcode_handler_t labels[]数组，这个 labels数组就是handlers的一张表，这个表有近4000个项，每个项都是一个handler的函数指针，当然有大量的NULL指针，还有一些重复的指针。如果我们能有一个跟labels数组对应的数组handler_names,数组中的每一个项对应的是labels中相应项中函数指针的函数名，那么我们就可以通过现有的op到handler的映射算法从handler_names中得到该op的handler的函数名。但是事情没有想象的那么容易，我们如何正确生成这个拥有4000个项的数组handler_names，答案就在{PHPSRC}/Zend/zend_vm_gen.php,这个PHP文件是用来生成{PHPSRC}/Zend/zend_vm_execute.h，可以在其中找到生成labels数组的部分，只要添加相关代码通过类似方式生成handler_names数组就可以了。有兴趣的读者可以尝试生成这个handler_names数组文件，然后编译到vld扩展中，在输出op list的时候把每个op执行的句柄函数名也一并输出。
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;方法二:&lt;/p&gt;

&lt;p&gt;此方法是我目前经常用到的，相对来说比较方便，还是在{PHPSRC}/Zend/zend_vm_gen.php这个文件里面想办法。这个文件会生成每个op的handler，所以如果想办法在每个handler函数的代码中输出该handler名字，那么就知道哪些handler被调用。这个并不太难，在zend_vm_gen.php第380行左右可以看到类似以下PHP代码：&lt;/p&gt;

&lt;p&gt;if (0 &amp;amp;&amp;amp; strpos($code, ‘{‘) === 0) {&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;...
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;}&lt;/p&gt;

&lt;p&gt;实际上这个条件中的代码就是在每个handler开始的一行中输出内容，但是因为条件永远无法满足，所以实际条件中的代码无法执行，可以将if中的条件改成true,然后大括号输出函数的名字就可以了，具体的代码如下：&lt;/p&gt;

&lt;p&gt;[php] view plain copy
if (1) {&lt;br /&gt;
    $name = $name.($spec?”_SPEC”:””).$prefix[$op1].$prefix[$op2].”_HANDLER”;&lt;br /&gt;
    $code = “{/n/tfprintf(stderr, /”$name//n/”);/n” . substr($code, 1);&lt;br /&gt;
}&lt;br /&gt;
 代码具体的原理就不介绍了。在修改好zend_vm_gen.php之后，在命令行下执行该脚本，就会生成一个新的zend_vm_execute.h( 同时会生成zend_vm_opcodes.h)，打开zend_vm_execute.h文件，可以看到很多函数开头都多出了这么一句:&lt;/p&gt;

&lt;p&gt;fprintf(stderr, “ZEND_***/n”);&lt;/p&gt;

&lt;p&gt;这样每个函数开始执行的时候就会把自己的名字输出到标准错误。下面的工作，就是重新编译Zend/zend_execute.lo，然后重新链接sapi/cli/php，如果你不知道如何单独完成这些操作，那么也可以更暴力一点重新安装整个PHP，需要注意的是修改后的PHP千万不要用在正式环境，因为会输出一大量不需要的信息，自己单独为试验安装一个PHP吧。 另外这个方法也会输出一些非直接的hanlder的函数名，有可能一个handler会调用另外一个函数，这样可能会输出这个handler的名字和那个被调用的函数的名字，所以实际输出的函数名字会多于op的数量。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;我们用方法二来查看前面的test.php的op handler的名字，直接用修改后的php 执行test.php得到以下内容：
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;ZEND_ASSIGN_SPEC_CV_CONST_HANDLER
ZEND_ECHO_SPEC_CV_HANDLER
Hello worldZEND_RETURN_SPEC_CONST_HANDLER
zend_leave_helper_SPEC_HANDLER&lt;/p&gt;

&lt;p&gt;可以看到一共输出了4个函数的名字，其中ZEND_ASSIGN_SPEC_CV_CONST_HANDLER函数就是ASSIGN的handler，ZEND_ECHO_SPEC_CV_HANDLER就是ECHO的handler,ZEND_RETURN_SPEC_CONST_HANDLER是RETURN的handler,这个handler会调用zend_leave_helper_SPEC_HANDLER函数，所以会输出4个函数的名字，知道了这些函数的名字，我们就能在zend_vm_execute.h中去找到其具体定义，这样就知道每个op到底是怎么在执行了。&lt;/p&gt;

</description>
        <pubDate>Mon, 12 Feb 2018 00:00:00 +0800</pubDate>
        <link>https://xiazemin.github.io/MyBlog/jekyll/2018/02/12/phpvld.html</link>
        <guid isPermaLink="true">https://xiazemin.github.io/MyBlog/jekyll/2018/02/12/phpvld.html</guid>
        
        
        <category>jekyll</category>
        
      </item>
    
      <item>
        <title>phpize</title>
        <description>&lt;!-- more --&gt;
&lt;p&gt;编译PHP扩展的工具，主要是根据系统信息生成对应的configure文件
安装php（fastcgi模式）的时候，常常有这样一句命令：/usr/local/webserver/php/bin/phpize
一、phpize是干嘛的？
phpize是什么东西呢？php官方的说明：
http://php.net/manual/en/install.pecl.phpize.php
phpize是用来扩展php扩展模块的，通过phpize可以建立php的外挂模块
比如你想在原来编译好的php中加入memcached或者ImageMagick等扩展模块，可以使用phpize，通过以下几步工作。
二、如何使用phpize？
当php编译完成后，php的bin目录下会有phpize这个脚本文件。在编译你要添加的扩展模块之前，执行以下phpize就可以了；
比如现在想在php中加入memcache扩展模块：我们要做的只是如下几步
————————————————————————
tar zxvf memcache-2.2.5.tgz
cd memcache-2.2.5/
/usr/local/webserver/php/bin/phpize
./configure –with-php-config=/usr/local/webserver/php/bin/php-config
make
make install
————————————————————————
注意./configure 后面可以指定的是php-config文件的路径
这样编译就完成了，还需要做的是在php.ini文件中加入extension值
extension = “memcache.so”&lt;/p&gt;

</description>
        <pubDate>Mon, 12 Feb 2018 00:00:00 +0800</pubDate>
        <link>https://xiazemin.github.io/MyBlog/web/2018/02/12/phpize.html</link>
        <guid isPermaLink="true">https://xiazemin.github.io/MyBlog/web/2018/02/12/phpize.html</guid>
        
        
        <category>web</category>
        
      </item>
    
      <item>
        <title>PHP 调试利器之 PHPDBG</title>
        <description>&lt;!-- more --&gt;
&lt;p&gt;PHPDBG是一个PHP的SAPI模块，可以在不用修改代码和不影响性能的情况下控制PHP的运行环境。&lt;/p&gt;

&lt;p&gt;PHPDBG的目标是成为一个轻量级、强大、易用的PHP调试平台。可以在PHP5.4和之上版本中使用。在php5.6和之上版本将内部集成。&lt;/p&gt;

&lt;p&gt;主要功能：
– 单步调试&lt;/p&gt;

&lt;p&gt;– 灵活的下断点方式（类方法、函数、文件:行、内存地址、opcode）&lt;/p&gt;

&lt;p&gt;– 可直接调用php的eval&lt;/p&gt;

&lt;p&gt;– 可以查看当前执行的代码&lt;/p&gt;

&lt;p&gt;– 用户空间API（userland/user space）&lt;/p&gt;

&lt;p&gt;– 方便集成&lt;/p&gt;

&lt;p&gt;– 支持指定php配置文件&lt;/p&gt;

&lt;p&gt;– JIT全局变量&lt;/p&gt;

&lt;p&gt;– readline支持（可选），终端操作更方便&lt;/p&gt;

&lt;p&gt;– 远程debug，使用java GUI&lt;/p&gt;

&lt;p&gt;– 操作简便（具体看help）&lt;/p&gt;

&lt;p&gt;安装
为了使用phpdgb，你首先需要下载一个php的源码包。然后下载phpdgb的源码包，并放在php源码包的sapi目录下。最后，你就可以执行命令安装了。编译安装示例如下：
假设我们已经下载php的源码包，并放在了/home/php目录下。&lt;/p&gt;

&lt;p&gt;Shell&lt;/p&gt;

&lt;p&gt;#cd /home/php/sapi
#git clone https://github.com/krakjoe/phpdbg
#cd ../
#./buildconf –force
#./config.nice
#make -j8
#make install-phpdbg&lt;/p&gt;

&lt;p&gt;#cd /home/php/sapi
#git clone https://github.com/krakjoe/phpdbg
#cd ../
#./buildconf –force
#./config.nice
#make -j8
#make install-phpdbg
注意：
1、如果你的php版本是php5.6或者更高的版本，phpdbg已经集成在php的代码包中，无需单独下载了。
2、编译参数中记得要加 –enable-phpdbg。
3、编译时参数，–with-readline 可以选择性添加。如果不添加，phpdbg的history等功能无法使用。&lt;/p&gt;

&lt;p&gt;基本使用
参数介绍
phpdbg是php的一个sapi，它可以以命令行的方式调试php。常用参数如下：&lt;/p&gt;

&lt;p&gt;The following switches are implemented (just like cli SAPI):
-n ignore php ini
-c search for php ini in path
-z load zend extension
-d define php ini entry
The following switches change the default behaviour of phpdbg:
-v disables quietness
-s enabled stepping
-e sets execution context
-b boring – disables use of colour on the console
-I ignore .phpdbginit (default init file)
-i override .phpgdbinit location (implies -I)
-O set oplog output file
-q do not print banner on startup
-r jump straight to run
-E enable step through eval()
Note: passing -rr will cause phpdbg to quit after execution, rather than returning to the console&lt;/p&gt;

&lt;p&gt;常用功能
之前我们介绍过gdb工具。其实phpdbg和gdb功能有些地方非常相似。如，可以设置断点，可以单步执行，等。只是他们调试的语言不一样，gdb侧重于调试c或者c++语言，而phpdbg侧重于调试php语言。下面我们将对phpdbg的一些常用调试功能做下介绍。要调试的代码如下：
文件test_phpdbg_inc.php源代码如下：&lt;/p&gt;

&lt;p&gt;PHP&lt;/p&gt;

&lt;?php 
function phpdbg_inc_func()
{     
    echo &quot;phpdbg_inc_func \n&quot;; 
} 
?&gt;
&lt;?php 
function phpdbg_inc_func()
{     
    echo &quot;phpdbg_inc_func \n&quot;; 
} 
?&gt;
&lt;p&gt;文件test_phpdgb.php的源代码如下：&lt;/p&gt;

&lt;p&gt;PHP&lt;/p&gt;

&lt;?php 
    include(dirname(__FILE__).&quot;/test_phpdbg_inc.php&quot;); 
    class demo{     
        public function __construct(){
             echo __METHOD__.&quot;:&quot;.__LINE__.&quot;\n&quot;;     
        }
        public function func($param){
             $param++;
             echo &quot;method func $param\n&quot;;
        }
        public function __destruct(){
             echo __METHOD__.&quot;:&quot;.__LINE__.&quot;\n&quot;;
        }
    } 

  function func(){     
      $param = &quot;ali&quot;;
      $param = $param + &quot;baba&quot;;
      echo &quot;function func $param\n&quot;;
  }

  $demo = new demo();
  $demo-&gt;func(1);
  func();
  phpdbg_inc_func();
?&gt;
&lt;?php 
    include(dirname(__FILE__).&quot;/test_phpdbg_inc.php&quot;); 
    class demo{     
        public function __construct(){
             echo __METHOD__.&quot;:&quot;.__LINE__.&quot;\n&quot;;     
        }
        public function func($param){
             $param++;
             echo &quot;method func $param\n&quot;;
        }
        public function __destruct(){
             echo __METHOD__.&quot;:&quot;.__LINE__.&quot;\n&quot;;
        }
    } 
 
  function func(){     
      $param = &quot;ali&quot;;
      $param = $param + &quot;baba&quot;;
      echo &quot;function func $param\n&quot;;
  }
 
  $demo = new demo();
  $demo-&gt;func(1);
  func();
  phpdbg_inc_func();
?&gt;
&lt;p&gt;启动phpdbg&lt;/p&gt;

&lt;p&gt;phpdbg安装成功后，会在安装目录的bin目录下。进入bin目录，直接输入phpdbg即可。如下：&lt;/p&gt;

&lt;p&gt;Shell&lt;/p&gt;

&lt;p&gt;#phpdeg
[Welcome to phpdbg, the interactive PHP debugger, v0.4.0]
To get help using phpdbg type “help” and press enter
[Please report bugs to &lt;a href=&quot;http://github.com/krakjoe/phpdbg/issues&quot;&gt;http://github.com/krakjoe/phpdbg/issues&lt;/a&gt;]
prompt&amp;gt;&lt;/p&gt;

&lt;p&gt;#phpdeg
[Welcome to phpdbg, the interactive PHP debugger, v0.4.0]
To get help using phpdbg type “help” and press enter
[Please report bugs to &lt;a href=&quot;http://github.com/krakjoe/phpdbg/issues&quot;&gt;http://github.com/krakjoe/phpdbg/issues&lt;/a&gt;]
prompt&amp;gt;
要想加载要调试的php脚本，只需要执行exec命令即可。如下：&lt;/p&gt;

&lt;p&gt;Shell&lt;/p&gt;

&lt;p&gt;#phpdbg
……
prompt&amp;gt; exec ./test_phpdbg.php&lt;/p&gt;

&lt;p&gt;#phpdbg
……
prompt&amp;gt; exec ./test_phpdbg.php
当然我们也可以在启动phpdbg的时候，指定e参数。如下：&lt;/p&gt;

&lt;p&gt;PHP&lt;/p&gt;

&lt;p&gt;#phpdbg -e ./test_phpdbg.php
#phpdbg -e ./test_phpdbg.php
查看帮助信息&lt;/p&gt;

&lt;p&gt;如果你之前使用过其他的调试工具，你会发现phpdbg和他们比较相似。但是，你使用初期，还是会经常需要获取帮助信息。通过help命令我们可以获取帮助信息。&lt;/p&gt;

&lt;p&gt;PHP&lt;/p&gt;

&lt;p&gt;……
prompt&amp;gt; help&lt;/p&gt;

&lt;p&gt;phpdbg is a lightweight, powerful and easy to use debugging platform for PHP5.4+
It supports the following commands:&lt;/p&gt;

&lt;p&gt;Information
  list     list PHP source
……
……
prompt&amp;gt; help&lt;/p&gt;

&lt;p&gt;phpdbg is a lightweight, powerful and easy to use debugging platform for PHP5.4+
It supports the following commands:&lt;/p&gt;

&lt;p&gt;Information
  list     list PHP source
……
设置断点&lt;/p&gt;

&lt;p&gt;设置断点的命令和gdb一样。都是break，简写形式为b。不过具体的命令参数还是有所差异的。和gdb的断点命令相同之处，它们都可以“按文件名:行号” 或者 行号的方式设置断点。除此之外，phpdbg还提供了一些针对php特有的设置断点的方式。如，根据opline设置断点，根据opcode设置断点等。&lt;/p&gt;

&lt;p&gt;众所周知，php代码最终是解析成opcode，然后由php内核一条条执行。一条php语句，可能会解析成多条opcode。如果可以按opcode设置断点，我们就可以更精确的跟踪程序执行过程。下面我们来看看phapdbg设置断点的具体示例。&lt;/p&gt;

&lt;p&gt;按opline设置断点：
这里所说的opline，就是以方法入口作为起点，当前代码的行号。如test_phpdgb.php文件中，第18行的代码“$param = $param + “baba”;”的opline就是 2。&lt;/p&gt;

&lt;p&gt;PHP&lt;/p&gt;

&lt;p&gt;……
prompt&amp;gt; b func#2
prompt&amp;gt; r
demo::__construct:5
method func 2
[Breakpoint #0 resolved at func#2 (opline 0x7f5b230a2e38)]
[Breakpoint #0 resolved at func#2 (opline 0x7f5b230a2e38)]
[Breakpoint #0 resolved at func#2 (opline 0x7f5b230a2e38)]
[Breakpoint #0 in func()#2 at ./test_phpdbg.php:18, hits: 1]&lt;/p&gt;
&lt;blockquote&gt;
  &lt;p&gt;00018:     $param = $param + “baba”;
 00019:     echo “function func $param\n”;;
 00020: }
……
……
prompt&amp;gt; b func#2
prompt&amp;gt; r
demo::__construct:5
method func 2
[Breakpoint #0 resolved at func#2 (opline 0x7f5b230a2e38)]
[Breakpoint #0 resolved at func#2 (opline 0x7f5b230a2e38)]
[Breakpoint #0 resolved at func#2 (opline 0x7f5b230a2e38)]
[Breakpoint #0 in func()#2 at ./test_phpdbg.php:18, hits: 1]
00018:     $param = $param + “baba”;
 00019:     echo “function func $param\n”;;
 00020: }
……
查看断点&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;和gdb一样，phpdbg也是使用info break命令查看断点。示例如下：&lt;/p&gt;

&lt;p&gt;PHP&lt;/p&gt;

&lt;p&gt;….
prompt&amp;gt; info break
————————————————
File Breakpoints:
#1      /home/hailong.xhl/test_phpdbg.php:10
————————————————
Opline Breakpoints:
#0      7ff3219e1df0        (function breakpoint)
————————————————
Function opline Breakpoints:
#0      func opline 2
….
….
prompt&amp;gt; info break
————————————————
File Breakpoints:
#1      /home/hailong.xhl/test_phpdbg.php:10
————————————————
Opline Breakpoints:
#0      7ff3219e1df0        (function breakpoint)
————————————————
Function opline Breakpoints:
#0      func opline 2
….
通过上面的显示，我们可以知道。info break的显示结果中会把断点的类型也给显示出来。#后面的数字是断点号。我们可以根据断点号删除断点。&lt;/p&gt;

&lt;p&gt;删除断点&lt;/p&gt;

&lt;p&gt;和gdb命令不一样。phpdbg的删除断点不是delete命令，而是break del 命令。示例如下：&lt;/p&gt;

&lt;p&gt;PHP&lt;/p&gt;

&lt;p&gt;……
prompt&amp;gt; break del 1
[Deleted breakpoint #1]
prompt&amp;gt;
……
……
prompt&amp;gt; break del 1
[Deleted breakpoint #1]
prompt&amp;gt;
……
break del 后面的数字1就是断点号。&lt;/p&gt;

&lt;p&gt;查看代码&lt;/p&gt;

&lt;p&gt;phpdbg查看代码的命令也是list。但是和gdb相比，使用的方式更多样一些。
显示指定函数的代码：&lt;/p&gt;

&lt;p&gt;Shell&lt;/p&gt;

&lt;p&gt;……
prompt&amp;gt; l f func
 00017:     $param = “ali”;
 00018:     $param = $param + “baba”;
 00019:     echo “function func $param\n”;;
 00020: }
 00021:
prompt&amp;gt;
……
……
prompt&amp;gt; l f func
 00017:     $param = “ali”;
 00018:     $param = $param + “baba”;
 00019:     echo “function func $param\n”;;
 00020: }
 00021:
prompt&amp;gt;
……
单步执行&lt;/p&gt;

&lt;p&gt;phpdbg的单步执行只有一个命令 step。和gdb的step命令差不多。都是一行一行的执行代码。注意，phpdbg是没有next命令的。&lt;/p&gt;

&lt;p&gt;PHP&lt;/p&gt;

&lt;p&gt;….
prompt&amp;gt; s
[Breakpoint #0 resolved at func#2 (opline 0x152ba40)]
[L19           0x152ba70 ZEND_ADD_STRING          C2      @0    ./test_phpdbg.php]&lt;/p&gt;
&lt;blockquote&gt;
  &lt;p&gt;00019:     echo “function func $param\n”;;
 00020: }
 00021:
….
….
prompt&amp;gt; s
[Breakpoint #0 resolved at func#2 (opline 0x152ba40)]
[L19           0x152ba70 ZEND_ADD_STRING          C2      @0    ./test_phpdbg.php]
00019:     echo “function func $param\n”;;
 00020: }
 00021:
….
继续执行&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;和gdb一样，phpdbg的继续执行命令也是continue，简写形式为c。&lt;/p&gt;

&lt;p&gt;执行php代码&lt;/p&gt;

&lt;p&gt;这个是phpdbg的一个特色。可以在调试的过程中使用ev命令执行任意的php代码。如：&lt;/p&gt;

&lt;p&gt;Shell&lt;/p&gt;

&lt;p&gt;……
prompt&amp;gt; ev $var = “val”;
val
prompt&amp;gt; ev var_dump($var);
string(3) “val”
……
……
prompt&amp;gt; ev $var = “val”;
val
prompt&amp;gt; ev var_dump($var);
string(3) “val”
……
可以通过这种方式，在调试过程中动态的修改变量值，查看执行效果。&lt;/p&gt;
</description>
        <pubDate>Mon, 12 Feb 2018 00:00:00 +0800</pubDate>
        <link>https://xiazemin.github.io/MyBlog/web/2018/02/12/phpdbg.html</link>
        <guid isPermaLink="true">https://xiazemin.github.io/MyBlog/web/2018/02/12/phpdbg.html</guid>
        
        
        <category>web</category>
        
      </item>
    
      <item>
        <title>dot</title>
        <description>&lt;!-- more --&gt;
&lt;p&gt;一、简介DOT &amp;amp; graphviz&lt;/p&gt;
&lt;ol&gt;
  &lt;li&gt;DOT
 DOT是一种文本图形描述语言。DOT语言文件通常具有.gv或是.dot的文件扩展名。当然，在编写好.dot或者.gv的文件之后，需要有专门的程序处理这些文件并将其渲染成为图片，dot就是其中一款程序，它可以将DOT语言描述的图形渲染成.png、.jpg、.pdf等多种类型。
 当然，作为工具，dot本身是很原始的，就像gcc之于c代码，g++之于cpp代码一样，或许某些程序员会热衷于在终端使用这些工具，但也有很多人喜欢交互式的界面，所以就有了gvedit之类的工具，它提供交互式的窗口来使用dot等工具渲染DOT语言描述的图形。&lt;/li&gt;
  &lt;li&gt;graphviz
 graphviz是一个开源软件包，上述dot和gvedit等工具都在该软件包中。
 所以，不妨简单的认为DOT是一门图形描述语言而graphviz是处理该语言文件的一个集成化的工具。&lt;/li&gt;
  &lt;li&gt;DOT &amp;amp; graphviz的局限性
 graphviz中有很多工具可以将DOT语言的文本渲染成为图片，但正如我们所见，我们在享受方便的编码的同时，将图片的布局等任务交给了这些工具，虽然这些工具有很不错的布局算法支持，但仍不一定能满足我们的要求，所以当对图片的布局有特殊要求时，DOT &amp;amp; graphviz就显示出了它的局限性。当然，我们可以再使用其他图片编辑器校正DOT语言生成的图片，但这种时候，DOT &amp;amp; graphviz的方便性或许早就消失殆尽了。&lt;/li&gt;
  &lt;li&gt;什么人适合使用DOT &amp;amp; graphviz
 就我个人体会而言，DOT &amp;amp; graphviz适合这些人使用：
 1&amp;gt; 像我一样的画图小白并且喜欢操作键盘远胜于鼠标；
 2&amp;gt; 没有熟练的掌握其他作图工具；
 3&amp;gt; 对图片布局等没有特殊要求；
 4&amp;gt; 要绘制的是流程图结构图之类的图而不是画小狗小猫山山水水。&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;二、使用DOT &amp;amp; graphviz&lt;/p&gt;
&lt;ol&gt;
  &lt;li&gt;环境配置
 graphviz的官网（http://www.graphviz.org）上可以下载适用于多个OS的graphviz版本，包括Linux的多个发行版（Fedora、Ubuntu等）、Solaris、Windows、Mac等，下载对应版本安装即可。Windows下安装时，官网有提示需要手动配置环境变量。&lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;开始战斗
 完成了安装之后，就可以编写DOT文本并用graphviz下的工具渲染图片了。
 打开gvedit，新建一个.gv或者点.dot的文件并输入DOT文本，在工具栏graph下选择layout（快捷键f5）即可在窗口中看到图片，graph下选择settings（快捷键shift+f5）可以进行设置，在设置里也可以看出有多种处理DOT文本的工具可以选择（默认dot），也可以选择多种导出的文件类型（默认.png）。gvedit实例截图如下：&lt;/p&gt;

    &lt;p&gt;你还可以在终端直接调用dot命令处理文本并生成图片（again：需要配置环境变量）。以把test.dot导出为test.png为例，命令为：&lt;/p&gt;
  &lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;[plain] view plain copy
dot -Tpng -o test.png test.dot&lt;br /&gt;
    该命令会在当前目录下生成test.png。
    当然，作为一个vim党，肯定是不愿意去用gvedit了，何况gvedit确实没有那么好使（主要是文本编辑功能确实不够强大），所以在vim中编辑文本，在终端调用命令生成图片就是一种不错的选择了。为了方便，我这里进行了简单配置，设置F8为快捷键，直接调用上述命令生成图片并打开：
[plain] view plain copy
map &lt;f8&gt; :w&lt;CR&gt;:!dot -Tpng -o %&amp;lt;.png % &amp;amp;&amp;amp; start %&amp;lt;.png&lt;CR&gt;  
    截图如下：&lt;/CR&gt;&lt;/CR&gt;&lt;/f8&gt;&lt;/p&gt;

&lt;p&gt;三、DOT语法
    现在已经可以愉快的使用DOT &amp;amp; graphviz绘图了，唯一需要的就是更好的了解DOT语法，以绘出我们期望的效果。
    DOT语法相对简单和松散，没有特别的格式要求，也没有复杂的运算符和结构。&lt;/p&gt;
&lt;ol&gt;
  &lt;li&gt;基本语法
 graph（无向图）或者digraph（无向图）表示图，然后｛｝中的内容是对图的描述，注释风格和C类似（“//”用于单行注释，/**/用于多行注释）。如一个无向图：&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;[plain] view plain copy
graph graph1 {      //无向图graph1&lt;br /&gt;
    a – b          //节点a和b之间连线&lt;br /&gt;
}&lt;/p&gt;
&lt;ol&gt;
  &lt;li&gt;节点
 DOT中，节点可以不用声明直接使用。每个节点首次出现的名称做为该节点的唯一标识。
 属性设置：对节点可以设置的常见通用属性有shape、label、style、color、fillcolor、rank等，对于不同的形状，可能还有不同的属性可以设置，如对于多边形可以设置边数等。节点属性设置时，node用于设置默认属性（对设置位置之后的点有效），在点后面用[]设置单独一个点的属性。
[plain] view plain copy
graph node_settings {&lt;br /&gt;
 node [shape = “box”, style = “filled”, color = “black”, fillcolor = “green”]   //设置节点的默认形状，类型，颜色，填充颜色&lt;br /&gt;
 a [shape = “ellipse”, color = “red”, label = “this is a”]     //设置节点a的颜色，注意默认节点类型是filled，所以这里的color只是设置a的边框颜色&lt;br /&gt;
 b [label = “two\nlines”]   //label支持’\n’换行&lt;br /&gt;
 a – b&lt;br /&gt;
 a – c     //如果不需要设置c的属性，可以不用声明c而直接使用&lt;br /&gt;
 node [shape = “circle”]&lt;br /&gt;
 d [label = “cicle”]&lt;br /&gt;
 c – d      //d使用之前最后出现的node设置，形状为circle&lt;br /&gt;
 {rank = same a, d}     //设置a和d在同一层&lt;br /&gt;
}&lt;/li&gt;
  &lt;li&gt;边
 边有有向边和无向边两种，无向边用于无向图，有向边用于有向图，不可混用。
 属性设置：边的常见设置有style、color、weight、label、labelfontcolor、headlabel、taillabel、decorate等，对于有向边，还可以设置边的起点位置等（用n、e、s、w和相邻字母的组合表示位置）。和节点类似的，边属性设置时，用edge[]设置默认属性，在边之后用[]设置单独一条边的属性。
[plain] view plain copy
digraph edge_settings {&lt;br /&gt;
 edge [color = “green”, decorate = false]        //设置边的默认属性&lt;br /&gt;
 node [shape = “polygon”, sides = 4, color = “blue”]&lt;br /&gt;
 a -&amp;gt; b [style = “dotted”, color = “red”, label = “a to b”]  //设置style、color、label&lt;br /&gt;
 b: se -&amp;gt; c: w [headlabel = “end”,  taillabel = “start”]     //设置边从b的“东南方”出发，从c的“西方”结束，设置有向边起点和重点的label&lt;br /&gt;
 edge [style = “bond”, decorate = true]      //设置之后的边加粗并且标签和连线之间有线标注&lt;br /&gt;
 {c, f} -&amp;gt; {d, e} [label = “multi-lines”]    //可以用这种方式同时画多条边&lt;br /&gt;
}&lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;图
 从前面的例子中已经可以看出，DOT语言可以描述无向图和有向图两种图，graph标识无向图，digraph标识有向图。
 属性设置：在一个图的开头写入属性即可设置图形的属性，常用的图形属性有size、label、labelloc、labeljust、bgcolor、rankdir等。
 子图，可以进行和“父图”类似的设置，唯一注意的是子图必须以”cluster”做为名称的开始。
 下面是实现的官网首页上的图：
[plain] view plain copy
digraph graph_settings {&lt;br /&gt;
 start [shape = “Mdiamond”]&lt;br /&gt;
 end [shape = “Msquare”]&lt;/p&gt;

    &lt;p&gt;subgraph cluster_sub1 {&lt;br /&gt;
     label = “process #1”&lt;br /&gt;
     labelloc = “t”&lt;br /&gt;
     bgcolor = “gray55”&lt;br /&gt;
     node [style = “filled”, color = “white”]&lt;br /&gt;
     a0 -&amp;gt; a1 -&amp;gt; a2 -&amp;gt; a3 -&amp;gt; a0&lt;br /&gt;
 }&lt;br /&gt;
 subgraph cluster_sub2 {&lt;br /&gt;
     label = “process #2”&lt;br /&gt;
     labelloc = “t”&lt;br /&gt;
     color = “blue”&lt;br /&gt;
     node [style = “filled”, color = “black”, fillcolor = “gray55”]&lt;br /&gt;
     b0 -&amp;gt; b1 -&amp;gt; b2 -&amp;gt; b3&lt;br /&gt;
 }&lt;/p&gt;

    &lt;p&gt;start -&amp;gt; {a0, b0}&lt;br /&gt;
 a1 -&amp;gt; b3&lt;br /&gt;
 b2 -&amp;gt; a3&lt;br /&gt;
 {a3, b3} -&amp;gt; end&lt;br /&gt;
}&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;语法总结
 DOT的语法非常简单，基本保证了随便可以“现炒现卖”，只不过用的越多可能对各种属性越熟悉罢了。具体的属性等可以参见官网的Document：http://www.graphviz.org/Documentation.php。&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;1   简单图的绘制
dot用于绘制有向图。他读取各个图表(graph)的属性并画图，并可以输出包括GIF、PNG、SVG、PostScript(可以转换成PDF)等等多种图片格式。&lt;/p&gt;

&lt;p&gt;dot绘图有四个主要步骤，了解这些有助于你理解你需要何种dot布局和如何控制他们。布局程序依赖于没有循环的图表。所以，第一步就是打破当前图表中形成循环的边缘。第二步是指定各个结点的离散层级。在一个从上到下的图表，dot会按照Y轴构造层级跨越超过一层的。超过一层的边缘需要使用虚拟节点来打破成单位长度。第三步排序结点避免交叉。第四步设置X轴保持边缘最短，并且作为最后一步路由各个边缘连接点。这是大多数分级有向图的绘制程序，基于 Warfield [War77] 、 Carpano [Car80] 和 Sugiyama [STT81] 。我们引用了 [GKNV93] 用于解释dot的算法。&lt;/p&gt;

&lt;p&gt;Note&lt;/p&gt;

&lt;p&gt;这里的图表，指原文中的graph。这里的边缘，指原文中的edge，实际上是指对象之间的连接线。&lt;/p&gt;

&lt;p&gt;dot接受DOT语言(见附录A)的代码。这种语言是包含三种对象的解释性语言：图表、结点、边缘。最外层的主要图表可以是可控制的(digraph)或不可控制的(graph)。因为dot会自动调整布局并生成有向图，所有下面的例子都使用digraph。(一旦单独的布局调整工具 neato 用于绘制可控制的图表 [Nor92] )。在主图表中，还允许定义子图表(subgraph)来定义结点和边缘的子集。&lt;/p&gt;

&lt;p&gt;图1是一个DOT语言的例子，第一行给出了图表的名字和类型。随后的行创建了结点、边缘和子图表，并设置属性。所有这些对象可以使C标识符、数字或引用的C标识符。引用会保留标点和空白。&lt;/p&gt;

&lt;p&gt;digraph G {
    main -&amp;gt; parse -&amp;gt; execute;
    main -&amp;gt; init;
    main -&amp;gt; cleanup;
    execute -&amp;gt; make_string;
    execute -&amp;gt; printf;
    init -&amp;gt; make_string;
    main -&amp;gt; printf;
    execute -&amp;gt; compare;
}
_images/dot_guide_00.jpg
一个结点在其名字首次出现时创建。一个边缘在使用 -&amp;gt; 连接两个结点时创建。例子中，第二行就创建了从main到parse的边缘，等等。运行dot命令可以输出文件:&lt;/p&gt;

&lt;p&gt;$ dot -Tps graph1.dot -o graph1.ps
这样就产生了图2。命令行选项 -Tps 选择使用PostScript来输出。而输出文件就随便玩了。&lt;/p&gt;

&lt;p&gt;调节各个结点、边缘的布局是比较常见的操作，这些都可以通过属性来描述。属性就是键值对。图3和图4距离说明了一些布局属性。在图3中，第二行设置图表大小为4,4(单位是英寸)。这个属性控制了图表尺寸，如果图表太大则会自动缩放。&lt;/p&gt;

&lt;p&gt;digraph G {
    size=”4,4”;
    main [shape=box]; /&lt;em&gt;注释&lt;/em&gt;/
    main -&amp;gt; parse [weight=8];
    parse -&amp;gt; execute;
    main -&amp;gt; init [style=dotted];
    main -&amp;gt; cleanup;
    execute -&amp;gt; {make_string; printf}
    init -&amp;gt; make_string;
    edge [color=red];
    main -&amp;gt; printf [style=bold,label=”100 times”];
    make_string [label=”make a\nstring”];
    node [shape=box, style=filled, color=”.7 .3 1.0”];
    execute -&amp;gt; compare;
}
_images/dot_guide_01.jpg
结点和边缘属性在方括号中设置。在第三行，结点main指定形状为box。第四行的边缘则使用之前并增加宽度(weight)。第六行的边缘则绘制成了点线。第八行使得边缘分别指向了两个目标。第十行设置缺省的边缘颜色为红色。这些设置会自动影响后面创建的边缘。第十一行设置边缘为粗体并设置标签。第十二行，结点make_string使用了多行标签。第十三行改变了缺省结点为box形状，并使用蓝色填充。结点compare继承了这些值。&lt;/p&gt;

&lt;p&gt;2   绘制属性
完整的绘图属性列表见附表1/2/3。&lt;/p&gt;

&lt;p&gt;2.1   结点形状
绘制结点的缺省属性为 shape=ellipse,width=.75,height=.5 而标签为节点名。其他允许的形状有 box 、 circle 、 record 、 plaintext 。附录E中有完整的节点形状列表。结点的形状 plaintext 就是不包含外部形状的，这也是一个重要的约定。仅用于结构不太复杂的图表中节省空间。绘图时生成的图形大小一般比指定的要大，当然标签也是如此。除非使用 fixedsize=true ，否则高度和宽度都是固定的。&lt;/p&gt;

&lt;p&gt;结点形状可以归于两大类：多边形和记录。除了 record 和 Mrecord 以外都可以归于多边形，并且可以用有限的边和几何属性来定义。这其中的一些属性可以在图表中定义，如果 regular=true ，则结点会强制为规则图形。参数 peripheries 设置需要绘制的边界曲线数量。例如，一个双圆(doublecircle?)的peripheries=2 。而 orientation 属性指定多边形的曲线方向和角度。&lt;/p&gt;

&lt;p&gt;Note&lt;/p&gt;

&lt;p&gt;有一种方法可以自定义结点形状，使用 shape=epsf 和 shapefile 属性并以来PostScript输出。细节参考本手册其他部分。&lt;/p&gt;

&lt;p&gt;形状 polygon 可以指定所有多边形参数，适用于创建自定义形状。附加参数如 regular 、 peripheries 和 orientation 等等，还有数字化参数 sides 、 skew 、distortion 。 skew 是一个-1.0到1.0之间的浮点数，指从上到下的倾斜度。比如，可以用 skew 把一个矩形转换成平行四边形。 distortion 用于从上到下缩短多边形，负数表示增加。可以用于把矩形变成梯形。例如:&lt;/p&gt;

&lt;p&gt;digraph G {
    a-&amp;gt;b-&amp;gt;c;
    b-&amp;gt;d;
    a[shape=polygon,sides=5,peripheries=3,color=lightblue,style=filled];
    c[shape=polygon,sides=4,skew=.4,label=”hello world”];
    d[shape=invtriangle];
    e[shape=polygon,sides=4,distortion=.7];
}
_images/dot_guide_02.jpg
基于记录的结点使用其他结点类。这包括 record 和 Mrecord 。他们俩除了后面那个拥有圆角以外，是相同的。他们用于描述递归列表，比如以横向或纵向描绘的多行矩形。递归结构依靠结点的 label 来识别，如下样式:&lt;/p&gt;

&lt;p&gt;rlabel        -&amp;gt; field(‘|’field)*
field         -&amp;gt; boxLabel|’‘rlabel’’
boxLabel      -&amp;gt; [’&amp;lt;’string’&amp;gt;’][string]
有如上面写的，竖线符号和尖括号必须使用转义，空格用于区别各个记号，所以用于表示字面意义时也必须转义。 boxLabel 的第一个字符串提供了字段名，用于提供矩形的端口名。第二个字符串用作字段的标签；当然可以包含多行转义的标签。一个例子:&lt;/p&gt;

&lt;p&gt;digraph structs {
node[shape=record];
    struct1[shape=record,label=”&lt;f0&gt; left|&lt;f1&gt; mid\ dle|&lt;f2&gt; right&quot;];
    struct2[shape=record,label=&quot;&lt;f0&gt; one|&lt;f1&gt; two&quot;];
    struct3[shape=record,label=&quot;hello\nworld |{ b |{c|&lt;here&gt; d|e}| f}| g | h&quot;];
    struct1-&amp;gt;struct2;
    struct1-&amp;gt;struct3;
}
_images/dot_guide_03.jpg
2.2   标签
缺省标签就是结点名称。边缘默认没有标签。结点和边缘可以设置 label 属性来设置标签。&lt;/here&gt;&lt;/f1&gt;&lt;/f0&gt;&lt;/f2&gt;&lt;/f1&gt;&lt;/f0&gt;&lt;/p&gt;

&lt;p&gt;虽然可以直接使用结点名作为标签，但是有些时候还是需要手动设置为好。例如画一个文件目录树，可能有多个目录有相同的名字，但是他们却不同。结点号或全路径名可能更适合做唯一标识符。因此每个结点的标签可以设置成完整文件名。&lt;/p&gt;

&lt;p&gt;多行标签可以使用转义符来实现，包括 \n 、 \l 、 \r 。&lt;/p&gt;

&lt;p&gt;Note&lt;/p&gt;

&lt;p&gt;\N 是结点名中可以使用的一种内部符号。&lt;/p&gt;

&lt;p&gt;图形和子图分组也可以有标签。图形标签默认显示在正下方。设置 labelloc=t 可以把标签放在正上方。分组标签放在矩形边框内，在左上角。设置labelloc=b 可以把标签放到矩形下边，而设置 labeljust=r 可以放到右侧。&lt;/p&gt;

&lt;p&gt;缺省字体是 14-point Times-Roman black 。其他字体族，大小和颜色可以使用 fontname 、 fontsize 、 fontcolor 来设置。字体名需要与解释器兼容。最好是用标准字体族，如 Times 、 Helvetica 、 Courier 或 Symbol 这些确保可以工作的很好的字体。例如 Times-Italic 、 Times-Bold 和可移植的 Courier ，而不是AvanteGardeDemiOblique 。&lt;/p&gt;

&lt;p&gt;对于点位图输出，或者GIF和JPG，dot依赖于有效的字体。可以设置 fontpath 属性来指定搜索字体文件的路径列表，如果没有设置则会到 DOTFONTPATH和 GDFONTPATH 环境变量去找。如果仍然找不到，则会用内置字体列表。&lt;/p&gt;

&lt;p&gt;边缘标签在边缘中间的一侧。要小心边缘标签与结点标签太近时发生的混淆。但是在复杂的图形里确实很难分辨一个标签属于哪个边缘。如果设置了decorate=true 则画线时会把标签嵌入其中。有时为了避免混淆还会强制把边缘画的更大一些。如果设置 labelfloat=true ，则不会做这些更改，以兼容模式来绘图。&lt;/p&gt;

&lt;p&gt;边缘还可以拥有附加标签，使用 headlabel 和 taillabel 来设置近端和远端的边缘标签。而标签也可以单独设置字体，使用 labelfontname 、 labelfontsize 和labelfontcolor 。这些标签会放置在边缘和结点的交汇处。想要调整，可以设置 labelangle 和 labeldistance 属性。调整边缘与结点间的角度，后面那个调整边缘到结点的距离的比例参数。&lt;/p&gt;

&lt;p&gt;结点属性：&lt;/p&gt;

&lt;p&gt;名称	缺省值	值
color	black	结点颜色
comment	–	字符串，(format-dependent)
distortion	0.0	供 shape=polygon 使用的结点扭曲
fillcolor	lightgrey/black	结点填充色
fixedsize	false	标签文字不影响结点大小
fontcolor	black	字体颜色
fontname	Times-Roman	字体名
fontsize	14	字体大小
group	–	节点所属的组
height	.5	以英寸为单位的高度
label	结点名	任意字符串
layer	覆盖范围	all 、 id 或 id:id
orientation	0.0	结点旋转角度
peripheries	形状依赖	结点界限数量
regular	false	使多边形变得规则
shape	ellipse	结点形状
shapefile	–	扩展的EPSF或SVG自定义形状文件
sides	4	shape=polygon 时边的数量
skew	0.0	shape=polygon 时的相位差
style	–	图形选项，例如 bold 、 dotted 、 filled 等
URL	–	指定结点的URL(format-dependent)
width	.75	以英寸为单位的宽度
z	0.0	VRML输出的z轴数据
边缘属性：&lt;/p&gt;

&lt;p&gt;名称	缺省值	值
arrowhead	normal	箭头的样式
arrowsize	1.0	箭头的比例因子
arrowtail	normal	箭头尾部的样式
color	black	边缘的颜色
comment	–	任意字符串，依赖于格式
constraint	true	强制约束，通过边缘限制结点范围
decorate	–	修饰，如果设置了，会画线连接标签到其他边缘
dir	forward	forward,back,both,none
fontcolor	black	字体颜色
fontname	Times-Roman	字体族
headlabel	–	箭头标签
headport	–	n,ne,e,se,s,sw,w,nw
headURL	–	如果输出格式为ismap时，标签附上URL
label	–	边缘标签
labelangle	-25.0	边缘标签的旋转角度
labeldistance	1.0	边缘标签距离结点的比例因子
labelfloat	false	边缘标签位置的强制约束
labelfontcolor	black	标签字体颜色
labelfontname	Times-Roman	标签字体族
labelfontsize	14	标签字体大小
layer	overlay range	all,id,或id:id
lhead	–	箭头使用的簇(cluster)的名字
ltail	–	箭尾使用的簇(cluster)的名字
minlen	1	头尾间最小长度
samehead	–	头结点的tag，拥有相同头结点tag的边缘会使用统一端点
sametail	–	同上，尾结点
style	–	图形选项，例如bold,dotted,filled
taillabel	–	箭尾标签
tailport	–	n,ne,e,se,s,sw,w,nw
tailURL	–	当输出格式为ismap时箭尾标签附加的URL
weight	1	边缘的延伸花费整数
图形属性：&lt;/p&gt;

&lt;p&gt;名称	缺省值	值
bgcolor	–	画图的背景图
center	false	在page的中心画图
clusterrank	local	global或none
color	black	对cluster,outline颜色等等的没有指定fillcolor时的默认颜色
comment	–	注释
compound	false	允许cluster之间的边缘
concentrate	false	允许边缘的集中
fillcolor	black	cluster的填充色
fontcolor	black	字体颜色
fontname	Times-Roman	字体族
fontpath	–	字体搜索路径
fontsize	14	字体大小
label	–	任意字符串
labeljust	centered	l和r用于cluster标签的左对齐和右对齐
labelloc	top	t和b用于cluster标签的上对齐和下对齐
layers	–	id:id:id…
margin	.5	page的空白，英寸
mclimit	1.0	mincross的跌带比例因子
nodesep	.25	结点之间的间隔，英寸
nslimit	–	如果设置了f，则使用网络界限迭代f(结点数)来设置x坐标
nslimit1	–	如果设置了f，则使用网络界限迭代f(结点数)设置结点排名(rank)
ordering	–	如果out则外部边缘顺序会保留
orientation	portrait	如果没用rotate，而值为landscape，使用风景画定位
page	–	标记页，例如”8.5,11”
pagedir	BL	多页之间的横断
quantum	–	结点标签的尺寸根据quantum的量度
rank	–	same,min,max,source,sink
rankdir	TB	LR(从左向右)或TB(从上到下)
ranksep	.75	等级之间的间隔，英寸
ratio	–	近似朝向approximate aspect ratio desired，fill或auto
remincross	–	如果为true且有多个集群，重新运行crossing最小化
rotate	–	如果为90，设置朝向
samplepoints	8	输出时用以表现椭圆和圆所用的点数，参见附录C
searchsize	30	切除的最大边缘，当用以寻找网络中的最小一个(完全没看懂?)
size	–	最大绘图尺寸，英寸
style	–	图形选项，例如集群的filled
URL	–	图形锚点，依赖于格式
2.3   图形样式
结点和边缘可以指定color属性，默认是黑色。这是绘制结点形状和边缘时使用的颜色。一个color值可以用灰度三角标识(以逗号分隔的3个0-1之间的浮点数)；每个颜色的名字在附录G中列出(从X window系统借用的)；或者是RGB颜色(3个十六进制的00-FF之间的数字，以”#”开头)。这样值”orchid”、”0.8396,0.4862,0.8549”和”#DA70D6”是同一种颜色的不同表示方式。数字形式会自动转换为实际的颜色。颜色名的会忽略大小写然后忽略非数字字符，所以warngrey和Warn_Grey是等同的。&lt;/p&gt;

&lt;p&gt;我们可以提供一些绘图中使用颜色的建议。首先，不要使用太多亮色。彩虹效应会让人很混乱。最好选择很窄范围的几种颜色，或者达到颜色饱和。第二如果结点填充深色或饱和颜色，标签设置为 fontcolor=white 或 fontname=Helvetica 会更容易阅读。(我们也有PostScript函数用以生成轮廓字体)。第三，在适应的输出格式，你可以定义自己的颜色空间。例如，如果使用PostScript输出，你可以重新定义 nodecolor 、 edgecolor 、 graphcolor 在库文件中。这样，想要使用RGB颜色，在 lib.ps 中定位如下行:&lt;/p&gt;

&lt;p&gt;/nodecolor {setrgbcolor} bind def
使用 -l 命令载入这个文件:&lt;/p&gt;

&lt;p&gt;dot -Tps -l lib.ps file.dot -o file.ps
style 属性控制图形中结点和边缘的多种功能。这个属性是以逗号分隔的一列参数。预定义的参数包括 solid 、 dashed 、 dotted 、 bold 和 invis 。前四个控制结点界限与边缘的绘制，意思代表实线、虚线、点线、粗线。而invis会让结点或边缘留空而不绘制。结点的 style 还可以包括 filled 、 diagonals 和rounded ，表示结点的填充方式为填充(默认用fillcolor，否则用color，如果还没有就用浅灰)、对角线(绘制最近两个边的定点的连线)、环绕(环绕多边形的各个角)。&lt;/p&gt;

&lt;p&gt;用户定义的风格元素可以使用自定义PostScript过程实现。这种元素(primitive)在 gsave 上下文中执行，在其他标签绘制前。参数列表会翻译成PostScript的表示法(notation)。例如，一个结点有 style=”setlinewidth(8) ，就会绘制很粗的轮廓。这里 setlinewidth 是PostScript内置的，但是用户自定义的过程也是一样的调用方式。这些过程的定义可以用库文件的方式用”-l”参数导入。&lt;/p&gt;

&lt;p&gt;边缘有 dir 属性以设置箭头。dir可以是 forward (缺省)、 back 、 both 、 none 。这只是改变箭头的绘制，而不是下面(underlying)的图形。例如设置dir=back 会使得箭头相反，但是它并不交换边缘的端点。属性 arrowhead 和 arrtail 设置箭头的样式，方便分别设置。允许的值有 normal 、 inv 、 dot 、invdot 、 odot 、 invodot 、 none ，具体的意思详见附录F。属性 arrowsize 设置箭头的多个因素的大小。例如 arrowsize=2.0 会让箭头两倍大和两倍宽。&lt;/p&gt;

&lt;p&gt;在演示和颜色的概念中，cluster作为一个盒子样的结点存在，cluster的界限(boundary)使用color属性绘制。而一般cluster的外貌(appearance)依赖于style、color、fillcolor属性。&lt;/p&gt;

&lt;p&gt;如果根图有 bgcolor 属性。这个颜色会用于整个背景的绘制。同时也作为缺省的填充色。&lt;/p&gt;

&lt;p&gt;2.4   绘图方向、大小和间隔
有两个属于对于dot的大小有重要的作用，是 nodesep 和 ranksep 。 nodesep 指定了以英寸为单位的最小占用空间，在同一范围内临近的两个结点的最小距离。 ranksep 指定了各个层次(rank)之间的间隔，就是在上一个rank中最下那个node到下一个rank中最上那个node之间的距离，单位是英寸。同时也可以设置 ranksep=equally ，可以使所有的rank拥有相同的间隔空间，特别适合于中心结点对旁边的结点进行等距离分配。在这种情况下，两个rank之间的间隔至少为上面设置的间隔。两种使用的 rankrep 是相互独立的，可以同时使用，例如 rankrep=”1.0 equally” 语句就会设置固定的相等间隔。&lt;/p&gt;

&lt;p&gt;大多数时候默认的结点尺寸和间距对打印机或者文档页面来说太大了。有很多种方式可以解决这个问题。首先我们复习一下dot如何计算最终的布局尺寸。&lt;/p&gt;

&lt;p&gt;首先布局按照初始的”natural”大小，使用缺省设置(除非 ratio=compress 设置，下面描述)。没有限制大小和方向(aspect)的比率(ratio)，所以如果图形很大，布局也会很大。如果你不指定size和ratio，就会打印自然大小。&lt;/p&gt;

&lt;p&gt;控制输出大小最简单的方式是设置 size=”x,y” ，在图形文件中(或者命令行选项的-G)。这会先决定于最终布局的大小。例如， size=”7.5,10” 会适应8.5x11的页面(假设缺省页方向)而无论初始布局有多大。&lt;/p&gt;

&lt;p&gt;ratio 也作用于布局大小。有几种情况，依赖于size和ratio的设置：&lt;/p&gt;

&lt;p&gt;Case1 ： ratio 设置了。如果绘图已经适应到给出的size，那么什么都不会发生。否则，绘图会自动减小到临界(critical)尺寸(dimension)。如果ratio设置了，则有四种子情况。
@page 15&lt;/p&gt;

&lt;p&gt;2.5   结点与边缘定位
dot中有多种方式处理大尺寸的结点和边缘布局，让用户感觉使用起来极其方便。这一节就是讨论这些事情。&lt;/p&gt;

&lt;p&gt;有时候需要让边缘从左到右，而不是从上到下。如果 rankdir=LR 定义于图的顶层，绘图会旋转以实现这种样式。TB(top to bottom)是缺省的。模式rankdir=BT 适用于从下到上的图。当然了还有 rankdir=RL 。&lt;/p&gt;

&lt;p&gt;在时间线、强调源和下沉结点，你可能需要强制定义下沉。子图的rank可以设置为 same 、 min 、 source 、 max 、 sink 。意义如下：&lt;/p&gt;

&lt;p&gt;same ：让子图继承相同的排列
min ：子图中所有结点至少比布局中其他结点的排列(rank)要小
source ：强制子图所有结点严格基于某个排列，同时比其他结点排列要小(除非这些子图也指定了min或source)(?)
max 或 sink ：做与最大排列接近的事情。
注意这些约束对结点都是相同的。如果一个子图强制结点A和B使用相同排列，而其他子图强制C和B共享排列，那么两个子图的其他结点也必须以相同排列绘图。例子9和10使用子图控制排列。&lt;/p&gt;

&lt;p&gt;在一些图中从左到右的顺序很重要。如果子图含有 ordering=out ，则每条产生的边都按照从左到右排列。同时注意平坦的边(edge)会扰乱这种排序。&lt;/p&gt;

&lt;p&gt;有很多方式微调(find-tune)结点与边缘的布局。例如，如果结点的一些边缘拥有相同的 group 属性，绘制时就会保持边缘是笔直的(straight)且进制其他边缘与其交叉。边缘的 weight 属性也会控制边缘的笔直。一个边缘的weight建议边缘的量度(measure)；这样weight的行为贴近于其结点。dot会让边缘更短与更直。&lt;/p&gt;

&lt;p&gt;边缘的weight与结点被强制相同rank时也有用。结点间拥有非零weight的边缘在同一方向跨越rank时会尽可能避免交叉。(此句不确定)。这个事实可以用于调整(adjust)结点顺序，通过指定边缘的 style=”invis” 。&lt;/p&gt;

&lt;p&gt;边缘的端点临近(adjacent)的结点可以被约束(constraint)使用 samehead 和 sametail 属性。特别的，所有边缘都有相同的箭头且有相同的 samehead 约束，则会指向结点的同一点。类似的(analogous)作用于箭尾的是 sametail 。&lt;/p&gt;

&lt;p&gt;@page 20&lt;/p&gt;

&lt;p&gt;3   高级特性
3.1   结点端口
结点端口是允许边缘连接的一个点。当没有指定端口时，边缘会自动连接指向结点中心并忽略结点的边界。&lt;/p&gt;

&lt;p&gt;@page 20&lt;/p&gt;

&lt;p&gt;3.2   cluster
cluster是一个子图，定位于一个举行区域中，并有自己的布局。一个子图被认为是一个cluster，如果其名字拥有前缀 cluster 。(如果顶级图有clusterrank=none ，那么这个处理就被关闭了。)标签、字体和 labelloc 属性可以设置顶级图形，然而cluster标签则是缺省显示的。对于cluster，标签默认左对齐，如果 labeljust=”r” 则标签就右对齐了。 color 属性指定了包围矩形的颜色。另外，cluster可以有 style=”filled” ，先定义包围矩形的颜色为fillcolor 。如果没指定fillcolor，则使用cluster的color属性。&lt;/p&gt;

&lt;p&gt;cluster的绘制通过递归技术，计算分配的rank和内部结点的布局。下面Finger17-19是cluster的例子。&lt;/p&gt;

&lt;p&gt;如果顶级图的 compound 属性设置为true，就会允许结点与cluster之间绘制边缘。这是通过定义边缘的 lhead 和 ltail 属性实现(accomplished)的。这些属性的值必须是包含头或尾结点的cluster的名字。这种情况下，边缘省略了cluster的边框。所有其他边缘的属性，例如 arrowhead 或 dir ，都被截断了。例如Finure20展示了图形使用compound属性的结果。&lt;/p&gt;

&lt;p&gt;3.3   集中器
@page 27&lt;/p&gt;

&lt;p&gt;4   命令行选项
缺省时，dot以过滤器模式工作，从stdin读取图形，然后写入图形到stdout，以DOT格式。 dot 支持一系列的命令行选项：&lt;/p&gt;

&lt;p&gt;-Tformat ：设置输出格式，允许的format如下：&lt;/p&gt;

&lt;p&gt;canon ：很好的打印输入，没有布局
dot ：属性DOT，打印输入布局附加在属性上，查看附录C
fit ：FIG输出
gd ：GD格式，这是GD图形库的内部格式，另一个可选的是gd2
gif ：GIF输出
hpgl ：HP-GL/2生成的打印机语言
imap ：生成服务器端图像地图。可以算作图像输出，使用 -Tgif 或 -Tjpg ，在网页附加链接到结点和边缘。格式ismap是imap格式的预处理器
cmap ：在客户端生成HTML地图文件
mif ：FrameMaker MIF格式。可以载入FrameMake并编辑，限于8种基本颜色
mp ：MetaPost输出
pc1 ：PCL-5输出，用于HP打印机
pic ：PIC输出
plain ：简单的，基于线的ASCII格式。附录B描述了这种输出。另一种可选格式是 plain-ext ，会提供边缘头尾端口名
png ：PNG(Portable Network Graphics)格式
ps ：PostScript(EPSF)输出
ps2 ：PostScript(EPSF)输出包含PDF注释，假设最终用于生成PDF
svg ：SVG输出，另一种选择 svgz 是压缩过的SVG
vrml ：VRML输出
vtx ：VTX格式用于Visual Thought
wbmp ：Wireless BitMap(WBMP)格式
-Gname=value ：设置缺省的图形属性。一般是设置大小、分页等参数。类似的选项 -N 和 -E 用于设置结点和边缘的缺省属性。不过注意，文件内容可以重载命令行参数。&lt;/p&gt;

&lt;p&gt;-llibfile ：指定设备相关的图形库文件。可以指定多个库。这些名字会被传递到代码生成器那里。&lt;/p&gt;

&lt;p&gt;-ooutfile ：指定输出文件名&lt;/p&gt;

&lt;p&gt;-v ：提供更多输出信息。在处理大的布局时，会给出处理进度的评估信息&lt;/p&gt;

&lt;p&gt;-V ：打印版本号&lt;/p&gt;

&lt;p&gt;5   有趣的功能
在顶级图之前，可以声明 strict digraph 。这会禁止自引用(self-arcs)和多条边缘(multi-edges)。他们会在输入文件中自动忽略。&lt;/p&gt;

&lt;p&gt;结点、边缘、图形可以有 URL 属性。在适当的输出格式(ps2、imap、ismap、cmap、svg)中，这些信息会整合(integrated)到输出中，所以这些结点、边缘和cluster就会变成链接。典型的URL附加到顶层图会作为基础URL，以便支持组件的相对URL。当输出格式是imap或cmap，类似的处理过程会被替换成headURL 和 tailURL 属性。&lt;/p&gt;

&lt;p&gt;对于适当的格式(ps2、fig、mif、mp、vtx、svg)， comment 属性可以用于嵌入式的人类可读的注释表示法。&lt;/p&gt;

&lt;p&gt;6   结论
dot语言可以构造复杂的分级图形并设置很多属性。&lt;/p&gt;

&lt;p&gt;虽然这些简单的方法已经工作的很好了，但是未来仍然有做复杂图形方面的研究和WEB动态图形生成。&lt;/p&gt;

&lt;p&gt;7   感谢
@page 32&lt;/p&gt;

&lt;p&gt;8   引用
[Car80]	
Carpano. Automatic display of hierarchized graphs for computer aided decision analysis. IEEE Transactions on Software Engineering, SE-12(4):538–546, April 1980.
[GKNV93]	Emden R. Gansner, Eleftherios Koutsofios, Stephen C. North, and Kiem-Phong Vo. A Technique for Drawing Directed Graphs. IEEE Trans. Sofware Eng., 19(3):214–230, May 1993.
[New89]	Frances J. Newbery. Edge Concentration: A Method for Clustering Directed Graphs. In 2nd International Workshop on Software Configuration Management, pages 76–85, October 1989. Published as ACM SIGSOFT Software Engineering Notes, vol. 17, no. 7, November 1989.
[Nor92]	Stephen C. North. Neato User’s Guide. Technical Report 59113-921014-14TM, AT&amp;amp;T Bell Laboratories, Murray Hill, NJ, 1992.
[STT81]	
Sugiyama, S. Tagawa, and M. Toda. Methods for Visual Understanding of Hierarchical System Structures. IEEE Transactions on Systems, Man, and Cybernetics, SMC-11(2):109–125, February 1981.
[War77]	JohnWarfield. Crossing Theory and Hierarchy Mapping. IEEE Transactions on Systems, Man, and Cybernetics, SMC-7(7):505–523, July 1977.
9   附录
9.1   图形文件语法
如下是DOT语言的抽象语法。终止符以粗体，非终止符以斜体。单字符(literal)以单引号。在需要时使用圆括号(parentheses)来表示组。方括号标识可选项。竖线分隔符分隔二选一的值。&lt;/p&gt;

&lt;table&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td&gt;graph -&amp;gt; [ strict ] ( digraph&lt;/td&gt;
      &lt;td&gt;graph ) id ‘{‘ stmt-list ‘}’&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;p&gt;stmt-list -&amp;gt; [ stmt [ ‘;’ ][ stmt-list ]]&lt;/p&gt;

&lt;table&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td&gt;stmt -&amp;gt; attr-stmt&lt;/td&gt;
      &lt;td&gt;node-stmt&lt;/td&gt;
      &lt;td&gt;edge-stmt&lt;/td&gt;
      &lt;td&gt;subgraph&lt;/td&gt;
      &lt;td&gt;id ‘=’ id&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;table&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td&gt;attr-stmt -&amp;gt; ( graph&lt;/td&gt;
      &lt;td&gt;node&lt;/td&gt;
      &lt;td&gt;edge ) attr-list&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;p&gt;attr-list -&amp;gt; ‘[’ [ a-list ] ‘]’ [ attr-list ]&lt;/p&gt;

&lt;p&gt;a-list -&amp;gt; id ‘=’ id [ ‘,’ ] [ a-list ]&lt;/p&gt;

&lt;p&gt;@page 34&lt;/p&gt;

&lt;p&gt;9.2   原始输出文件格式(-Tplain)
Warning&lt;/p&gt;

&lt;p&gt;pause @ page 35&lt;/p&gt;

&lt;p&gt;9.3   DOT属性格式(-Tdot)
Warning&lt;/p&gt;

&lt;p&gt;pause @ page 36&lt;/p&gt;

&lt;p&gt;9.4   层
Warning&lt;/p&gt;

&lt;p&gt;pause @ page 37&lt;/p&gt;

&lt;p&gt;9.5   结点形状
_images/dot_guide_nodeshape.png
9.6   箭头类型
_images/dot_guide_arrowhead.png
9.7   颜色名
Warning&lt;/p&gt;

&lt;p&gt;pause @ page 40&lt;/p&gt;
</description>
        <pubDate>Mon, 12 Feb 2018 00:00:00 +0800</pubDate>
        <link>https://xiazemin.github.io/MyBlog/web/2018/02/12/dot.html</link>
        <guid isPermaLink="true">https://xiazemin.github.io/MyBlog/web/2018/02/12/dot.html</guid>
        
        
        <category>web</category>
        
      </item>
    
      <item>
        <title>netty</title>
        <description>&lt;!-- more --&gt;
&lt;p&gt;1.为什么选择Netty
Socket通信（IO/NIO/AIO）编程仅仅是一个模型，如果想把这些真正的用于实际工作中，那么还需要不断的完善、扩展和优化。比如经典的TCP读包写包问题，或者是数据接收的大小，实际的通信处理与应答的处理逻辑等等一些细节问题需要认真的去思考，而这些都需要大量的时间和经历，以及丰富的经验。所以想学好Socket通信不是件容易事，那么接下来就来学习一下新的技术Netty，为什么会选择Netty？因为它简单！使用Netty不必编写复杂的逻辑代码去实现通信，再也不需要去考虑性能问题，不需要考虑编码问题，半包读写等问题。强大的Netty已经帮我们实现好了，我们只需要使用即可。&lt;/p&gt;

&lt;p&gt;Netty是最流行的NIO框架，它的健壮性、功能、性能、可定制性和可扩展性在同类框架都是首屈一指的。它已经得到成百上千的商业/商用项目验证，如Hadoop的RPC框架Avro、RocketMQ以及主流的分布式通信框架Dubbox等等。&lt;/p&gt;

&lt;p&gt;2.Netty简介&lt;/p&gt;

&lt;p&gt;Netty是基于Java NIO client-server的网络应用框架，使用Netty可以快速开发网络应用，例如服务器和客户端协议。Netty提供了一种新的方式来开发网络应用程序，这种新的方式使它很容易使用和具有很强的扩展性。Netty的内部实现是很复杂的，但是Netty提供了简单易用的API从网络处理代码中解耦业务逻辑。Netty是完全基于NIO实现的，所以整个Netty都是异步的。&lt;/p&gt;

&lt;p&gt;网络应用程序通常需要有较高的可扩展性，无论是Netty还是其他的基于Java Nio的框架，都会提供可扩展性的解决方案。Netty中一个关键组成部分是它的异步特性，本片文章将讨论同步（阻塞）和异步（非阻塞）的IO来说明为什么使用异步代码解决扩展性问题以及如何使用异步。&lt;/p&gt;

&lt;p&gt;3.Netty架构组成（借用一下网上的图片）&lt;/p&gt;

&lt;p&gt;Netty实现原理浅析，写的很不错，感兴趣的可以看一下。&lt;/p&gt;

&lt;p&gt;4.Helloworld入门&lt;/p&gt;

&lt;p&gt;在学习Netty之前，先来回顾一下NIO的通信步骤：&lt;/p&gt;

&lt;p&gt;①创建ServerSocketChannel，为其配置非阻塞模式。&lt;/p&gt;

&lt;p&gt;②绑定监听，配置TCP参数，录入backlog大小等。&lt;/p&gt;

&lt;p&gt;③创建一个独立的IO线程，用于轮询多路复用器Selector。&lt;/p&gt;

&lt;p&gt;④创建Selector，将之前创建的ServerSocketChannel注册到Selector上，并设置监听标识位SelectionKey.OP_ACCEPT。&lt;/p&gt;

&lt;p&gt;⑤启动IO线程，在循环体中执行Selector.select()方法，轮询就绪的通道。&lt;/p&gt;

&lt;p&gt;⑥当轮询到处于就绪状态的通道时，需要进行操作位判断，如果是ACCEPT状态，说明是新的客户端接入，则调用accept方法接收新的客户端。&lt;/p&gt;

&lt;p&gt;⑦设置新接入客户端的一些参数，如非阻塞，并将其继续注册到Selector上，设置监听标识位等。&lt;/p&gt;

&lt;p&gt;⑧如果轮询的通道标识位是READ，则进行读取，构造Buffer对象等。&lt;/p&gt;

&lt;p&gt;⑨更细节的问题还有数据没发送完成继续发送的问题……&lt;/p&gt;

&lt;p&gt;好啦，开始学习Netty了。先去http://netty.io/上下载所有的Netty包。&lt;/p&gt;

&lt;p&gt;Netty通信的步骤：&lt;/p&gt;

&lt;p&gt;①创建两个NIO线程组，一个专门用于网络事件处理（接受客户端的连接），另一个则进行网络通信的读写。&lt;/p&gt;

&lt;p&gt;②创建一个ServerBootstrap对象，配置Netty的一系列参数，例如接受传出数据的缓存大小等。&lt;/p&gt;

&lt;p&gt;③创建一个用于实际处理数据的类ChannelInitializer，进行初始化的准备工作，比如设置接受传出数据的字符集、格式以及实际处理数据的接口。&lt;/p&gt;

&lt;p&gt;④绑定端口，执行同步阻塞方法等待服务器端启动即可。&lt;/p&gt;

&lt;p&gt;强烈推荐读一读Netty官方翻译文档。&lt;/p&gt;

&lt;p&gt;好了，说了那么多，下面就来HelloWorld入门吧！&lt;/p&gt;

&lt;p&gt;服务器端：&lt;/p&gt;

&lt;p&gt;[java] view plain copy print?
public class Server {&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;private int port;  
  
public Server(int port) {  
    this.port = port;  
}  
  
public void run() {  
    EventLoopGroup bossGroup = new NioEventLoopGroup(); //用于处理服务器端接收客户端连接  
    EventLoopGroup workerGroup = new NioEventLoopGroup(); //进行网络通信（读写）  
    try {  
        ServerBootstrap bootstrap = new ServerBootstrap(); //辅助工具类，用于服务器通道的一系列配置  
        bootstrap.group(bossGroup, workerGroup) //绑定两个线程组  
                .channel(NioServerSocketChannel.class) //指定NIO的模式  
                .childHandler(new ChannelInitializer&amp;lt;SocketChannel&amp;gt;() { //配置具体的数据处理方式  
                    @Override  
                    protected void initChannel(SocketChannel socketChannel) throws Exception {  
                        socketChannel.pipeline().addLast(new ServerHandler());  
                    }  
                })  
                /** 
                 * 对于ChannelOption.SO_BACKLOG的解释： 
                 * 服务器端TCP内核维护有两个队列，我们称之为A、B队列。客户端向服务器端connect时，会发送带有SYN标志的包（第一次握手），服务器端 
                 * 接收到客户端发送的SYN时，向客户端发送SYN ACK确认（第二次握手），此时TCP内核模块把客户端连接加入到A队列中，然后服务器接收到 
                 * 客户端发送的ACK时（第三次握手），TCP内核模块把客户端连接从A队列移动到B队列，连接完成，应用程序的accept会返回。也就是说accept 
                 * 从B队列中取出完成了三次握手的连接。 
                 * A队列和B队列的长度之和就是backlog。当A、B队列的长度之和大于ChannelOption.SO_BACKLOG时，新的连接将会被TCP内核拒绝。 
                 * 所以，如果backlog过小，可能会出现accept速度跟不上，A、B队列满了，导致新的客户端无法连接。要注意的是，backlog对程序支持的 
                 * 连接数并无影响，backlog影响的只是还没有被accept取出的连接 
                 */  
                .option(ChannelOption.SO_BACKLOG, 128) //设置TCP缓冲区  
                .option(ChannelOption.SO_SNDBUF, 32 * 1024) //设置发送数据缓冲大小  
                .option(ChannelOption.SO_RCVBUF, 32 * 1024) //设置接受数据缓冲大小  
                .childOption(ChannelOption.SO_KEEPALIVE, true); //保持连接  
        ChannelFuture future = bootstrap.bind(port).sync();  
        future.channel().closeFuture().sync();  
    } catch (Exception e) {  
        e.printStackTrace();  
    } finally {  
        workerGroup.shutdownGracefully();  
        bossGroup.shutdownGracefully();  
    }  
}  
  
public static void main(String[] args) {  
    new Server(8379).run();  
}   }  
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;ServerHandler类：&lt;/p&gt;

&lt;p&gt;[java] view plain copy print?
public class ServerHandler  extends ChannelHandlerAdapter {&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;@Override  
public void channelRead(ChannelHandlerContext ctx, Object msg) throws Exception {  
  
        //do something msg  
        ByteBuf buf = (ByteBuf)msg;  
        byte[] data = new byte[buf.readableBytes()];  
        buf.readBytes(data);  
        String request = new String(data, &quot;utf-8&quot;);  
        System.out.println(&quot;Server: &quot; + request);  
        //写给客户端  
        String response = &quot;我是反馈的信息&quot;;  
        ctx.writeAndFlush(Unpooled.copiedBuffer(&quot;888&quot;.getBytes()));  
        //.addListener(ChannelFutureListener.CLOSE);  
          
  
}  
  
@Override  
public void exceptionCaught(ChannelHandlerContext ctx, Throwable cause) throws Exception {  
    cause.printStackTrace();  
    ctx.close();  
}  
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;}&lt;/p&gt;

&lt;p&gt;客户端：&lt;/p&gt;

&lt;p&gt;[java] view plain copy print?
public class Client {&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;public static void main(String[] args) throws InterruptedException {  
    EventLoopGroup workerGroup = new NioEventLoopGroup();  
    Bootstrap bootstrap = new Bootstrap();  
    bootstrap.group(workerGroup)  
            .channel(NioSocketChannel.class)  
            .handler(new ChannelInitializer&amp;lt;SocketChannel&amp;gt;() {  
                @Override  
                protected void initChannel(SocketChannel socketChannel) throws Exception {  
                    socketChannel.pipeline().addLast(new ClientHandler());  
                }  
            });  
    ChannelFuture future = bootstrap.connect(&quot;127.0.0.1&quot;, 8379).sync();  
    future.channel().writeAndFlush(Unpooled.copiedBuffer(&quot;777&quot;.getBytes()));  
    future.channel().closeFuture().sync();  
    workerGroup.shutdownGracefully();  
}  
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;}&lt;/p&gt;

&lt;p&gt;ClientHandler类：
[java] view plain copy print?
public class ClientHandler extends ChannelHandlerAdapter {&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;@Override  
public void channelRead(ChannelHandlerContext ctx, Object msg) throws Exception {  
    try {  
        ByteBuf buf = (ByteBuf) msg;  
        byte[] data = new byte[buf.readableBytes()];  
        buf.readBytes(data);  
        System.out.println(&quot;Client：&quot; + new String(data).trim());  
    } finally {  
        ReferenceCountUtil.release(msg);  
    }  
}  
  
  
@Override  
public void exceptionCaught(ChannelHandlerContext ctx, Throwable cause) throws Exception {  
    cause.printStackTrace();  
    ctx.close();  
}  
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;}&lt;/p&gt;

&lt;p&gt;运行结果：&lt;/p&gt;

&lt;p&gt;5.TCP粘包、拆包问题&lt;/p&gt;

&lt;p&gt;熟悉TCP编程的可能都知道，无论是服务器端还是客户端，当我们读取或者发送数据的时候，都需要考虑TCP底层的粘包/拆包机制。&lt;/p&gt;

&lt;p&gt;TCP是一个“流”协议，所谓流就是没有界限的遗传数据。大家可以想象一下，如果河水就好比数据，他们是连成一片的，没有分界线，TCP底层并不了解上层业务数据的具体含义，它会根据TCP缓冲区的具体情况进行包的划分，也就是说，在业务上一个完整的包可能会被TCP分成多个包进行发送，也可能把多个小包封装成一个大的数据包发送出去，这就是所谓的粘包/拆包问题。&lt;/p&gt;

&lt;p&gt;解决方案：&lt;/p&gt;

&lt;p&gt;①消息定长，例如每个报文的大小固定为200个字节，如果不够，空位补空格。&lt;/p&gt;

&lt;p&gt;②在包尾部增加特殊字符进行分割，例如加回车等。&lt;/p&gt;

&lt;p&gt;③将消息分为消息头和消息体，在消息头中包含表示消息总长度的字段，然后进行业务逻辑的处理。&lt;/p&gt;

&lt;p&gt;Netty中解决TCP粘包/拆包的方法：&lt;/p&gt;

&lt;p&gt;①分隔符类：DelimiterBasedFrameDecoder（自定义分隔符）&lt;/p&gt;

&lt;p&gt;②定长：FixedLengthFrameDecoder&lt;/p&gt;

&lt;p&gt;6.Netty编解码技术&lt;/p&gt;

&lt;p&gt;通常我们也习惯将编码（Encode）成为序列化，它将数据序列化为字节数组，用于网络传输、数据持久化或者其他用途。反之，解码（Decode）/反序列化（deserialization）&lt;/p&gt;

&lt;p&gt;把从网络、磁盘等读取的字节数组还原成原始对象（通常是原始对象的拷贝），以方便后续的业务逻辑操作。进行远程跨进程服务调用时（例如RPC调用），需要使用特定的编解码技术，对需要进行网络传输的对象做编码或者解码，以便完成远程调用。&lt;/p&gt;

&lt;p&gt;主流的编解码框架：&lt;/p&gt;

&lt;p&gt;①JBoss的Marshalling包&lt;/p&gt;

&lt;p&gt;②google的Protobuf&lt;/p&gt;

&lt;p&gt;③基于Protobuf的Kyro&lt;/p&gt;

&lt;p&gt;④MessagePack框架&lt;/p&gt;

&lt;p&gt;上代码，一读就懂，注意红色字体部分。&lt;/p&gt;

&lt;p&gt;服务器端：&lt;/p&gt;

&lt;p&gt;public class Server {&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;public Server(int port) {

    EventLoopGroup bossGroup = newNioEventLoopGroup();

    EventLoopGroup workerGroup = newNioEventLoopGroup();

    try {

        ServerBootstrap bootstrap = newServerBootstrap();

        bootstrap.group(bossGroup, workerGroup)

               .channel(NioServerSocketChannel.class)

                .handler(newLoggingHandler(LogLevel.INFO))

                .childHandler(newChannelInitializer&amp;lt;SocketChannel&amp;gt;() {

                    @Override

                    protected voidinitChannel(SocketChannel socketChannel) throws Exception {

                        socketChannel.pipeline().addLast(MarshallingCodeCFactory.buildMarshallingDecoder());

                        socketChannel.pipeline().addLast(MarshallingCodeCFactory.buildMarshallingEncoder());

                       socketChannel.pipeline().addLast(new ServerHandler());

                    }

                })

                .option(ChannelOption.SO_BACKLOG,1024)

               .option(ChannelOption.SO_RCVBUF, 32 * 1024)

               .option(ChannelOption.SO_SNDBUF, 32 * 1024)

               .option(ChannelOption.SO_KEEPALIVE, true);

        ChannelFuture future = bootstrap.bind(port).sync();

       future.channel().closeFuture().sync();

    } catch (Exception e) {

        e.printStackTrace();

    } finally {

        bossGroup.shutdownGracefully();

        workerGroup.shutdownGracefully();

    }

}

 

public static void main(String[] args) {

    new Server(8765);

}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;}&lt;/p&gt;

&lt;p&gt;ServerHandler类：&lt;/p&gt;

&lt;p&gt;public classServerHandler extends ChannelHandlerAdapter {&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;@Override

public voidexceptionCaught(ChannelHandlerContext ctx, Throwable cause) throws Exception {

    cause.printStackTrace();

    ctx.close();

}

 

@Override

public voidchannelActive(ChannelHandlerContext ctx) throws Exception {

    super.channelActive(ctx);

}

 

@Override

public void channelRead(ChannelHandlerContextctx, Object msg) throws Exception {

    Request request = (Request) msg;

    System.out.println(&quot;Server:&quot;+ request.getId() + &quot;,&quot; + request.getName() + &quot;,&quot; +request.getReqeustMessag());

 

    Response response = new Response();

    response.setId(request.getId());

    response.setName(&quot;response &quot;+ request.getId());

    response.setResponseMessage(&quot;响应内容：&quot; +request.getReqeustMessag());

    byte[] unGizpData =GzipUtils.unGzip(request.getAttachment());

    char separator = File.separatorChar;

    FileOutputStream outputStream = newFileOutputStream(System.getProperty(&quot;user.dir&quot;) + separator +&quot;recieve&quot; + separator + &quot;1.png&quot;);

    outputStream.write(unGizpData);

    outputStream.flush();

    outputStream.close();

    ctx.writeAndFlush(response);

}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;}&lt;/p&gt;

&lt;p&gt;客户端：&lt;/p&gt;

&lt;p&gt;public class Client {&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;public static void main(String[] args) {

    EventLoopGroup workerGroup = newNioEventLoopGroup();

    try {

        Bootstrap bootstrap = new Bootstrap();

        bootstrap.group(workerGroup)

                .handler(newLoggingHandler(LogLevel.INFO))

               .channel(NioSocketChannel.class)

                .handler(newChannelInitializer&amp;lt;SocketChannel&amp;gt;() {

                    @Override

                    protected voidinitChannel(SocketChannel socketChannel) throws Exception {

                        socketChannel.pipeline().addLast(MarshallingCodeCFactory.buildMarshallingEncoder());

                        socketChannel.pipeline().addLast(MarshallingCodeCFactory.buildMarshallingDecoder());

                       socketChannel.pipeline().addLast(new ClientHandler());

                    }

                });

        ChannelFuture future =bootstrap.connect(new InetSocketAddress(&quot;127.0.01&quot;, 8765)).sync();

        for(int i=1; i&amp;lt;=5; i++) {

            Request request = newRequest();

            request.setId(i);

            request.setName(&quot;pro&quot;+ i);

           request.setReqeustMessag(&quot;数据信息&quot; + i);

            //传输图片

            char separator =File.separatorChar;

            File file = newFile(System.getProperty(&quot;user.dir&quot;) + separator + &quot;source&quot;+ separator + &quot;2.jpg&quot;);

            FileInputStream inputStream = newFileInputStream(file);

            byte[] data = newbyte[inputStream.available()];

            inputStream.read(data);

            inputStream.close();

            byte[] gzipData =GzipUtils.gzip(data);

           request.setAttachment(gzipData);

           future.channel().writeAndFlush(request);

        }

 

       future.channel().closeFuture().sync();

    } catch (Exception e) {

        e.printStackTrace();

    } finally {

        workerGroup.shutdownGracefully();

    }

}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;}&lt;/p&gt;

&lt;p&gt;ClientHandler类：&lt;/p&gt;

&lt;p&gt;public classClientHandler extends ChannelHandlerAdapter {&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;@Override

public voidexceptionCaught(ChannelHandlerContext ctx, Throwable cause) throws Exception {

    super.exceptionCaught(ctx, cause);

}

 

@Override

public voidchannelActive(ChannelHandlerContext ctx) throws Exception {

    super.channelActive(ctx);

}

 

@Override

public voidchannelRead(ChannelHandlerContext ctx, Object msg) throws Exception {

    Response response = (Response) msg;

    System.out.println(&quot;Client:&quot;+ response.getId() + &quot;,&quot; + response.getName() + &quot;,&quot; +response.getResponseMessage());

}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;}&lt;/p&gt;

&lt;p&gt;Marshalling工具类：&lt;/p&gt;

&lt;p&gt;public final classMarshallingCodeCFactory {&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;/**

 * 创建Jboss Marshalling解码器MarshallingDecoder

 * @return MarshallingDecoder

 */

public static MarshallingDecoderbuildMarshallingDecoder() {

      //首先通过Marshalling工具类的精通方法获取Marshalling实例对象 参数serial标识创建的是java序列化工厂对象。

              final MarshallerFactorymarshallerFactory =Marshalling.getProvidedMarshallerFactory(&quot;serial&quot;);

              //创建了MarshallingConfiguration对象，配置了版本号为5

              final MarshallingConfigurationconfiguration = new MarshallingConfiguration();

              configuration.setVersion(5);

              //根据marshallerFactory和configuration创建provider

              UnmarshallerProvider provider= new DefaultUnmarshallerProvider(marshallerFactory, configuration);

              //构建Netty的MarshallingDecoder对象，俩个参数分别为provider和单个消息序列化后的最大长度

              MarshallingDecoder decoder =new MarshallingDecoder(provider, 1024 * 1024);

              return decoder;

}

 

/**

 * 创建Jboss Marshalling编码器MarshallingEncoder

 * @return MarshallingEncoder

 */

public static MarshallingEncoderbuildMarshallingEncoder() {

              final MarshallerFactorymarshallerFactory =Marshalling.getProvidedMarshallerFactory(&quot;serial&quot;);

              final MarshallingConfigurationconfiguration = new MarshallingConfiguration();

              configuration.setVersion(5);

              MarshallerProvider provider =new DefaultMarshallerProvider(marshallerFactory, configuration);

              //构建Netty的MarshallingEncoder对象，MarshallingEncoder用于实现序列化接口的POJO对象序列化为二进制数组

              MarshallingEncoder encoder =new MarshallingEncoder(provider);

              return encoder;

}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;}&lt;/p&gt;

&lt;p&gt;Gizp压缩与解压缩工具类：&lt;/p&gt;

&lt;p&gt;public classGzipUtils {&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;public static byte[] gzip(byte[] val)throws IOException {

    ByteArrayOutputStream bos = newByteArrayOutputStream(val.length);

    GZIPOutputStream gos = null;

    try {

        gos = new GZIPOutputStream(bos);

        gos.write(val, 0, val.length);

        gos.finish();

        gos.flush();

        bos.flush();

        val = bos.toByteArray();

    } finally {

        if (gos != null)

            gos.close();

        if (bos != null)

            bos.close();

    }

    return val;

}

 

public static byte[] unGzip(byte[] buf)throws IOException {

    GZIPInputStream gzi = null;

    ByteArrayOutputStream bos = null;

    try {

        gzi = new GZIPInputStream(newByteArrayInputStream(buf));

        bos = newByteArrayOutputStream(buf.length);

        int count = 0;

        byte[] tmp = new byte[2048];

        while ((count = gzi.read(tmp)) !=-1) {

            bos.write(tmp, 0, count);

        }

        buf = bos.toByteArray();

    } finally {

        if (bos != null) {

            bos.flush();

            bos.close();

        }

        if (gzi != null)

            gzi.close();

    }

    return buf;

}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;}&lt;/p&gt;

&lt;p&gt;7.最佳实践&lt;/p&gt;

&lt;p&gt;（1）数据通信&lt;/p&gt;

&lt;p&gt;我们需要了解在真正项目中如何使用Netty，大体上对于一些参数设置都是根据服务器性能决定的。我们需要考虑的问题是两台机器（甚至多台）使用Netty怎样进行通信。&lt;/p&gt;

&lt;p&gt;大体上分为三种：
     ①使用长连接通道不断开的形式进行通信，也就是服务器和客户端的通道一直处于开启状态，如果服务器性能足够好，并且客户端数量也比较上的情况下，推荐这种方式。
     ②一次性批量提交数据，采用短连接方式。也就是说先把数据保存到本地临时缓存区或者临时表，当达到界值时进行一次性批量提交，又或者根据定时任务轮询提交，&lt;/p&gt;

&lt;p&gt;这种情况的弊端是做不到实时性传输，对实时性要求不高的应用程序中推荐使用。
     ③使用一种特殊的长连接，在某一指定时间段内，服务器与某台客户端没有任何通信，则断开连接。下次连接则是客户端向服务器发送请求的时候，再次建立连接。
     在这里将介绍使用Netty实现第三种方式的连接，但是我们需要考虑两个因素：
     ①如何在超时（即服务器和客户端没有任何通信）后关闭通道？关闭通道后又如何再次建立连接？
     ②客户端宕机时，我们无需考虑，下次重启客户端之后就可以与服务器建立连接，但服务器宕机时，客户端如何与服务器端通信？&lt;/p&gt;

&lt;p&gt;服务器端：增加了红色框部分&lt;/p&gt;

&lt;p&gt;客户端（注意红色字体部分）：&lt;/p&gt;

&lt;p&gt;public class Client {&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;private static class SingleHodler {

    static final Client client = newClient();

}

 

public static Client getInstance() {

    return SingleHodler.client;

}

 

private EventLoopGroup workerGroup;

private Bootstrap bootstrap;

private ChannelFuture future;

 

private Client() {

    workerGroup = new NioEventLoopGroup();

    bootstrap = new Bootstrap();

    bootstrap.group(workerGroup)

           .channel(NioSocketChannel.class)

            .handler(newChannelInitializer&amp;lt;SocketChannel&amp;gt;() {

                @Override

                protected voidinitChannel(SocketChannel socketChannel) throws Exception {

                   socketChannel.pipeline().addLast(MarshallingCodeCFactory.buildMarshallingEncoder());

                   socketChannel.pipeline().addLast(MarshallingCodeCFactory.buildMarshallingDecoder());

                    socketChannel.pipeline().addLast(newReadTimeoutHandler(5)); //5秒后未与服务器通信，则断开连接。

                   socketChannel.pipeline().addLast(new ClientHandler());

                }

            });

}

 

public void connect() {

    try {

        future =bootstrap.connect(&quot;127.0.0.1&quot;, 8765).sync();

    } catch (InterruptedException e) {

        e.printStackTrace();

    }

}

 

public ChannelFuture getFuture() {

    if(future == null ||!future.channel().isActive()) {

        this.connect();

    }

    return future;

}

 

public static void main(String[] args)throws InterruptedException {

    Client client = getInstance();

    ChannelFuture future = client.getFuture();

 

    for(int i=1; i&amp;lt;=3; i++) {

        Message message = new Message(i,&quot;pro&quot; + i, &quot;数据信息&quot; + i);

       future.channel().writeAndFlush(message);

        Thread.sleep(4000);  //休眠4秒后再发送数据

    }

 

    future.channel().closeFuture().sync();

 

    new Thread(() -&amp;gt; {

        try {

            System.out.println(&quot;子线程开始....&quot;);

            ChannelFuture f =client.getFuture();

            Message message = newMessage(4, &quot;pro&quot; + 4, &quot;数据信息&quot; + 4);

            f.channel().writeAndFlush(message);

           f.channel().closeFuture().sync();

        } catch (Exception e) {

            e.printStackTrace();

        }

    }).start();

 

    System.out.println(&quot;主线程退出......&quot;);

}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;}&lt;/p&gt;

&lt;p&gt;其他的类与之前的一样，没有变化。&lt;/p&gt;

&lt;p&gt;运行结果：&lt;/p&gt;

&lt;p&gt;（2）心跳检测&lt;/p&gt;

&lt;p&gt;我们使用Socket通信一般经常会处理多个服务器之间的心跳检测，一般来讲我们去维护服务器集群，肯定要有一台或多台服务器主机（Master），然后还应该有N台（Slave），那么我们的主机肯定要时时刻刻知道自己下面的从服务器的各方面情况，然后进行实时监控的功能。这个在分布式架构里交做心跳检测或者心跳监控。最佳处理方案是使用一些通信框架进行实现，Netty就可以做这样的事。&lt;/p&gt;

&lt;p&gt;这个例子需要使用Sigar，不熟悉的可以看这篇文章。&lt;/p&gt;

&lt;p&gt;Server&lt;/p&gt;

&lt;p&gt;public class Server {&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;public Server(int port) {

    EventLoopGroup bossGroup = newNioEventLoopGroup();

    EventLoopGroup workerGroup = newNioEventLoopGroup();

    try {

        ServerBootstrap bootstrap = newServerBootstrap();

        bootstrap.group(bossGroup,workerGroup)

               .channel(NioServerSocketChannel.class)

                .childHandler(newChannelInitializer&amp;lt;SocketChannel&amp;gt;() {

                    @Override

                    protected voidinitChannel(SocketChannel sc) throws Exception {

                       sc.pipeline().addLast(MarshallingCodeCFactory.buildMarshallingEncoder());

                        sc.pipeline().addLast(MarshallingCodeCFactory.buildMarshallingDecoder());

                       sc.pipeline().addLast(new ServerHeartBeatHandler());

                    }

                })

                .handler(newLoggingHandler(LogLevel.INFO))

               .option(ChannelOption.SO_BACKLOG, 1024);

        ChannelFuture future =bootstrap.bind(new InetSocketAddress(&quot;127.0.0.1&quot;, port)).sync();

       future.channel().closeFuture().sync();

    } catch (Exception e) {

        e.printStackTrace();

    } finally {

        bossGroup.shutdownGracefully();

        workerGroup.shutdownGracefully();

    }

}

 

public static void main(String[] args) {

    new Server(8765);

}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;}&lt;/p&gt;

&lt;p&gt;ServerHeartBeatHandler类：&lt;/p&gt;

&lt;p&gt;public classServerHeartBeatHandler extends ChannelHandlerAdapter {&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;private static Map&amp;lt;String, String&amp;gt;AUTH_IP_MAP = new HashMap&amp;lt;&amp;gt;();

private static final String SUCCESS_KEY =&quot;auth_success_key&quot;;

 

static {

    AUTH_IP_MAP.put(&quot;192.168.3.176&quot;,&quot;1234&quot;);

}

 

private boolean auth(ChannelHandlerContextctx, Object msg) {

    String[] rets = ((String)msg).split(&quot;,&quot;);

    String auth = AUTH_IP_MAP.get(rets[0]);

    if(auth != null &amp;amp;&amp;amp;auth.equals(rets[1])) {

        ctx.writeAndFlush(SUCCESS_KEY);

        return true;

    } else {

        ctx.writeAndFlush(&quot;authfailure!&quot;).addListener(ChannelFutureListener.CLOSE);

        return false;

    }

}

 

@Override

public void channelRead(ChannelHandlerContextctx, Object msg) throws Exception {

    if(msg instanceof String) {

        auth(ctx, msg);

    } else if(msg instanceof RequestInfo) {

        RequestInfo info = (RequestInfo)msg;

        System.out.println(&quot;----------------------------------------------&quot;);

        System.out.println(&quot;当前主机ip：&quot; +info.getIp());

        System.out.println(&quot;当前主机cpu：情况&quot;);

        Map&amp;lt;String, Object&amp;gt; cpuMap =info.getCpuPercMap();

        System.out.println(&quot;总使用率：&quot; +  cpuMap.get(&quot;combined&quot;));

        System.out.println(&quot;用户使用率：&quot; +cpuMap.get(&quot;user&quot;));

        System.out.println(&quot;系统使用率：&quot; +cpuMap.get(&quot;sys&quot;));

        System.out.println(&quot;等待率：&quot; +cpuMap.get(&quot;wait&quot;));

        System.out.println(&quot;空闲率：&quot; +cpuMap.get(&quot;idle&quot;));

        System.out.println(&quot;当前主机memory情况：&quot;);

        Map&amp;lt;String, Object&amp;gt; memMap =info.getMemoryMap();

        System.out.println(&quot;内存总量：&quot; +memMap.get(&quot;total&quot;));

        System.out.println(&quot;当前内存使用量：&quot; +memMap.get(&quot;used&quot;));

        System.out.println(&quot;当前内存剩余量：&quot; +memMap.get(&quot;free&quot;));

       System.out.println(&quot;-----------------------------------------------&quot;);

        ctx.writeAndFlush(&quot;inforeceived!&quot;);

    } else {

        ctx.writeAndFlush(&quot;connectfailure&quot;).addListener(ChannelFutureListener.CLOSE);

    }

}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;}&lt;/p&gt;

&lt;p&gt;Client类：&lt;/p&gt;

&lt;p&gt;public class Client {&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;public static void main(String[] args) {

    EventLoopGroup workerGroup = newNioEventLoopGroup();

    try {

        Bootstrap bootstrap = newBootstrap();

        bootstrap.group(workerGroup)

               .channel(NioSocketChannel.class)

                .handler(newChannelInitializer&amp;lt;SocketChannel&amp;gt;() {

                    @Override

                    protected void initChannel(SocketChannelsc) throws Exception {

                       sc.pipeline().addLast(MarshallingCodeCFactory.buildMarshallingDecoder());

                       sc.pipeline().addLast(MarshallingCodeCFactory.buildMarshallingEncoder());

                       sc.pipeline().addLast(new ClientHeartBeatHandler());

                    }

                });

        ChannelFuture future =bootstrap.connect(new InetSocketAddress(&quot;127.0.0.1&quot;, 8765)).sync();

        future.channel().closeFuture().sync();

    } catch (Exception e) {

        e.printStackTrace();

    } finally {

        workerGroup.shutdownGracefully();

    }

}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;}&lt;/p&gt;

&lt;p&gt;ClientHeartBeatHandler类：&lt;/p&gt;

&lt;p&gt;public classClientHeartBeatHandler extends ChannelHandlerAdapter {&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;private ScheduledExecutorService scheduled= Executors.newScheduledThreadPool(1);

private ScheduledFuture&amp;lt;?&amp;gt; heartBeat;

private InetAddress address;

private static final String SUCCESS_KEY =&quot;auth_success_key&quot;;

 

@Override

public voidchannelActive(ChannelHandlerContext ctx) throws Exception {

    address = InetAddress.getLocalHost();

    String ip = address.getHostAddress();

    String key = &quot;1234&quot;;

    String auth = ip + &quot;,&quot; + key;

    ctx.writeAndFlush(auth);

}

 

@Override

public voidexceptionCaught(ChannelHandlerContext ctx, Throwable cause) throws Exception {

    cause.printStackTrace();

    if(heartBeat != null) {

        heartBeat.cancel(true);

        heartBeat = null;

    }

    ctx.fireExceptionCaught(cause);

}

 

@Override

public voidchannelRead(ChannelHandlerContext ctx, Object msg) throws Exception {

    try {

        if(msg instanceof String) {

            String data = (String) msg;

            if(SUCCESS_KEY.equals(data)) {

                heartBeat =scheduled.scheduleWithFixedDelay(new HeartBeatTask(ctx), 0, 5,TimeUnit.SECONDS);

                System.out.println(msg);

            } else {

                System.out.println(msg);

            }

        }

    } finally {

        ReferenceCountUtil.release(msg);

    }

}

 

private class HeartBeatTask implements Runnable{

    private final ChannelHandlerContextctx;

 

    publicHeartBeatTask(ChannelHandlerContext ctx) {

        this.ctx = ctx;

    }

 

    @Override

    public void run() {

        try {

            RequestInfo requestInfo = newRequestInfo();

           requestInfo.setIp(address.getHostAddress());

            Sigar sigar = new Sigar();

            CpuPerc cpuPerc =sigar.getCpuPerc();

            Map&amp;lt;String, Object&amp;gt;cpuPercMap = new HashMap&amp;lt;&amp;gt;();

            cpuPercMap.put(&quot;combined&quot;,cpuPerc.getCombined());

           cpuPercMap.put(&quot;user&quot;, cpuPerc.getUser());

            cpuPercMap.put(&quot;sys&quot;,cpuPerc.getSys());

           cpuPercMap.put(&quot;wait&quot;, cpuPerc.getWait());

            cpuPercMap.put(&quot;idle&quot;,cpuPerc.getIdle());

 

            Mem mem = sigar.getMem();

            Map&amp;lt;String, Object&amp;gt;memoryMap = new HashMap&amp;lt;&amp;gt;();

           memoryMap.put(&quot;total&quot;, mem.getTotal() / (1024 * 1024));

            memoryMap.put(&quot;used&quot;,mem.getUsed() / (1024 * 1024));

            memoryMap.put(&quot;free&quot;,mem.getFree() / (1024 * 1024));

 

           requestInfo.setCpuPercMap(cpuPercMap);

           requestInfo.setMemoryMap(memoryMap);

 

            ctx.writeAndFlush(requestInfo);

        } catch (Exception e) {

            e.printStackTrace();

        }

    }

}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;}&lt;/p&gt;

&lt;p&gt;RequestInfo类：&lt;/p&gt;

&lt;p&gt;public classRequestInfo implements Serializable {&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;     private String ip ;

     private Map&amp;lt;String, Object&amp;gt;cpuPercMap ;

     private Map&amp;lt;String, Object&amp;gt;memoryMap;

     //.. other field

 

     public String getIp() {

              return ip;

     }

 

     public void setIp(String ip) {

              this.ip = ip;

     }

 

     public Map&amp;lt;String, Object&amp;gt;getCpuPercMap() {

              return cpuPercMap;

     }

 

     public voidsetCpuPercMap(Map&amp;lt;String, Object&amp;gt; cpuPercMap) {

              this.cpuPercMap = cpuPercMap;

     }

 

     public Map&amp;lt;String, Object&amp;gt;getMemoryMap() {

              return memoryMap;

     }

 

     public void setMemoryMap(Map&amp;lt;String,Object&amp;gt; memoryMap) {

              this.memoryMap = memoryMap;

     }
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;}&lt;/p&gt;

&lt;p&gt;MarshallingCodeCFactory类就不贴出来了，跟之前的一样。
每5秒发送一次数据到服务器端，这样主服务器就可以知道每台从服务器的状态了。当然，这只是一个简单的小例子，真实环境中肯定需要更严格的校验。&lt;/p&gt;

&lt;p&gt;作者：郭无心
链接：https://www.zhihu.com/question/24322387/answer/78947405
来源：知乎
著作权归作者所有。商业转载请联系作者获得授权，非商业转载请注明出处。&lt;/p&gt;

&lt;p&gt;Netty是什么？1）本质：JBoss做的一个Jar包2）目的：快速开发高性能、高可靠性的网络服务器和客户端程序3）优点：提供异步的、事件驱动的网络应用程序框架和工具通俗的说：一个好使的处理Socket的东东如果没有Netty？远古：java.net + java.io
近代：java.nio
其他：Mina，Grizzly
与Mina相比有什么优势？1、都是Trustin Lee的作品，Netty更晚；2、Mina将内核和一些特性的联系过于紧密，使得用户在不需要这些特性的时候无法脱离，相比下性能会有所下降，Netty解决了这个设计问题；3、Netty的文档更清晰，很多Mina的特性在Netty里都有；4、Netty更新周期更短，新版本的发布比较快；5、它们的架构差别不大，Mina靠apache生存，而Netty靠jboss，和jboss的结合度非常高，Netty有对google protocal buf的支持，有更完整的ioc容器支持(spring,guice,jbossmc和osgi)；6、Netty比Mina使用起来更简单，Netty里你可以自定义的处理upstream events 或/和 downstream events，可以使用decoder和encoder来解码和编码发送内容；7、Netty和Mina在处理UDP时有一些不同，Netty将UDP无连接的特性暴露出来；而Mina对UDP进行了高级层次的抽象，可以把UDP当成”面向连接”的协议，而要Netty做到这一点比较困难。—————————————————————————————————————————————–Netty的特性1）设计统一的API，适用于不同的协议（阻塞和非阻塞）基于灵活、可扩展的事件驱动模型高度可定制的线程模型可靠的无连接数据Socket支持（UDP）2）性能更好的吞吐量，低延迟更省资源尽量减少不必要的内存拷贝3）安全完整的SSL/TLS和STARTTLS的支持能在Applet与Android的限制环境运行良好4）健壮性不再因过快、过慢或超负载连接导致OutOfMemoryError不再有在高速网络环境下NIO读写频率不一致的问题5）易用完善的JavaDoc，用户指南和样例简洁简单仅信赖于JDK1.5——————————————————————————————————————————————-Netty 在哪些行业得到了应用？互联网行业：随着网站规模的不断扩大，系统并发访问量也越来越高，传统基于 Tomcat 等 Web 容器的垂直架构已经无法满足需求，需要拆分应用进行服务化，以提高开发和维护效率。从组网情况看，垂直的架构拆分之后，系统采用分布式部署，各个节点之间需要远程服务调用，高性能的 RPC 框架必不可少，Netty 作为异步高性能的通信框架，往往作为基础通信组件被这些 RPC 框架使用。　　典型的应用有：阿里分布式服务框架 Dubbo 的 RPC 框架使用 Dubbo 协议进行节点间通信，Dubbo 协议默认使用 Netty 作为基础通信组件，用于实现各进程节点之间的内部通信。
    服务提供者和服务消费者之间，服务提供者、服务消费者和性能统计节点之间使用 Netty 进行异步/同步通信。　　除了 Dubbo 之外，淘宝的消息中间件 RocketMQ 的消息生产者和消息消费者之间，也采用 Netty 进行高性能、异步通信。　　除了阿里系和淘宝系之外，很多其它的大型互联网公司或者电商内部也已经大量使用 Netty 构建高性能、分布式的网络服务器。游戏行业：无论是手游服务端、还是大型的网络游戏，Java 语言得到了越来越广泛的应用。Netty 作为高性能的基础通信组件，它本身提供了 TCP/UDP 和 HTTP 协议栈，非常方便定制和开发私有协议栈。账号登陆服务器、地图服务器之间可以方便的通过 Netty 进行高性能的通信，架构示意图如下：&lt;img src=&quot;https://pic2.zhimg.com/50/9adabad98edc4b4e9001e2fc63d6da87_hd.jpg&quot; data-rawwidth=&quot;494&quot; data-rawheight=&quot;196&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;494&quot; data-original=&quot;https://pic2.zhimg.com/9adabad98edc4b4e9001e2fc63d6da87_r.jpg&quot; /&gt;　　图1-2 Netty 在游戏服务器架构中的应用大数据领域：经典的 Hadoop 的高性能通信和序列化组件 Avro 的 RPC 框架，默认采用 Netty 进行跨节点通信，它的 Netty Service 基于 Netty 框架二次封装实现。　　大数据计算往往采用多个计算节点和一个/N个汇总节点进行分布式部署，各节点之间存在海量的数据交换。由于 Netty 的综合性能是目前各个成熟 NIO 框架中最高的，因此，往往会被选中用作大数据各节点间的通信。企业软件：企业和 IT 集成需要 ESB，Netty 对多协议支持、私有协议定制的简洁性和高性能是 ESB RPC 框架的首选通信组件。事实上，很多企业总线厂商会选择 Netty 作为基础通信组件，用于企业的 IT 集成。通信行业：Netty 的异步高性能、高可靠性和高成熟度的优点，使它在通信行业得到了大量的应用。&lt;/p&gt;

&lt;p&gt;作者：知乎用户
链接：https://www.zhihu.com/question/24322387/answer/282001188
来源：知乎
著作权归作者所有。商业转载请联系作者获得授权，非商业转载请注明出处。&lt;/p&gt;

&lt;p&gt;作为一个学Java的，如果没有研究过Netty，那么你对Java语言的使用和理解仅仅停留在表面水平，会点SSH，写几个MVC，访问数据库和缓存，这些只是初等Java程序员干的事。如果你要进阶，想了解Java服务器的深层高阶知识，Netty绝对是一个必须要过的门槛。有了Netty，你可以实现自己的HTTP服务器，FTP服务器，UDP服务器，RPC服务器，WebSocket服务器，Redis的Proxy服务器，MySQL的Proxy服务器等等。如果你想知道Nginx是怎么写出来的，如果你想知道Tomcat和Jetty是如何实现的，如果你也想实现一个简单的Redis服务器，那都应该好好理解一下Netty，它们高性能的原理都是类似的。我们回顾一下传统的HTTP服务器的原理创建一个ServerSocket，监听并绑定一个端口一系列客户端来请求这个端口服务器使用Accept，获得一个来自客户端的Socket连接对象启动一个新线程处理连接读Socket，得到字节流解码协议，得到Http请求对象处理Http请求，得到一个结果，封装成一个HttpResponse对象编码协议，将结果序列化字节流写Socket，将字节流发给客户端继续循环步骤3HTTP服务器之所以称为HTTP服务器，是因为编码解码协议是HTTP协议，如果协议是Redis协议，那它就成了Redis服务器，如果协议是WebSocket，那它就成了WebSocket服务器，等等。使用Netty你就可以定制编解码协议，实现自己的特定协议的服务器。上面我们说的是一个传统的多线程服务器，这个也是Apache处理请求的模式。在高并发环境下，线程数量可能会创建太多，操作系统的任务调度压力大，系统负载也会比较高。那怎么办呢？于是NIO诞生了，NIO并不是Java独有的概念，NIO代表的一个词汇叫着IO多路复用。它是由操作系统提供的系统调用，早期这个操作系统调用的名字是select，但是性能低下，后来渐渐演化成了Linux下的epoll和Mac里的kqueue。我们一般就说是epoll，因为没有人拿苹果电脑作为服务器使用对外提供服务。而Netty就是基于Java NIO技术封装的一套框架。为什么要封装，因为原生的Java NIO使用起来没那么方便，而且还有臭名昭著的bug，Netty把它封装之后，提供了一个易于操作的使用模式和接口，用户使用起来也就便捷多了。那NIO究竟是什么东西呢？NIO的全称是NoneBlocking IO，非阻塞IO，区别与BIO，BIO的全称是Blocking IO，阻塞IO。那这个阻塞是什么意思呢？Accept是阻塞的，只有新连接来了，Accept才会返回，主线程才能继Read是阻塞的，只有请求消息来了，Read才能返回，子线程才能继续处理Write是阻塞的，只有客户端把消息收了，Write才能返回，子线程才能继续读取下一个请求所以传统的多线程服务器是BlockingIO模式的，从头到尾所有的线程都是阻塞的。这些线程就干等在哪里，占用了操作系统的调度资源，什么事也不干，是浪费。那么NIO是怎么做到非阻塞的呢。它用的是事件机制。它可以用一个线程把Accept，读写操作，请求处理的逻辑全干了。如果什么事都没得做，它也不会死循环，它会将线程休眠起来，直到下一个事件来了再继续干活，这样的一个线程称之为NIO线程。while true {
    events = takeEvents(fds)  // 获取事件，如果没有事件，线程就休眠
    for event in events {
        if event.isAcceptable {
            doAccept() // 新链接来了
        } elif event.isReadable {
            request = doRead() // 读消息
            if request.isComplete() {
                doProcess()
            }
        } elif event.isWriteable {
            doWrite()  // 写消息
        }
    }
}
NIO的流程大致就是上面的伪代码描述的过程，跟实际真实的代码有较多差异，不过对于初学者，这样理解也是足够了。Netty是建立在NIO基础之上，Netty在NIO之上又提供了更高层次的抽象。在Netty里面，Accept连接可以使用单独的线程池去处理，读写操作又是另外的线程池来处理。Accept连接和读写操作也可以使用同一个线程池来进行处理。而请求处理逻辑既可以使用单独的线程池进行处理，也可以跟放在读写线程一块处理。线程池中的每一个线程都是NIO线程。用户可以根据实际情况进行组装，构造出满足系统需求的并发模型。Netty提供了内置的常用编解码器，包括行编解码器［一行一个请求］，前缀长度编解码器［前N个字节定义请求的字节长度］，可重放解码器［记录半包消息的状态］，HTTP编解码器，WebSocket消息编解码器等等Netty提供了一些列生命周期回调接口，当一个完整的请求到达时，当一个连接关闭时，当一个连接建立时，用户都会收到回调事件，然后进行逻辑处理。Netty可以同时管理多个端口，可以使用NIO客户端模型，这些对于RPC服务是很有必要的。Netty除了可以处理TCP Socket之外，还可以处理UDP Socket。在消息读写过程中，需要大量使用ByteBuffer，Netty对ByteBuffer在性能和使用的便捷性上都进行了优化和抽象。总之，Netty是Java程序员进阶的必备神奇。如果你知其然，还想知其所以然，一定要好好研究下Netty。如果你觉得Java枯燥无谓，Netty则是重新开启你对Java兴趣大门的钥匙。&lt;/p&gt;
</description>
        <pubDate>Sat, 10 Feb 2018 00:00:00 +0800</pubDate>
        <link>https://xiazemin.github.io/MyBlog/web/2018/02/10/netty.html</link>
        <guid isPermaLink="true">https://xiazemin.github.io/MyBlog/web/2018/02/10/netty.html</guid>
        
        
        <category>web</category>
        
      </item>
    
      <item>
        <title>Tachyon</title>
        <description>&lt;p&gt;Tachyon是分布式文件系统，也就是说Tachyon实现了文件的存储结构，比如inode节点，数据block，以及文件查询的API，比如某个文件在哪个block上面，并且能以文件流的形式对数据进行读写，可以理解为这个是和NTFS、EXT4这些进行比较的，只是Tacyon的数据都放在内存中，不在硬盘中，快快快！而Redis就是个内存数据库，是的，是个数据库，数据库是构建在存储系统之上的，Redis用了内存和文件系统，和Tachyon不在一个层次上。Redis和Tachyon都是可以作为分布式cache层对系统进行加速，唯一不同在于Redis是kv接口，Tachyon是文件系统接口&lt;/p&gt;

&lt;p&gt;Tachyon是Spark生态系统内快速崛起的一个新项目。 本质上， Tachyon是个分布式的内存文件系统， 它在减轻Spark内存压力的同时，也赋予了Spark内存快速大量数据读写的能力。Tachyon把内存存储的功能从Spark中分离出来， 使Spark可以更专注计算的本身， 以求通过更细的分工达到更高的执行效率。 本文将先向读者介绍Tachyon在Spark生态系统中的使用， 也将分享百度在大数据平台上利用Tachyon取得的性能改善的用例，以及在实际使用Tachyon过程中遇到的一些问题和解决方案。最后我们将介绍一下Tachyon的一些新功能。&lt;/p&gt;

&lt;p&gt;Tachyon简介
Spark平台以分布式内存计算的模式达到更高的计算性能，在最近引起了业界的广泛关注，其开源社区也十分活跃。以百度为例，在百度内部计算平台已经搭建并运行了千台规模的Spark计算集群，百度也通过其BMR的开放云平台对外提供Spark计算平台服务。然而，分布式内存计算的模式也是一柄双刃剑，在提高性能的同时不得不面对分布式数据存储所产生的问题，具体问题主要有以下几个：&lt;/p&gt;

&lt;p&gt;当两个Spark作业需要共享数据时，必须通过写磁盘操作。比如：作业1要先把生成的数据写入HDFS，然后作业2再从HDFS把数据读出来。在此，磁盘的读写可能造成性能瓶颈。
由于Spark会利用自身的JVM对数据进行缓存，当Spark程序崩溃时，JVM进程退出，所缓存数据也随之丢失，因此在工作重启时又需要从HDFS把数据再次读出。
当两个Spark作业需操作相同的数据时，每个作业的JVM都需要缓存一份数据，不但造成资源浪费，也极易引发频繁的垃圾收集，造成性能的降低。
仔细分析这些问题后，可以确认问题的根源来自于数据存储，由于计算平台尝试自行进行存储管理，以至于Spark不能专注于计算本身，造成整体执行效率的降低。Tachyon的提出就是为了解决这些问题：本质上，Tachyon是个分布式的内存文件系统，它在减轻Spark内存压力的同时赋予了Spark内存快速大量数据读写的能力。Tachyon把存储与数据读写的功能从Spark中分离，使得Spark更专注在计算的本身，以求通过更细的分工达到更高的执行效率。
&lt;img src=&quot;https://xiazemin.github.io/MyBlog/img/Tachyon1.jpg&quot; /&gt;
图1: Tachyon的部署&lt;/p&gt;

&lt;p&gt;图1显示了Tachyon的部署结构。Tachyon被部署在计算平台（Spark，MR）之下以及存储平台（HDFS， S3）之上，通过全局地隔离计算平台与存储平台， Tachyon可以有效地解决上文列举的几个问题，：&lt;/p&gt;

&lt;p&gt;当两个Spark作业需要共享数据时，无需再通过写磁盘，而是借助Tachyon进行内存读写，从而提高计算效率。
在使用Tachyon对数据进行缓存后，即便在Spark程序崩溃JVM进程退出后，所缓存数据也不会丢失。这样，Spark工作重启时可以直接从Tachyon内存读取数据了。
当两个Spark作业需要操作相同的数据时，它们可以直接从Tachyon获取，并不需要各自缓存一份数据，从而降低JVM内存压力，减少垃圾收集发生的频率。
Tachyon系统架构
在上一章我们介绍了Tachyon的设计，本章我们来简单看看Tachyon的系统架构以及实现。 图2显示了Tachyon在Spark平台的部署：总的来说，Tachyon有三个主要的部件：Master， Client，与Worker。在每个Spark Worker节点上，都部署了一个Tachyon Worker，Spark Worker通过Tachyon Client访问Tachyon进行数据读写。所有的Tachyon Worker都被Tachyon Master所管理，Tachyon Master通过Tachyon Worker定时发出的心跳来判断Worker是否已经崩溃以及每个Worker剩余的内存空间量。
	&lt;img src=&quot;https://xiazemin.github.io/MyBlog/img/Tachyon2.jpg&quot; /&gt;
图2: Tachyon在Spark平台的部署&lt;/p&gt;

&lt;p&gt;图3显示了Tachyon Master的结构，其主要功能如下：首先，Tachyon Master是个主管理器，处理从各个Client发出的请求，这一系列的工作由Service Handler来完成。这些请求包括：获取Worker的信息，读取File的Block信息， 创建File等等；其次，Tachyon Master是个Name Node，存放着所有文件的信息，每个文件的信息都被封装成一个Inode，每个Inode都记录着属于这个文件的所有Block信息。在Tachyon中，Block是文件系统存储的最小单位，假设每个Block是256MB，如果有一个文件的大小是1GB，那么这个文件会被切为4个Block。每个Block可能存在多个副本，被存储在多个Tachyon Worker中，因此Master里面也必须记录每个Block被存储的Worker地址；第三，Tachyon Master同时管理着所有的Worker，Worker会定时向Master发送心跳通知本次活跃状态以及剩余存储空间。Master是通过Master Worker Info去记录每个Worker的上次心跳时间，已使用的内存空间，以及总存储空间等信息。 
	&lt;img src=&quot;https://xiazemin.github.io/MyBlog/img/Tachyon3.jpg&quot; /&gt;
	图3: Tachyon的Master设计&lt;/p&gt;

&lt;p&gt;图4显示了Tachyon Worker的结构，它主要负责存储管理：首先，Tachyon Worker的Service Handler处理来自Client发来的请求，这些请求包括：读取某个Block的信息，缓存某个Block，锁住某个Block，向本地内存存储要求空间等等。第二，Tachyon Worker的主要部件是Worker Storage，其作用是管理Local Data（本地的内存文件系统）以及Under File System（Tachyon以下的磁盘文件系统，比如HDFS）。第三，Tachyon Worker还有个Data Server以便处理其他的Client对其发起的数据读写请求。当由请求达到时，Tachyon会先在本地的内存存储找数据，如果没有找到则会尝试去其他的Tachyon Worker的内存存储中进行查找。如果数据完全不在Tachyon里，则需要通过Under File System的接口去磁盘文件系统（HDFS）中读取。
	&lt;img src=&quot;https://xiazemin.github.io/MyBlog/img/Tachyon4.jpg&quot; /&gt;
	图4: Tachyon的Worker设计&lt;/p&gt;

&lt;p&gt;图5显示了Tachyon Client的结构，它主要功能是向用户抽象一个文件系统接口以屏蔽掉底层实现细节。首先，Tachyon Client会通过Master Client部件跟Tachyon Master交互，比如可以向Tachyon Master查询某个文件的某个Block在哪里。Tachyon Client也会通过Worker Client部件跟Tachyon Worker交互， 比如向某个Tachyon Worker请求存储空间。在Tachyon Client实现中最主要的是Tachyon File这个部件。在Tachyon File下实现了Block Out Stream，其主要用于写本地内存文件；实现了Block In Stream主要负责读内存文件。在Block In Stream内包含了两个不同的实现：Local Block In Stream主要是用来读本地的内存文件，而Remote Block In Stream主要是读非本地的内存文件。请注意，非本地可以是在其它的Tachyon Worker的内存文件里，也可以是在Under File System的文件里。
	&lt;img src=&quot;https://xiazemin.github.io/MyBlog/img/Tachyon5.jpg&quot; /&gt;
图5: Tachyon的Client设计&lt;/p&gt;

&lt;p&gt;现在我们通过一个简单的场景把各个部件都串起来：假设一个Spark作业发起了一个读请求，它首先会通过Tachyon Client去Tachyon Master查询所需要的Block所在的位置。如果所在的Block不在本地的Tachyon Worker里，此Client则会通过Remote Block In Stream向别的Tachyon Worker发出读请求，同时在Block读入的过程中，Client也会通过Block Out Stream把Block写入到本地的内存存储里，这样就可以保证下次同样的请求可以由本机完成。&lt;/p&gt;

&lt;p&gt;Tachyon在百度内部的使用
在百度内部，我们使用Spark SQL进行大数据分析工作, 由于Spark是个基于内存的计算平台，我们预计绝大部分的数据查询应该在几秒或者十几秒完成以达到互动查询的目的。可是在Spark计算平台的运行中，我们却发现查询都需要上百秒才能完成，其原因如图6所示：我们的计算资源(Data Center 1)与数据仓库(Data Center 2)可能并不在同一个数据中心里面，在这种情况下，我们每一次数据查询都可能需要从远端的数据中心读取数据，由于数据中心间的网络带宽以及延时的问题，导致每次查询都需要较长的时间（&amp;gt;100秒）才能完成。更糟糕的是，很多查询的重复性很高，同样的数据很可能会被查询多次，如果每次都从远端的数据中心读取，必然造成资源浪费。&lt;/p&gt;

&lt;p&gt;为了解决这个问题，我们借助Tachyon把数据缓存在本地，尽量避免跨数据中心调数据。当Tachyon被部署到Spark所在的数据中心后，每次数据冷查询时，我们还是从远端数据仓库拉数据，但是当数据再次被查询时，Spark将从同一数据中心的Tachyon中读取数据，从而提高查询性能。实验表明：如果从非本机的Tachyon读取数据，耗时降到10到15秒，比原来的性能提高了10倍；最好的情况下，如果从本机的Tachyon读数据，查询仅需5秒，比原来的性能提高了30倍，效果相当明显。&lt;/p&gt;

&lt;p&gt;在使用了这个优化后，热查询性能达到了互动查询的要求，可是冷查询的用户体验还是很差。分析了用户行为后，我们发现用户查询的模式比较固定：比如很多用户每天都会跑同一个查询，只是所使用过滤数据的日期会发生改变。借助这次特性，我们可以根据用户的需求进行线下预查询，提前把所需要的数据导入Tachyon，从而避免用户冷查询。
	&lt;img src=&quot;https://xiazemin.github.io/MyBlog/img/Tachyon6.jpg&quot; /&gt;
图6: Tachyon在百度大数据平台的部署&lt;/p&gt;

&lt;p&gt;在使用Tachyon过程中，我们也遇到了一些问题：在刚开始部署Tachyon的时候， 我们发现数据完全不能被缓存，第一次与后续的查询耗时是一样的。如图7的源代码所示：只有整个数据Block被读取后，这个Block才会被缓存住；否则缓存的操作会被取消。比如一个Block是256MB，如果你读了其中的255MB，这个Block还是不会被缓存，因为它只需读取整个block中的部分数据。在百度内部，我们很多数据是用行列式存储的，比如ORC与Parquet文件，每次查询只会读其中的某几列， 因此不会读取完整的Block, 以致block缓存失败。为了解决这个问题，我们对Tachyon进行了修改，如果数据Block不是太大的话，冷查询时即使用户请求的只是其中几列，我们也会把整个Block都读进来，保证整个Block能被缓存住，然后再次查询的话就可以直接从Tachyon读取了。在使用了修改的版本后，Tachyon达到了我们期待的效果，大部分查询可以在10秒内完成。 
	&lt;img src=&quot;https://xiazemin.github.io/MyBlog/img/Tachyon7.jpg&quot; /&gt;
图7: Tachyon缓存数据逻辑&lt;/p&gt;

&lt;p&gt;Tachyon的一些新功能
我们把Tachyon当作缓存来使用，但是每台机器的内存有限，内存很快会被用完。 如果我们有50台机器，每台分配20GB的内存给Tachyon，那么总共也只有1TB的缓存空间，远远不能满足我们的需要。在Tachyon最新版本有一个新的功能： Hierarchical Storage,即使用不同的存储媒介对数据分层次缓存。如图8所示，它类于CPU的缓存设计：内存的读写速度最快所以可以用于第0级缓存，然后SSD可以用于第1级缓存，最后本地磁盘可以作为底层缓存。这样的设计可以为我们提供更大的缓存空间，同样50台机器，现在我们每台可贡献出20TB的缓存空间，使总缓存空间达到1PB，基本可以满足我们的储存需求。与CPU缓存类似，如果Tachyon的block Replacement Policy设计得当，99%的请求可以被第0级缓存（内存）所满足，从而在绝大部分时间可以做到秒级响应。
	&lt;img src=&quot;https://xiazemin.github.io/MyBlog/img/Tachyon8.jpg&quot; /&gt;
图8: Tachyon Hierarchical Storage&lt;/p&gt;

&lt;p&gt;当Tachyon收到读请求时，它首先检查数据是否在第0层，如果命中，直接返回数据，否则它会查询下一层缓存，直到找到被请求的数据为止。数据找到后会直接返回给用户，同时也会被Promote到第0层缓存，然后第0层被替换的数据Block会被LRU算法置换到下一层缓存。如此一来，如果用户再次请求相同的数据就会直接从第0层快速得到，从而充分发挥缓存的Locality特性。&lt;/p&gt;

&lt;p&gt;当Tachyon收到写请求时，它首先检查第0层是否有足够空间，如果有，则直接写入数据后返回。否则它会查询下一层缓存，直到找到一层缓存有足够空间，然后把上一层的一个Block用LRU算法推到下一层，如此类推，直到把第0层有足够空间以写入新的数据，然后再返回。这么做的目的是保证数据被写入第0层，如果读请求马上发生在写请求后，数据可以快速被读取。可是，这样做的话写的性能有可能变的很差：比如头两层缓存都满的话，它需要把一个Block从第1层丢到第2层，再把一个Block从第0层丢到第1层，然后才能写数据到第0层，再返回给用户。&lt;/p&gt;

&lt;p&gt;对此我们做了个优化， 与其层层类推腾出空间，我们的算法直接把数据写入有足够空间的缓存层，然后快速返回给用户。如果缓存全满，则把底层的一个Block置换掉，然后把数据写入底层缓存后返回。经过实验，我们发现优化后的做法会把写延时降低约50%，大大的提高了写的效率。但是读的效率又如何呢，由于在TACHYON里，写是通过Memory-Mapped File进行的，所以是先写入内存，再Flush到磁盘，如果读是马上发生在写之后的话，其实会从操作系统的Buffer，也就是内存里读数据，因此读的性能也不会下降。&lt;/p&gt;

&lt;p&gt;Hierarchical Storage很好地解决了我们缓存不够用的问题，下一步我们将继续对其进行优化。比如，现在它只有LRU一种置换算法，并不能满足所有的应用场景， 我们将针对不同的场景设计更高效的置换算法，尽量提高缓存命中率。&lt;/p&gt;

&lt;p&gt;结语
我个人相信更细的分工会达到更高的效率，Spark作为一个内存计算平台，如果使用过多的资源去缓存数据，会引发频繁的垃圾收集，造成系统的不稳定，或者影响性能。在我们使用Spark的初期，系统不稳定是我们面临的最大挑战，而频繁的垃圾收集正是引起系统不稳定最大的原因。比如当一次垃圾收集耗时过长时，Spark Worker变的响应非常不及时，很容易被误认为已经崩溃，导致任务重新执行。Tachyon通过把内存存储的功能从Spark中分离出来，让Spark更专注在计算本身，从而很好的解决了这个问题。随着内存变的越来越便宜，我们可以预期未来一段时间里，我们的服务器里可使用的内存会不断增长，Tachyon会在大数据平台中发挥越来越重要的作用。现在还是Tachyon发展的初期，在本文完成时Tachyon才准备发布0.6版，还有很多功能亟需完善，这也是一个好机遇，有兴趣的同学们可以多关注Tachyon，到社区里进行技术讨论以及功能开发。
&lt;!-- more --&gt;
Tachyon是一个以内存为核心的开源分布式存储系统，也是目前发展最迅速的开源大数据项目之一。Tachyon为不同的大数据计算框架（如Apache Spark，Hadoop MapReduce, Apache Flink等）提供可靠的内存级的数据共享服务。此外，Tachyon还能够整合众多现有的存储系统（如Amazon S3, Apache HDFS, RedHat GlusterFS, OpenStack Swift等），为用户提供统一的、易用的、高效的数据访问平台。本文首先向读者介绍Tachyon项目的诞生背景和目前发展的情况；然后详解Tachyon系统的基本架构以及目前一些重要的功能；最后，分享一个Tachyon在百度大数据生产环境下的几个应用案例。&lt;/p&gt;

&lt;p&gt;1.Tachyon简介
随着技术的发展，内存的吞吐量在不断地提高，单位容量的内存价格在不断降低，这为“内存计算”提供可能。在大数据计算平台领域，采用分布式内存计算模式的Spark验证了这一点。Spark相比于MapReduce大大提升了大数据的计算性能，受到了业界和社区的广泛关注。然而，还是有很多问题在计算框架层难以解决，如：不同的Spark应用或不同计算框架（Spark，MapReduce，Presto）间仍需通过基于磁盘的存储系统（如HDFS，Amazon S3等）交换数据；当Spark计算任务崩溃，JVM缓存的数据会丢失； JVM中大量缓存的数据增加了Java垃圾回收的压力。&lt;/p&gt;

&lt;p&gt;Tachyon最初出现是为了有效地解决了上述问题，它计划构建一个独立的存储层来快速共享不同计算框架的数据，实现方式上将数据置于堆外(off-heap)内存以避免大量垃圾回收开销。例如，对应Spark应用而言，可以带来以下作用：&lt;/p&gt;

&lt;p&gt;不同Spark应用，甚至不同计算平台上的应用需要数据共享时，通过Tachyon进行内存读写，避免缓慢的磁盘操作。
使用Tachyon进行数据缓存，当Spark任务崩溃，数据仍缓存在Tachyon内存中，任务重启后能够直接从Tachyon中读取数据。
多个Spark应用理论上甚至可以共享同一份Tachyon缓存的数据，避免内存资源的浪费，减轻Java垃圾回收的压力。
图片描述&lt;/p&gt;

&lt;p&gt;图1. Tachyon在生态系统的位置
图1给出了Tachyon部署时所处的位置。Tachyon被部署在计算平台之下和现有的存储系统之上，能够在不同计算框架间共享数据。同时，现有的海量数据不需要进行迁移，上层的计算作业仍能通过Tachyon访问到底层存储平台上的数据。Tachyon作为一个以内存为中心的中间存储层，不仅能极大地提升上层计算平台的性能，还能充分利用不同特性的底层存储系统，更可以有效地整合两者的优势。&lt;/p&gt;

&lt;p&gt;Tachyon最初是由李浩源博士发起的源自UC Berkeley AMPLab的研究项目（该实验室也是Mesos和Spark的发源地）。自2013年4月开源以来，Tachyon社区不断壮大，已经成为发展速度最快的开源大数据项目之一，目前已有来自超过50个组织机构的200多人参与到了对Tachyon项目的贡献中，也有超过100家公司部署了Tachyon。于此同时，Tachyon的核心创建者和开发人员创立了Tachyon Nexus公司，其中不乏UC Berkeley、CMU等博士以及Google, Palantir, Yahoo!等前员工。 2015年3月美国华尔街日报报道了Tachyon Nexus获得硅谷著名风投Andreessen Horowitz 的750万美元A轮投资。&lt;/p&gt;

&lt;p&gt;图片描述&lt;/p&gt;

&lt;p&gt;图2. Tachyon项目贡献者的增长情况
在学术界， 国内的南京大学PASA大数据实验室一直积极关注并参与到Tachyon项目的开发中，共向Tachyon社区贡献了100多个PR，近300次commit，包括为Tachyon实现性能测试框架tachyon-perf，增加LFU、LRFU等多个替换策略，改进WebUI页面，以及其他一些性能优化的工作。此外，我们还撰写了Tachyon相关的中文博客，以便中文读者和用户能够更深入地了解和使用Tachyon。&lt;/p&gt;

&lt;p&gt;在工业界，百度也把Tachyon运用到其大数据系统中， Tachyon在过去一年中稳定的支持着百度的可交互式查询业务，令百度的交互式查询提速30倍。在验证了Tachyon的高性能以及可靠性后，百度在内部使用Tachyon的0.9版成功部署了1000个worker的世界最大Tachyon集群，总共提供50TB的内存存储。此集群在百度内部已经稳定运行了一个月，也验证的Tachyon的可扩展性。于此同时，百度的另外一个Tachyon部署中用Tachyon层次化数据管理了2PB数据。&lt;/p&gt;

&lt;p&gt;2.Tachyon系统架构
这一章中我们简介Tachyon系统的基本架构，包括Tachyon的基本组件及其功能。&lt;/p&gt;

&lt;p&gt;图片描述&lt;/p&gt;

&lt;p&gt;图3. Tachyon的系统架构
图2是Tachyon系统的基本架构，主要包括4个基本组件：Master、Worker和Client，以及可插拔的底层存储系统（Underlayer Storage System）。每个组件的具体功能职责如下：&lt;/p&gt;

&lt;p&gt;Tachyon Master主要负责管理两类重要信息。第一，Tachyon Master中记录了所有数据文件的元数据信息，包括整个Tachyon命名空间（namespace）的组织结构，所有文件和数据块的基本信息等。第二，Tachyon Master监管着整个Tachyon系统的状态，包括整个系统的存储容量使用情况，所有Tachyon Worker的运行状态等。&lt;/p&gt;

&lt;p&gt;Tachyon Worker负责管理本地节点上的存储资源，包括内存、SSD和HDD等。Tachyon中的所有数据文件被划分为一系列数据块，Tachyon Worker以块为粒度进行存储和管理，如：为新的数据块分配空间、将热数据块从SSD或HDD移至内存、实时或定期备份数据块到底层存储系统。同时，Tachyon Worker定时向Tachyon Master发送心跳（heartbeat）以告知自身的状态信息。&lt;/p&gt;

&lt;p&gt;Tachyon Client是上层应用访问Tachyon数据的入口。访问过程可以包括如下几步：①Client向Master询问数据文件的基本信息，包括文件位置，数据块大小等；②Client尝试从本地Worker中读取对应数据块，若本地不存在Worker或者数据块不在本地Worker中，则尝试从远程Worker中读取；③若数据还未被缓存到Tachyon中，则Client会从底层存储系统中读取对应数据。此外，Tachyon Client会向所有建立连接的Tachyon Master和Tachyon Worker定时发送心跳以表示仍处于连接租期中，中断连接后Tachyon Master和Tachyon Worker会回收对应Client的临时空间。&lt;/p&gt;

&lt;p&gt;底层存储系统既可以被Tachyon用来备份数据，也可以作为Tachyon缓存数据的来源，上层应用在使用Tachyon Client时也能直接访问底层存储系统上的数据。底层存储系统保证了Tachyon Worker在发生故障而崩溃后不会导致数据丢失，同时也使得上层应用在迁移到Tachyon的同时不需要进行底层数据的迁移。目前Tachyon支持的底层存储系统有HDFS，GlusterFS，Amazon S3，OpenStack Swift以及本地文件系统，且能够比较容易地嵌入更多的现有存储系统。&lt;/p&gt;

&lt;p&gt;在实际部署时， Tachyon Master通常部署在单个主节点上（Tachyon也支持多个节点上部署Tachyon Master，并通过使用ZooKeeper来防止单点故障）；将Tachyon Worker部署在多个从节点；Tachyon Client和应用相关，可以位于任何一个节点上。&lt;/p&gt;

&lt;p&gt;3.Tachyon的特色功能
本节我们简介Tachyon面向上层应用的特色功能。&lt;/p&gt;

&lt;p&gt;3.1 支持多种部署方式&lt;/p&gt;

&lt;p&gt;作为大数据系统中的存储层，Tachyon为用户提供了不同的启动模式、对资源管理框架的支持、以及目标运行环境，能够部署多种大数据平台环境中：&lt;/p&gt;

&lt;p&gt;启动模式：以正常模式启动单个Tachyon Master；以高级容错模式启动多个Tachyon Master，并使用ZooKeeper进行管理；
资源管理框架：以Standalone方式直接运行在操作系统之上；运行在Apache Mesos之上；运行在Apache Hadoop Yarn之上；
目标运行环境：部署在本地集群环境中；部署在Virtual Box虚拟机中；部署在容器（如Docker）中；部署在Amazon EC2云平台上（Tachyon社区正在开发支持Tachyon部署在阿里云OSS上）
用户可以自由选择不同的启动模式、资源管理框架和目标运行环境，Tachyon为多种组合都提供了相应的启动脚本，能够很方便地将Tachyon部署在用户的环境中。&lt;/p&gt;

&lt;p&gt;3.2 层次化存储&lt;/p&gt;

&lt;p&gt;Tachyon的层次化存储充分利用了每个Tachyon Worker上的本地存储资源，将Tachyon中的数据块按不同热度存放在了不同的存储层中。目前Tachyon所使用的本地存储资源包括MEM（Memory，内存）、SSD（Solid State Drives，固态硬盘）和HDD（Hard Disk Drives，磁盘）。在Tachyon Worker中，每一类存储资源被视作一层（Storage Tier），每一层又可以由多个目录（Storage Directory）组成，并且用户可以设置每个存储目录的容量。&lt;/p&gt;

&lt;p&gt;在读写Tachyon数据时，分配器（Allocator）负责为新的数据块选择目标存储目录，替换器（Evictor）负责将冷数据从内存剔至SSD和HDD，同时将热数据从SSD和HDD提升至内存中。目前分配器所使用的分配策略包括Greedy、MaxFree和RoundRobin。替换器所使用的替换策略包括Greedy、LRU/PartialLRU、LRFU。额外地，Tachyon还为用户提供了Pin功能，支持用户将所需要的数据始终存放在内存中。关于如何配置Tachyon层次化存储，可以进一步参考Tachyon官方文档。&lt;/p&gt;

&lt;p&gt;3.3 灵活的读写机制&lt;/p&gt;

&lt;p&gt;为了充分利用多层次的存储资源和底层存储系统，Tachyon为用户提供了不同的读写类型（ReadType/WriteType）API，用于灵活控制读写数据时的行为方式，不同的读写类型及其含义如表1所示。&lt;/p&gt;

&lt;p&gt;表1. 读写类型（ReadType/WriteType）的取值及其含义
图片描述&lt;/p&gt;

&lt;p&gt;除了上述的读写类型外，Tachyon还提供了另一套控制方式：TachyonStorageType和UnderStorageType，用于分别控制在Tachyon存储和底层存储系统上的读写行为，具体取值及其含义如表2所示。实际上，这种控制方式是Tachyon-0.8之后新增的，控制粒度更细，功能也更多，因此推荐用户采用这种方式控制读写行为。&lt;/p&gt;

&lt;p&gt;表2. TachyonStorageType/UnderStorageType的值及其含义
图片描述&lt;/p&gt;

&lt;p&gt;3.4 文件系统层的Lineage容错机制&lt;/p&gt;

&lt;p&gt;在Tachyon中，Lineage表示了两个或多个文件之间的世系关系，即输出文件集B是由输入文件集A通过怎样的操作得到的。有了Lineage信息后，在文件数据意外丢失时，Tachyon就会启动重计算作业，根据现有的文件重新执行同样的操作，以恢复丢失的数据。图3给出了一个Lineage示例，文件集A通过一个Spark作业生成文件集B；文件集C通过另一个Spark作业生成文件集D；B和D作为同一个MapReduce作业的输入，输出为文件集E。那么，如果文件集E意外丢失，并且没有备份，那么Tachyon就会重新启动对应的MapReduce作业，再次生成E。&lt;/p&gt;

&lt;p&gt;图片描述
图4. Tachyon的Lineage机制
3.5 统一命名空间&lt;/p&gt;

&lt;p&gt;对于Tachyon的用户而言，通过Tachyon提供的接口所访问到的是Tachyon文件系统的命名空间。当用户需要访问Tachyon以外的文件和数据时，Tachyon提供了Mount接口，能够将外部存储系统的文件或目录挂载到Tachyon的命名空间中。这样用户就能够在统一的Tachyon命名空间中，使用相同或者自定义的路径，访问其他存储系统上的文件和数据。&lt;/p&gt;

&lt;p&gt;图片描述&lt;/p&gt;

&lt;p&gt;图5. Tachyon的统一命名空间
3.6 HDFS兼容接口&lt;/p&gt;

&lt;p&gt;在Tachyon出现之前，诸如Hadoop MapReduce以及Apache Spark的应用大多使用HDFS、Amazon S3等存储文件。Tachyon为这些应用提供了一套HDFS兼容的接口（确切地说，是兼容了org.apache.hadoop.fs.FileSystem的接口），用户可以在不改动应用源码的情况下，通过以下3个步骤，将目标文件系统更改为Tachyon：&lt;/p&gt;

&lt;p&gt;1.将对应版本Tachyon Client的jar包添加至运行环境的CLASSPATH中； 
2.添加Hadoop配置项&amp;lt;“fs.tachyon.impl”, “tachyon.hadoop.TFS”&amp;gt;； 
3.将原先的”hdfs://ip:port/file/X”路径更改为”tachyon://ip:port/file/X”。&lt;/p&gt;

&lt;p&gt;通常，用户可以结合使用“HDFS兼容接口”和“统一命名空间”这两个特性，将原先的大数据应用直接运行在Tachyon之上，而不需要进行任何代码和数据的迁移。&lt;/p&gt;

&lt;p&gt;3.7 丰富的命令行式工具&lt;/p&gt;

&lt;p&gt;Tachyon自带了一个名为 “tfs”的命令行工具，能够让用户以命令行的方式与Tachyon交互，而不需要编写源码来查看、新建、删除Tachyon文件。例如：&lt;/p&gt;

&lt;p&gt;图片描述&lt;/p&gt;

&lt;p&gt;“tfs”工具提供的全部命令使用方式详见Tachyon官方文档。&lt;/p&gt;

&lt;p&gt;3.8 方便管理的WebUI&lt;/p&gt;

&lt;p&gt;除了“tfs”工具外，Tachyon还在Tachyon Master和每个Tachyon Worker节点上启动了一个网页管理页面，用户可以通过浏览器打开对应的WebUI（默认为http://:19999和http://:30000）。WebUI上列举了整个Tachyon系统的基本信息、所有Tachyon Worker的运行状态、以及当前Tachyon系统的配置信息。同时，用户可以直接在WebUI上浏览整个Tachyon文件系统、预览文件内容、甚至下载具体的某个文件。&lt;/p&gt;

&lt;p&gt;图片描述&lt;/p&gt;

&lt;p&gt;图6. Tachyon的WebUI
3.9 实时指标监控系统&lt;/p&gt;

&lt;p&gt;图片描述&lt;/p&gt;

&lt;p&gt;图片描述
图7. Tachyon监控的实时指标（WebUI模式、JSON格式）
对于高级用户和系统管理人员，Tachyon提供了一套实时指标监控系统，实时地记录和管理了Tachyon中一些重要的统计信息，包括存储容量使用情况、现有Tachyon文件数、对文件的操作次数、现有的数据块数、对数据块的操作次数、总共读写的字节数等。根据用户的配置，这些指标能够以多种方式进行输出：标准控制台输出、以CSV格式保存为文件、输出到JMX控制台、输出到Graphite服务器以及输出到Tachyon的WebUI。&lt;/p&gt;

&lt;p&gt;3.10支持Linux FUSE&lt;/p&gt;

&lt;p&gt;Tachyon-FUSE是Tachyon最新开发版的新特性，由Tachyon Nexus和IBM共同主导开发。在Linux系统中，FUSE（Filesystem in Userspace，用户空间文件系统）模块使得用户能将其他文件系统挂载到本地文件系统的某一目录下，然后以统一的方式进行访问。Tachyon-FUSE的出现使得用户同样可以将Tachyon文件系统挂载到本地文件系统中。通过Tachyon-FUSE，用户/应用可以使用访问本地文件系统的方式来访问Tachyon。这更加方便了用户对Tachyon的管理和使用，以及现有基于FUSE接口的应用通过Tachyon进行内存加速或者数据共享。&lt;/p&gt;

&lt;p&gt;4.Tachyon在百度大数据平台的应用案例
在百度，我们从2014年底开始关注Tachyon。当时我们使用Spark SQL进行大数据分析工作，由于Spark是个基于内存的计算平台，我们预计绝大部分的数据查询应该在几秒或者十几秒完成以达到交互查询的体验。然而，我们却发现实际查询几乎都需要上百秒才能完成，其原因在于我们的计算资源与数据仓库可能并不在同一个数据中心。 在这种情况下，我们每一次数据查询都可能需要从远端的数据中心读取数据，由于数据中心间的网络带宽以及延时的问题，导致每次查询都需要较长的时间（&amp;gt;100秒）才能完成。更糟糕的是，很多查询的重复性或相似性很高，同样的数据很可能会被查询多次，如果每次都从远端的数据中心读取，必然造成资源浪费。&lt;/p&gt;

&lt;p&gt;为了解决这个问题，在一年前我们借助Tachyon管理远程及本地数据读取和调度，尽量避免跨数据中心读数据。 当Tachyon被部署到Spark所在的数据中心后，每次数据冷查询时，我们还是从远端数据仓库拉数据，但是当数据再次被查询时， Spark将直接从同一数据中心的Tachyon中读取数据， 从而提高查询性能。在我们的环境和应用中实验表明：如果是从非本机的Tachyon读取数据的话，耗时降到10到15秒，比原来的性能提高了10倍； 最好的情况下，如果从本机的Tachyon读数据，查询仅需5秒，比原来的性能提高了30倍， 效果很明显。除了性能的提高，更难能可贵的是Tachyon运行稳定，在过去一年中很好的支持着百度的交互式查询业务， 而且社区在每一版迭代更新中都不断提供更多的功能以及不断提高系统的稳定性，让业界对Tachyon系统更有信心。&lt;/p&gt;

&lt;p&gt;在过去一个月，百度在为大规模使用Tachyon做准备，验证Tachyon的可扩展性。我们使用Tachyon的最新版成功部署了1000个worker的Tachyon集群，在本文完成时这应该是世界最大的Tachyon集群。此集群总共提供超过50TB的内存存储，在百度内部已经稳定运行了一个月，现在有不同的百度业务在上面试运行以及压力测试。在百度的图搜变现业务上，我们与社区合作在Tachyon上搭建了一个高性能的Key/Value存储，提供线上图片服务。同时由于图片直接存在Tachyon里，我们的线下计算可以直接从Tachyon中读取图片。 这使得我们将线上以及线下系统整合成一个系统，既简化了开发流程，也节省了存储资源，达到了事半功倍的效果。本文篇幅有限，期待在后期给大家详细介绍百度是1000 worker的Tachyon 集群的实用案例，包括如何使用Tachyon整合线上线下的存储资源等。&lt;/p&gt;

&lt;p&gt;5.结语
作为一个以内存为中心、统一的分布式存储系统，Tachyon极大地增强了大数据生态中存储层的功能。虽然Tachyon项目相对还比较年轻，但已经很成熟稳定，并且已经在学术界以及工业界取得了成功。随着整个计算机产业的发展，内存变的越来越便宜，在计算集群中可使用的内存容量会不断增长，我们相信Tachyon也必将会在大数据平台中发挥越来越重要的作用。&lt;/p&gt;

&lt;p&gt;现在Tachyon项目发展迅速，更多的功能也在逐步得到完善，应用前景也颇为广阔。Tachyon正不断地在支持更多的底层存储系统（特别地，社区中已经有人正在实施支持阿里云OSS存储系统以及百度开放云平台，这对国内的用户和开发者来说是个很好的机会）；同时Tachyon也在实现安全性相关的支持，以充分满足业界生成环境的需要；更进一步地，Tachyon目前更多地被视为文件系统，而作为一个统一存储系统，Tachyon也将支持更多的数据结构，以满足不同计算框架的需要。在本文完成时Tachyon已经准备发布下一版，有兴趣的读者们可以多关注Tachyon，到社区里进行技术讨论以及功能开发。&lt;/p&gt;

&lt;p&gt;版本选择
Tachyon目前的最新发布版为0.5.0，最新开发版为0.6.0-SNAPSHOT。由于两者向上层提供的API有了不小的差异，这里以最新的0.6.0-SNAPSHOT开发版为基础进行介绍。它具有更多功能，更多新特性，更方便用户使用。在介绍时，我们也会标注出那些和0.5.0版本兼容的部分，让大家能够同时Hold住不同的版本。&lt;/p&gt;

&lt;p&gt;官方资料： Tachyon-0.5.0； 最新开发版。（本文章介绍的Tachyon基于的版本是0.6.0-SNAPSHOT，2014-12-27）&lt;/p&gt;
&lt;ol&gt;
  &lt;li&gt;Tachyon的安装
由于目前Tachyon使用了RamFS作为内存层，因此推荐在Linux环境下安装Tachyon。&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;第①步——下载&amp;amp;编译
对于已经发布的版本，如Tachyon-0.5.0或更早的版本，可以直接下载已经编译好的包，并解压。下载地址为https://github.com/amplab/tachyon/releases&lt;/p&gt;

&lt;p&gt;为了更好地契合用户的本地环境，如java版本、hadoop版本或其他一些软件包的版本，可以下载Tachyon源码自行编译。Tachyon开源在GitHub上，可以很方便地获得其不同版本的源码：Tachyon-0.5.0；最新开发版。Tachyon项目采用Maven进行管理，因此可以采用 mvn package 命令进行编译打包。在Tachyon-0.6.0-SNAPSHOT版本中，默认依赖的java版本为1.6，默认依赖的hadoop版本为1.0.4，如果要更改这些依赖的版本号可以在编译时加入选项，如：&lt;/p&gt;

&lt;p&gt;1
mvn clean package -Djava.version=1.7 -Dhadoop.version=2.3.0 -DskipTests
完成这一步后，我们就得到了能够运行在用户本地环境的Tachyon，下面我们分别介绍如何在单机和分布式环境下配置和启动Tachyon。&lt;/p&gt;

&lt;p&gt;1.1 单机安装Tachyon
这里要注意一点，Tachyon在单机（local）模式下启动时会自动挂载RamFS，所以请保证使用的账户具有sudo权限。&lt;/p&gt;

&lt;p&gt;第②步——配置
在conf/workers文件中配置需要启动TachyonWorker的节点，默认是localhost，所以在单机模式下不用更改。（在Tachyon-0.5.0版本中，该文件为conf/slaves）&lt;/p&gt;

&lt;p&gt;将conf/tachyon-env.sh.template复制为conf/tachyon-env.sh，并在conf/tachyon-env.sh中修改具体配置，下面列举了一些重要的配置项，稍后会详细地介绍更多的配置项。&lt;/p&gt;

&lt;p&gt;JAVA_HOME —— 系统中java的安装路径
TACHYON_MASTER_ADDRESS —— 启动TachyonMaster的地址，默认为localhost，所以在单机模式下不用更改
TACHYON_UNDERFS_ADDRESS —— Tachyon使用的底层文件系统的路径，在单机模式下可以直接使用本地文件系统，如”/tmp/tachyon”，也可以使用HDFS，如”hdfs://ip:port”
TACHYON_WORKER_MEMORY_SIZE —— 每个TachyonWorker使用的RamFS大小&lt;/p&gt;

&lt;p&gt;第③步——启动
完成配置后，即可以单机模式启动Tachyon，格式化、启动和停止Tachyon的命令分别为：&lt;/p&gt;

&lt;p&gt;1
2
3
bin/tachyon format
bin/tachyon-start.sh local
bin/tachyon-stop.sh
1.2 分布式安装Tachyon
这里我们以一个三个节点的集群为例，分别为slave201，slave202和slave203。三个节点都运行TachyonWorker，slave201运行TachyonMaster。&lt;/p&gt;

&lt;p&gt;第②步——配置（该过程在TachyonMaster节点，即slave201上完成）
在conf/workers文件中配置需要启动TachyonWorker的节点，即&lt;/p&gt;

&lt;p&gt;1
2
3
slave201
slave202
slave203
将conf/tachyon-env.sh.template复制为conf/tachyon-env.sh，并在conf/tachyon-env.sh中修改具体配置。不同于单机模式，这里需要修改TachyonMaster地址以及底层文件系统路径&lt;/p&gt;

&lt;p&gt;1
2
export TACHYON_MASTER_ADDRESS=slave201
export TACHYON_UNDERFS_ADDRESS=hdfs://slave201:9000
完成配置文件的修改后，将整个tachyon文件夹复制到每个节点的相同路径下&lt;/p&gt;

&lt;p&gt;1
2
scp –r tachyon-master slave202:/home/…/
scp –r tachyon-master slave203:/home/…/&lt;/p&gt;

&lt;p&gt;第③步——启动 
在分布式模式下，格式化和停止Tachyon的命令仍然为：&lt;/p&gt;

&lt;p&gt;1
2
bin/tachyon format
bin/tachyon-stop.sh
但启动Tachyon有了更多的选项：&lt;/p&gt;

&lt;p&gt;bin/tachyon-start.sh all Mount #在启动前自动挂载TachyonWorker所使用的RamFS，然后启动TachyonMaster和所有TachyonWorker。由于直接使用mount命令，所以需要用户为root
bin/tachyon-start.sh all SudoMount #在启动前自动挂载TachyonWorker所使用的RamFS，然后启动TachyonMaster和所有TachyonWorker。由于使用sudo mount命令，所以需要用户有sudo权限
bin/tachyon-start.sh all NoMount #认为RamFS已经挂载好，不执行挂载操作，只启动TachyonMaster和所有TachyonWorker
因此，如果不想每次启动Tachyon都挂载一次RamFS，可以先使用命令 bin/tachyon-mount.sh Mount workers 或 bin/tachyon-mount.sh SudoMount workers 挂载好所有RamFS，然后使用 bin/tachyon-start.sh all NoMount 命令启动Tachyon。&lt;/p&gt;

&lt;p&gt;单机和分布式模式的区别就在于配置和启动步骤，事实上，也可以在分布式模式下只设置一个TachyonWorker（伪分布式），在这种情况下两者就基本一样了。&lt;/p&gt;

&lt;p&gt;第④步——查看&amp;amp;测试
启动Tachyon后，可以用 jps 命令查看TachyonMaster和TachyonWorker进程是否存在&lt;/p&gt;

&lt;p&gt;也可以在浏览器内打开Tachyon的WebUI，如 http://slave201:19999 ，查看整个Tachyon的状态，各个TachyonWorker的运行情况，各项配置信息，浏览文件系统等。&lt;/p&gt;

&lt;p&gt;此外，还能在任一启动了TachyonWorker的节点上执行 bin/tachyon runTests 命令来测试Tachyon是否运行正常。&lt;/p&gt;

&lt;p&gt;步骤①-④即完成了Tachyon的安装和启动，之后我们也会给出具体地如何使用Tachyon。&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;Tachyon的配置
Tachyon的可配置项远不止上面步骤②的配置文件中的那些，用户可以根据自己的需求更改Tachyon的各项配置。这里以0.6.0-SNAPSHOT版本为例，介绍Tachyon中可配置参数的具体含义。（Tachyon-0.5.0的可配置项基本上是Tachyon-0.6.0-SNAPSHOT的一个子集）&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;Tachyon中的可配置项分为两类，一种是系统环境变量，用于在不同脚本间共享配置信息；另一种是程序运行参数，通过-D选项传入运行Tachyon的JVM中。程序运行参数又分为通用配置（Common Configuration）、TachyonMaster配置（Master Configuration）、TachyonWorker配置（Worker Configuration）和用户配置（User Configuration）。要修改或添加这些可配置项，请修改conf/tachyon-env.sh文件。&lt;/p&gt;

&lt;p&gt;2.1 Tachyon环境变量
JAVA_HOME：系统中java的安装路径
TACHYON_RAM_FOLDER：配置ramfs挂载的文件目录，默认为/mnt/ramdisk。
TACHYON_MASTER_ADDRESS：启动TachyonMaster的地址，默认为localhost，所以在单机模式下不用更改
TACHYON_UNDERFS_ADDRESS：Tachyon使用的底层文件系统的路径，本地文件系统（单机模式下），如”/tmp/tachyon”，或HDFS，如”hdfs://ip:port”
TACHYON_WORKER_MEMORY_SIZE：每个TachyonWorker使用的RamFS大小，默认为1GB
2.2 通用配置
tachyon.underfs.address：Tachyon在底层文件系统的的路径，默认为$TACHYON_UNDERFS_ADDRESS
tachyon.home：Tachyon的安装路径，启动Tachyon时为当前 tachyon 文件夹的路径
tachyon.data.folder：Tachyon数据在底层文件系统的存放路径，默认为$TACHYON_UNDERFS_ADDRESS/tmp/tachyon/data
tachyon.workers.folder：TachyonWorkers在底层文件系统的工作路径，默认为$TACHYON_UNDERFS_ADDRESS/tmp/tachyon/workers
tachyon.usezookeeper：TachyonMaster是否使用ZooKeeper容错，默认为false。
tachyon.zookeeper.adress：如果启用，ZooKeeper的地址
tachyon.zookeeper.election.path：如果启用，Zookeeper的election文件夹路径，默认为/election
tachyon.zookeeper.leader.path：如果启用，Zookeeper的leader文件夹路径，默认为/leader
tachyon.underfs.hdfs.impl：实现HDFS的类，默认org.apache.hadoop.hdfs,DistributedFileSystem
tachyon.max.columns：Tachyon中RawTable允许的最大列数，默认为1000
tachyon.table.metadata.byte：Tachyon中RawTable元数据允许存储的最大字节数，默认为5242880，即5MB
tachyon.underfs.glusterfs.impl：如果使用GlusterFS为底层文件系统，实现GlusterFS的类，默认为org.apache.hadoop.fs.glusterfs.GlusterFileSystem
tachyon.underfs.glusterfs.mounts：如果使用GlusterFS为底层文件系统，GlusterFS卷的挂载目录
tachyon.underfs.glusterfs.volumes：如果使用GlusterFS为底层文件系统，GlusterFS的卷名
tachyon.underfs.glusterfs.mapred.system.dir：如果使用GlusterFS为底层文件系统，GlusterFS用于存放MapReduce中间数据的可选子目录，默认为glusterfs:///mapred/system
tachyon.web.resources：Tachyon WebUI可用的资源，默认为$tachyon.home/core/src/main/webapp
tachyon.async.enabled：是否启用异步模式，默认为false
tachyon.underfs.hadoop.prefixes：底层使用hadoop文件系统的前缀列表，默认为”hdfs://”，”s3://”，”s3n://”，”glusterfs:///”
tachyon.test.mode：是否启用测试模式，默认为false
tachyon.master.retry：连接重试次数，默认为29&lt;/p&gt;

&lt;p&gt;2.3 TachyonMaster配置
tachyon.master.worker.timeout.ms：TachyonMaster和TachyonWorker心跳包失效时长，默认为60000ms
tachyon.master.journal.folder：TachyonMaster的journal日志存放路径，默认为$TACHYON_HOME/journal/
tachyon.master.hostname：TachyonMaster的主机名
tachyon.master.port：TachyonMaster的远程调用通讯端口，默认为19998
tachyon.master.web.port：TachyonMaster的WebUI端口，默认为19999
tachyon.master.web.threads：TachyonMaster的WebUI线程数，默认为9
tachyon.master.whitelist：可缓存的路径前缀列表，列表以逗号隔开，表示该路径下的文件能够被缓存至内存，默认为/，即根目录
tachyon.master.temporary.folder：TachyonMaster的临时文件夹，默认为/tmp
tachyon.master.heartbeat.interval.ms：TachyonMaster心跳包间隔时间，默认为1000ms
tachyon.master.selector.threads：TachyonMaster的thrift监听线程数，默认为3
tachyon.master.queue.size.per.selector：TachyonMaster的thrift消息队列长度，默认为3000
tachyon.master.server.threads：TachyonMaster节点的thrift服务线程数，默认为CPU核数的2倍
tachyon.master.pinlist：常驻内存的文件列表，以逗号隔开，表示该路径下的文件不会从内存中剔除，默认为null
2.4 TachyonWorker配置
tachyon.worker.data.folder：TachyonWorker在RamFS中的工作路径，默认为$TACHYON_RAM_FOLDER/tachyonworker/
tachyon.work.port：TachyonWorker的远程调用通讯端口，默认为29998
tachyon.worker.data.port：TachyonWorker的数据传输服务的端口，默认为29999
tachyon.worker.memory.size：TachyonWorker所使用的RamFS大小，默认为$TACHYON_WORKER_MEMORY_SIZE
tachyon.worker.heartbeat.timeout.ms：TachyonWorker心跳包失效的时长，默认为10000ms
tachyon.worker.to.master.heartbeat.interval.ms：TachyonWorker向TachyonMaster发送心跳包的时间间隔，默认为1000ms
tachyon.worker.selector.threads：TachyonWorker的thrift监听线程数，默认为3
tachyon.worker.queue.size.per.selector：TachyonWorker的thrift消息队列长度，默认为3000
tachyon.worker.server.threads：TachyonWorker的thrift服务线程数，默认为CPU核数
tachyon.worker.user.timeout.ms：TachyonWorker和用户之间心跳包失效时长，默认为10000ms
tachyon.worker.checkpoint.threads：TachyonWorker的checkpoint线程数，默认为1
tachyon.worker.per.thread.checkpoint.cap.mb.sec：TachyonWorker的checkpoint的速度，默认为1000MB/s
tachyon.worker.network.type：TachyonWorker在传输文件数据时使用的传输方式，默认为NETTY，可选为NIO或NETTY
2.5 用户配置
tachyon.user.failed.space.request.limits：用户向文件系统请求空间失败时的最大重试次数,默认为3
tachyon.user.quota.unit.bytes：客用户一次向TachyonWorker请求的最少字节数，默认为8388608，即8MB
tachyon.user.file.buffer.byte：用户读写文件时的缓存区大小，默认为1048576，即1MB
tachyon.user.default.block.size.byte：用户创建文件时的默认块大小，默认为1073741824，即1GB
tachyon.user.remote.read.buffer.size.byte：用户读远程文件时的缓冲区大小，默认为1048576，即1MB
tachyon.user.heartbeat.interval.ms：用户心跳包时间间隔，默认为1000ms
tachyon.user.file.writetype.default：用户在使用tachyon.hadoop.TFS时的默认写类型，默认为CACHE_THROUGH&lt;/p&gt;
&lt;ol&gt;
  &lt;li&gt;Tachyon的使用
受益于Tachyon良好的设计和兼用性，用户可以很方便地将现有的利用HDFS进行存储的程序移植至Tachyon。同时，Tachyon也提供了自己的命令行工具和一套完整的文件系统API，用户可以灵活地使用Tachyon。&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;3.1 从HDFS到Tachyon
对于现有的运行在Hadoop MapReduce或者Spark上，使用 “hdfs://ip:port/” 为存储路径的程序，能够很方便地移植至Tachyon。&lt;/p&gt;

&lt;p&gt;3.1.1 Hadoop MapReduce
将tachyon-client jar包添加至$HADOOP_CLASSPATH，jar包位于 tachyon/client/target/tachyon-client-0.6.0-SNAPSHOT-jar-with-dependencies.jar（如果是Tachyon-0.5.0，则文件名为tachyon-client-0.5.0-jar-with-dependencies.jar）
添加配置项&amp;lt;”fs.tachyon.impl”, ” tachyon.hadoop.TFS”&amp;gt;，可以在core-site.xml文件中添加，也可以在程序中使用Configuration.set()方法添加
将原有的”hdfs://ip:port/path”路径更改为”tachyon://ip:port/path”
3.1.2 Spark
同样地，添加依赖包，添加配置项，然后更改文件系统路径。&lt;/p&gt;

&lt;p&gt;额外地，添加配置项&amp;lt;”spark.tachyonStore.url”, “tachyon://ip:port/”&amp;gt;后，能够使用”rdd.persist(StorageLevel.OFF_HEAP)”语句将Spark RDD缓存至Tachyon中以减少Java GC的开销。&lt;/p&gt;

&lt;p&gt;3.2 命令行工具
Tachyon提供了命令行工具为用户提供了简单的交互功能，使用方式为&lt;/p&gt;

&lt;p&gt;1
bin/tachyon tfs [COMMAND]
具体的命令有：&lt;/p&gt;

&lt;p&gt;cat：将文件内容输出到控制台
count：输出符合路径前缀的文件总数
ls：输出目录中的文件信息
lsr：递归输出目录中的文件信息
mkdir：创建指定目录包括路径中的父目录，如果目录已经存在则创建失败
rm：删除文件或者目录
tail：将文件的最末1KB输出到控制台
touch：在指定的位置创建空的文件
mv：将文件移动到指定位置
copyFromLocal：将文件从本地文件系统拷贝到Tachyon文件系统指定位置
copyToLocal：将文件从Tachyon文件系统拷贝到本地文件系统指定位置
fileinfo：打印指定文件的块信息
pin：将指定文件常驻内存
unpin：将常驻内存的文件撤销常驻状态
3.3 Java API
Tachyon是用Java开发实现的，因此提供的API也是Java函数。要使用这些API需要依赖tachyon-client jar包，位于 tachyon/client/target/tachyon-client-0.6.0-SNAPSHOT-jar-with-dependencies.jar （如果是Tachyon-0.5.0，则文件名为tachyon-client-0.5.0-jar-with-dependencies.jar）此外，如果是已发布的Tachyon-0.5.0并且目标项目由Maven管理，可以在 pom.xml 文件中添加如下内容以获取依赖包：&lt;/p&gt;
&lt;dependency&gt;
          &lt;groupId&gt;org.tachyonproject&lt;/groupId&gt;
          &lt;artifactId&gt;tachyon-client&lt;/artifactId&gt;
          &lt;version&gt;0.5.0&lt;/version&gt;
 &lt;/dependency&gt;
&lt;p&gt;（Tachyon-0.5.0和Tachyon-0.6.0-SNAPSHOT提供的Java API一大不同之处在于Tachyon-0.6.0-SNAPSHOT中新增了tachyon.TachyonURI类，用来表示Tachyon文件系统中的路径，类似于Hadoop中的org.apache.hadoop.fs.Path。Tachyon-0.5.0中的大部分API在Tachyon-0.6.0-SNAPSHOT中仍然存在，但被标记为@Deprecated）&lt;/p&gt;

&lt;p&gt;Tachyon的Java API功能大部分集中于tachyon.client.TachyonFS和tachyon.client.TachyonFile两个类中&lt;/p&gt;

</description>
        <pubDate>Sat, 10 Feb 2018 00:00:00 +0800</pubDate>
        <link>https://xiazemin.github.io/MyBlog/spark/2018/02/10/Tachyon.html</link>
        <guid isPermaLink="true">https://xiazemin.github.io/MyBlog/spark/2018/02/10/Tachyon.html</guid>
        
        
        <category>spark</category>
        
      </item>
    
      <item>
        <title>crlf 攻击</title>
        <description>&lt;p&gt;CRLF Injection很少遇见，这次被我逮住了。我看zone中（http://zone.wooyun.org/content/13323）还有一些同学对于这个漏洞不甚了解，甚至分不清它与CSRF，我详细说一下吧。&lt;/p&gt;

&lt;p&gt;CRLF是”回车 + 换行”（\r\n）的简称。在HTTP协议中，HTTP Header与HTTP Body是用两个CRLF分隔的，浏览器就是根据这两个CRLF来取出HTTP 内容并显示出来。所以，一旦我们能够控制HTTP 消息头中的字符，注入一些恶意的换行，这样我们就能注入一些会话Cookie或者HTML代码，所以CRLF Injection又叫HTTP Response Splitting，简称HRS。&lt;/p&gt;

&lt;p&gt;HRS是比XSS危害更大的安全问题，具体是为什么，我们往下看。&lt;/p&gt;

&lt;p&gt;对于HRS最简单的利用方式是注入两个\r\n，之后在写入XSS代码，来构造一个xss。&lt;/p&gt;

&lt;p&gt;举个例子，一般网站会在HTTP头中用Location: http://baidu.com这种方式来进行302跳转，所以我们能控制的内容就是Location:后面的XXX某个网址。&lt;/p&gt;

&lt;p&gt;所以一个正常的302跳转包是这样：&lt;/p&gt;

&lt;p&gt;HTTP/1.1 302 Moved Temporarily 
Date: Fri, 27 Jun 2014 17:52:17 GMT 
Content-Type: text/html 
Content-Length: 154 
Connection: close 
Location: http://www.sina.com.cn
但如果我们输入的是&lt;/p&gt;

&lt;p&gt;http://www.sina.com.cn%0aSet-cookie:JSPSESSID%3Dwooyun
注入了一个换行，此时的返回包就会变成这样：&lt;/p&gt;

&lt;p&gt;HTTP/1.1 302 Moved Temporarily 
Date: Fri, 27 Jun 2014 17:52:17 GMT 
Content-Type: text/html 
Content-Length: 154 
Connection: close 
Location: http://www.sina.com.cn 
Set-cookie: JSPSESSID=wooyun
这个时候这样我们就给访问者设置了一个SESSION，造成一个“会话固定漏洞”。&lt;/p&gt;

&lt;p&gt;当然，HRS并不仅限于会话固定，通过注入两个CRLF就能造成一个无视浏览器Filter的反射型XSS。&lt;/p&gt;

&lt;p&gt;比如一个网站接受url参数http://test.sina.com.cn/?url=xxx，xxx放在Location后面作为一个跳转。如果我们输入的是：&lt;/p&gt;

&lt;p&gt;http://test.sina.com.cn/?url=%0d%0a%0d%0a&amp;lt;img src=1 onerror=alert(/xss/)&amp;gt;
我们的返回包就会变成这样：&lt;/p&gt;

&lt;p&gt;HTTP/1.1 302 Moved Temporarily 
Date: Fri, 27 Jun 2014 17:52:17 GMT 
Content-Type: text/html 
Content-Length: 154 
Connection: close 
Location:&lt;/p&gt;

&lt;p&gt;&amp;lt;img src=1 onerror=alert(/xss/)&amp;gt;
之前说了浏览器会根据第一个CRLF把HTTP包分成头和体，然后将体显示出来。于是我们这里&lt;img /&gt;这个标签就会显示出来，造成一个XSS。&lt;/p&gt;

&lt;p&gt;为什么说是无视浏览器filter的，这里涉及到另一个问题。&lt;/p&gt;

&lt;p&gt;浏览器的Filter是浏览器应对一些反射型XSS做的保护策略，当url中含有XSS相关特征的时候就会过滤掉不显示在页面中，所以不能触发XSS。&lt;/p&gt;

&lt;p&gt;怎样才能关掉filter？一般来说用户这边是不行的，只有数据包中http头含有X-XSS-Protection并且值为0的时候，浏览器才不会开启filter。&lt;/p&gt;

&lt;p&gt;说到这里应该就很清楚了，HRS不正是注入HTTP头的一个漏洞吗，我们可以将X-XSS-Protection:0注入到数据包中，再用两个CRLF来注入XSS代码，这样就成功地绕过了浏览器filter，并且执行我们的反射型XSS。&lt;/p&gt;

&lt;p&gt;所以说HRS的危害大于XSS，因为它能绕过一般XSS所绕不过的filter，并能产生会话固定漏洞。&lt;/p&gt;

&lt;p&gt;我们来一个真实案例吧。&lt;/p&gt;

&lt;p&gt;新浪某分站含有一个url跳转漏洞，危害并不大，于是我就想到了CRLF Injection，当我测试&lt;/p&gt;

&lt;p&gt;http://xxx.sina.com.cn/?url=%0a%0d%0a%0d%3Cimg%20src=1%3E
的时候，发现图片已经输出在页面中了，说明CRLF注入成功了：&lt;/p&gt;

&lt;p&gt;那么我们试试XSS看看：&lt;/p&gt;

&lt;p&gt;看控制台，果然被XSS Filter拦截了。&lt;/p&gt;

&lt;p&gt;那么我们就注入一个X-XSS-Protection:0到数据包中，看看什么效果：&lt;/p&gt;

&lt;p&gt;@mramydnei 还想到了一个利用字符编码来绕过XSS Filter的方法，当编码是is-2022-kr时浏览器会忽略%0f，这样我们在onerror后面加个%0f就能绕过filter，前提是注入一个&amp;lt;meta charset=ISO-2022-KR&amp;gt;：
当然，在Location:这里注入只有webkit内核浏览器才能够利用，其他浏览器可能会跳转、出错。不过对于chrome的使用量来说，危害已经足够了。&lt;/p&gt;

&lt;p&gt;如何修复HRS漏洞，当然是过滤\r 、\n之类的换行符，避免输入的数据污染到其他HTTP头。&lt;/p&gt;

</description>
        <pubDate>Tue, 06 Feb 2018 00:00:00 +0800</pubDate>
        <link>https://xiazemin.github.io/MyBlog/web/2018/02/06/crlf.html</link>
        <guid isPermaLink="true">https://xiazemin.github.io/MyBlog/web/2018/02/06/crlf.html</guid>
        
        
        <category>web</category>
        
      </item>
    
      <item>
        <title>iputils</title>
        <description>&lt;!-- more --&gt;
&lt;p&gt;1.1       iputils软件包简介
    iputils软件包是linux环境下一些实用的网络工具的集合。一开始由Alexey Kuznetsov维护。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;iputils包含以下几个工具：

1. ping。使用 ping可以测试计算机名和计算机的ip地址，验证与远程计算机的连接。ping程序由ping.c ping6.cping_common.c ping.h 文件构成

2. tracepath。与traceroute功能相似，使用tracepath测试IP数据报文从源主机传到目的主机经过的路由。tracepath程序由tracepath.c tracepath6.c traceroute6.c 文件构成。

3. arping。使用arping向目的主机发送ARP报文，通过目的主机的IP获得该主机的硬件地址。arping程序由arping.c文件构成。

4. tftpd。tftpd是简单文件传送协议TFTP的服务端程序。tftpd程序由tftp.h tftpd.c tftpsubs.c文件构成。

5. rarpd。rarpd是逆地址解析协议的服务端程序。rarpd程序由rarpd.c文件构成。

6. clockdiff。使用clockdiff可以测算目的主机和本地主机的系统时间差。clockdiff程序由clockdiff.c文件构成。

7. rdisc。rdisc是路由器发现守护程序。rdisc程序由rdisc.c文件构成。
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;1.2       本文简介
   本文是在对源程序的分析的过程中写的总结文档。本文将依次对软件包中的程序进行介绍。介绍主要按照如下几个方面进行：&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;1. 在前言中简要介绍程序的基本用途、基本原理等。这是对于软件包中各软件的基本认识的总结。

2. 在程序使用中介绍程序的使用方法、使用选项等。这是对于使用软件包中程序的使用方法的介绍。

3. 在程序流程图中给出程序的基本流程。流程图的优点是比较能直观地给出程序的功能实现的流程，方便对程序有全局的掌握。然而不可避免地，流程图隐去了诸多的实现细节，所以如果要进一步分析程序，还需要进一步深入细节。

4. 介绍全局变量的含义、用途、变化等。全局变量是在程序中任何地方都可以访问的变量，所以分析全局变量有助于理解程序的数据变化流程。

5. 对于重要函数的介绍。一些重要的函数，不仅在程序的实现上占有重要的作用，而且理解起来有一定的难度，我觉得有必要进行分析。

6. 对于牵涉到的网络协议的介绍。阅读iputils源码的目的和好处之一就是帮助进一步理解网络协议。iputils涉及到IP、UDP、 ARP、RARP、ICMP、TFTP等不同层次的网络协议。本文将给出网络协议的基本介绍，主要是给出了网络报文的格式等内容。

7. 对于程序中重要的实现方法的介绍。而在iputils源码分析中，遇到了很多计算机网络方面的概念、思想、策略和机制。结合iputils的具体实现方法，本文将介绍计算机网络方面的相关知识。
&lt;/code&gt;&lt;/pre&gt;

&lt;ol&gt;
  &lt;li&gt;对其他知识的介绍，例如基于linux的多线程编程或linux下socket编程的知识。在分析源码的过程中，不可回避地遇到了这些知识的使用。
1.3       附件说明&lt;/li&gt;
&lt;/ol&gt;

&lt;pre&gt;&lt;code&gt;本文基于的源码版本为iputils-s20071127。源代码可以在http://www.linux-ipv6.org/gitweb/gitweb.cgi?p=gitroot/iputils.git中下载。

在阅读和分析源代码过程中，对代码进行了大量的注释，附件可以在下载http://download.csdn.net/detail/fsdev/4498604。

为了能够编译通过，定义了rdisc.c需要使用但是源代码中没有定义的宏：

#define OPEN_MAX   10

这个宏的意义是程序所能够打开的最大的文件数目。rdisc程序在退到后台之后，需要关闭除了socket文件之外的所有文件，OPEN_MAX宏就是在这里使用的。为了能够输出测试信息，并尽量不修改原程序代码，定义宏：

#define lixiprintf printf

所有添加输出信息的部分都使用lixiprintf宏。除了加入注释和以上两个更改外，没有修改程序其他地方。
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;2.1       引言
   “ping”这个名字源于声纳定位操作。Ping程序由Mike Muuss编写，目的是为了测试另一台主机是否可达。该程序发送一份ICMP回显请求报文给主机，并等待返回ICMP回显应答。&lt;/p&gt;

&lt;p&gt;2.2       ping程序的使用
    敲入命令：&lt;/p&gt;

&lt;p&gt;[plain] view plain copy
lixi@lixi-desktop:~$ ping -V&lt;br /&gt;
ping utility, iputils-sss20071127&lt;br /&gt;
    说明本机中安装的ping程序和本文研究的ping程序一样，是最新版本。&lt;/p&gt;

&lt;p&gt;[plain] view plain copy
lixi@lixi-desktop:~$ ping -T tsonly www.ustc.edu.cn -c 1&lt;br /&gt;
PING www.ustc.edu.cn (202.38.64.9) 56(124) bytes of data.&lt;br /&gt;
64 bytes from 202.38.64.9: icmp_seq=1 ttl=62 time=0.795 ms&lt;br /&gt;
TS:     6123570 absolute&lt;br /&gt;
    493&lt;br /&gt;
    364&lt;br /&gt;
    -857378&lt;br /&gt;
    0&lt;br /&gt;
    857378&lt;br /&gt;
    -363&lt;br /&gt;
    -493&lt;/p&gt;

&lt;p&gt;— www.ustc.edu.cn ping statistics —&lt;br /&gt;
1 packets transmitted, 1 received, 0% packet loss, time 0ms&lt;br /&gt;
rtt min/avg/max/mdev = 0.795/0.795/0.795/0.000 ms&lt;br /&gt;
    6123570是时间戳的绝对值，而输出的其他时间戳是相对上一个时间戳的差别。在北京时间9：42做的测试，北京时区为UTC+8，故此有9＋42/60-8=1.7&lt;/p&gt;

&lt;p&gt;而6123570/60/60/1000＝1.7。故此出现这个结果是非常有道理的。&lt;/p&gt;

&lt;p&gt;[plain] view plain copy
lixi@lixi-desktop:~$ ping www.ustc.edu.cn -R -c 1&lt;br /&gt;
PING www.ustc.edu.cn (202.38.64.9) 56(124) bytes of data.&lt;br /&gt;
64 bytes from 202.38.64.9: icmp_seq=1 ttl=62 time=0.852 ms&lt;br /&gt;
RR:     lixi-desktop.local (210.45.74.25)&lt;br /&gt;
    202.38.96.36&lt;br /&gt;
    local-gw.ustc.edu.cn (202.38.64.126)&lt;br /&gt;
    202.38.64.9&lt;br /&gt;
    202.38.64.9&lt;br /&gt;
    202.38.96.33&lt;br /&gt;
    210.45.74.1&lt;br /&gt;
    lixi-desktop.local (210.45.74.25)&lt;br /&gt;
    对照上面的路由信息，我们就可以分析出为什么时间戳信息里会有对称的现象，而对称轴的值是0了。&lt;/p&gt;

&lt;p&gt;产生对称性的另一个条件是RTT很小，这里只有0.8ms。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;我们可以还可以分析出202.38.64.9的系统时间和其他路由的系统时间相差很大，大约有-14分钟。
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;[plain] view plain copy
lixi@lixi-desktop:~$ ping -T tsandaddr www.ustc.edu.cn -c 1&lt;br /&gt;
PING www.ustc.edu.cn (202.38.64.9) 56(124) bytes of data.&lt;br /&gt;
64 bytes from 202.38.64.9: icmp_seq=1 ttl=62 time=1.66 ms&lt;br /&gt;
TS:     lixi-desktop.local (210.45.74.25)   7375300 absolute&lt;br /&gt;
    210.45.74.1 828&lt;br /&gt;
    local-gw.ustc.edu.cn (202.38.64.126)    26&lt;br /&gt;
    202.38.64.9 -857405&lt;br /&gt;
Unrecorded hops: 3&lt;/p&gt;

&lt;p&gt;— www.ustc.edu.cn ping statistics —&lt;br /&gt;
1 packets transmitted, 1 received, 0% packet loss, time 0ms&lt;br /&gt;
rtt min/avg/max/mdev = 1.664/1.664/1.664/0.000 ms&lt;br /&gt;
   上面是同时记录路由和时间戳信息。不过这里由于IP选项长度的限制，只能存储4个路由和它对应的时间戳。
[plain] view plain copy
lixi@lixi-desktop:~$ ping -T tsprespec 202.38.64.9 202.38.96.33 210.45.74.1 www.ustc.edu.cn -c 1&lt;br /&gt;
PING www.ustc.edu.cn (202.38.64.9) 56(124) bytes of data.&lt;br /&gt;
64 bytes from 202.38.64.9: icmp_seq=1 ttl=62 time=0.893 ms&lt;br /&gt;
TS:     202.38.64.9 6741320 absolute&lt;br /&gt;
    202.38.96.33    0&lt;br /&gt;
    210.45.74.1 857353&lt;br /&gt;
Unrecorded hops: 1&lt;/p&gt;

&lt;p&gt;— www.ustc.edu.cn ping statistics —&lt;br /&gt;
1 packets transmitted, 1 received, 0% packet loss, time 0ms&lt;br /&gt;
rtt min/avg/max/mdev = 0.893/0.893/0.893/0.000 ms&lt;br /&gt;
    如果我们一定要得到以后的几个路由和时间戳，我们可以采用上述的办法。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;这里在北京时间10：07分的时候进行的测试，202.38.64.9的时间戳是6741320，而我们上面的分析，202.38.64.9的系统时间大约比北京时间晚14分钟。10-8-14/60=1.87。6741320/60/60/1000=1.87。故此出现这个时间戳也是很有道理的。

ping程序的选项解释如下：

-a   

    可听见的ping。

    所谓可听见,不过是在ping.c文件的parse_reply的函数中,输出ASCII码'/a',beep一下。
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;-A&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;    自适应的ping。调整报文间隔时间，使其适应于RTT，这样非常有效率地使得网络中传输的不超过一个（如果-l参数设置了就为多个）。对于非超级用户，最小的时间间隔为200毫秒，在一个RTT比较得下的网络中，这个模式和-f的洪泛模式基本相同。

    为了调整报文时间间隔,使用update_interval()函数来调整时间间隔。

-b

    允许ping广播地址。

    设置broadcast_pings为1，当判断到这个选项设为1之后，且地址是广播地址，那么就设置setsockopt(icmp_sock, SOL_SOCKET, SO_BROADCAST,&amp;amp;broadcast_pings, sizeof(broadcast_pings))。

-B

    不允许ping改变报文的源主机地址，该地址在ping开始运行的时候就已经指定了。

    为了指定源主机地址,ping.c使用函数bind()来把套接字和本地套接字地址绑定，即在已创建的套接字上加上本地套接字地址。

-c &amp;lt;count&amp;gt;

    在发送&amp;lt;count&amp;gt;个ECHO_REQUEST报文。当和-w &amp;lt;deadline&amp;gt;一起设置时，ping等待收到&amp;lt;count&amp;gt;个ECHO_REPLY报文，直到超出时间限制为止。

    设置npackets选项为&amp;lt;count&amp;gt;就可以了。在没有设置deadline的情况下，当nreceived + nerrors &amp;gt;=npackets时就可以退出循环，完成ping的任务了。

-d

    设置socket中的SO_DEBUG选项，使能调试跟踪。实质上Linux内核中没有使用这个套接字选项。

    设置方法：setsockopt(icmp_sock,SOL_SOCKET, SO_DEBUG, (char *)&amp;amp;hold, sizeof(hold));

-F &amp;lt;flow&amp;gt; &amp;lt;label&amp;gt;

   这个选项只有ping6才有。

-f

  洪泛模式。对每一个ECHO_REQUEST报文的发送，打印一个“.”，当接受到ECHO_REPLY报文时，打印一个backspace字符。这样能够快速地表明网络丢失了多少个报文。如果interval没有设置，则设置interval为0，并按照报文接受的速度和一百次每秒的速度来发送报文（看哪个速度快）。只有超级用户能够和-i 0选项一起使用这个选项。

-i &amp;lt;interval&amp;gt;

   在发送每个报文之间等待&amp;lt;interval&amp;gt;秒。默认设置是等待一秒，在洪泛模式下则不等待。只有超级用户才能将&amp;lt;interval&amp;gt;设置为小于0.2秒的数。

   interval为&amp;lt;interval&amp;gt;*1000，程序的实现决定了&amp;lt;interval&amp;gt;输入整型数和浮点数都能被正确接受。

-I &amp;lt;interface/address&amp;gt;

    设置发送的地址或者网络设备。

    程序首先尝试用intinet_pton(int af, const char *src, void *dst)函数由将src代表的字符串转化为dst中的IP地址。如果不能正确转换，则意味着这个选项不是地址，例如210.45.74.25，而是设备名如eth0。如果是后者，则设置device为&amp;lt;interface&amp;gt;，并用bind(icmp_sock, (structsockaddr*)&amp;amp;source, sizeof(source))      setsockopt(probe_fd,SOL_SOCKET, SO_BINDTODEVICE, device, strlen(device)+1)来将套接字和本地套接字地址进行绑定。

-l &amp;lt;preload&amp;gt;

    &amp;lt;preload&amp;gt;是在没有接受到回复报文之前能发送的最多报文。非超级用户最多只能设置为3。

    尽可能快地发送预载的报文，然后再返回到正常发送模式。

    将&amp;lt;preload&amp;gt;值赋到preload变量中。如果不赋值preload默认为1。

-L

    禁止多播数据包的回环，只有在ping的目的主机是广播地址时才管用。

-n

    只有数字形式ip地址值的输出，不通过查询DNS获知IP地址对应的主机名，以节省时间。

    设置F_NUMERIC，不用调用gethostbyaddr来查询DNS主机名了。

    用gethostbyaddr的由查询目的主机的IP地址。

-p &amp;lt;pattern&amp;gt;

    允许为传输的回显报文中包含的内容指定字节模式。这对于诊断与传输数据有关的网络问题可能很有用。数据采用16进制，例如“-p ff”可将传输的报文填充为全1。

-Q &amp;lt;tos&amp;gt;

    用来设置服务质量（Quality of Service ）

    例如最小开销、 可靠性、吞吐量、低延迟。

    IP协议有一个8bit的DS区分服务（以前叫服务类型）。前三位是优先（precedence）字段（在目前，优先字段并未被大家使用），接着4bit是TOS位，最后1bit没有使用，但必须置0。

    4比特TOS位的意义分别为D（最小时延）、T（最大吞吐量）、R（最高可靠性）、C（最小代价）。要设置TOS位为对应意义，可以设置-Q &amp;lt;tos&amp;gt;分别为0x10，0x08，0x04，0x02。TOS的各个位不能同时置1。

-q

    静默模式。这种模式下，出了开始的提示和结束的数据统计，不会输出任何东西。

-R

    记录路由信息。在发送的IP报文首部选项中放入记录路由选项，在接到到报文回复之后，打印出回复报文的路由信息。

    注意：IP报文的选项中最多只能计算9个路由信息，计算方式如下：

    首部长度HLEN。这4bit字段用来定义首部的长度，以4字节为单位。由于首部长度可变，默认长度是20字节，此时4bit字段值为5。4bit的字段最大可以表示的数为15，故此首部长度最大为15*4byte，即60byte。首部的可变字节数为60-20＝40byte，RR选项用去3byte（参见记录路由选项的一般格式），只剩下37byte，最多只能放下9个IP地址。

    注意：很多的主机会略过IP报文的路由选项，因此有可能在回复报文中没有路由信息。

    注意：不能和-T选项一起使用。

-r

    绕过一般的路由表而直接向一个连接着的主机发送报文。如果主机不是通过直接连接的网络相连，则会出现错误。这个选项可以用来ping一个没有通过路由相连而是通过一个接口相连（假设也使用了-I选项）的本地主机。

    使用setsockopt函数设置套接字的SOL_SOCKET级别的SO_DONTROUTE选项即可。

-s &amp;lt;packetsize&amp;gt;

    设置ICMP报文的数据部分的长度。默认值是56，和ICMP首部的8字节一起作为IP报文的数据部分。

    设置datalen变量就可以了，datalen默认为DEFDATALEN（值是56）。长度为datalen的数据和8字节的首部一起作为ICMP报文。

-S &amp;lt;sndbuf&amp;gt;

    设置套接字的发送缓冲区大小。如果没有设置，则被设定为不超过一个报文长度的长度。

-t &amp;lt;ttl&amp;gt;

    设置TTL（time to live）。

    使用setsockopt函数设置套接字的IPPROTO_IP级别的IP_MULTICAST_TTL和IP_TTL选项即可。

-T &amp;lt;timestamp&amp;gt; &amp;lt;option&amp;gt;

    设置IP时间戳选项。时间戳选项可以是以下三种：

    -T tsonly 只记录时间戳。

    -T tsandaddr 收集时间戳和IP地址。

    -T tsprespec [host1 [host2 [host3[host4]]]] 收集来自预定的网络段的时间戳和地址，发送端对选项列表进行初始化，存放了4个IP地址和四个取值为0的时间戳。只有在列表中的下一个地址和当前路由地址相匹配时，才记录它的时间戳。

    与-R选项的分析类似，首部的可变字节数为60-20＝40byte，选项用去4byte（参见时间戳选项的一般格式），只剩下36byte，最多只能放下9个时间戳。

    注意：由于IP首部的空间限制，程序限制-R选项与-T不能同时使用。

-M &amp;lt;hint&amp;gt;

    设定Path MTU查找选下项，可设置成下列三种：

    -M do 不允许分段，甚至不允许在本地分段。

    -M want 找出PMTU，在如果包太大就在本地分段。

    -M dont 不要设置IP首部中的DF位，即允许分段。

    使用setsockopt函数设置套接字的SOL_IP级别的IP_MTU_DISCOVER选项即可。

-U

-v

   冗余输出。输出很多具体信息。

-V

    打印ping的版本，然后退出。

-w &amp;lt;deadline&amp;gt;

    设定时间期限为&amp;lt;deadline&amp;gt;秒，不管已经发送和接到了多少包，只要达到时间期限就结束ping的过程。

-W &amp;lt;timeout&amp;gt;

    等待回复的时间，单位是秒。这个选项只在没有接到任何的回复的情况下有效，只要接到了一个回复，就将等待时间设置为两倍的RTT。如果没有设置，则等待时间设置为一个最大值。
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;2.3       ping程序的流程图
    ping程序的流程图如下所示：&lt;/p&gt;

&lt;p&gt;2.4       IP报文结构
    IP报文结构如下所示：&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;IP数据报文的首部中有选项部分，这个部分可以用来存储IP时间戳或者IP记录路由选项。

存储IP时间戳，如下图所示：

 

IP记录路由选项，如下图所示：
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;2.5       ICMP报文结构
    ICMP的封装方式如下图所示：&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;ICMP报文的结构如下图所示：
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;2.6       ICMP回显请求和回显应答报文格式
    ICMP回显请求和回显应答报文格式如下所示：&lt;/p&gt;

&lt;p&gt;2.7       ICMP报文类型列表
    不同种类的ICMP报文的首部有所不同。如下：&lt;/p&gt;

&lt;p&gt;类型&lt;/p&gt;

&lt;p&gt;代码&lt;/p&gt;

&lt;p&gt;描述&lt;/p&gt;

&lt;p&gt;0&lt;/p&gt;

&lt;p&gt;ICMP_ECHOREPLY&lt;/p&gt;

&lt;p&gt;0&lt;/p&gt;

&lt;p&gt;回显应答&lt;/p&gt;

&lt;p&gt;3&lt;/p&gt;

&lt;p&gt;ICMP_DEST_UNREACH&lt;/p&gt;

&lt;p&gt;目的不可达&lt;/p&gt;

&lt;p&gt;0&lt;/p&gt;

&lt;p&gt;ICMP_NET_UNREACH&lt;/p&gt;

&lt;p&gt;网络不可达&lt;/p&gt;

&lt;p&gt;1&lt;/p&gt;

&lt;p&gt;ICMP_HOST_UNREACH&lt;/p&gt;

&lt;p&gt;主机不可达&lt;/p&gt;

&lt;p&gt;2&lt;/p&gt;

&lt;p&gt;ICMP_PROT_UNREACH&lt;/p&gt;

&lt;p&gt;端口不可达&lt;/p&gt;

&lt;p&gt;3&lt;/p&gt;

&lt;p&gt;ICMP_PORT_UNREACH&lt;/p&gt;

&lt;p&gt;协议不可达&lt;/p&gt;

&lt;p&gt;4&lt;/p&gt;

&lt;p&gt;ICMP_FRAG_NEEDED&lt;/p&gt;

&lt;p&gt;需要进行分片单设置了不分片比特&lt;/p&gt;

&lt;p&gt;5&lt;/p&gt;

&lt;p&gt;ICMP_SR_FAILED&lt;/p&gt;

&lt;p&gt;源站选路失败&lt;/p&gt;

&lt;p&gt;6&lt;/p&gt;

&lt;p&gt;ICMP_NET_UNKNOWN&lt;/p&gt;

&lt;p&gt;目的网络不认识&lt;/p&gt;

&lt;p&gt;7&lt;/p&gt;

&lt;p&gt;ICMP_HOST_UNKNOWN&lt;/p&gt;

&lt;p&gt;目的主机不认识&lt;/p&gt;

&lt;p&gt;8&lt;/p&gt;

&lt;p&gt;ICMP_HOST_ISOLATED&lt;/p&gt;

&lt;p&gt;源主机被隔离（作废不用）&lt;/p&gt;

&lt;p&gt;9&lt;/p&gt;

&lt;p&gt;ICMP_NET_ANO&lt;/p&gt;

&lt;p&gt;目的网络被强制禁止&lt;/p&gt;

&lt;p&gt;10&lt;/p&gt;

&lt;p&gt;ICMP_HOST_ANO&lt;/p&gt;

&lt;p&gt;目的主机被强制禁止&lt;/p&gt;

&lt;p&gt;11&lt;/p&gt;

&lt;p&gt;ICMP_NET_UNR_TOS&lt;/p&gt;

&lt;p&gt;由于服务类型TOS，网络不可达&lt;/p&gt;

&lt;p&gt;12&lt;/p&gt;

&lt;p&gt;ICMP_HOST_UNR_TOS&lt;/p&gt;

&lt;p&gt;由于服务类型TOS，主机不可达&lt;/p&gt;

&lt;p&gt;13&lt;/p&gt;

&lt;p&gt;ICMP_PKT_FILTERED&lt;/p&gt;

&lt;p&gt;由于过滤，通信被强制禁止&lt;/p&gt;

&lt;p&gt;14&lt;/p&gt;

&lt;p&gt;ICMP_PREC_VIOLATION&lt;/p&gt;

&lt;p&gt;主机越权&lt;/p&gt;

&lt;p&gt;15&lt;/p&gt;

&lt;p&gt;ICMP_PREC_CUTOFF&lt;/p&gt;

&lt;p&gt;优先权终止生效&lt;/p&gt;

&lt;p&gt;ICMP_SOURCE_QUENCH&lt;/p&gt;

&lt;p&gt;4&lt;/p&gt;

&lt;p&gt;0&lt;/p&gt;

&lt;p&gt;源端被关闭&lt;/p&gt;

&lt;p&gt;ICMP_REDIRECT&lt;/p&gt;

&lt;p&gt;5&lt;/p&gt;

&lt;p&gt;重定向&lt;/p&gt;

&lt;p&gt;0&lt;/p&gt;

&lt;p&gt;ICMP_REDIR_NET&lt;/p&gt;

&lt;p&gt;对网络重定向&lt;/p&gt;

&lt;p&gt;1&lt;/p&gt;

&lt;p&gt;ICMP_REDIR_HOST&lt;/p&gt;

&lt;p&gt;对主机重定向&lt;/p&gt;

&lt;p&gt;2&lt;/p&gt;

&lt;p&gt;ICMP_REDIR_NETTOS&lt;/p&gt;

&lt;p&gt;对服务类型和网络重定向&lt;/p&gt;

&lt;p&gt;3&lt;/p&gt;

&lt;p&gt;ICMP_REDIR_HOSTTOS&lt;/p&gt;

&lt;p&gt;对服务类型和主机重定向&lt;/p&gt;

&lt;p&gt;ICMP_ECHO&lt;/p&gt;

&lt;p&gt;8&lt;/p&gt;

&lt;p&gt;0&lt;/p&gt;

&lt;p&gt;请求回显&lt;/p&gt;

&lt;p&gt;9&lt;/p&gt;

&lt;p&gt;0&lt;/p&gt;

&lt;p&gt;路由器通告&lt;/p&gt;

&lt;p&gt;10&lt;/p&gt;

&lt;p&gt;0&lt;/p&gt;

&lt;p&gt;路由器请求&lt;/p&gt;

&lt;p&gt;ICMP_TIME_EXCEEDED&lt;/p&gt;

&lt;p&gt;11&lt;/p&gt;

&lt;p&gt;超时&lt;/p&gt;

&lt;p&gt;0&lt;/p&gt;

&lt;p&gt;ICMP_EXC_TTL&lt;/p&gt;

&lt;p&gt;传输请见生存时间为0&lt;/p&gt;

&lt;p&gt;1&lt;/p&gt;

&lt;p&gt;ICMP_EXC_FRAGTIME&lt;/p&gt;

&lt;p&gt;在数据包组装期间生存时间为0&lt;/p&gt;

&lt;p&gt;ICMP_PARAMETERPROB&lt;/p&gt;

&lt;p&gt;12&lt;/p&gt;

&lt;p&gt;参数问题&lt;/p&gt;

&lt;p&gt;0&lt;/p&gt;

&lt;p&gt;坏的IP首部&lt;/p&gt;

&lt;p&gt;1&lt;/p&gt;

&lt;p&gt;缺少必需的选项&lt;/p&gt;

&lt;p&gt;ICMP_TIMESTAMP&lt;/p&gt;

&lt;p&gt;13&lt;/p&gt;

&lt;p&gt;0&lt;/p&gt;

&lt;p&gt;时间戳请求&lt;/p&gt;

&lt;p&gt;ICMP_TIMESTAMPREPLY&lt;/p&gt;

&lt;p&gt;14&lt;/p&gt;

&lt;p&gt;0&lt;/p&gt;

&lt;p&gt;时间戳应答&lt;/p&gt;

&lt;p&gt;ICMP_INFO_REQUEST&lt;/p&gt;

&lt;p&gt;15&lt;/p&gt;

&lt;p&gt;0&lt;/p&gt;

&lt;p&gt;信息请求&lt;/p&gt;

&lt;p&gt;ICMP_INFO_REPLY&lt;/p&gt;

&lt;p&gt;16&lt;/p&gt;

&lt;p&gt;0&lt;/p&gt;

&lt;p&gt;信息应答&lt;/p&gt;

&lt;p&gt;ICMP_ADDRESS&lt;/p&gt;

&lt;p&gt;17&lt;/p&gt;

&lt;p&gt;0&lt;/p&gt;

&lt;p&gt;地址掩码请求&lt;/p&gt;

&lt;p&gt;ICMP_ADDRESSREPLY&lt;/p&gt;

&lt;p&gt;18&lt;/p&gt;

&lt;p&gt;0&lt;/p&gt;

&lt;p&gt;地址掩码应答&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;pr_icmph()函数中分析ICMP报文类型，并针对错误报文打印出出错问题。惨照上表就能比较好地分析各种问题出现的大致原因了。

另外在rdisc.c文件中使用了ICMP的路由器通告报文（类型为9）和ICMP路由器请求报文（类型为10）。

各种ICMP类型和代码的常量定义在linux-2.6.27/include/linux/icmp.h文件中。
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;2.8       socket选项
    程序中使用setsockopt()函数设定了套接字的选项。用到的选项如下：&lt;/p&gt;

&lt;p&gt;level（级别）&lt;/p&gt;

&lt;p&gt;optname（选项名）&lt;/p&gt;

&lt;p&gt;说明&lt;/p&gt;

&lt;p&gt;标志&lt;/p&gt;

&lt;p&gt;SOL_SOCKET&lt;/p&gt;

&lt;p&gt;SO_BROADCAST&lt;/p&gt;

&lt;p&gt;允许或禁止发送广播数据&lt;/p&gt;

&lt;p&gt;Ö&lt;/p&gt;

&lt;p&gt;SO_ATTACH_FILTER&lt;/p&gt;

&lt;p&gt;安装过滤器。&lt;/p&gt;

&lt;p&gt;SO_SNDBUF&lt;/p&gt;

&lt;p&gt;设置发送缓冲区的大小。&lt;/p&gt;

&lt;p&gt;SO_RCVBUF&lt;/p&gt;

&lt;p&gt;设置接收缓冲区的大小。&lt;/p&gt;

&lt;p&gt;SO_DEBUG&lt;/p&gt;

&lt;p&gt;打开或关闭调试信息&lt;/p&gt;

&lt;p&gt;Ö&lt;/p&gt;

&lt;p&gt;SO_DONTROUTE&lt;/p&gt;

&lt;p&gt;打开或关闭路由查找功能。&lt;/p&gt;

&lt;p&gt;Ö&lt;/p&gt;

&lt;p&gt;SO_TIMESTAMP&lt;/p&gt;

&lt;p&gt;打开或关闭数据报中的时间戳接收。&lt;/p&gt;

&lt;p&gt;Ö&lt;/p&gt;

&lt;p&gt;SO_SNDTIMEO&lt;/p&gt;

&lt;p&gt;设置发送超时时间。&lt;/p&gt;

&lt;p&gt;SO_RCVTIMEO&lt;/p&gt;

&lt;p&gt;设置接收超时时间。&lt;/p&gt;

&lt;p&gt;SO_BINDTODEVICE&lt;/p&gt;

&lt;p&gt;将套接字绑定到一个特定的设备上。&lt;/p&gt;

&lt;p&gt;SOL_RAW&lt;/p&gt;

&lt;p&gt;ICMP_FILTER&lt;/p&gt;

&lt;p&gt;设置套接字ICMP过滤选项。&lt;/p&gt;

&lt;p&gt;IPPROTO_IP&lt;/p&gt;

&lt;p&gt;IP_OPTIONS&lt;/p&gt;

&lt;p&gt;设置发出的数据报中的IP选项&lt;/p&gt;

&lt;p&gt;IP_MULTICAST_LOOP&lt;/p&gt;

&lt;p&gt;多播API，禁止组播数据回送&lt;/p&gt;

&lt;p&gt;Ö&lt;/p&gt;

&lt;p&gt;IP_MULTICAST_TTL&lt;/p&gt;

&lt;p&gt;多播API，设置输出组播数据的TTL值&lt;/p&gt;

&lt;p&gt;IP_TOS&lt;/p&gt;

&lt;p&gt;设置发出的数据报中的IP TOS&lt;/p&gt;

&lt;p&gt;SOL_IP&lt;/p&gt;

&lt;p&gt;IP_MTU_DISCOVER&lt;/p&gt;

&lt;p&gt;为套接字设置Path MTU Discovery setting(路径MTU发现设置)&lt;/p&gt;

&lt;p&gt;Ö&lt;/p&gt;

&lt;p&gt;IP_RECVERR&lt;/p&gt;

&lt;p&gt;允许传递扩展的可靠的错误信息&lt;/p&gt;

&lt;p&gt;Ö&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;程序首先取得了一个UDP的套接字probe_fd，并根据用户的输入配置套接字的选项。probe_fd用到的选项主要有：SO_BINDTODEVICE、SO_BINDTODEVICE、SO_BROADCAST、IP_TOS等。

ICMP报文的套接字icmp_sock用到的选项除了SO_BINDTODEVICE选项以外，列表中的所有选项都用到了。
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;2.9       ping.c程序的全局变量的分析
    static int ts_type;&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;    timestamp的类型

    在-T选项中设置，可以设置为IPOPT_TS_TSONLY、IPOPT_TS_TSANDADDR或者IPOPT_TS_PRESPEC。

static int nroute = 0;

     主机输入的总数，最多为9个，因为IP首部选项中最多能存储9个地址

static __u32 route[10];     

    在输入多个主机时，存储地址。

    可能输入多个主机的情况是：-Ttsprespec [host1 [host2 [host3 [host4]]]] 选项，或者ping hostName1 hostName2 ... hostNameN；前者是想获得确定几个路由对应的时间戳，而后者为什么这么设置，我还不大明白  。

struct sockaddr_in whereto;

    存储了目的主机的信息。

int optlen = 0;

    ip选项的长度。

    由IP的协议可知，最大为40，在需要在IP首部选项字段中存储数据时（例如-T、-R选项）就设置为最大值。

int settos = 0;

    服务质量的设置。

    可以用-Q选项用来设置服务质量，例如最小开销、 可靠性、吞吐量、低延迟。

    IP协议有一个8bit的DS区分服务（以前叫服务类型）。前三位是优先（precedence）字段（在目前，优先字段并未被大家使用），接着4bit是TOS位，最后1bit好像没有使用。

    4比特TOS位的意义分别为D（最小时延）、T（最大吞吐量）、R（最高可靠性）、C（最小代价）。

    要设置TOS位为对应意义，可以设置-Q &amp;lt;tos&amp;gt;中的 &amp;lt;tos&amp;gt;分别为0x10，0x08，0x04，0x02     。

int icmp_sock;

    ICMP的soket文件描述符。

u_char outpack[0x10000];

    用来存储ICMP报文首部和数据的数组，为ICMP报文分配的存储空间。

int maxpacket = sizeof(outpack);

    用来存储ICMP报文首部和数据的数组的最大大小。

static int broadcast_pings = 0;

    标识用户是不是想ping广播地址。

    可以通过-b选项设置。

    如果不设置，则默认为0。

struct sockaddr_in source;

    存储了源主机的信息。

    如果-I选项后面带的是源主机地址而不是设备名的话，就将主机的信息存储在source中。在socket试探的连接成功后，程序还用getsockname重新确定了source的值。

char *device;

    如果-I选项后面带的是设备名而不是源主机地址的话，如eth0，就用device指向该设备名。

    该device指向一个设备名之后，会设置socket的对应设备为该设备。

int pmtudisc = -1;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;2.10   ping_common.c程序的全局变量的分析
    int options;&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;    存储各种选项的FLAG设置情况。

    在判断输入选项时设置各个bit位。

int sndbuf;

    发送缓冲区大小。

    可以在-S &amp;lt;sndbuf&amp;gt;中设置，如果没有设置，则估计一个大小。

int ttl;

    报文ttl的值。

    可以在-t选项中设置。

    在设置soket选项时设置IP广播报文TTL和IP报文的TTL都为ttl值。

int rtt;

    用指数加权移动平均算法估计出来的RTT值。

    初始值是0。

    gather_statistics()函数中根据上次的RTT值和原来的rtt值加权得到新rtt的值。

    在update_interva()函数中用来计算新的interval的值。

int rtt_addend;

    配合rtt使用。

    用来计算新的interval的值，似乎是更具上个rtt的值给interval留部分余量。

__u16 acked;

    接到ACK的报文的16bit序列号。

    在gather_statistics()函数里更新，实际的更新方法似的acked不超过0x7FFF，不然就会发生回绕。

int mx_dup_ck = MAX_DUP_CHK;

    ？

long npackets;

    需要传输的最多报文数。

    可以在-c 选项里设置。

    如果没有设置则默认是0，故此每次在查询此值时就判断是否为0，0似乎作为无穷大来考虑。

long nreceived;

    得到回复的报文数。

    初始值是0。

    在gather_statistics函数中递加，进行统计。在程序执行finsh时，使用这个变量，打印出来作为参考。

long nrepeats;

    重复的报文数。

    初始值是0。

    在gather_statistics函数中递加，进行统计。在程序执行finsh时，使用这个变量，打印出来作为参考。

long ntransmitted;

    发送的报文的最大序列号。

    初始值是0。

   在pinger函数中递加，进行统计。在程序执行finsh时，使用这个变量，打印出来作为参考。

long nchecksum;

    checksum错误的恢复报文。

    初始值是0。

    在gather_statistics函数中，若csfailed为1的时候，则递加，进行统计。在程序执行finsh时，使用这个变量，打印出来作为参考。

    不过似乎checksum是不会被改变的，因为gather_statistics的选项csfailed在唯一的一次调用中（parse_reply()函数中）为0。

long nerrors;

    icmp错误数。

    初始值是0。

    在程序接受到出错的报文之后，就会调用receive_error_msg。在这个函数里如果判断确实是一个错误，错误有可能是本地出错，有可能是网络出错，不管是哪个出错，都将这nerrors递加。parse_reply也会改变这个变量。在程序执行finsh时，使用这个变量，打印出来作为参考。

int interval = 1000;           

    发送两个相邻报文之间相距的时间，单位为毫秒。

    可以在-i选项中设置。

    在设置-f的洪泛模式下，会设置interval为0。

    如果没有设置，则默认是1000。

int preload;

    在接受到第一个回复报文之前所发送的报文数。

    可以通过-l &amp;lt;preload&amp;gt;选项设置。

    如果没有设置，默认值是1。

int deadline = 0;

    在deadline秒之后，程序退出。

    可以由-w选项设置。如果设置了，则在setup函数中设置闹钟，当程序执行到deadline秒时产生SIGALRM中断，退出程序。
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;如果没有设置则默认值是0，程序运行没有时间限制。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;int lingertime = MAXWAIT*1000;

    等待回复的最长时间，单位为毫秒。

    可以通过-W选项设置。这个值在完成一次正确发收过程后就由2*tmax代替，而失去作用了。

    默认值是MAXWAIT*1000即10000，MAXWAIT定义在ping_common.h中。

struct timeval start_time;

    程序运行开始时的主机时间。

    在setup函数中使用gettimeofday初始化，在finish函数中和cur_time一起用来计算程序运行的时间。

struct timeval cur_time;

    程序运行时当前的主机时间。

volatile int exiting;

    程序是不是应该退出。

    初始值是0，就是不应该退出。

    在中断处理程序sigexit中会将这个值设为1。这个中断处理程序只在产生SIGALRM和SIGINT中断时(可以用Ctrl+c产生)才会执行。中断处理程序在setup函数中安装。

volatile int status_snapshot;

    程序是不是应该调用status()函数打印出程序的运行状态。

    初始值是0。

    在中断处理程序sigstatus中会将这个值设为1。这个中断处理程序只在产生SIGQUIT中断时(可以用Ctrl+\产生)才会执行。中断处理程序在setup函数中安装。

int confirm = 0;

    表明sendmsg函数的选项的MSG_CONFIRM选项是否设置。

    如果设置MSG_CONFIRM，则会告诉链路层的传送有了进展：已经接受到对方的一个成功的答复。由于MSG_CONFIRM的这个意义，所以在发送第一个数据是MSG_CONFIRM选项不因该设置，即confirm初始值为0。在成功接受到一个回复之后，confirm则应该设置为MSG_CONFIRM了。只有在确定取得一个回复时才将confirm由0改为MSG_CONFIRM，这就是为什么confirm只有在gather_statistics()才会被改变的原因。然而更麻烦的是MSG_CONFIRM选项只有在Linux 2.3及以上内核中才支持，所以就需要confirm_flag变量了。

int confirm_flag = MSG_CONFIRM;

    用来修补老版本linux内核的问题。

    confirm_flag的初始值为MSG_CONFIRM。这样在gather_statistics()里confirm就更新为confirm_flag了。但是，如果由于设置MSG_CONFIRM而产生了发送错误（linux版本较老，不支持MSG_CONFIRM选项）。这样就会在下个循环里调用gather_statistics()，更新confirm变量，保证不会发送出错了。

int working_recverr;

    ？

int timing;

    是否能够在ping过程中测算时间

    如果ICMP报文的数据长度足以存储timeval结构数据，则timing设置为1。如果timing设置为1，则在ICMP报文中插入发送的时间，这样在接受到ICMP回复时，就可以根据该数据计算RRT。否则就无法计算RRT，也就无法进行时间统计了。

    从根本上说timing的值由datalen变量的大小决定。

    可以尝试运行ping -s1 www.ustc.edu.cn -c 1，看看运行结果怎样。

    可以看到没有时间统计输出，因为-s选项设置的datalen值太小。

long tmin = LONG_MAX;             /*minimum round trip time */

    最小RRT

    初始值为LONG_MAX，每次接受到回复报文之后，就在gather_statistics函数中本次RRT是不是比tin大，如果是，就更新tmin。在程序执行完成之后，将打印出这个信息作为参考。

long tmax;                        

    最大RRT

    初始值为0，每次接受到回复报文之后，就在gather_statistics函数中本次RRT是不是比tmax大，如果是，就更新tmax。在程序执行完成之后，将打印出这个信息作为参考。

    此外tmax还作为每次发送报文后等待接受报文的时间长度的参考，见__schedule_exit函数。如果超出这个时间长度还没有完成一次发送和接受，则发生超时中断。

long long tsum;                 /*sum of all times, for doing average */

    每次RRT之和。

    初始值为0，每次接受到回复报文之后，就在gather_statistics函数中加上本次RRT。

    用来计算平均RRT。

long long tsum2;

    每次RRT的平方和。

    初始值为0，每次接受到回复报文之后，就在gather_statistics函数中加上本次RRT的平方。

    用来计算RRT的方差。

int  pipesize =-1;

    初始值为-1。

int datalen = DEFDATALEN;

    数据长度。

    初始值为DEFDATALEN，即56。

    可以通过-s选项设置     。

char *hostname;

    目的主机名字。

    在开始的时候，由用户作为程序的选项输入。随后通过gethostbyname()函数由主机名得到主机，然后将主机名改为函数返回的官方主机名。

    在最后输出的目的主机名就是这个名字。

int uid;

    用户ID。

    在main函数中通过getuid()取得。

    如果uid不是0，即用户不是超级用户，则在设置选项的时候有限制：

    -i&amp;lt;interval&amp;gt;，&amp;lt;interval&amp;gt;不得小于0.2；在ping广播地址时，&amp;lt;interval&amp;gt;不能设置为小于1的数。

    -M&amp;lt;hint&amp;gt;，在ping广播地址时，&amp;lt;hint&amp;gt;不能设置为IP_PMTUDISC_DO之外的IP_PMTUDISC_DONT或IP_PMTUDISC_WANT。

    -s&amp;lt;packetsize&amp;gt;， &amp;lt;packetsize&amp;gt;不能超过sizeof(outpack)-8。

    -v，不会输出比较敏感的冗长信息，例如parse_reply函数中可能输出的额外信息。

    -l&amp;lt;preload&amp;gt;，ping广播地址时，&amp;lt;preload&amp;gt;不能大于3。

    -f，必须要和-i选项配合使用，且&amp;lt;interval&amp;gt;不小于0.2。

int ident;

    本进程的ID。

    在setup函数中通过getpid()取得。

    在ICMP的数据中添加进程ID，并通过判断接受到的ICMP回复的进程ID是不是正确来判断ICMP回复是不是本进程的回复。

static int screen_width = INT_MAX;

   窗口的宽度大小，也就是控制台一行能打印多少字符。

   在setup函数中通过ioctl()取得。
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;2.11   重要函数的分析
    int main(int argc, char **argv);&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;    主函数。

    在这个函数里：取得用户输入的选项，并根据这些选项及其参数设置相应的标识和参数值。根据这些标识和参数值，首先连接（connect）一个探测的UDP报文，以探知目的地址的基本情况。然后设置ICMP报文的套接字选项，然后调用setup()函数来进一步设置与协议无关的套接字选项（与ping6公用）。在套接字设置好后，调用main_loop()函数完成探测。

    定义在ping.c文件中。

void main_loop(int icmp_sock, __u8 *packet, intpacklen);

    完成报文发送、分析的主要函数。

    在这个函数里：一直调用pinger()函数发ICMP报文和调用recvmsg()函数接受报文。如果recvmsg()函数没有正确接受报文，调用receive_error_msg()函数处理接受到的ICMP差错报文。如此反复，直到用户要求终止或者报文发送次数达到要求，或者超出的程序的时间限制，程序才停止发送/接受；程序在停止发送/接受后，调用finish()函数打印出统计数据。

    在main()函数中调用到此函数。

    定义在ping_common.c文件中。在这个文件中的所有函数都能够被ping和ping6共同使用。

void int pinger(void);

    构成并发送报文。

    在这个函数里：调用send_probe()尝试发送报文，并处理send_probe()没有成功发送时出现的错误。在处理某些种类的错误时，用到receive_error_msg()函数。

    在main_loop()函数中调用到此函数。

    定义在ping_common.c文件中。

int send_probe()

    构建报文，并发送报文。

    在这个函数里：根据用户的参数设置，设置ICMP报文的类型、代码、序号、标识符，并往ICMP报文的选项数据部分添加发送时间，然后计算校验和。构建出这个ICMP报文后，调用sendmsg()函数发送ICMP报文。此函数不处理发送出错。

    在pinger()函数中调用到此函数。

    定义在ping.c文件中。

int receive_error_msg()

    处理ICMP差错报文。

    在这个函数里：调用设置了MSG_ERRQUEUE标识的recvmsg()来接收错误队列中的ICMP错误报文。取得错误信息之后，分析出错的原因是由于本地原因还是网络原因，并进行处理（比如设置更严格的ICMP过滤）。

    在main_loop()函数和pinger()函数中调用到此函数。

    定义在ping.c文件中。

void setup(int icmp_sock)

    设置与协议无关的选项。

    在这个函数里：根据用户设置，这些设置包括interval的设置，socket的是否打开调试信息（SO_DEBUG）、是否打开路由查找功能（SO_DONTROUTE）、是否打开数据报中的时间戳接收（SO_TIMESTAMP）、发送时间限制（SO_SNDTIMEO）、接受时间限制（SO_RCVTIMEO）等选项，往报文内填内容的设置，中断处理程序的设置，闹钟的设置等。

    在main()函数和pinger()函数中调用到此函数。

    定义在ping_common.c文件中。
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;2.12   时间间隔和报文预发机制的实现
    程序使用一个分配时间片的概念，来控制发送报文的时间间隔，并实现在没有接到回复报文之前就预先发送preload个请求报文。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;初始时分配interval*preload的时间片用来发送报文（程序中第一次发送设置时间片为interval*(preload-1)，由于设置后没有减去第一次发送用去的interval时间片，所以相当于分配了interval*preload的时间片）。每次发送报文都要用掉interval毫秒的时间片。如果时间片不为负数的话，则一直持续发送报文。如果时间片为负数，则退出循环，开始处理接受到的回复报文。处理接受到的回复报文，会用去比较长的时间。

从上次发送报文，到当前准备发送报文的时间被计时器记录（实际上是通过记录上次发送报文的系统时间到当前系统时间之差来记录的），并作为新的时间片加入原时间片中，作为下次发送报文的时间片。为了确保没有接到回复而发送了的报文数目不会超过preload个，这个新的时间片如果超过interval*preload，则被改为interval*preload。如果新的时间片小于发送一个报文的时间interval，则仍然不发送报文，退出发送报文的循环，接受回复报文和处理可能出现的中断。

通过上述方法，实现了两个功能：

 1. 可以在不等待回复的情况下，预先发送preload个报文。由于初始时分配的时间片为interval*preload，所以刚开始，程序就连续发送interval个请求报文；如果程序等了很长时间没有发送报文，则计时器的引入使得这一段时间也作为发送时间片的新的一部分，这样程序又可以连续发送几个报文。

2. 可以控制报文发送的时间间隔为interval。从初始时开始，在连续发送preload个报文后，时间片被耗尽。只有在计时器中累加的时间片超过interval时才能再连续发送一个或几个报文（不超过preload个）。

相关函数：

int pinger(void);

void main_loop(int icmp_sock, __u8 *packet, int packlen);

相关选项：

-l &amp;lt;preload&amp;gt;

-i &amp;lt;interval&amp;gt;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;2.13   回复等待计时的实现
    当用户使用-c &lt;count&gt;设置了需要传送/接受的报文数，且通过-w &lt;deadline&gt;设置了程序运行的时间，那么则程序只需要在发送&lt;count&gt;个报文，并等待接受报文，直到接受到&lt;count&gt;个回复或者程序运行时间超过限制为止。如果用户只使用-c&lt;count&gt;设置了需要传送/接受的报文数，没有设置程序运行的时间，那么鉴于有些请求报文丢失而永远不会接到报文，程序不能在发送了&lt;count&gt;个报文之后一直等待。程序一直等待一个可能再也不会出现的事情是难以接受的，它应该做的是在发送&lt;count&gt;个请求报文后，等待一段时间，如果实在没有等到回复报文，就退出。&lt;/count&gt;&lt;/count&gt;&lt;/count&gt;&lt;/count&gt;&lt;/count&gt;&lt;/deadline&gt;&lt;/count&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;上面说的等待时间怎么确定呢？如果程序成功地收到了一个或者几个针对请求报文的回复，那么就将两倍的最大RTT作为等待的时间。如果程序没有接到任何的回复，RTT无从得知，就使用lingertime作为等待的最长时间。这个lingertime可以通过-W &amp;lt;timeout&amp;gt;选项由用户设置；如果用户没有设置则为一个常量（程序中，默认等待10秒）。不过值得主注意的是lingertime这个变量在程序成功地收到了回复之后，就没有任何作用了。

最长等待时间由一个闹钟实现。如上所述，设定这个闹钟的条件有下面几个：

1. 需要传送/接受的报文被设置了。

2. 程序运行的时间没有被设置。

3. 已经发送的报文数等于或大于需要传送/接受的报文数。

闹钟的时间被设置为：

1. 如果程序成功地收到了一个或者几个针对请求报文的回复，那么就将两倍的最大RTT作为等待的时间。

2. 否则，设置为lingertime。

当超出闹钟的时间之后，就会产生SIGALRM中断，使得程序退出。

相关函数：

void main_loop(int icmp_sock, __u8 *packet, int packlen);

staticinline int schedule_exit(int next);

schedule_exit(int next)

相关选项：

-c&amp;lt;count&amp;gt;

-w&amp;lt;deadline&amp;gt;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;3.1       引言
    在IP报文的首部和ICMP报文的首部都可以放入时间戳数据。clockdiff程序正是使用时间戳来测算目的主机和本地主机的系统时间差。&lt;/p&gt;

&lt;p&gt;3.2       clockdiff程序的使用
[plain] view plaincopy 
lixi@lixi-desktop:~$ ping -T tsandaddr www.ustc.edu.cn -c 1&lt;br /&gt;
PING www.ustc.edu.cn (202.38.64.9) 56(124) bytes of data.&lt;br /&gt;
64 bytes from 202.38.64.9: icmp_seq=1 ttl=62 time=0.823 ms&lt;br /&gt;
TS:     lixi-desktop.local (210.45.74.25)   12522473 absolute&lt;br /&gt;
    210.45.74.1 -251&lt;br /&gt;
    local-gw.ustc.edu.cn (202.38.64.126)    248&lt;br /&gt;
    202.38.64.9 -857514&lt;br /&gt;
Unrecorded hops: 3&lt;/p&gt;

&lt;p&gt;— www.ustc.edu.cn ping statistics —&lt;br /&gt;
1 packets transmitted, 1 received, 0% packet loss, time 0ms&lt;br /&gt;
rtt min/avg/max/mdev = 0.823/0.823/0.823/0.000 ms&lt;br /&gt;
    首先由上面的得出在RRT不大的时候，几个ICMP时间戳的关系。本地主机和202.38.64.9之间的时间差约为:-857514+248-251=-857517。&lt;/p&gt;

&lt;p&gt;分别用-o（IP选项中时间戳）和不带选项（ICMP路由时间戳）上述路由的系统时间进行测试。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;得到的结果：
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;[plain] view plaincopy 
lixi@lixi-desktop:~# ./clockdiff -o 202.38.64.9  &lt;br /&gt;
…………………………………………..&lt;br /&gt;
host=202.38.64.9 rtt=1(0)ms/1ms delta=-857517ms/-857517ms Wed Dec 17 11:28:30 2008&lt;/p&gt;

&lt;p&gt;[plain] view plaincopy 
lixi@lixi-desktop:~# ./clockdiff 202.38.64.9&lt;br /&gt;
.&lt;br /&gt;
host=202.38.64.9 rtt=750(187)ms/0ms delta=-857517ms/-857517ms Wed Dec 17 11:28:35 2008&lt;/p&gt;

&lt;p&gt;两种方法测试的都比较准确.&lt;/p&gt;

&lt;p&gt;[plain] view plaincopy 
lixi@lixi-desktop:~#./clockdiff gigagate1.Princeton.EDU&lt;br /&gt;
…………………………………………..&lt;br /&gt;
host=gigagate1.Princeton.EDU rtt=307(21)ms/271ms delta=-5ms/-5ms Wed Dec 17 11:50:16 2008&lt;br /&gt;
    上面是测试一个RTT较大的目的主机和本地主机的系统时间差。不过在使用clockdiff的时候，需要一点运气，因为很多路由会忽略ICMP或IP时间戳。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;对clockdiff选项的解释如下：

-o

    使用IP时间戳选项来测量系统时间差。时间戳只用3个。

-o1

    使用IP时间戳选项来测量系统时间差。用4个时间戳。如果-o和-o1都没有设置，那么就是用ICMP时间戳来测试系统时间差。
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;3.3       clockdiff程序的流程图&lt;/p&gt;

&lt;p&gt;3.4       clockdiff程序的主要函数的分析
    int main(int argc, char *argv[]);&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;    主函数。

    在这个函数里：取得用户输入的选项，并根据这些选项及其参数设置相应的标识和参数值。然后取得ICMP报文的套接字。如果设置-o或者-o1选项，设置IP报文的套接字时间戳选项，且调用measure_opt()函数来使用IP时间戳选项来测量本地主机和服务器主机的系统时间差。如果没有设置-o或者-o1选项，并调用measure()函数来使用ICMP时间戳报文来测量本地主机和服务器主机的系统时间差。测量完成后，打印出测试信息或者出错信息。

int measure_opt(struct sockaddr_in * addr);

    使用IP时间戳选项来测量本地主机和服务器主机的系统时间差。

    函数设置ICMP的报文，并发送出去。然后，程序接受ICMP报文，取得IP时间戳选项，并计算本地主机和服务器系统时间差。

int measure(struct sockaddr_in * addr);

    使用ICMP时间戳报文来测量本地主机和服务器主机的系统时间差。

    函数设置ICMP的报文，并发送出去。然后，程序接受ICMP报文，取得ICMP时间戳选项，并计算本地主机和服务器系统时间差。
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;6.5       clockdiff程序的全局变量的分析
    int interactive = 0;&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;    标识标准输入输出是不是和一个终端相连，如果是就输出比较详细的信息，否则只输出必要数据。

    例如clockdiff -o www.ustc.edu.cn &amp;gt;a.txt，就只会输出三个数据，因为标准输出被重定向到了文件的写入里，不与终端相连。

int id;

    当前进程的ID，放在ICMP时间戳请求和应答报文中的标识符中。

    在接受到ICMP回复报文时，用这个标识符来判断ICMP报文是不是本进程发出的ICMP报文的回复报文。

int sock;

    ？

int sock_raw;

    ICMP报文的套接字。

struct sockaddr_in server;

    服务器主机的地址。

    要对比本机和目的主机的系统时间，目的主机就相当于一个服务器。

int ip_opt_len = 0;

    ip_opt_len是ip选项中用来存储时间戳的长度

    可以通过-o和-o1选项来设置。

    如果选择-o选项，则ip_opt_len为4 + 4*8，也就是可以在IP选项中存储4个IP时间戳。时间戳的组织形式为：



    如果选择-o1选项，则ip_opt_len为4 + 3*8，也就是可以在IP选项中存储3个IP时间戳。时间戳的组织形式为：



#define BIASP        43199999

    程序通过计算时间戳中标明的时间来计算本地主机和服务器主机的系统时间差。在系统时间发生回绕的时候，会出现系统时间差的计算问题。这里BIASP就是为了解决这个问题。     

    在假设本地主机和服务器的系统时间差最多不超过12个小时（即43200000毫秒）的情况下：

    对于主机发送报文，如果本地主机在发送报文的时刻，本地主机系统时间已经超过0点。而该报文到达服务器主机的时刻，服务器主机系统时间仍然没有超过0点，则两个时间戳的差值（接受时间减去发送时间）会大于BIASP毫秒。

    同样，对于逆过程（主机接受服务器的报文），如果服务器主机在发送报文的时刻，服务器主机系统时间已经超过0点。而该报文到达本地主机的时刻，本地主机系统时间仍然没有超过0点，则两个时间戳的差值也会大于BIASP毫秒。

#define BIASN         -43200000

    与BIASP类似，BIASN也是为了解决系统时间回绕不一致的问题。

    在假设本地主机和服务器的系统时间差最多不超过12个小时（即43200000毫秒）的情况下：

    对于主机发送报文，如果本地主机在发送报文的时刻，本地主机系统时间没有超过0点。而该报文到达服务器主机的时刻，服务器主机系统时间已经超过0点，则两个时间戳的差值会小于BIASN毫秒。

    同样，对于逆过程（主机接受服务器的报文），如果服务器主机在发送报文的时刻，服务器主机系统时间没有超过0点。而该报文到达本地主机的时刻，本地主机系统时间已经超过0点，则两个时间戳的差值也会小于BIASN毫秒。

    为了解决系统时间回绕不一致的问题，当时间差不处在BIASN和BIASP之间的情况下，则将它们对应到这个去区间内。特别需要强调的是这里有基本假设：本地主机和服务器的系统时间差最多不超过12个小时（即43200000毫秒）。如果不满足这个假设，这种对应关系是错误的。

#define MODULO         86400000

    24个小时就是86400000毫秒，与在BIASN和BIASP一起处理系统时间回绕问题。

#define PROCESSING_TIME      0

    由于记录时间和报文发送的准确时间会有一定的偏差，所以这类处理过程消耗的时间可能会对最终计算出来的系统时间差会产生一个偏移量的影响。这里PROCESSING_TIME就是为了消除这个偏移量的影响的。这里忽略了这个偏移量。而且可以预见的是，想要分析和给出偏移量的影响大小并不容易，因为它与太多的变量有关系。

#define PACKET_IN       1024

    接受报文的存储字节数。

int measure_delta;

    计算的系统时间差。

    计算的系统时间差有两种假设，measure_delta1是另一种假设下的计算结果。

int measure_delta1;

    计算的系统时间差。

    计算的系统时间差有两种假设，measure_delta是另一种假设下的计算结果。

static u_short seqno;

    发送报文的序列号。

    每次发送报文都设置ICMP报文的序列号为seqno，seqno递加。

static u_short seqno0;

    发送报文的最小序列号。

    当接受到报文时要判断ICMP报文的序列号是不是介于seqno0和seqno之间，否则将不认为这个ICMP报文是本程序的恢复报文。

static u_short acked;

    接受到ICMP回复报文的最大序列号。

    当接受到报文时，如果ICMP报文的序列号大于现在的acked，则更新acked。

long rtt = 1000;

    对RTT的预测。

    预测方法是使用指数加权移动平均。

    和rtt_sigma一起用来设置超时时间，用的就是Jacobson/Karels算法。

long min_rtt;

    RTT的最小值。

long rtt_sigma = 0;

    对RTT预测的误差。

    和rtt一起用来设置超时时间，用的就是Jacobson/Karels算法。
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;3.6       clockdiff程序RTT预测的实现
    clockdiff程序使用Jacobson/Karels算法，使用以前的RTT实测值来预测下一次的RTT，并设定传输时间超时值。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;Jacobson/Karels算法在[[1]]文中有介绍。伪代码如下：

Difference = SampleRTT - EstimatedRTT

EstimatedRTT = EstimatedRTT + (δ × Difference)

Deviation = Deviation + δ × (|Difference| - Deviation)

TimeOut = μ × EstimatedRTT + φ × Deviation

其中：

SampleRTT是测量所得的新的RTT数据。

EstimatedRTT是预测的RTT值。

Deviation是预测的偏差值。

TimeOut是超时时间值。

δ为0到1之间的常数。

μ和φ均是一个常数。

在clockdiff程序的实现中：

δ设置为1/4。

μ和φ均设置为1。

相关函数：

int measure_opt(struct sockaddr_in * addr)void main_loop(inticmp_sock, __u8 *packet, int packlen);

int measure(struct sockaddr_in * addr);
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;6.7       clockdiff程序系统时间差测量的实现
    设两台主机的系统时间相差detaT，即源主机的系统时间为T的时刻，目的主机的系统时间为T+detaT。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;通过ICMP时间戳或者IP选项时间戳，可以获得如下信息：

delta1：接受时间戳减去发起时间戳。

delta2：接到回复报文时间减传送时间戳。

时间戳的插入过程如下图所示：

 


由上图可以知道：

delta1 = (T + dataT + RTT/2) – T = RTT/2+detaT

delta2 = (T + RTT) - (T + dataT + RTT/2) =RTT/2-detaT

故此(delta1 - delta2) / 2就是两个主机之间的系统时间差。

由于一次测量的delta1和delta2可能会由于网络拥塞情况的变化而发生较大偏差，故此在实际的实现中多次测量求较优值。引入了如下几个变量：

min1：多次传送中delta1的最小值。

min2：多次传送中delta2的最小值。

min_rtt：多次传送中delta1+delta2的最小值。

PROCESSING_TIME：处理过程中所消耗的时间。

在基于以下的几个基本假设情况下，可以测算系统时间的差值：

1. RTT中发送到目的主机的时间和返回源主机的时间基本相等都为RTT/2。

2. 当min1最小时，min1是对RTT/2+detaT的较优预测。同样，当min2最小时，min2是对RTT/2-detaT的较优预测。故此，(min1 - min2)/2是对deltaT的较优预测。这种预测方法的系统时间差预测值存储为变量measure_delta。

3. 当min_rtt最小时，(delta1 - delta2)/2也是对deltaT的较优预测。这种预测方法的系统时间差预测值存储为变量measure_delta1。

4. 各主机从接受到报文到记录接受到报文时间，这两个时刻的时间间隔为可以忽略；即发送和接受报文的处理过程中所消耗的时间可以忽略。实际上PROCESSING_TIME正是用来消除由处理过程的时间造成的对于计算出来的系统时间差别的影响。不过这里PROCESSING_TIME设置为0，认为处理消耗时间可以忽略。

以上的假设决定了clockdiff测算出来的系统时间差别的不准确性。

相关函数：

int measure_opt(struct sockaddr_in * addr)void main_loop(inticmp_sock, __u8 *packet, int packlen);

int measure(struct sockaddr_in * addr); .1       引言
tracepath和更为强大和更为广泛使用的程序traceroute一样，可以让我们看到IP数据报从一台主机传到另一台主机所经过的路由。

tracepath的作者是Alexey Kuznetsov。
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;4.2       tracepath程序的使用
lixi@lixi-desktop:~$ tracepath 210.45.74.25/8888
 1:  lixi-desktop.local (210.45.74.25)                      0.123ms pmtu 16436
 1:  lixi-desktop.local (210.45.74.25)                      0.054ms reached
 1:  lixi-desktop.local (210.45.74.25)                      0.045ms reached
     Resume: pmtu 16436 hops 1 back 64 
    210.45.74.25是本地主机的IP地址，8888是选择的测试端口。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;可以发现在本机进行了三次测试，为什么有三次测试，在下面的内容中有分析。
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;lixi@lixi-desktop:~$ tracepath 210.45.74.25/8888
 1:  lixi-desktop.local (210.45.74.25)                      0.122ms pmtu 16436
 1?: reply received 8)
 1:  lixi-desktop.local (210.45.74.25)                      0.048ms reached
     Resume: pmtu 16436 hops 1 back 64 
    编写简单的UDP服务程序，对8888端口的UDP请求进行服务（程序见&amp;lt;./test/udpserv.c&amp;gt;）。在运行这个服务程序之后，得到的测试结果如上。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;在第二轮时程序接受到了UDP的程序，所以输出了一个'?'表示疑问。
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;lixi@lixi-desktop:~$ tracepath 210.45.74.25/44444
 1:  lixi-desktop.local (210.45.74.25)                      0.131ms pmtu 16436
 1:  lixi-desktop.local (210.45.74.25)                      0.054ms reached
 1:  lixi-desktop.local (210.45.74.25)                      0.046ms reached
     Resume: pmtu 16436 hops 1 back 64 
     在运行对8888端口进行服务的UDP服务程序时，如果tracepath采用其他端口就不会产生上例中的情况了。&lt;/p&gt;

&lt;p&gt;lixi@lixi-desktop:~$ tracepath www.ustc.edu.cn
 1:  lixi-desktop.local (210.45.74.25)                      0.198ms pmtu 1500
 1:  210.45.74.1 (210.45.74.1)                              0.777ms 
 1:  210.45.74.1 (210.45.74.1)                              0.775ms 
 2:  202.38.96.33 (202.38.96.33)                            1.068ms 
 3:  202.38.64.9 (202.38.64.9)                              1.012ms reached
     Resume: pmtu 1500 hops 3 back 253
    对比此例和上例，可以发现PMTU发生了变化，由16436变成了1500。&lt;/p&gt;

&lt;p&gt;lixi@lixi-desktop:~$ tracepath www.ustc.edu.cn -l 1500
 1:  210.45.74.1 (210.45.74.1)                              0.828ms 
 2:  202.38.96.33 (202.38.96.33)                            0.988ms 
 3:  202.38.64.9 (202.38.64.9)                              1.140ms reached
     Resume: pmtu 1500 hops 3 back 253
    我们将MTU手动设置为1500，程序就不会默认将MTU设置为一个很大的数，然后找出PMTU了。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;tracepath程序的选项解释如下：

-n

    与ping命令的-n选项差不多。

    只有数字形式的输出，不查找DNS主机以节省时间，不查寻主机名，仅仅给出ip地址值。

    只要设置了F_NUMERIC，就不用调用gethostbyaddr来查询DNS主机名了。

    用gethostbyaddr的由查询目的主机的IP地址。

-l

    设置初始的包的大小。如果不设置则，则报文的大小为65535
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;4.3       tracepath程序的流程图
    tracepath程序的流程图如下：&lt;/p&gt;

&lt;p&gt;深入理解iputils网络工具第4篇 tracepath：路由追踪程序&lt;/p&gt;

&lt;p&gt;4.4       tracepath重要函数的分析
    int main(int argc, char argv);&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;    接受用户的选项，设置发送MTU或者设置是否不要验证主机名等标识。取得一个UDP类型的套接字，并设置好这个套接字的选项。，从1开始递增，直至31，设置套接字的IP_TTL选项为不同的值，调用probe_ttl()函数，直到probe_ttl()函数告知找到目的主机或者出现严重的错误为止。

int probe_ttl(int fd, int ttl);

    循环执行十次如下操作，直到正确发送报文跳出循环，或者recverr()返回0：

    调用sendto()函数尝试发送UDP报文到目的地址，如果发送出现错误则调用recverr()函数处理接受到的ICMP差错报文。如果正确发送报文，则跳出循环。

    如果循环过程中：recverr()函数返回0，则本函数返回0；如果recverr()函数返回大于0的数，则重新进行如上循环。

    如果循环超过十次，则表明因为某种原因，无法发送UDP报文，程序返回0。

    如果正确发送了UDP报文，则尝试使用recv()函数接受UDP报文的。正常情况下不会有UDP的，如果果真接受到了，则打印‘?’号表示吃惊，返回0。如果正如所预见到的，没有接到，则调用recverr()函数处理可能接受到的ICMP差错报文，返回recverr()返回的数值。

    总结本函数的返回值意义如下：

    返回0表示找到主机或者有严重的错误。

    返回负数-1，表示没有接受到ICMP差错报文。

    返回正数是当前MTU，表示接受并处理了一些错误，但是还没有找到目的主机。

int recverr(int fd, int ttl);

    函数将progress初始化为-1，然后不断循环执行如下操作，直到循环中函数返回：调用recvmsg()函数接受错误报文，并处理错误，如果没有错误返回progress。在错误队列中查找对应错误（SOL_IP级别IP_RECVERR类型），progress设置为MTU的值，并处理错误。如果错误队列的错误不是对应错误，返回0。

    并处理错误的几种情况如下：

    如果是MTU太大（EMSGSIZE），则修改MTU的变量值，继续循环。

    如果是UDP端口不可达错误（ECONNREFUSED），则UDP报文已经在规定TTL内传送到了目的主机。这种情况返回0。

    如果是EHOSTUNREACH错误且出错原因是接受到了ICMP差错报文，这个ICMP差错报文如果类型为11，代码为0，则表示因为在传输期间TTL等于0所以出错（参看ICMP报文类型）。这就说明UDP还没有到达目的主机TTL就变成了0，需要进一步递加TTL进行试探。

    如果是其他的错误，对于不严重的错误继续循环，否则返回0。

    总结本函数的返回值意义如下：

    返回0表示找到主机或者有严重的错误。

    返回的数如果大于0，其值是当前的MTU，表示接受并处理了一个或几个错误。

    返回负数-1，表示没有发现任何错误，也就是没有进展（progress）。
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;4.5       tracepath全局变量的分析
    struct hhistory his[64];&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;    用来存放历史上发出的UDP报文的ttl设置值和发送时间。

    当发送UDP报文时，将报文的端口号设置为base_port + hisptr，在his[hisptr]元素中，存储该UDP报文的ttl设置值和发送时间。

    当接受到一个UDP的报文（“端口不可达”错误ICMP报文）时，通过ICMP报文的端口号，就可以知道该UDP报文对应的ttl设置值和发送时间存储在his数组的哪个元素里了。

    his数组大小有限，只有64个元素。不过已经能够保证即使hisptr回绕也不会出错了。

int hisptr;

    用来指向his数组的元素。

    当发送UDP报文时，hisptr递加，将发出的UDP报文的ttl设置值和发送时间存储在his[hisptr]元素中。

    由于his数组大小为64，故此hisptr每次加到63，下一次就会回绕到0。

struct sockaddr_in target;

    要查询的目的主机的地址。

    包括地址种类（IPv4）、IP地址、端口号等信息。

    端口号会被设置为基础端口号加上hisptr。

__u16 base_port;

    基础端口号

    可以在设定目的主机时连带设定，否则程序默认是44444端口。

    基础端口号加上hisptr就是UDP报文的发送端口号。

    设置这么大的端口号，是为了使得目的主机的任何一个应用程序都不可能使用该端口，而产生一个“端口不可达”错误。

    这个值很大，目的就是让UDP出现“端口不可达”错误。

const int overhead = 28;

    在UDP数据部分之前的头部大小。

    IP首部为20，UDP首部为8，故此总共为28字节。

    这个数是个常量。

int mtu = 65535;

    可以通过-l选项设置，如果设置的值不大于传输路径的MTU。

    如果不设置默认值是65535，这个默认值肯定会超过传输路径的MTU，当超过了路径的MTU时，程序会受到错误消息，并根据这个错误消息所带的MTU值，更新MTU值。这样就tracepath能找出路径的MTU了。

int hops_to = -1;

    从本地主机到目的主机的跳数。

    如果目的主机不可达，则hops_to一直维持-1，最后就不会输出hops_to。

    当程序接受到目的主机发出的“拒绝服务”ICMP错误报文时，就说明探测到了目的主机。hops_to取为此时的recverr()函数局部变量sndhops的值。

    sndhops有两种方式取得，一种是取得发送时存储在his数组中的ttl值（前面已经谈到如何通过错误报文的IP端口得到存储地址），另一种是取得当前探测阶段发送的UDP报文的ttl的值。

    如果不出意外，第一种方式能比较可靠地取得；但是由于某种原因，前一种方式出问题后，就用后一种方式作为代替。

int hops_from = -1;

    从目的主机到本地主机的剩余TTL值。

    如果目的主机不可达，则hops_from一直维持-1，最后就不会输出。

    hops_from从目的主机发送给本地主机的IP报文头取得TTL字段值即可。

int no_resolve = 0;

    标识是否不要验证主机名。

    可以通过-n选项设置为1。

    如果设置为0，就调用gethostbyaddr的由查询目的主机的IP地址，否则就不用，以节省时间。 5.1       引言
ARP协议是“Address Resolution Protocol”（地址解析协议）的缩写。在同一以太网中，通过地址解析协议，源主机可以通过目的主机的IP地址获得目的主机的MAC地址。arping程序就是完成上述过程的程序。

ARP协议可以参看RFC 826。
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;5.2       arping程序的使用
    敲入命令：&lt;/p&gt;

&lt;p&gt;[plain] view plain copy
lixi@lixi-desktop:~/temp/iputils/iputils-s20071127$ arping 210.45.74.29 -c 1 -D&lt;br /&gt;
ARPING 210.45.74.29 from 0.0.0.0 eth0&lt;br /&gt;
Unicast reply from 210.45.74.29 [00:40:D0:59:CD:D3]  0.684ms&lt;br /&gt;
Sent 1 probes (1 broadcast(s))&lt;br /&gt;
Received 1 response(s)&lt;br /&gt;
    在本地主机的局域网内有一台IP地址为210.45.74.29的主机，所以会接到一个回复。&lt;/p&gt;

&lt;p&gt;[plain] view plain copy
lixi@lixi-desktop:~$ arping 210.45.74.28 -c 1 -D&lt;br /&gt;
ARPING 210.45.74.28 from 0.0.0.0 eth0&lt;br /&gt;
Sent 1 probes (1 broadcast(s))&lt;br /&gt;
Received 0 response(s)&lt;br /&gt;
    向一个不存在的IP发送报文不会接受到回复。&lt;/p&gt;

&lt;p&gt;[plain] view plain copy
root@lixi-desktop:~# arping 210.45.74.25 –U&lt;br /&gt;
root@lixi-desktop:~# tcpdump arp -n | grep 210.45.74.25&lt;br /&gt;
    得到输出结果如下：&lt;/p&gt;

&lt;p&gt;[plain] view plain copy
11:03:13.848653 arp who-has 210.45.74.25 (ff:ff:ff:ff:ff:ff) tell 210.45.74.25&lt;br /&gt;
    这里就是一个免费ARP的例子。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;-A

    与-U选项类似，但是发送的是ARP 回复报文，而不是ARP请求报文。

-b

    只发送MAC级别的广播。一般的arping开始时发送广播，在接受到回复后开始发送单播。

-c &amp;lt;count&amp;gt;

    在发送count个ARP请求后就退出。在和deadline选项一起使用时，arping程序一直等到收到count个ARP回复报文或者时间消耗完毕时才退出。
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;-D&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;    重复地址检测模式（DAD，Duplicate  address detection  mode）。参见RFC2131，4.4.1。如果DAD成功，则返回0，即不会接受到没有任何回复。

-f

    在接受到第一个确定目标主机存在的回复之后，就结束程序，否则一直发送ARP请求。

-I &amp;lt;interface&amp;gt;

    设置网络设备的名字，这个名字就是发送ARP请求报文的设备名字。

-h   

    打印帮助信息，然后退出。

-q

    静默输出，不打印探测结果。

-s &amp;lt;source&amp;gt;

    在ARP报文中使用的IP源地址。如果这个选项没有设置，则源地址设置方法为：

    1. DAD模式下（-D选项），设置为0.0.0.0。

    2. 在主动ARP模式（-U或者-A选项），设置为目的地址。

    3. 其他情况下，通过路由表得到。

-U

    为了更新以太网邻居的ARP快速缓存而主动进行的ARP。也就是免费ARP（gratuitous ARP）。

-V

    打印出版本信息，然后退出。

-w deadline

    设定时间期限为&amp;lt;deadline&amp;gt;秒，不管已经发送和接到了多少包，只要达到时间期限就结束ping的过程。在这种情况下，这样arping程序只有在接受到cout个回复或者deadline的时间消耗完后才退出；而不是像只有-c选项的情况，在发送count个ARP请求的就退出。
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;5.3       arping程序的流程图
    arping程序的流程图如下所示：&lt;/p&gt;

&lt;p&gt;5.4       ARP报文的分组格式
    ARP报文的分组格式如下图所示：&lt;/p&gt;

&lt;p&gt;5.5       arping程序的全局变量的分析
    int quit_on_reply=0;&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;    标识是否在接受到一个回复之后，就马上退出程序。

    可以在-f选项和-D选项中设定为非0值（同时有-f、-D选项或者有多个同种选项）。     

char *device=&quot;eth0&quot;;

    源主机的网络设备号。 

    可以通过-I参数设置。

    默认为eth0。

(setsockopt(probe_fd, SOL_SOCKET,SO_BINDTODEVICE, device, strlen(device)+1)。

    不过好像只有超级用户这个才能执行。

int ifindex;

    Interface number。

char *source;

    存储-s设置的源地址。

    地址的形式可以是IPv4的标准数字和点组成的形式，如210.45.74.25；也可以是主机名字的形式，如www.ustc.edu.cn。

struct in_addr src；

    存储源IP地址，即对ARP的回复报文所要发往的主机的IP地址，有可能是广播地址。

    可以通过-s选项设置。如果这个选项没有设置，则源地址设置方法为：

    1. DAD模式下（-D选项），设置为0.0.0.0。

    2. 在主动ARP模式（-U或者-A选项），设置为目的地址。

    3. 其他情况下，通过路由表得到。

struct in_addr dst;

    存储目的IP地址，即ARP报文所要发往的主机的IP地址。

char *target;

    存储用户设置的目的地址，地址的形式必须是IPv4的标准数字和点组成的形式。

int dad;

    标识是不是DAD模式。

    如果是DAD模式，则原源主机地址一直没有设置，那么就意味着源地址为0.0.0.0。这样当目的主机接到之后，就会向0.0.0.0发送回复，就相当于广播给以太网中所有的主机。因为进行D重复地址检测模式的原因很可能是由于源主机的IP地址没有设置，从而想设置自身的IP地址。在IP地址没有设置的时候，主机只能接受到地址为0.0.0.0的广播信号。

    可以通过-D参数设置。

int unsolicited;

    标识是不是发送免费ARP。

    在-A选项和-U选项中设置unsolicited为1。

int advert;

    标识在免费ARP模式下发送的是ARP回复报文，而不是ARP请求报文。

    在-A选项中设置advert为1。

int quiet;

    标识是否静默输出。

    可以通过-q选项设置。

int count=-1;

    发送ARP的个数。

    可以通过-c选项设置，如果不设置，默认值为-1，即没有个数限制（回绕成0基本不可能）。

int timeout;

    程序运行的时间限制。

    通过-w选项设置。

int unicasting;

    标识是不是应该发送单播报文。

    在程序接受到一个ARP的回复之后，已经能够知道回复者的IP地址了，这时候就可以不广播，而设置传播地址。因此，在接受到ARP回复之后，如果broadcast_only没有被设置，unicasting就应该设置为1，以让下次进行单播。

int s;

    ARP报文的套接字。

int broadcast_only;

    标识是不是一直发送广播报文，而不在接受到一个回复以后就改成单播报文。

    通过-b选项可以设置broadcast_only为1。 

struct sockaddr_ll me;

    存储本地主机的信息，包括本地主机的以太网地址、硬件地址的类型、硬件地址长度和协议地址长度等信息

struct sockaddr_ll he;

    存储本地主机的信息。

struct timeval start;

    程序发送第一个报文的系统时间。

    记录这个时间，可以用来判断程序是否超出时间限制。如果当前的系统时间减去start超过用户设置的时间限制有500毫秒，则程序退出。

struct timeval last;

    程序发送上一个报文的系统时间。

    记录这个时间，可以用来判断是否应当发出下一个ARP请求。如果当前系统时间减去last超过500毫秒，则发出下一个ARP请求。

int sent;

    程序发送的ARP报文数量。

    每次在发送ARP报文之后递加。

int brd_sent;

    程序广播的ARP报文数量。

    每次在发送ARP报文之后，如果ARP报文是广播报文，则递加。

int received;

    程序接受的ARP报文数量。

    每次在接受到正确的ARP报文之后，递加。

int brd_recv;

    程序接受的ARP广播报文数量。

    每次在接受到正确的ARP报文之后，如果报文不是单播报文则递加。

int req_recv;

    程序接受到ARP请求报文数量。

    每次在接受到正确的ARP报文之后，如果报文是ARP请求报文则递加。 7.1       引言
TFTP ( Trivial File Transfer Protocol)即简单文件传送协议，是TCP/IP协议族中的一个用来在客户机与服务器之间进行简单文件传输的协议，提供简单的、低开销的文件传输服务。tftpd程序就是进行tftp服务的服务程序。
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;TFTP协议可以参看RFC 1350。&lt;/p&gt;

&lt;p&gt;7.2       tftpd程序的使用
    由于这个程序需要inetd程序的配合，而环境比较难搭建，所以对程序的测试比较困难。&lt;/p&gt;

&lt;p&gt;7.3       tftpd程序的流程图&lt;/p&gt;

&lt;p&gt;7.4       TFTP报文格式
    TFTP报文格式如下所示：&lt;/p&gt;

&lt;p&gt;7.5       tftpd.c程序的全局变量的分析
    int   peer;&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;    服务连接的套接字。

int   rexmtval =TIMEOUT;

    程序采用停止和等待的自动请求重发（ARQ）算法，当接受ACK报文或者数据报文的时间超过rexmtval，则认为接受超时，重新开始接受报文过程。

    rexmtval一直维持TIMEOUT的值，没有被改变过。

int   maxtimeout =5*TIMEOUT;

    当接受数据报文或者ACK报文的时候，如果出现超时，则会进入中断处理程序。如果中断次数过多，则timeout会累加rexmtval时间。一旦超时中断过多，导致timeout超过maxtimeout，则程序退出，停止服务。

    maxtimeout一直维持5*TIMEOUT的值，没有被改变过。

#define  PKTSIZE     SEGSIZE+4

    如果TFTP报文的操作码是data，表明传输的是0到512字节的数据。

    SEGSIZE是TFTP报文的数据的最大长度，即512字节。

    由于TFTP报文还包括2字节的操作码和2字节的块编号，所以TFTP数据报文的长度为SEGSIZE+4。

char       buf[PKTSIZE];

    缓冲空间，在以下的情况下，作为存储TFTP报文的内存空间：

    1. 清楚初始时接收的报文。

    2. 发送操作码为error类型的TFTP报文。

    3. 在文件传输完毕时（上一次接受到的数据不足512字节），尝试接受操作码为data数据类型的TFTP报文，因为服务器传给用户主机的最后一个ACK有可能丢失。

char       ackbuf[PKTSIZE];

    缓冲空间，在以下的情况下，作为存储TFTP报文的内存空间：

    1. 接受操作码为ACK类型的TFTP报文。

    2. 发送操作码为ACK类型的TFTP报文。

union {

    struct     sockaddr    sa;

    struct     sockaddr_in sin;

    struct     sockaddr_in6 sin6;

} from;

    描述客户连接的地址。

socklen_t      fromlen;

    from所占的内存空间大小。

#define MAXARG    1

    在启动tftpd程序的时候，需要指定ftp文件夹的路径。MAXARG是所能指定文件夹的个数。

char       *dirs[MAXARG+1];

    dirs[0]里保存了ftp文件夹的路径。

int   confirmed;

    表明sendmsg函数的选项的MSG_CONFIRM选项是否设置。

    如果设置MSG_CONFIRM，则会告诉链路层的传送有了进展：已经接受到对方的一个成功的答复。由于MSG_CONFIRM的这个意义，所以在发送第一个数据是MSG_CONFIRM选项不因该设置，即confirm初始值为0。在成功接受到一个回复之后，confirm则应该设置为MSG_CONFIRM了。

int   timeout;

    表示由于等待接受超时的时间总和。

    当接受数据报文或者ACK报文的时候，如果出现超时，则会进入中断处理程序，将timeout递加rexmtval秒，如果。一旦超时中断过多，导致timeout超过maxtimeout，则程序退出，停止服务。

jmp_buf timeoutbuf;

    在发生等待接收超时时，应当将要发送的报文重新发送（报文可能为ACK报文或者data报文）。setjmp()和longjmp()函数就可以用来实现这种跳转的功能。

    由于等待超时时会进入计时器中断处理程序，在中断处理程序中调用longjmp()函数来跳转到最后一次用setjmp()设置timeoutbuf的地方运行，也就是重新进行报文的发送。

    timeoutbuf就记录了调用setjmp()的时候的程序上下文。
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;7.6       tftpsub.c程序的全局变量的分析
    struct bf {&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;    int counter;

    charbuf[PKTSIZE];

} bfs[2];

    缓冲空间，在以下的情况下，作为存储TFTP报文的内存空间：

    1. 接受操作码为data类型的TFTP报文。

    2. 发送操作码为data类型的TFTP报文。

    counter用来标识存储的缓冲空间的数据是一下三种的哪一种：

    1. BF_ALLOC，标识是已经申请的存储空间。

    2. BF_FREE，标识存储空间没有使用。

    3. 大于0的数，标识里面已经存储数据。

static int nextone;

    待使用的下一个缓冲的标号。

static int current;

    正在使用的当前缓冲的标号。

int newline = 0;

    在数据传输是按照8位的ASCII码形式（netascii）组织的情况下，标识是不是有新的行出现。

    在顺次读取或者写入字节流时，如果遇到'\n'或者'\r'字符都会设置newline为1，方便进行特殊处理。

int prevchar = -1;     /* putbuf: previous char (cr check) */

    在数据传输是按照8位的ASCII码形式（netascii）组织的情况下，记录上个处理的字符。

    和newline一样，prevchar是为了处理'\r'或者'\n'的特殊字符。

    处理的效果是：

    1. 如果要发送'\r'字符则传送的实际是\r\0&quot;；如果要发送'\n'字符则传送的实际是&quot;\r\n&quot;。

    2. 如果接受到&quot;\r\n&quot;，则保存的实际是字符'\n'；如果接受到&quot;\r\0&quot;，则保存的实际是字符'\r'。
&lt;/code&gt;&lt;/pre&gt;
</description>
        <pubDate>Mon, 05 Feb 2018 00:00:00 +0800</pubDate>
        <link>https://xiazemin.github.io/MyBlog/linux/2018/02/05/iputils.html</link>
        <guid isPermaLink="true">https://xiazemin.github.io/MyBlog/linux/2018/02/05/iputils.html</guid>
        
        
        <category>linux</category>
        
      </item>
    
  </channel>
</rss>
